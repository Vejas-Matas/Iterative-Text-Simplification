{
  "iterative": [
    {
      "SARI": 42.420360401214964,
      "BLEU": 0.31612944619901057,
      "FKGL": 20.890285714285714
    },
    [
      {
        "source": "Abstract   Novel technological advances in mobile devices and applications can be exploited in wildfire confrontation, enabling end-users to easily conduct several everyday tasks, such as access to data and information, sharing of intelligence and coordination of personnel and vehicles. This work describes an innovative mobile application for wildfire information management that operates on Windows Phone devices and acts as a complementary tool to the web-based version of the AEGIS platform for wildfire prevention and management. Several tasks can be accomplished from the AEGIS App, such as routing, spatial search for closest facilities and firefighting support infrastructures, access to weather data and visualization of fire management data (water sources, gas refill stations, evacuation sites etc.). An innovative feature of AEGIS App is the support of these tasks by a digital assistant for artificial intelligence named Cortana (developed by Microsoft for Windows Phone devices), that allows information utilization through voice commands. The application is to be used by firefighting personnel in Greece and is potentially expected to contribute towards a more sophisticated transferring of information and knowledge between wildfire confrontation operation centers and firefighting units in the field.",
        "prediction": "Abstract  \nNovel technological advances in mobile devices and applications can be exploited in wildfire confrontation, enabling end-users to easily conduct several everyday tasks, such as accessing data and information, sharing intelligence, and coordinating personnel and vehicles. This work describes an innovative mobile application for wildfire information management that operates on Windows Phone devices and acts as a complementary tool to the web-based version of the AEGIS platform for wildfire prevention and management. Users can accomplish several tasks with the AEGIS App, including routing, searching for the closest facilities and firefighting support infrastructures, accessing weather data, and visualizing fire management data such as water sources, gas refill stations, and evacuation sites. A new feature of the AEGIS App is that it uses an artificial intelligence assistant called Cortana, made by Microsoft for Windows Phone devices. Cortana helps users by allowing them to use voice commands to get information. The application is designed for firefighting personnel in Greece and is expected to enhance the sharing of information and knowledge between wildfire operation centers and firefighting units in the field.",
        "reference": "Novel mobile devices and applications can be used in wildfire confrontation by helping users to access data and information and coordinate personnel and vehicles. This paper describes a new Windows Phone application for wildfire information management which is complementary to the web version of the AEGIS platform for wildfire prevention and management. The AEGIS App can be used for searching for the closest firefighting infrastructures, as well as access to weather data, and visualization of water sources, gas refill stations, evacuation sites, etc. The AEGIS App supports these tasks through voice commands with Microsoft Cortana (AI digital assistant for Windows Phone).Â  The application is designed for firefighters in Greece but it can help communication between wildfire coordination and local firefighting units."
      },
      {
        "source": "In recent years, mobile technologies have developed and applied in education fields, and some mobile emerging carriers with mobile technologies include a personal digital assistant (PDA), smart phone, and e-book. Some of the mobile carriers combines context-aware technologies or involve into wireless network environments to make effective use through the combination of learning scenarios and technologies, and then provide students new learning experiences differed from the past learning. In view of the application of mobile technology in education, some previous studies have addressed that mobile learning is a meaningful learning that can improve the interaction between students and the situations and reach the purposes of learning. In the main stream of mobile learning, using mobile carriers with suitable learning methods or strategies in mobile learning activities for different students to enhance learning have gradually become a important and concern issue. The purpose of this study is to investigate the learning achievement and learning attitude of elementary school students on a campus plant learning activity when they use mobile carriers and competitive learning strategies. The experimental results show that the competitive learning group of students have better learning performance than non-competitive learning group of students. After completing the learning activity, the two groups of students presented high positive attitudes towards learning.",
        "prediction": "In recent years, mobile technologies have developed and been applied in educational fields, with emerging mobile devices such as personal digital assistants (PDAs), smartphones, and e-books. Some mobile devices use context-aware technologies and connect to wireless networks to effectively combine learning scenarios with technology, providing students with new learning experiences that are different from traditional methods. Previous studies have shown that mobile learning can enhance interaction between students and their learning environments, helping them achieve their educational goals. In the mainstream of mobile learning, using mobile devices with appropriate learning methods or strategies for different students has become an important area of focus. This study aims to investigate the learning achievement and attitudes of elementary school students during a campus plant learning activity using mobile devices and competitive learning strategies. The experimental results indicate that the competitive learning group performed better than the non-competitive learning group. After completing the activity, both groups of students expressed high positive attitudes towards their learning.",
        "reference": "Mobile technologies, such as personal digital assistants (PDA), smartphones, and e-books, are increasingly used in the educational field. Some mobile carriers combine learning scenarios and context-aware technologies or wireless network environments providing students with new learning experiences. Mobile learning is effective as it can improve the interaction between students and situations. An important question in the mobile learning field is how to enhance learning through the use of mobile carriers with suitable learning methods in student activities. This study investigates learning achievement and attitude of elementary school students when they use mobile carriers and competitive learning strategies during campus plant learning activities. The competitive learning group of students has better learning performance than the non-competitive one. After the activity, both groups of students were positive about learning."
      },
      {
        "source": "This paper proposes an electrophysiological wireless patient monitoring system which integrates a Wireless ECG signal transmitter, GPS device and a mobile phone to acquire physiological signals and transmit them to a local server via Bluetooth wireless technology. Four kinds of monitor units were specially designed for a wireless communication, including a control center , a local monitor unit, mobile devices (personal digital assistant; PDA), and a Web page (for both patient and doctor). The use of various monitor units is created to fulfill different medical personnel requirements and wishes. This application was developed to promote the mobility and flexibility for the patients and also for the medical personnel, which further will improve both the quality of health care and lifestyle of the patient.",
        "prediction": "This paper proposes a wireless system for monitoring patients that uses an ECG signal transmitter, GPS device, and mobile phone to collect health data and send it to a local server using Bluetooth technology Four types of monitor units were specially designed for wireless communication including a control center a local monitor unit mobile devices personal digital assistant PDA and a web page for both patients and doctors These various monitor units are created to meet different medical personnel requirements and preferences This application was developed to enhance mobility and flexibility for both patients and medical personnel ultimately improving the quality of healthcare and the lifestyle of patients",
        "reference": "This paper suggests a system to monitor patients wirelessly using a device that transmits ECG signals, a GPS device, and a mobile phone. The signals are sent to a local server via Bluetooth technology. Four types of monitor units were created for wireless communication: a control center, a local monitor unit, mobile devices such as personal digital assistants (PDA), and a web page accessible to both patients and doctors. Various monitor units are used to satisfy different medical personnel needs. This application was developed to boost the quality of healthcare and patient lifestyle by increasing mobility and flexibility for both patients and medical personnel."
      },
      {
        "source": "As various kinds of output devices emerged, such as highresolution printers or a display of PDA(Personal Digital Assistant), the importance of high-quality resolution conversion has been increasing. This paper proposes a new method for enlarging image with high quality. One of the largest problems on image enlargement is the exaggeration of the jaggy edges. To remedy this problem, we propose a new interpolation method, which uses artificial neural network to determine the optimal values of interpolated pixels. The experimental results are shown and evaluated. The effectiveness of our methods is discussed by comparing with the conventional methods.",
        "prediction": "As various kinds of output devices emerged such as high-resolution printers or displays from Personal Digital Assistants PDAs the importance of high-quality resolution conversion has increased This paper proposes a new method for enlarging images with high quality One of the biggest challenges in image enlargement is the exaggeration of jagged edges We suggest a new interpolation method that uses artificial neural networks to find the best values for the new pixels The experimental results are shown and evaluated and the effectiveness of our methods is discussed by comparing them with conventional methods",
        "reference": "The rise of output devices like high-resolution printers and PDA displays has increased the need for high-quality resolution conversion. The paper proposes a new method to make images bigger while maintaining high quality. The main issue with enlarging images is that jagged edges can become exaggerated. To solve this problem, we suggest a new method that helps us to estimate the value of the newly generated pixels using a neural network. The experiment's results are presented and analyzed. We evaluate the effectiveness of our methods by comparing them to traditional approaches."
      },
      {
        "source": "A significative percentage of the human population suffer from impairments in their capacity to distinguish or even see colours. For them, everyday tasks like navigating through a train or metro network map becomes demanding. We present a novel technique for extracting colour information from everyday natural stimuli and presenting it to visually impaired users as pleasant, non-invasive sound. This technique was implemented inside a Personal Digital Assistant (PDA) portable device. In this implementation, colour information is extracted from the input image and categorised according to how human observers segment the colour space. This information is subsequently converted into sound and sent to the user via speakers or headphones. In the original implementation, it is possible for the user to send its feedback to reconfigure the system, however several features such as these were not implemented because the current technology is limited.We are confident that the full implementation will be possible in the near future as PDA technology improves.",
        "prediction": "A significative percentage of the human population suffer from impairments in their capacity to distinguish or even see colours. For them, everyday tasks like navigating through a train or metro network map become demanding. We present a novel technique for extracting colour information from everyday natural stimuli and presenting it to visually impaired users as pleasant, non-invasive sound. This technique was used in a portable device called a Personal Digital Assistant PDA. In this device, colour information is taken from images and sorted based on how people see and divide colours. This information is then converted into sound and sent to the user via speakers or headphones. In the original implementation, users can send feedback to reconfigure the system; however, several features were not implemented because current technology is limited. We are confident that a complete implementation will be possible in the near future as PDA technology improves.",
        "reference": "A significant percentage of people have trouble differentiating or seeing colors. Simple tasks like using a train or subway map can be difficult for them. We introduce a new method to help visually impaired users perceive color information using non-invasive, pleasant sounds generated from everyday stimuli. We put this technique into a portable device called a Personal Digital Assistant (PDA). In this implementation, we extract color information from the input image and organize it based on how people perceive color. Then, the information is changed into sound and sent to the user through speakers or headphones. In the first version, the user could give feedback to change the system, but we couldn't add all the features due to technology limitations. We believe that we can add all the features soon as PDA technology advances."
      },
      {
        "source": "Inappropriate use of medicines increases the risk of hospital admissions for the elderly. Not only does this lead to unnecessary suffering for the patients but also incurs a great financial cost to the society. A medicine decision support system in a Personal Digital Assistant (PDA), with a barcode reader, can provide an overview of the patientsu0027 complete medicine use, and detect unsuitable drugs and drug combinations. Focusing on the elderly, our aim was to evaluate if a mobile medicine decision support system with a barcode reader is useful and user-friendly for nurses in home care. The participants received a comprehensive overview from the patientsu0027 medicine use and noted drug-drug interactions, therapeutic duplications and warnings for drugs unsuitable for elderly people. The nurses regarded that the decision support system increased prevention and safety, was useful and user-friendly. Our findings suggest that most of the content and functions were regarded as important. Therefore, this decision support system might be a useful tool for district nurses.",
        "prediction": "Inappropriate use of medicines increases the risk of hospital admissions for the elderly. Not only does this lead to unnecessary suffering for patients, but it also incurs significant financial costs to society. A medicine decision support system on a Personal Digital Assistant (PDA) with a barcode reader can show a summary of all the medicines patients are using and identify unsafe drugs and drug combinations.\n\nFocusing on the elderly, our aim was to evaluate whether this mobile medicine decision support system, equipped with a barcode reader, is useful and user-friendly for nurses in home care. The participants received a comprehensive overview of the patients' medicine use, noting drug-drug interactions, therapeutic duplications, and warnings for drugs unsuitable for elderly people. The nurses felt that the decision support system increased prevention and safety and was both useful and easy to use.\n\nOur findings indicate that most of the content and functions were deemed important. Therefore, this decision support system could be a valuable tool for district nurses.",
        "reference": "Misusing medicines can make older people more likely to end up in the hospital. This causes patient suffering and financial cost to society. A support system for medicine decision, with a bar code reader, in a PDA can help identify inappropriate medication use and combinations by providing a complete overview of the patient's medication The goal was to evaluate if a mobile medicine decision support system with a barcode reader is helpful and easy to use for home care nurses working specially with older patients. The participants were provided with a complete overview of the patient's medication usage, and identified any drug interactions, duplicated medications, and any warnings about drugs that are not suitable for elderly patients. The nurses found the decision support system to be helpful, and easy to use, and improving the prevention and safety measures. Our results indicate that the majority of the content and features were considered significant. So, this system could be helpful for district nurses."
      },
      {
        "source": " :[0],\"access to patient appointment schedules can help clinicians manage time and problems better. Many large health care organizations manage clinical appointment scheduling via enterprise resource scheduling systems which are poorly accessible by clinicians. Also, staff other than the clinicianu0027s personal assistant(s) may manage scheduling, making it difficult for clinicians to stay informed of changes. Many a clinician today uses a personal digital assistant (PDA) containing basic calendaring functionality. Our âPalmOversiteâ project demonstrates the feasibility of integrating enterprise appointment schedule information into a PDA calendar, making schedule information much more readily available to the clinician.",
        "prediction": "Access to patient appointment schedules can help clinicians manage their time and problems better. Many large healthcare organizations use scheduling systems for appointments that are hard for clinicians to access. Additionally, staff other than the clinicianâs personal assistant(s) may handle scheduling, making it difficult for clinicians to stay informed of changes. Many clinicians today use a personal digital assistant (PDA) with basic calendar features. Our âPalmOversiteâ project demonstrates how we can integrate information from these scheduling systems into a PDA calendar, making schedule information much more available to clinicians.",
        "reference": "Knowing patients' appointment schedules can help clinicians manage time and problems more effectively. Healthcare organizations often use enterprise resource scheduling systems for clinical appointment scheduling, but these systems may not be easily accessible by clinicians. Moreover, scheduling may not only be handled by the clinician's assistant(s), creating challenges for clinicians to stay updated on any changes. Many clinicians today use a personal digital assistant (PDA) with a basic calendar. Our project called 'PalmOversite' shows the practicability of integrating enterprise appointment schedule information into a PDA calendar. This makes it easier for clinicians to access their schedule information."
      },
      {
        "source": "Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of multidrug-resistant tuberculosis (MDR-TB) patients in Peru, in conjunction with the Peruvian National TB Program (NTP). Monthly bacteriology tests, which must be collected from health establishments located across this major city, are an integral part of this treatment. Currently, a SES employee visits each health establishment to collect this information by hand, process it and type it into an electronic medical record system  this :[81],\"paper, we describe the development and implementation of a personal digital assistant (PDA)-based electronic system to collect, verify and upload monthly bacteriology data into the PIH-EMR. After an initial implementation period, we performed a pilot study to test the use of this system. We completed a baseline assessment in two health districts and then implemented the electronic system in one of the districts while the control site continued to use the paper-based system during the same period. The PDA-based system had a processing time of 6.2 days, significantly lower than measurements for both the baseline [54.8] and control sites [64.4] (both pu003c0.0001). It was also able to reduce the frequency of discrepancy from 10.1% to 2.8% (pu003c0.0001) and receive positive feedback from the users. Finally, the systemâs cost would be recuperated in three months from time savings due to increased work efficiency. This system will be the subject of a larger study to determine its impact on delays, errors and costs.",
        "prediction": "Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of multidrug-resistant tuberculosis (MDR-TB) patients in Peru, in conjunction with the Peruvian National TB Program (NTP). Monthly bacteriology tests, which are an integral part of this treatment, must be collected from health establishments located across this major city. Currently, a SES employee visits each health establishment to collect this information by hand, processes it, and types it into an electronic medical record system. \n\nTo improve this process, we explain how we created and used a system based on personal digital assistants (PDAs) to gather, check, and upload monthly bacteria test data into the PIH electronic medical record. After an initial implementation period, we performed a pilot study to test the use of this system. We completed a baseline assessment in two health districts and then implemented the electronic system in one district, while the control site continued to rely on the paper-based system during the same period. \n\nThe PDA-based system had a processing time of 6.2 days, which is significantly lower than the measurements for both the baseline [54.8] and control sites [64.4] (both pu003c0.0001). Additionally, it was able to reduce the frequency of discrepancies from 10.1% to 2.8% (pu003c0.0001) and received positive feedback from the users. Finally, the systemâs cost would be recuperated in three months from time savings due to increased work efficiency. This system will be the subject of a larger study to determine its impact on delays, errors, and costs.",
        "reference": "PIH (Partners In Health) and SES (Socios En Salud) provide treatment for most of the MDR-TB (multidrug-resistant tuberculosis) patients in Peru along with the Peruvian NTP (National TB Program). Monthly bacteriology tests are necessary for this treatment and must be collected from various health establishments located throughout the city. An employee from SES is currently going to each health establishment and collecting monthly bacteriology test results by hand, processing them, and typing them into an electronic medical record system. In this paper, we explain how we made a digital system using a personal digital assistant (PDA) to gather, check, and upload monthly bacteriology data into the PIH-EMR (Partners In Health Electronic Medical Record).  After an initial period of putting the system into action, we conducted a test study to evaluate the effectiveness of using this system. We first evaluated the current system in two health districts, then introduced the electronic system in one district while the other continued using the paper-based system during the same time. The PDA-based system took only 6.2 days to process, which was significantly lower than both the baseline (54.8) and control sites (64.4) (both less than 0.0001). The PDA-based system reduced differences from 10.1% to 2.8% and received positive feedback from users. The system would pay for itself in three months due to increased efficiency and time savings. A larger study will be conducted to assess the impact of this system on delays, errors, and costs."
      },
      {
        "source": "In order to facilitate knowledge transfer between specialists and generalists and between experts and novices, and to promote interdisciplinary communication, there is a need to provide methods and tools for doing so. This interdisciplinary research team developed and evaluated a decision support tool (DST) on a personal digital assistant (PDA) for cardiac tele-triage/tele-consultation when the presenting problem was chest pain. The combined human factors methods of cognitive work analysis during the requirements-gathering phase and ecological interface design during the design phase were used to develop the DST. A pilot clinical trial was conducted at a quaternary cardiac care hospital over a 3-month period. During this time, the DST was used by the nine nursing coordinators who provide tele-triage/tele-consultation 24/7. This clinical trial validated the design and demonstrated its usefulness to advanced cardiac care nurses, its potential for use by nurses less experienced in cardiac care, and for its potential use in an interdisciplinary team environment.",
        "prediction": "To help specialists and generalists, as well as experts and novices, share knowledge and improve communication between different fields, we need to provide tools and methods. An interdisciplinary research team developed and evaluated a decision support tool (DST) on a personal digital assistant (PDA) for cardiac tele-triage and tele-consultation when the presenting problem was chest pain. They used human factors methods, including cognitive work analysis during the requirements-gathering phase and ecological interface design during the design phase, to develop the DST. A pilot clinical trial was conducted at a cardiac care hospital over a 3-month period, during which the DST was used by nine nursing coordinators providing tele-triage and tele-consultation 24/7. This clinical trial validated the design and demonstrated its usefulness to advanced cardiac care nurses, its potential for use by less experienced nurses, and its application in an interdisciplinary team environment.",
        "reference": "To improve communication between specialists, generalists, experts, and novices and encourage interdisciplinary collaboration, we need to develop methods and tools. An interdisciplinary research team created and tested a decision support tool (DST) on a personal digital assistant (PDA) to aid cardiac tele-triage/tele-consultation for patients with chest pain. To create the DST (Decision Support Tool), we used both cognitive work analysis and ecological interface design methods during the requirements-gathering and design phases. A trial was done for 3 months at a quaternary cardiac care hospital During the trial, nine nursing coordinators used DST for 24/7 tele-triage/tele-consultation. This clinical trial confirmed that the design is useful for advanced cardiac care nurses, as well as for less experienced nurses and interdisciplinary teams."
      },
      {
        "source": "This paper presents M-CALL, a mobile computer-assisted language learning courseware for Korean language learners. Since conventional computer-assisted language learning is often boring, it exploits a cyber pet game to increase the learnerâs interest. M-CALL runs on a personal digital assistant with public wireless LAN for mobile learning. It grows a cyber pet by solving problems of Korean language learning. Korean Proficiency Test (KPT), a nationally certified Korean language test, was used as problem sets. It consists of cyber pet game, mobile learning courseware, mobile learning system, and mobile tutoring. It provides various functions for Korean language learning. Currently, the prototype M-CALL was designed and partly implemented between mobile PDA and personal computer.",
        "prediction": "This paper presents M-CALL, a mobile computer-assisted language learning courseware for Korean language learners. Traditional computer language learning can be boring, so M-CALL uses a fun cyber pet game to make learning more interesting. It runs on a personal digital assistant with public wireless LAN for mobile learning and helps learners grow a cyber pet by solving Korean language problems. The Korean Proficiency Test (KPT), a nationally certified Korean language test, is used as the problem set. M-CALL includes a cyber pet game, mobile learning courseware, a mobile learning system, and mobile tutoring, providing various functions for Korean language learning. Currently, the prototype M-CALL has been designed and partly implemented between mobile PDAs and personal computers.",
        "reference": "M-CALL is a mobile courseware for Korean language learners. It incorporates a cyber pet game to make it more engaging for learners than traditional computer-assisted language learning methods. M-CALL is a mobile learning system that uses a personal digital assistant with public wireless LAN (Computer network in small geographic areas). A cyber pet is raised while solving problems related to Korean language learning. The KPT, a nationally recognized exam for Korean language proficiency, served as the source material for the problem sets. It includes a virtual pet game, a mobile course for learning, a mobile learning platform, and mobile tutoring. It offers multiple features for learning Korean. Right now, a preliminary version of M-CALL has been developed and partially implemented for use on both mobile PDAs and personal computers."
      },
      {
        "source": "This study compared text entry performance of two stylus-driven soft keyboards for use in hand-held computing devices: the QWERTY and the T9. Participants transcribed text presented on a computer screen into a personal digital assistant (PDA) using a stylus and one of these two keyboards. We introduced a new psychophysical technique for measuring transcription rate that provides a composite measure of speed and accuracy. Using this technique, we calculated the maximum transcription rate for each keyboard. The results show that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9 keyboardâs apparent superior physical characteristics. An ancillary experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in visual scanning time due to perceptual grouping of the letters on the keys. Together these findings imply that the QWERTY keyboard layout remains the most effective of the currently available designs for stylus tapping on soft keyboards.",
        "prediction": "This study compared text entry performance of two stylus-driven soft keyboards for use in hand-held computing devices: the QWERTY and the T9. Participants transcribed text presented on a computer screen into a personal digital assistant (PDA) using a stylus and one of these two keyboards. We used a new method to measure how fast and accurately people can type. With this method, we calculated the maximum transcription rate for each keyboard. The results showed that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9 keyboardâs apparent superior physical characteristics. An additional experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in visual scanning time due to how the letters are grouped on the keys. Together, these findings imply that the QWERTY keyboard layout remains the most effective of the currently available designs for stylus tapping on soft keyboards.",
        "reference": "This study compared two onscreen keyboards, the QWERTY and the T9, for text entry performance on hand-held computing devices. Participants used a stylus to input text on a PDA using either a QWERTY or T9 keyboard in this study. We created a new way to measure transcription rate that considers both speed and accuracy together. We used this method to determine the fastest possible typing speed for each keyboard. The study found that the QWERTY keyboard had a higher transcription rate than the T9 keyboard, even though the T9 keyboard was physically better. Another test showed that the T9 keyboard's lower performance might be because the grouped letters on its keys require more visual scanning time. Overall, these results suggest that, among the current options, the QWERTY keyboard layout is still the most efficient for typing on touch screens with a stylus."
      },
      {
        "source": "The proliferation of mobile devices such as smart phones and Personal Digital Assistant (PDA) opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system). In Mcommerce systems, we still see many common components that we have in standard E-commerce applications, such as web servers and database servers. However, these new applications raise some unique challenges. For example, the limitations of mobile devices (e.g., small screen size and reduced CPU performance) implies that software development is partly different from desktop applications. Questions which are posed when designing M-commerce system include: âWhat kind of information do the users want to access via mobile devices?â, âHow can we provide useful applications with limited user input facility?â, âHow can we test a distributed M-commerce system?â In this paper, we discuss about some software development issues for mobile commerce systems from our experiences while developing an M-commerce system for tourists. Our prototype, easyHotel, is an useful software that allows booking hotel rooms via mobile phones.",
        "prediction": "The proliferation of mobile devices such as smartphones and Personal Digital Assistants (PDAs) opens new ways for developing mobile E-commerce systems known as Mobile-commerce or M-commerce systems. In M-commerce systems, we still see many common components that exist in standard E-commerce applications such as web servers and database servers. However, these new applications bring some unique challenges. For example, the limitations of mobile devices e.g. small screen size and reduced CPU performance imply that software development differs somewhat from that of desktop applications. When designing M-commerce systems, we ask questions like: What information do users want on their mobile devices? How can we create useful apps with limited input? and How do we test an M-commerce system? In this paper, we discuss some software development issues for mobile commerce systems based on our experiences while developing an M-commerce system for tourists. Our prototype easyHotel is useful software that allows users to book hotel rooms via mobile phones.",
        "reference": "The increasing use of mobile devices like smartphones and PDAs provides opportunities for the development of new mobile e-commerce systems, also known as M-commerce (Mobile-commerce) systems. M-commerce systems share several components with traditional E-commerce applications, such as web servers and database servers. However, these new applications present some distinct challenges. For example, due to mobile devices' limitations, such as smaller screens and weaker processors (also called CPUs), software development for mobile applications is partially different from desktop applications. Designing an M-commerce system involves asking questions such as: \"What information do users want on mobile devices?\", \"How can we create useful apps with limited user input?\", and \"How do we test a distributed M-commerce system?\" In this paper, we share our experiences developing an M-commerce system for tourists and discuss software development issues for such systems. Our software prototype, easyHotel, is a helpful application enabling users to book hotel rooms through their mobile phones."
      },
      {
        "source": "It is widely acknowledged that information such as web content should be adapted for mobile platforms to account for restrictions in mobile environments. As emerging mobile platforms such as different kinds of Personal Digital Assistant (PDA) tend to vary largely in their capabilities, we suggest that adaptation should be platform-specific. Common approaches for content adaptation are automated conversion and explicit specification of adapted content, with a trade-off between quality and development/maintenance effort. As alternative avoiding this trade-off, we propose a simple object-oriented framework for content adaptation. To facilitate the use of this framework in the Web, we base our approach on the object-oriented WebComposition model and its XML-based implementation WCML. We apply our object-oriented approach to an example application to demonstrate how object-oriented specification of platform-adapted content reduces development/maintenance effort.",
        "prediction": "It is widely acknowledged that information, such as web content, should be adapted for mobile platforms to account for restrictions in mobile environments. As new mobile platforms, including various types of Personal Digital Assistants (PDAs), have different capabilities, we recommend that adaptation be tailored to each platform. There are two common ways to adapt content: using automated conversion and clearly describing the adapted content. Both methods involve a trade-off between quality and the amount of effort required for development and maintenance. To address this trade-off, we propose a straightforward object-oriented framework for content adaptation. To facilitate the use of this framework on the web, we base our approach on the object-oriented WebComposition model and its XML-based implementation, known as WCML. We demonstrate our object-oriented approach using an example application to explain how specifying platform-adapted content in this way reduces development and maintenance effort.",
        "reference": "It is widely recognized that information, such as web content, should be adjusted for mobile platforms to accommodate the limitations of mobile environments. As new mobile platforms, such as various types of PDAs, differ significantly in their capabilities, we propose that adaptation should be tailored to each platform. Common methods for content adaptation involve automated conversion or explicitly specifying adapted content, balancing the trade-off between quality and the effort required for development and maintenance. Instead of making this trade-off, we suggest using a straightforward object-oriented framework for content adaptation. To make this framework more accessible for use on the web, we build our approach on the object-oriented WebComposition model and its implementation, WCML, which is an application of XML. We use our object-oriented framework in an example application to show how specifying platform-adapted content using an object-oriented approach can lower development and maintenance costs."
      },
      {
        "source": "In monitoring a patientu0027s real-time vital signs through Body Area Networks (BAN), rich data sources are communicated to medical practitioners. It is essential that data is delivered in timely-context aware manner. In this paper a system is designed for patients with cardiac disorders, with an emphasis on the design of the sensing device and communication scheme chosen. Several existing wearable physiological devices (Patient Sensing Device â PSD) used in the Healthcare systems are bulky in design and are not flexible and comfortable for the elderly patients. Presented is a unique flexible, as well as detachable PSD for the comfort of patients. Also discussed is a model for transmission, storage and processing of patient related data, which ensures periodic logging of patient data without saturating communication networks. A proof of concept prototype has been developed and implemented to enable transmission of Electrocardiogram (ECG) signal and body temperature of a patient, which can be expanded to include other vital signs. Communication between a mobile smart-phone and the ECG and temperature acquisition apparatus is implemented Bluetooth. The presented Data Management System â Periodic Model (DMS â PM) is designed to manage wireless interface of sensor units with the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a Smart phone making use of the existing GSM network.",
        "prediction": "In monitoring a patient's real-time vital signs through Body Area Networks (BAN), rich data sources are communicated to medical practitioners. It is essential that data is delivered in a timely and context-aware manner. In this paper, a system is designed for patients with cardiac disorders, focusing on the design of the sensing device and communication scheme. Some current wearable health devices (Patient Sensing Device â PSD) are large and uncomfortable for elderly patients. To address this, a unique flexible and detachable PSD is presented for the comfort of patients. Additionally, a model for the transmission, storage, and processing of patient-related data is discussed, ensuring periodic logging of patient information without overloading the communication networks. A proof of concept prototype has been developed to enable the transmission of Electrocardiogram (ECG) signals and body temperature, with potential to include other vital signs. Communication between a mobile smartphone and the ECG and temperature acquisition apparatus is established through Bluetooth. The Data Management System â Periodic Model (DMS â PM) is designed to manage the wireless connection between sensor units and the patient database at a Medical Service Provider (MSP) using a Personal Digital Assistant (PDA) or smartphone through the existing GSM network.",
        "reference": "Medical practitioners can access a wealth of data sources by using Body Area Networks (BAN) to monitor a patient's real-time vital signs. A BAN refers to a network of wearable or implantable devices worn on or attached to the human body for various purposes. Timely and context-aware delivery of data is crucial. This paper presents a system specifically designed for patients with cardiac disorders, focusing on the design of the sensing device and communication scheme selected. Many of the current wearable physiological devices used in healthcare systems, known as Patient Sensing Devices (PSD), are bulky and uncomfortable for elderly patients due to their inflexible design. We introduce a unique Patient Sensing Device (PSD) that is both flexible and detachable, designed for patient comfort. We also propose a model for transmitting, storing, and processing patient-related data that ensures regular logging of data without overwhelming communication networks. We have developed and implemented a proof-of-concept prototype that can transmit a patient's Electrocardiogram (ECG) signal and body temperature, potentially expanding to other vital signs. Communication between a mobile smartphone and the ECG and temperature acquisition apparatus is achieved via Bluetooth. The Data Management System - Periodic Model (DMS - PM) introduced here is created to facilitate the wireless connection between sensor units and the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a smartphone, utilizing the existing GSM network."
      },
      {
        "source": "Advancement of wireless and mobile technology has enabled additional platforms to support learning in a single learning space. Current trend integrates usage of mobile terminals such as smart PDA (personal digital assistant) in a learning system. Such devices can communicate with wireless mobile terminal and realize the intelligence exchange with its surroundings [1]. A LOCH (Language Learning Outside the Classroom) system named One Day Trip is developed to assist overseas students to learn Japanese in real life situations with the help of a PDA. This paper proposes the implementation with Knowledge Management (KM) concepts in the system to aid the teacher and learners in the learning environment.",
        "prediction": "Advancements in wireless and mobile technology have created new platforms to support learning in a single learning space. The current trend uses mobile devices, like smart PDAs (personal digital assistants), in education. These devices can communicate with wireless mobile terminals and share information with their surroundings. A LOCH (Language Learning Outside the Classroom) system called One Day Trip has been developed to assist overseas students in learning Japanese in real-life situations, utilizing a PDA. This paper proposes the integration of Knowledge Management (KM) concepts in the system to support both teachers and learners in the learning environment.",
        "reference": "Wireless and mobile technology progress has allowed more platforms to facilitate learning within a unified space. The current trend is to use mobile devices, such as smart PDAs, in learning systems. These devices can communicate wirelessly with mobile terminals and exchange information with the surrounding environment One Day Trip is a language learning system called LOCH (Language Learning Outside the Classroom), designed to help foreign students learn Japanese in real-life situations using a PDA. This paper suggests incorporating Knowledge Management (KM) concepts in the One Day Trip system to support both the teacher and learners in the learning environment."
      },
      {
        "source": "In recent years, we have developed applications for teaching both wired and wireless networking. These applications have been written for the Cybiko personal digital assistant, an inexpensive alternative to other hardware. Unfortunately, the Cybiko PDA was recently discontinued. As a result, these applications had to be ported to other platforms to remain useful. Instead of porting each application to individual platforms, which would prove to be extremely time consuming because of other APIu0027s and networking protocols, we created the Vassar College Messaging Layer. This layer abstracts the Cybiko networking structure and interface, allowing Cybiko applications to be ported to other platforms with minimal code alteration.",
        "prediction": "In recent years we have developed applications for teaching both wired and wireless networking. These applications were written for the Cybiko personal digital assistant an inexpensive alternative to other hardware. Unfortunately the Cybiko PDA was recently discontinued which meant that these applications had to be ported to other platforms to remain useful. Rather than adapting each application for different platforms which would take a lot of time due to various APIs and networking methods we created the Vassar College Messaging Layer. This layer abstracts the Cybiko networking structure and interface allowing Cybiko applications to be easily ported to other platforms with minimal code changes",
        "reference": "In recent years, we have created applications for teaching both wired and wireless networking. These applications are designed for the Cybiko personal digital assistant, which offers a cost-effective alternative to other hardware options. The Cybiko PDA was discontinued recently. Consequently, these applications needed to be adapted to other platforms to maintain their usefulness. To avoid the time-consuming task of porting each application to various platforms due to different APIs and networking protocols, we developed the Vassar College Messaging Layer. This layer simplifies the Cybiko networking structure and interface, making it easier to adapt Cybiko applications to different platforms without needing to make significant changes to the code."
      },
      {
        "source": "Unlike many other classes of hardware, smartcards do not have the ability to communicate securely with the user. Deprived of means to keep the owner informed, the positive properties of smartcards are difficult to utilize. We explore the area at the border between smartcards and other, more powerful (and thus more useful), machines. On the other side of this border we find the Personal Digital Assistant  :[66],\"our view, to be useful as an extension of the usersu0027 private sphere, a machine must at least have enough functionality and resources to create trustworthy digital signatures (to speak for the user, as it were). A less resourceful machine can merely act as a memory prothesis, helping the owner remembering addresses and phone  are :[121],\"designed to be tamper resistant, and as such they seem ideal as a minimal machine. However, trustworthy digital signatures can not be created by smartcards alone, simply because the user does not know what is given to the card for  :[163],\"order to be trusted--that is, being able to make trustworthy digital signatures--a smartcard must be supported by some infrastructure outside the card proper. We explore what must be included in such an infrastructure, and demonstrate that trustworthy digital signatures can in fact be made using a standard  :[211],\"argue that based on this fact, nontrivial distributed systems can be constructed by utilizing smartcards; a nontrivial system is one where holders of smartcards are \"first class citizens\". Asserting that a smartcard can act as a trusted machine gives new opportunities for designers of user-centric  that smartcards are :[257],\"here to stay, finding ways to apply them in constructive manners is prudent.",
        "prediction": "Unlike many other classes of hardware smartcards do not have the ability to communicate securely with the user Deprived of means to keep the owner informed the positive properties of smartcards are difficult to utilize We explore the area at the border between smartcards and other more powerful and thus more useful machines On the other side we find Personal Digital Assistants PDAs For a machine to effectively enhance the user's private space it needs to have enough functionality and resources to create reliable digital signatures which means it can securely represent the user A less resourceful machine can merely act as a memory prosthesis helping the owner remember addresses and phone numbers\n\nSmartcards are designed to be tamper-resistant which makes them seem ideal as minimal machines However trustworthy digital signatures cannot be created by smartcards alone simply because the user does not know what data is given to the card for them to be trusted To be trusted that is to generate reliable digital signatures a smartcard must be supported by additional infrastructure outside the card itself\n\nWe explore what this infrastructure must include and demonstrate that trustworthy digital signatures can indeed be made using standard approaches Based on this fact we argue that nontrivial distributed systems can be constructed utilizing smartcards such a system is one where holders of smartcards are considered first class citizens Asserting that a smartcard can act as a trusted machine opens up new opportunities for designers of user-centric systems Therefore it is prudent to find constructive applications for smartcards as they are here to stay",
        "reference": "Smartcards lack the capability to communicate with the user in a secure manner, unlike other hardware classes. (Smart cards are small, portable devices that have a special chip inside. They can store and process information securely.) Without a way to keep the owner updated, it becomes challenging to take advantage of the useful features of smart cards. We look at how smart cards and powerful machines can be combined to make even better devices. We believe that Personal Digital Assistants (PDAs) are more useful than smartcards because they can extend the user's private sphere. PDAs have enough functionality and resources to create trustworthy digital signatures, which can speak for the user. A less resourceful machine can serve as a memory aid, assisting the owner in remembering addresses and phone numbers, such as [121]. These machines are designed to be tamper-resistant, making them suitable for a minimalistic purpose. To create trustworthy digital signatures, a smartcard needs support from infrastructure outside the card itself. This is because the user is not aware of what information is given to the card, making it impossible for the card to be trusted solely on its own. We investigate the necessary components of this infrastructure and show that reliable digital signatures can indeed be created using a standard method [211]. We propose that smartcards can be utilized to build nontrivial distributed systems, where smartcard holders are considered important participants or \"first class citizens\". Claiming that smartcards can function as trusted machines opens up fresh possibilities for designers focused on user-centric approaches. It is evident that smartcards are here to stay, so it is wise for designers to explore and implement them in meaningful ways."
      },
      {
        "source": "In this paper we present the main features of a system that we have developed and that provides a new kind of tele-assistance service to elderly people.apart from the functionalities offered by the current tele-assistance services, also provides a high quality, anywhere and at any time assistance. We rate the assistance as high quality because allows the monitoring of vital signs and a local detection of anomalous situations by the device that the person carries in real time. Therefore, it sends alarms autonomously when  this paper we :[84],\"explain the three main functionalities offered by AINGERU: universal assistance anywhere and at any time, monitoring of vital signs irrespective of location or time and remote monitoring by allowing authorized external persons to consult data about monitored persons using the Internet. Moreover we show how those functionalities are achieved by making use of PDAs (Personal Digital Assistant), wireless communication, Semantic Web, Web services and agent technologies.",
        "prediction": "In this paper, we present the main features of a system we have developed that provides a new type of tele-assistance service to elderly people. In addition to the functionalities offered by current tele-assistance services, it provides high-quality assistance anywhere and at any time. We consider this assistance to be high quality because it can monitor vital signs and detect unusual situations with the device the person carries in real time, and it sends alarms autonomously. We explain the three main functionalities offered by AINGERU: universal assistance anywhere and at any time, monitoring of vital signs regardless of location or time, and remote monitoring that allows authorized external persons to consult data about monitored individuals using the Internet. Furthermore, we show how these functionalities are achieved through the use of PDAs (Personal Digital Assistants), wireless communication, Semantic Web, Web services, and agent technologies.",
        "reference": "This paper introduces a new tele-assistance service for elderly people that goes beyond existing services by offering high-quality assistance anywhere and anytime. Our system provides high-quality assistance because it allows real-time monitoring of vital signs and local detection of anomalous situations through the device carried by the person. We explain the three main functions of AINGERU in this paper: universal assistance anywhere and at any time, monitoring vital signs regardless of location or time, and remote monitoring that allows authorized external individuals to access data about monitored persons via the internet. We use PDAs, wireless communication, Semantic Web (aims to enhance the World Wide Web by adding meaning to the information available online), Web services, and agent technologies to achieve the aforementioned functionalities."
      },
      {
        "source": "Objective: To evaluate the effectiveness of a personal digital assistant (PDA)âbased clinical decision support system (CDSS) on nonsteroidal anti-inflammatory drug (NSAID) prescribing safety in the outpatient  :[26],\"The design was a randomized, controlled trial conducted in a university-based resident clinic. Internal medicine residents received a PDA-based CDSS suite. For intervention residents, the CDSS included a prediction rule for NSAID-related gastrointestinal risk assessment and treatment recommendations. Unannounced standardized patients (SPs) trained to portray musculoskeletal symptoms presented to study physicians. Safety outcomes were assessed from the prescriptions given to the SPs. Each prescription was reviewed by a committee of clinicians blinded to participant, intervention group assignment, and baseline or follow-up  :[108],\"Prescriptions were judged as safe or unsafe. :[26],\"The main outcome measure was the differential change in unsafe prescribing of NSAIDs for the intervention versus the control  :[135],\"At baseline, the mean proportion of cases per physician with unsafe prescriptions for the two groups was similar (0.27 vs. 0.29, p u003e 0.05). Controlling for baseline performance, intervention participants prescribed more safely than controls after receiving the CDSS (0.23 vs. 0.45 [F = 4.24, p u003c 0.05]). With the CDSS, intervention participants documented more complete assessment of patient gastrointestinal risk from  :[198],\"Participants provided with a PDA-based CDSS for NSAID prescribing made fewer unsafe treatment decisions than participants without the CDSS.",
        "prediction": "Objective To evaluate the effectiveness of a personal digital assistant PDAbased clinical decision support system CDSS on nonsteroidal antiinflammatory drug NSAID prescribing safety in the outpatient setting This study was a randomized controlled trial conducted in a universitybased resident clinic Internal medicine residents were given a PDA-based clinical decision support system which included a tool to help evaluate the risk of gastrointestinal problems from NSAIDs and provide treatment suggestions Unannounced standardized patients SPs trained to portray musculoskeletal symptoms presented to the study physicians Safety outcomes were assessed based on the prescriptions given to the SPs Each prescription was reviewed by a committee of clinicians who were blinded to participant information intervention group assignment and baseline or follow-up data Prescriptions were classified as safe or unsafe The main outcome measure was the change in unsafe prescribing of NSAIDs between the intervention group and the control group At baseline the mean proportion of cases per physician with unsafe prescriptions for the two groups was similar 027 vs 029 p > 005 After controlling for baseline performance intervention participants prescribed more safely than controls after receiving the CDSS 023 vs 045 F = 424 p < 005 Additionally with the CDSS intervention participants documented a more complete assessment of patient gastrointestinal risk Overall participants who used the PDA-based CDSS for NSAID prescribing made fewer unsafe treatment decisions compared to those who did not use the CDSS",
        "reference": "We did a study to test if a clinical decision support system (CDSS) on a personal digital assistant (PDA) could improve the safety of prescribing nonsteroidal anti-inflammatory drugs (NSAIDs) in outpatient clinics. We conducted a randomized, controlled trial in a university-based resident clinic. Residents in internal medicine were given a CDSS suite based on PDA. Intervention residents were provided with a CDSS that had a prediction rule for assessing gastrointestinal risk related to NSAIDs and recommendations for treatment. Trained individuals, known as standardized patients (SPs), who were equipped with musculoskeletal symptoms, interacted with the physicians participating in the study without prior notification. The study evaluated the safety outcomes of prescriptions given to standardized patients portraying musculoskeletal symptoms. A committee of clinicians who didn't know about the participant, intervention group assignment, or the baseline or follow-up data reviewed each prescription. They determined whether a prescription was safe or unsafe. The study aimed to see if the PDA-based CDSS would result in a reduction of unsafe prescribing of NSAIDs. The main outcome measured the difference in unsafe prescribing between the intervention and control groups. At the beginning of the study, both groups had a similar proportion of unsafe prescriptions. (0.27 vs 0.29) After controlling for the baseline performance, it was found that those who received the CDSS suite prescribed nonsteroidal anti-inflammatory drugs more safely than those who didn't (0.23 vs 0.45, with statistical significance). Participants who had access to the CDSS through a PDA documented a more comprehensive assessment of gastrointestinal risk in patients. Moreover, the presence of the CDSS resulted in fewer unsafe treatment decisions compared to participants who did not have access to the CDSS."
      },
      {
        "source": "Recently pedestrian navigation has been studied by many researchers, which provides pedestrians with a similar function of car navigation. On the other hand, a 3dimensional (3D) map, which is one of major themes in machine vision research, has been utilized as a simulation tool in city and landscape planning, and other engineering fields. The 3D maps will give more intuitive information compared to conventional 2-dimensional (2D) ones. In this paper we first propose pedestrian navigation based on 3D maps, and describe technologies required and its use situations. Secondly we compare effectiveness of 2D and 3D maps for navigation by object search experiments under conditions: 3D maps with and without texture; display sizes corresponding to a mobile phone and PDA (Personal Digital Assistant). The experimental results show that 3D maps with texture on mobile phone display size, and 3D maps without texture on PDA display size are superior to 2D maps in search time and error rate. From these results, we can say the effectiveness of 3D maps in pedestrian navigation.",
        "prediction": "Recently, researchers have studied pedestrian navigation, providing pedestrians with a function similar to car navigation. Additionally, a three-dimensional (3D) map, a major theme in machine vision research, has been used as a simulation tool in city and landscape planning, as well as in other engineering fields. Compared to traditional two-dimensional (2D) maps, 3D maps offer more intuitive information. In this paper, we first propose pedestrian navigation based on 3D maps and describe the necessary technologies and their usage situations. Next, we compare how well 2D and 3D maps work for navigation using object search experiments. We examine 3D maps with texture, those without, and the display sizes of mobile phones and Personal Digital Assistants (PDAs). The experimental results show that 3D maps with texture on mobile phone displays and 3D maps without texture on PDA displays are superior to 2D maps in terms of search time and error rate. From these results, we conclude that 3D maps are effective for pedestrian navigation.",
        "reference": "Recently many researchers have studied pedestrian navigation, which is similar to car navigation but designed for pedestrians. A 3D map is widely used in machine vision research and various engineering fields, such as city and landscape planning, as a simulation tool. 3D maps are more intuitive than 2D maps. In this paper, we suggest using 3D maps for pedestrian navigation and explain the necessary technology and possible scenarios for its application. We will conduct object search experiments to compare the effectiveness of 2D and 3D maps for navigation. The experiments will consider the following conditions: 3D maps with and without texture, and display sizes equivalent to a mobile phone and a Personal Digital Assistant (PDA). The results of the experiment suggest that 3D maps with texture on a mobile phone display and 3D maps without texture on a PDA display are better than 2D maps in terms of search time and error rate. Based on these results, we can conclude that 3D maps are effective for pedestrian navigation."
      },
      {
        "source": "Mobile agents are a competitive concept of client-server computing and are especially suitable in mobile environments, that are characterized by low bandwidth communication facilities and ad hoc connection/disconnection to stationary systems. They can be used for information retrieval and information filtering, in which case they evaluate replies and return only the relevant data. Mobile agents as a metaphor of active objects are created on a mobile device such as a Personal Digital Assistant (PDA), will be launched into the information galaxy and are fulfilling the mobile user âs task on the services available on networked stationary systems. One transmission channel for these itinerant agents is email. This paper introduces Active M 3 as an example of an active mail framework, which can be regarded as a first approach in authoring mobile agents in a graphical interactive manner. Active M 3 integrates two known concepts: active mail and multimedia mail.",
        "prediction": "Mobile agents are a competitive concept in client-server computing and are particularly suitable for mobile environments, which are characterized by low bandwidth communication facilities and occasional connection/disconnection from stationary systems. They can be used for information retrieval and filtering, evaluating replies and returning only relevant data. Mobile agents are like active objects created on devices such as Personal Digital Assistants (PDAs). They are sent into the information network to help mobile users complete tasks using services on connected stationary systems. One transmission channel for these itinerant agents is email. This paper introduces Active M 3 as an example of an active mail framework, which represents a first approach to creating mobile agents in a graphical interactive manner. Active M 3 combines two well-known concepts: active mail and multimedia mail.",
        "reference": "Mobile agents are a competitive concept in client-server computing, particularly well-suited for mobile environments. These environments are characterized by limited bandwidth communication and the frequent connection and disconnection to stationary systems. They can be utilized for information retrieval and filtering, where they assess responses and provide only the pertinent data. Mobile agents act like active objects that can be created on a mobile device like a PDA. They are sent out to perform tasks on the networked stationary systems and fulfill the user's needs. Email serves as a transmission channel for these mobile agents. This paper presents Active M 3, which is an active mail framework that allows users to create mobile agents using a graphical interface. Active M3 is a framework that combines two concepts: active mail and multimedia mail."
      },
      {
        "source": "Digital Video Broadcasting â Handheld (DVB-H) is a technology developed as an extension of Digital Video Broadcasting â Terrestrial (DVB-T) with additional features that make it suitable for delivery to mobile devices such as phones and Personal Digital Assistant (PDAs). This paper deals with the conditions of receiving digital video broadcast type services in mobile handheld devices. The DVB-H standard is introduced and the key technology elements on data link layer and physical layer are discussed in some details. Finally the DVB-H terminal and network design is described.",
        "prediction": "Digital Video Broadcasting â Handheld (DVB-H) is a technology developed as an extension of Digital Video Broadcasting â Terrestrial (DVB-T) with additional features that make it suitable for delivery to mobile devices such as phones and Personal Digital Assistants (PDAs). This paper discusses how to receive digital video broadcast services on mobile handheld devices. The DVB-H standard is described, and important technology parts related to data transfer and physical connections are explained. Finally, the design of the DVB-H terminal and network is outlined.",
        "reference": "DVB-H is a technology based on DVB-T that is designed for delivering content to mobile devices like phones and PDAs. This paper discusses how digital video broadcast services can be received on mobile handheld devices. The introduction of the DVB-H standard includes a discussion of key technology elements on the data link layer and physical layer, providing some detailed information. This paper also covers the design of DVB-H terminals and networks."
      },
      {
        "source": "Summary form only given, as follows. We present a design for a low cost but powerful and high speed communications device powered by IDTu0027s RV4640 as its processing engine. The device can achieve very high speed, thanks to the PCI bus compatible IDT ATM NIC. The device could be used as a two way pager, a set-top box, an Internet terminal, a personal digital assistant or as a video phone. The RV4640 is a very affordable 64 bit RISC processor that executes 175 dhrystone MIPS at 133 MHz. The RV4640 can be connected to a System Interface Chip which will provide I/O and memory control. The IDT77903 ATM card is a full duplexed 25 Mbps NIC with a PCI bus interface and it costs less than $100 (US). Integrating this card into our device as a network interface will make highspeed videoconferencing and multimedia applications easily implementable.",
        "prediction": "We present a design for a low cost but powerful and high-speed communications device powered by IDT's RV4640 as its processing engine. The device can work at very high speeds because of the IDT ATM NIC that is compatible with the PCI bus. The device could be used as a two-way pager, a set-top box, an Internet terminal, a personal digital assistant, or as a video phone. The RV4640 is a very affordable 64-bit RISC processor that executes 175 dhrystone MIPS at 133 MHz. The RV4640 can be connected to a System Interface Chip that controls input, output, and memory. The IDT77903 ATM card is a full duplexed 25 Mbps NIC that costs less than $100. This card connects to the device using a PCI bus interface. Integrating this card into our device as a network interface will make high-speed videoconferencing and multimedia applications easily implementable.",
        "reference": "Summary provided in the following. We propose a low-cost and high-speed communication device that uses IDT's RV4640 as the processing engine. This device is designed with IDT's RV4640 as the processing engine and can achieve high speed due to the PCI bus (a type of computer bus that simplifies the communication between computer components by providing a standardized interface) compatible IDT ATM NIC. This device can serve multiple purposes such as a two-way pager, set-top box, Internet terminal, personal digital assistant, or video phone. The RV4640 is a low-cost 64-bit RISC processor that runs at 133 MHz and can execute 175 dhrystone MIPS. The RV4640 can connect to a System Interface Chip for I/O (a specialized integrated circuit designed to facilitate communication between a computer system and its external devices) and memory control. The IDT77903 ATM card, which costs less than $100 (US), is a NIC with a PCI bus interface that is capable of full duplexing at 25 Mbps. Using the IDT77903 ATM card as a network interface in our device will make it easy to implement high-speed videoconferencing and multimedia applications."
      },
      {
        "source": "Dr. Who is a Microsoft research project aiming at creating a speech-centric multimodal interaction framework, which serves as the foundation for the NET natural user interface. The paper discusses MiPadu0027s design, implementation work in progress, and preliminary user study in comparison to the existing pen-based PDA interface. MiPad is the application prototype that demonstrates compelling user advantages for wireless personal digital assistant (PDA) devices, MiPad fully integrates continuous speech recognition (CSR) and spoken language understanding (SLU) to enable users to accomplish many common tasks using a multimodal interface and wireless technologies. It tries to solve the problem of pecking with tiny styluses or typing on minuscule keyboards in todayu0027s PDAs. Unlike a cellular phone, MiPad avoids speech-only interaction. It incorporates a built-in microphone that activates whenever a field is selected. As a user taps the screen or uses a built in roller to navigate, the tapping action narrows the number of possible instructions for spoken word understanding. MiPad currently runs on a Windows CE Pocket PC with a Windows 2000 machine where speech recognition is performed. The Dr Who CSR engine uses a unified CFG and n-gram language model. The Dr Who SLU engine is based on a robust chart parser and a plan-based dialog manager.",
        "prediction": "Dr Who is a Microsoft research project aiming at creating a speech-centric multimodal interaction framework which serves as the foundation for the NET natural user interface The paper discusses MiPads design implementation work in progress and a preliminary user study in comparison to the existing pen-based PDA interface MiPad is the application prototype that demonstrates compelling user advantages for wireless personal digital assistant PDA devices MiPad combines speech recognition and understanding so that users can easily complete common tasks with a user-friendly interface and wireless technology It addresses the challenges of using tiny styluses or typing on small keyboards in today's PDAs Unlike a cellular phone MiPad avoids speech-only interaction and incorporates a built-in microphone that activates whenever a field is selected As users tap the screen or use a built-in roller to navigate their tapping reduces the number of possible spoken instructions MiPad currently runs on a Windows CE Pocket PC with a Windows 2000 machine where speech recognition is performed The Dr Who CSR engine uses a unified CFG and n-gram language model while the Dr Who SLU engine is based on a robust chart parser and a plan-based dialog manager",
        "reference": "Dr. Who is a Microsoft research project that aims to create a speech-focused system for interacting with technology. This system will serve as the foundation for a natural user interface called NET. The paper discusses MiPad's design and implementation, which are still in progress, as well as a preliminary user study comparing it to existing pen-based PDA interfaces. MiPad is a prototype application that shows how wireless personal digital assistants (PDAs) can benefit from integrating continuous speech recognition (CSR) and spoken language understanding (SLU) technologies. This allows users to perform common tasks using a multimodal interface and wireless technology. It aims to solve the issue of having to use small styluses or type on tiny keyboards on modern PDAs. MiPad does not rely solely on speech interaction, unlike a cellular phone. MiPad has a built-in microphone that turns on when a field is selected. When a user taps the screen or utilizes a built-in roller for navigation, this action reduces the range of potential instructions for spoken word comprehension. MiPad is currently operating on a Windows CE Pocket PC, with speech recognition being carried out on a Windows 2000 machine. The Windows CE Pocket PC is a PDA that runs the Windows Embedded Compact operating system. The Dr Who CSR engine combines a CFG and an n-gram language model. The Dr Who SLU engine uses a chart parser and a plan-based dialog manager."
      },
      {
        "source": "Little is known about how viable new mobile applications emerge in complex commercial environments. Research in the sociology of technology suggests that the evolution of new applications is a process of social interaction between multiple constituencies, aiming to create a common definition of mobile technology problems and solutions that is obvious only in retrospect. This theory is illustrated by the early evolution of the personal digital assistant (PDA). According to this view, established technological communities attempt to impose their own definitions of key problems and solutions on new mobile technology, thereby forcing newer players to provide a \"total system\" that completely redefines a new application area.",
        "prediction": "Little is known about how viable new mobile applications emerge in complex commercial environments. Research in the sociology of technology shows that new applications develop through social interactions among various groups. These groups work together to define mobile technology problems and solutions, which may seem clear only after the fact. This theory is illustrated by the early evolution of the personal digital assistant PDA. According to this view, established technological communities try to impose their own definitions of key problems and solutions on new mobile technology. This pressure forces newer players to create a total system that completely redefines a new application area.",
        "reference": "We don't know much about how new mobile apps succeed in complicated business environments. Research in the sociology of technology indicates that the development of new applications involves social interaction among different groups. These groups work together to establish a shared understanding of mobile technology challenges and solutions, which often becomes clear only in hindsight. The PDA's early evolution exemplifies this theory. This idea suggests that existing technology groups try to define the problems and solutions for new mobile tech, which puts pressure on new players to create a total system that redefines the application area."
      },
      {
        "source": "In the ubiquitous environment, mobile terminals like personal digital assistant or cellular phone are used to access the Web. We implemented the procedures in a ubiquitous/universal passive viewer (u-PaV) system that transforms Web content into passive viewing content that is especially useful for mobile terminals. Extracting images and text from Web content, u-PaV generates a Macromedia Flash file, which is a popular multimedia format. Although the presentation of Web content depends on the terminal type, the Web interface of mobile terminals is designed almost the same as that of personal computers. However, comparing mobile and desktop terminals, some difference in device characteristics, such as screen resolution or sound faithfulness, affect the presentation on the terminal. Moreover, when changing the access style between interactive and passive, the presentation should be adjusted for the terminal type because the lacking information is usually not perceived after transformation. To adjust the play style of Web content to the terminal type, we developed a method for visual presentation. First, using keyword analysis, we represent the emotional aspect of a Web page by adjusting the background color of the screen. Second, we emphasize the subject of the content by the logotype of the keyword. Third, we segment the picture of the content into pieces and present one after another using visual effects. These procedures can be applied to any type of terminal.",
        "prediction": "In the ubiquitous environment mobile terminals like personal digital assistants or cellular phones are used to access the Web We implemented the procedures in a ubiquitous/universal passive viewer u-PaV system that transforms Web content into passive viewing content that is especially useful for mobile terminals By extracting images and text from Web content u-PaV generates a Macromedia Flash file which is a popular multimedia format Although the presentation of Web content depends on the terminal type the Web interface of mobile terminals is almost designed the same as that of personal computers However when comparing mobile and desktop terminals differences in device characteristics such as screen resolution or sound quality can affect how content is displayed Additionally when switching between interactive and passive styles of access the presentation should be adjusted for the terminal type to ensure that important information is perceived after the transformation\n\nTo change how Web content looks based on the type of device we created a way to present it visually First we analyze keywords to show the emotions of a Web page by changing the background color Second we emphasize the subject of the content using the logotype of the keyword Third we segment the picture of the content into pieces and present them one after another using visual effects These procedures can be applied to any type of terminal",
        "reference": "In the ubiquitous environment, devices like personal digital assistants or cell phones are used to access the Internet. We created a system called ubiquitous/universal passive viewer (u-PaV) that converts Web content into a format suitable for easy viewing on mobile devices. u-PaV takes text and images from the Web and creates a multimedia file in Macromedia Flash format, a widely used multimedia format. Mobile devices and personal computers have similar Web interfaces, although they may look different depending on the device. Mobile and desktop terminals have some differences in device characteristics, such as screen resolution and sound quality, which can affect how content is presented on the device. When switching between interactive and passive access styles, the presentation needs to be adjusted for the device type because some information may be lost during transformation and not noticed by the user. We developed a visual presentation method to customize how Web content is displayed based on the device type. First, we analyze keywords to capture the emotional tone of a web page and adjust the screen's background color accordingly. Then, we use the keyword's logo to highlight the main subject of the content. Finally, we divide the content's image into sections and present them one by one using visual effects. These steps can be used on any type of device."
      },
      {
        "source": "We have developed two-way location aware system, named as âThe Beijing Explorerâ, which exchanged positioning information and usersâ situation to one another using a PDA (Personal Digital Assistant) with built-in wireless LAN and a GPS (Global Positioning System) receiver in real time. Users can see their position and their chats on the screen of a PDA using the system real-timely. The system was used for the guidance of the Palace Museum (Forbidden City) in Beijing, China. We carried on experiments two times using the system. The results of experiments show that the service using positioning data and sharing contents were valuable and interesting. The correct positioning information is important for the guidance system.",
        "prediction": "We have developed a two-way location aware system named The Beijing Explorer which shares location information and user details using a PDA Personal Digital Assistant that has a built-in wireless network and GPS Global Positioning System receiver in real time Users can see their position and chats on the screen of the PDA in real time The system was used to guide visitors at the Palace Museum Forbidden City in Beijing China We conducted experiments using the system twice The results show that the service which uses positioning data and shares content was valuable and interesting Correct positioning information is important for the guidance system",
        "reference": "We created a location-aware system called \"The Beijing Explorer\" that uses a PDA with wireless LAN and GPS to exchange positioning and user information in real-time. Users can view their position and chats in real-time on the PDA screen when using the system. The system was used to guide visitors at the Palace Museum (Forbidden City) in Beijing, China. We conducted two experiments using the system. The experiment results indicate that the service was useful and engaging because it shared positioning data and content. Accurate positioning information is crucial for the guidance system."
      },
      {
        "source": "A truly personal machine, called a private machine and implemented as a Personal Digital Assistant (PDA), is fundamentally different from traditional machines. It is personal and private in an unprecedented manner, and its modus operandi is such that network and power failures will not be rare. Designing distributed systems where PDAs are treated as \"first class citizens\" is a  private :[59],\"assets (electronic money, keys for authentication and opening doors) will be stored in PDAs. Ownership and control of these :[59],\"assets and the media that store and communicate them should remain with the user. This must be reflected in the design of systems for private  :[105],\"introduce the \"open-ended argument\" to describe the design strategy we used for designing a system that is designed to reveal information to the user (as opposed to hide it). We argue and show that when systems are designed this way, the user (a human) is better able to control the system and his personal data, as he can make better decisions than the system itself based on qualitative assessment of the provided information. The system we have designed and implemented under this design guidelines is presented and discussed.",
        "prediction": "A truly personal machine called a private machine and implemented as a Personal Digital Assistant PDA is fundamentally different from traditional machines. It is personal and private in an unprecedented manner and its modus operandi is such that network and power failures will not be rare. Creating systems where PDAs are given equal importance as other key components is essential. Assets such as electronic money and keys for authentication and opening doors will be stored in PDAs. Ownership and control of these assets along with the media that store and communicate them should remain with the user. This principle must be reflected in the design of systems for private environments. We introduce the open-ended argument to describe the design strategy we employed to create a system that reveals information to the user rather than hides it. We argue and show that when systems are designed this way users humans are better able to control the system and their personal data as they can make more informed decisions based on a qualitative assessment of the information provided. The system we have designed and implemented under these guidelines is presented and discussed.",
        "reference": "A Personal Digital Assistant (PDA) used as a private machine, is fundamentally distinct from traditional machines because it is a personalized device. It offers an unprecedented level of personal and private experience, and its operation is designed to handle network and power failures, which are expected to occur frequently. In designing distributed systems, PDAs are given high importance and treated as \"first class citizens\". This means that important assets like electronic money and authentication keys will be stored in PDAs. The user should retain ownership and control of these assets and the media that stores and communicates them. This principle should be incorporated into the design of private systems. We introduced the concept of the \"open-ended argument\" to describe our design strategy, which focuses on creating systems that are intended to provide information to the user rather than hiding it. We argue and demonstrate that when systems are designed in this manner, the user (a human) gains improved control over both the system and their personal data. By enabling users to make decisions based on qualitative assessment of the information provided, they are better equipped to make informed choices compared to relying solely on the system's automated decisions. We have created a system based on the design guidelines and we will explain it."
      },
      {
        "source": "Depression is under recognized in a variety of pediatric settings. The purpose of this paper is to describe the development and initial evaluation of a personal digital assistant (PDA)-based decision support system (DSS) for pediatric depression screening in ages 8 to 18 years of age by pediatric advanced practice nurse (APN) students. Three aspects are described: selection of depression screening instrument; integration of the instrument into the PDA; and quantitative (usage) and qualitative (focus group) evaluation. Only one third of eligible patients were screened. Twenty percent of those screened were identified as at risk for mood disorder. The barriers to screening identified through focus groups included a lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor motivation and comfort, as well as perceived or real cultural barriers. Suggestions for educational, research, and interventions to integrate clinical based PDA-based screening are discussed.",
        "prediction": "Depression is not recognized enough in different pediatric settings. This paper aims to explain how a personal digital assistant (PDA)-based decision support system (DSS) was developed and initially evaluated for screening pediatric depression in children and teens aged 8 to 18, conducted by advanced practice nurse (APN) students. This paper covers three main topics: selecting a depression screening tool, incorporating it into the PDA, and assessing its effectiveness using both numerical data (usage) and feedback from focus groups. Only one third of eligible patients were screened, and among those screened, twenty percent were identified as at risk for mood disorders. Focus groups identified several barriers to screening, including not having enough time, lacking knowledge, unclear intervention protocols, limited referral resources, problems using the PDA, low motivation and comfort among preceptors, and perceived or real cultural barriers. The paper also discusses suggestions for educational initiatives, research, and interventions to effectively integrate clinical PDA-based screening",
        "reference": "Depression often goes unnoticed in many pediatric settings. This paper aims to explain the creation and early assessment of a decision support system (DSS) that uses personal digital assistants (PDAs) for screening pediatric depression among children aged 8 to 18 years, carried out by pediatric advanced practice nurse (APN) students. Three aspects are discussed: choosing a depression screening tool, incorporating the tool into the PDA, and evaluating it through quantitative (usage) and qualitative (focus group) assessments. Only one third of eligible patients were screened. 20% of the screened patients were found to be at risk for a mood disorder. Barriers to screening were identified through focus groups, including lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor motivation and comfort, and cultural barriers. The paper discusses suggestions for integrating PDA-based screening into clinical practice through education, research, and interventions."
      },
      {
        "source": "This study explored the potential of the application of wireless and mobile computing technologies to be used in improving the efficiency of patient care and education and future developments in information and communication technologies to support healthcare professionals and medical students in healthcare research, medical education and training. The design used for this study was a systematic review of published materials obtained from EMBASE and MEDLINE online databases, and the Cochrane Library database, including personal observations. Today, more than 50% of healthcare professionals and medical students are using Personal Digital Assistant with expected growth of more than 75% by year-end 2007. In addition, wireless and mobile computing technologies allows Personal Digital Assistant to connect directly to networks or the Internet. Studies relating to processes of patient care and should evaluate mobile computing technologies as a potential timesaving tool. Wireless and mobile computing technologies is only beginning to take its first step in improving patient care and education. They have shown a positive impact on patient safety, health care efficiency, and ultimately patient satisfaction.",
        "prediction": "This study looked at how wireless and mobile computing technologies can improve patient care and education as well as support healthcare professionals and medical students in their research and training. The design of this study was a systematic review of published materials obtained from EMBASE and MEDLINE online databases and the Cochrane Library database which included personal observations. Today more than 50% of healthcare professionals and medical students are using Personal Digital Assistants with expected growth of more than 75% by year-end 2007. In addition wireless and mobile computing technologies allow Personal Digital Assistants to connect directly to networks or the Internet. Studies related to patient care processes should evaluate mobile computing technologies as potential time-saving tools. Wireless and mobile computing technologies are just beginning to make strides in improving patient care and education. They have shown a positive impact on patient safety healthcare efficiency and ultimately patient satisfaction",
        "reference": "This study examined how wireless and mobile computing technologies can enhance patient care and education. It also explored how advancements in information and communication technologies can support healthcare professionals and medical students in research, education, and training. We conducted a systematic review for this study, analyzing published materials from databases such as EMBASE, MEDLINE, and the Cochrane Library, as well as personal observations. Over 50% of healthcare professionals and medical students currently use Personal Digital Assistants, and this number is expected to grow by more than 75% by the end of 2007. Wireless and mobile computing technologies enable Personal Digital Assistants to connect directly to networks or the Internet. Studies should examine whether mobile computing technologies can save time in patient care processes. Wireless and mobile computing technologies are still in the early stages of improving patient care and education. These technologies have positively impacted patient safety, healthcare efficiency, and patient satisfaction."
      },
      {
        "source": "Nursing students can learn many things through practical training by experiencing actual medical practice and by coming in contact with patients. Therefore practical training is an effective learning opportunity for developing the practical nursing care ability of nursing students. Moreover, at hospitals, which are important training facilities, with regard to medical safety, the use of learning tools that produce electrical waves is not possible. So, we created a learning support environment that facilitates the imagination of nursing techniques, and enables effective preparation, review, and learning at anytime and anywhere using a portable digital assistant (PDA) device for practical training. As described in this paper, we report on the outline of the educational materials named \"digital nursing dictionary\" that we developed and the evaluation of the practices using it.",
        "prediction": "Nursing students can learn many things through practical training by experiencing actual medical practice and by coming in contact with patients. Therefore, practical training is an effective learning opportunity for developing the practical nursing care abilities of nursing students. Additionally, at hospitals, which are important training facilities, the use of learning tools that create electrical signals is not allowed due to medical safety concerns. To address this, we created a learning support environment that fosters the imagination of nursing techniques and enables effective preparation, review, and learning anytime and anywhere using a portable digital assistant PDA device for practical training. In this paper, we report on the outline of the educational materials named digital nursing dictionary that we developed and the evaluation of the practices using it.",
        "reference": "Nursing students can learn through practical training and by interacting with patients in real medical settings. Practical training is effective for developing the practical nursing care ability of nursing students. Moreover, hospitals, which are important training facilities, do not allow the use of learning tools that produce electrical waves due to medical safety concerns. We developed a learning support environment that helps nursing students visualize and practice techniques. It allows for convenient preparation, review, and learning using a portable digital assistant (PDA) device, enabling anytime and anywhere practical training. We developed an educational tool called the 'digital nursing dictionary' and evaluated its effectiveness, as outlined in this paper."
      },
      {
        "source": "Limitation in display size and resolution on mobile devices is one of the main obstacles for wide-spread use of web applications in a wireless environment. Web pages are often too large for a PDA (Personal Digital Assistant) screen to present. The same problem exists for devices with low resolution such as WebTV. Manual reconstruction of web pages for these devices would ease the problem; however, the large variation of display capabilities will greatly increase the burden of web page designers since they have to customize a web page for each possible display device. In this paper, we propose a document segmentation and presentation system. The system automatically divides a web document into a number of logical segments based on the screen size and the structure and content of the document. Additional information such as overviews and summaries is also extracted to facilitate navigation. The system presents the segments and structural information of a web document to make full use of the screen for information finding.",
        "prediction": "Limitation in display size and resolution on mobile devices is one of the main obstacles for widespread use of web applications in a wireless environment. Web pages are often too large for a PDA (Personal Digital Assistant) screen to present, and the same problem exists for devices with low resolution, such as WebTV. Manually adjusting web pages for these devices could help, but the wide range of display sizes makes it harder for web designers because they have to change the web page for each type of device. In this paper, we propose a document segmentation and presentation system. The system automatically divides a web document into several logical segments based on screen size, as well as the structure and content of the document. It also extracts additional information, such as overviews and summaries, to help with navigation. The system presents the segments and structural information in a way that makes full use of the screen for finding information.",
        "reference": "Small screens and low resolutions on mobile devices are a major obstacle for the widespread adoption of web applications in a wireless environment. PDA screens are often too small to display entire web pages. Low-resolution devices like WebTV face the same problem. Manually reconstructing web pages for these devices would help, but the wide range of display capabilities would make it challenging for web page designers as they would have to customize each web page for every possible display device, increasing their workload. This paper suggests a system for segmenting and presenting documents. The system divides a web document into logical segments automatically, using information about the screen size, document structure, and content. The system also extracts summaries and overviews to make navigation easier. The system optimizes the use of the screen for information finding by showing the segments and structure of a web document."
      },
      {
        "source": "Take 8-bit microcontroller (C8051F005) as the nucleus and study a kind of voltage harmonic monitor device that satisfies the long-range monitor. The harmonic analysis algorithm adopts Fast Fourier Transform (FFT). This device has two work modes: ânativeâ and âremoteâ. It also can communicate with monitor center through telephone line, serial port, IC card, PDA (Personal Digital Assistant), etc.",
        "prediction": "Take 8-bit microcontroller C8051F005 as the nucleus and study a type of voltage harmonic monitor device for long-range monitoring. The harmonic analysis algorithm uses a method called Fast Fourier Transform FFT to analyze signals. This device has two work modes: native and remote. It can also communicate with the monitor center through a telephone line, serial port, IC card, PDA Personal Digital Assistant, and other methods.",
        "reference": "Study a voltage harmonic monitor device for long-range monitoring using the 8-bit microcontroller C8051F005 as the core. The harmonic analysis uses FFT. The device has two modes: \"native\" and \"remote\". It can communicate with a monitoring center via different methods such as telephone line, serial port, IC card, and PDA (Personal Digital Assistant)."
      },
      {
        "source": "With network and small screen device improvements, such as wireless abilities, increased memory and CPU speeds, users are no longer limited by location when accessing on-line information. We are interested in studying the effect of users switching from a large screen device, such as a desktop or laptop to use the same web page on a small device, in this case a PDA (Personal Digital Assistant). We discuss three common transformation approaches for display of web pages on the small screen: Direct Migration, Linear and Overview. We introduce a new Overview method, called the Gateway, for use on the small screen that exploits a userâs familiarity of a web page. The users in an initial study prefer using the Gateway and Direct Migration approach for web pages previously used on the large screen, despite the common Linear approach used by many web sites.",
        "prediction": "With network and small screen device improvements such as wireless abilities increased memory and CPU speeds users are no longer limited by location when accessing online information We are interested in studying the effect of users switching from large screen devices like desktops or laptops to use the same web page on small devices specifically PDAs Personal Digital Assistants We discuss three common approaches to display web pages on small screens Direct Migration Linear and Overview We present a new Overview method called the Gateway designed for small screens that takes advantage of how familiar users are with a web page In an initial study users preferred the Gateway and Direct Migration approaches for web pages they had previously accessed on large screens despite the common Linear method used by many websites",
        "reference": "Improvements in network and small-screen devices, such as wireless capabilities, faster CPU speeds, and increased memory, have eliminated location restrictions for accessing online information. We want to study the impact of users switching from a desktop or laptop to a PDA (Personal Digital Assistant) when accessing the same web page. We are looking at three common ways to display web pages on small screens: Direct Migration, Linear, and Overview. Gateway is our new Overview method for small screens that use the user's familiarity with a web page. Many websites use the Linear method, but an initial study showed that users prefer using the Gateway and the Direct Migration method for web pages."
      },
      {
        "source": "The limitations and constraints of mobile systems need to be adequately addressed in software development. We have been developing a taxonomy of risks based on SEIu0027s risk questionnaire and applied it during the development of a negotiation support system for a Personal Digital Assistant (PDA). In our planned research, we will explore how we can better integrate existing risk management strategies and Agile Methods (AM).",
        "prediction": "The limitations and constraints of mobile systems need to be adequately addressed in software development. We have been creating a list of potential risks using SEI's risk questionnaire and used it while developing a decision-making support system for a Personal Digital Assistant PDA. In our planned research, we will explore how we can better integrate existing risk management strategies with Agile Methods AM.",
        "reference": "During software development, restrictions due to mobile systems need to be addressed. Based on SEI's risk questionnaire, we developed a classification of risks and applied it while developing a negotiation support system for a PDA. Risk management strategies and Agile Methods and how we can integrate them better will be studied in our future research."
      },
      {
        "source": "Expansions of mobile services and private data have required increased level of protection. Speaker recognition, one of the biometric technologies, arises lots of research interests for its simple, cheap and convenient characteristics. In this paper, a robust speaker recognition system which facilitates reliable authentication with multi-channel voices is presented. A large multi-channel corpus, including mobile phone, personal digital assistant (PDA), telephone and microphone, is collected to evaluate the system performance.",
        "prediction": "Expansions of mobile services and private data have required an increased level of protection. Speaker recognition, one of the biometric technologies, has generated significant research interest due to its simplicity, low cost, and convenience. In this paper, we present a robust speaker recognition system that ensures reliable authentication with multi-channel voices. To evaluate the system's performance, we gathered a large collection of audio recordings from various devices, including mobile phones, personal digital assistants (PDAs), telephones, and microphones.",
        "reference": "The growth of mobile services and private data necessitates higher levels of protection. Speaker recognition, a technology using the voice of users to identify them, leads to a lot of research interest because of its simple, cheap, and convenient characteristics. This work presents a powerful speaker recognition system that makes the authentification with multi-channel voices easier. Data are collected on mobile phones, PDAs, telephones, and microphones to evaluate the system's performance."
      },
      {
        "source": "This paper presents a method to generate unique and nevertheless highly random pseudonyms in a distributed environment. More precisely, each user can now generate his pseudonym locally in his personal security environment, e.g. in his smart card or his personal digital assistant. There is no need for any information interchange between issuing parties or global data (especially keys), except unique identifiers for each user and each device of the system. Additionally the holder can prove, that he generated a specific pseudonym without revealing his identity and he can reveal his identity by disclosing the pseudonym. Whereas the verifier of a disclosed pseudonym can be sure, that the presenter of the pseudonym is the holder of the pseudonym (i.e. the person which originally generated it). The identifier of the user and the identifier of the useru0027s device will be used to generate unique pseudonyms, but to ensure pseudonymity, both components will be stored in the pseudonym in encrypted form.",
        "prediction": "This paper presents a method to generate unique and highly random pseudonyms in a distributed environment. More precisely, each user can now generate their pseudonym locally in their personal security environment, such as a smart card or personal digital assistant. There is no need to share information between parties or use global data (like keys), only unique identifiers for each user and device. Additionally, the holder can prove that they generated a specific pseudonym without revealing their identity, and they can reveal their identity by disclosing the pseudonym. The verifier of a disclosed pseudonym can be sure that the presenter of the pseudonym is the holder (i.e., the person who originally generated it). The identifier of the user and the identifier of the userâs device will be used to generate unique pseudonyms, but to ensure pseudonymity, both components will be stored in the pseudonym in encrypted form.",
        "reference": "This work presents a method to generate unique and random pseudonyms in a distributed system. Every user can now create his pseudonym locally in their own personal security environment, e.g. in his chip card or PDA. No information exchange is required between issuing parties or global data, except for unique identifiers for each user and device in the system. The holder can also prove that he generated a distinct pseudonym without revealing his identity; by divulging it, he can reveal his identity. In that case, the verifier of a divulgated pseudonym can be sure that the one who presents the pseudonym is holding it. (i.e. the person that originally created it) The user identifier and device's identifier will be used to create unique pseudonyms but to ensure anonymity with pseudonyms, both identifiers will be stored within the pseudonym in encrypted form."
      },
      {
        "source": "In todayu0027s mobile information society, location-based services play an increasingly important role. These services are to be accessed by users with a mobile end device for the use of city maps, route planning, navigation, or traffic information. Mobile end devices, however, do not have computing power or storage capacity comparable to that of a personal computer or laptop. These deficits can be bypassed by employing special methods in development of the respective applications. This paper outlines the experience gained in the development of a prototype for route computation in public transport networks to be used on a personal digital assistant. Subdivision of the route computation process into various steps for minimizing the computation expenditure on the mobile end device plays a significant role.",
        "prediction": "In todayâs mobile information society location-based services play an increasingly important role These services can be accessed by users with mobile devices for city maps route planning navigation or traffic information However mobile devices do not have as much computing power or storage space as personal computers or laptops These limitations can be overcome by employing special methods in the development of these applications This paper outlines the experience gained in developing a prototype for route computation in public transport networks intended for use on a personal digital assistant The subdivision of the route computation process into various steps to minimize the computation burden on mobile devices plays a significant role",
        "reference": "Location-based service's role in today's mobile information society is increasing . Users can access city maps, route planning, navigation, or traffic information with their mobile devices. Compared to laptops or personal computers, mobile devices do not have the same computing power or storage capacity. This shortage can be overcome by using specific methods during the development of the respective application. This paper shows the gained experience from developing a prototype designed for a PDA that calculates routes in public transport networks. Dividing the route computation process into multiple steps to reduce the computational load on the mobile device is crucial."
      },
      {
        "source": "DIANE is a digital assistant system that aims to fasten the doctor access to various informations at the hospital such as health care facility, medical records, and also human resource data. The fasten access could be achieved by implementing face recognition and live streaming as part of the digital assistant system.",
        "prediction": "DIANE is a digital assistant system that aims to help doctors quickly access various information at the hospital such as healthcare facilities medical records and human resource data Quick access can be provided by using face recognition and live video as part of the digital assistant system",
        "reference": "DIANE is a digital assistant system that allows the doctor a faster access patient and hospital information. This could be done with face recognition and live streaming."
      },
      {
        "source": "Digital assistants are emerging to become more prevalent in our daily lives. In interacting with these assistants, users may engage in multiple tasks within a short period of time.",
        "prediction": "Digital assistants are becoming more common in our daily lives and users may interact with them to complete multiple tasks in a short period of time",
        "reference": "Digital assistants are becoming popular in our daily lives. It will allow users to do multiple tasks in a faster way."
      },
      {
        "source": "As extensive experimental research has shown individuals suffer from diverse biases in decision-making. In our paper we analyze the effects of decision-making biases of managers in collaborative decision processes on organizational performance. In the simulations, managerial decisions which are based on different levels of organizational complexity and different incentive systems suffer from biases known from descriptive decision theory. The results illustrate how biases in combination with each other and in different organizational contexts affect organizational performance. We find that, contrary to intuition, some combinations of biases significantly improve organizational performance while these biases negatively affect organizational performance when they occur separately. This might evoke considerations whether decision-making should be as rational as possible.",
        "prediction": "As extensive experimental research has shown, individuals suffer from diverse biases in decision-making. In our paper, we analyze the effects of decision-making biases of managers in collaborative decision processes on organizational performance. In the simulations, we found that managers' decisions can be influenced by various levels of organizational complexity and different incentive systems, leading to biases described in decision-making theory. The results illustrate how these biases, both separately and in combination, affect organizational performance in various contexts. Contrary to intuition, some combinations of biases significantly improve organizational performance, while these biases can negatively impact performance when they occur alone. This raises questions about whether decision-making should aim to be as rational as possible",
        "reference": "Research showed that people suffer from diverse biases (disproportionate weight in favor of or against an idea) in decision-making. We analyzed the effects of decision-making biases of managers on organizational performance. In the simulations, managers decisions which are based on organizational skills and rules, suffer from several known biases. The results illustrate how combined biases in different contexts affect organizational performance. Contrary to expectations, some combinations of biases improve organizational performance. However, when they occur separately, they decrease performance. This raises questions about the importance of rationality in decision-making."
      },
      {
        "source": "Big data, the enhanced ability to collect, store and analyze previously unimaginable quantities of data in tremendous speed and with negligible costs, delivers immense benefits in marketing efficiency, healthcare, environmental protection, national security and more. The central tenets of the current privacy framework, the principles of data minimization and purpose limitation, are severely strained by the big data technological and business reality. As we increasingly interact with these artificial agents in unsupervised settings, with no human mediators, their seeming autonomy and increasingly sophisticated functionality and behavior, raises legal and philosophical questions. The focus on the machine is a distraction from the debate surrounding data driven ethical dilemmas, such as privacy, fairness and discrimination. The machine may exacerbate, enable, or simply draw attention to the ethical challenges, but it is humans who must be held accountable. Policymakers should seek to devise agreed-upon guidelines for ethical data analysis and profiling. Such guidelines would address the use of legal and technical mechanisms to obfuscate data; criteria for calling out unethical, if not illegal, behavior; categories of privacy and non-privacy harms; and strategies for empowering individuals through access to data in intelligible form.",
        "prediction": "Big data, the enhanced ability to collect, store, and analyze previously unimaginable quantities of data at tremendous speed and with negligible costs, delivers immense benefits in marketing efficiency, healthcare, environmental protection, national security, and more. However, the main ideas of today's privacy rules, which focus on collecting only necessary data and using it for specific purposes, are being challenged by the reality of big data technology and business practices. As we increasingly interact with these artificial agents in unsupervised settings, with no human mediators, their seeming autonomy and increasingly sophisticated functionality and behavior raise legal and philosophical questions. Focusing too much on the machines distracts us from the important debates about data-driven ethical dilemmas, such as privacy, fairness, and discrimination. While machines may exacerbate or highlight these ethical challenges, it is ultimately humans who must be held accountable. Policymakers should work to create shared guidelines for ethical data analysis and profiling. Such guidelines would cover the use of legal and technical methods to protect data, criteria for identifying unethical or illegal behavior, categories of privacy and non-privacy harms, and strategies to empower individuals by giving them access to data in a clear format.",
        "reference": "Big data (the ability to collect, store and analyze huge quantities of data in a really fast and cheap way) offers immense benefits in marketing, healthcare, environment, national security and more. The principles of privacy, limitation of data collection and use are stretched by the business and technological reality of big data. Our increasing interactions with these technologies without human supervision, and their growing autonomy, functionality and behavior raises legal and philosophical questions. The focus on the machine is a distraction from the debate on ethical dilemmas about data like privacy, fairness and discrimination. The machine may influence the ethical challenges, but the humans must remain responsible. Responsible people should find guidelines for ethical data analysis and collection. These guidelines would deal with mechanisms to protect data, criteria about unethical or illegal behavior, privacy harms, and strategies to give people access to data."
      },
      {
        "source": "Amazon's Echo, and Apple's Siri have drawn attention from different user groups; however, these existing commercial VUIs support limited language options for users including native English speakers and non-native English speakers. we conducted a usability study of the Google Home Smart Speaker with 20 participants including native English and non-native English speakers to understand their differences in using the Google Home Smart Speaker. The findings show that compared with their counterparts, the native English speakers had better and more positive user experiences in interacting with the device. It also shows that users' English language proficiency plays an important role in interacting with VUIs. The findings from this study can create insights for VUI designers and developers for implementing multiple language options and better voice recognition algorithms in VUIs for different user groups across the world.",
        "prediction": "Amazon's Echo and Apple's Siri have gained attention from various user groups; however, these existing commercial voice user interfaces (VUIs) offer limited language options for both native and non-native English speakers. We conducted a usability study of the Google Home Smart Speaker with 20 participants, including both native and non-native English speakers, to explore their differences in using this device. The findings show that native English speakers had better and more positive experiences using the device than non-native speakers. Additionally, users' English language proficiency plays an important role in their interactions with VUIs. The insights from this study can help VUI designers and developers implement multiple language options and improve voice recognition algorithms for diverse user groups worldwide.",
        "reference": "The VUIs (voice user interface) like Amazonâs Echo or Appleâs Siri are popular nowadays. However, they have limited language options for users. We studied the usability of the Google Home Smart Speaker with native and non-native English speakers to understand their differences in using this device. The results show that the native English speakers had a better experience with the device than the non-native. It also shows that language skills play an important role. The results of this study can help VUI developers for improving language options and voice recognition in the devices."
      },
      {
        "source": "the smart speakers cannot distinguish human voice from machine voice. a method to identify which of human or machine is sending voice commands to a smart speaker is desired. to prevent such machine-voice based attacks to a smart speaker in absence of residents, we propose a system consisting of a speaker and a microphone array to detect the existence of a human nearby, supposing it can be incorporated in a smart speaker in the future.",
        "prediction": "The smart speakers cannot distinguish human voice from machine voice. A method to identify which is sending voice commands to a smart speaker is desired. To stop attacks on smart speakers by machine voices when no one is home, we propose a system that includes a speaker and a microphone array to detect if a human is nearby, with the hope that it can be incorporated into a smart speaker in the future",
        "reference": "The smart speakers cannot differentiate between human voice and machine voice. A method to identify if the voice command is from a human or a machine is required. We propose a system composed of a speaker and microphones to detect the presence of humans. It could help to prevent attacks on a smart speaker with a machine voice in absence of residents"
      },
      {
        "source": "As smart speakers with voice interaction capability permeate continuously in the world, more and more people will gradually get used to the new interaction mediumâvoice. Although speech recognition, natural language processing (NLP) have been greatly improved over the past few years, users still may encounter errors from time to time like âcannot understandâ, âno requested audio resource (such as music)â, which can frustrate users. Therefore, when an error message is reported, it is vital that the smart speaker gives an effective and proper response. However, currently the response strategies adopted by leading smart speaker brands in China differed mainly on two dimensions: âapology or notâ and âhumor or neutralâ. We explored userâs preference of response strategies under two error scenariosâââcannot understandâ and âno requested audio resourceâ. Two dependent variables (satisfaction and perceived sincerity of response) were measured. The results showed that participants were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios. In the âno requested audio resourceâ scenario, humor had no significant impact on the perception of satisfaction and sincerity. But in the âcannot understandâ scenario, humorous expression decreased perceived sincerity.",
        "prediction": "As smart speakers with voice interaction capability continue to spread around the world, more and more people will gradually get used to this new interaction mediumâvoice. Although speech recognition and natural language processing (NLP) have significantly improved over the past few years, users may still encounter errors from time to time, such as âcannot understandâ or âno requested audio resource (such as music),â which can be frustrating. Therefore, when an error message is reported, it is vital for the smart speaker to provide an effective and appropriate response. Currently, the main response strategies used by popular smart speaker brands in China focus on two things: whether to apologize or not, and whether to be funny or serious. We explored users' preferences for response strategies under two error scenariosââcannot understandâ and âno requested audio resource.â We measured two main factors: satisfaction and how sincere the response seemed. The results showed that participants were more satisfied and perceived higher sincerity when smart speakers apologized in both error scenarios. In the âno requested audio resourceâ scenario, humor had no significant impact on satisfaction and perceived sincerity. However, in the âcannot understandâ scenario, humorous expressions decreased perceived sincerity.",
        "reference": "Smart speakers are becoming popular around the world and people will get used to this new way of interacting with the voice. Even with the progress of speech recognition and natural language processing (interactions between computers and human language), users may still get errors like âcannot understandâ or âno requested audio resourceâ which can frustrate users. So, it is important that the smart speaker gives an effective and proper response during an error message. The responses of the most popular brand of smart speakers are based on 2 elements, apology and humor. We studied userâs preference in two error scenarios : âcannot understandâ and âno requested resourceâ Satisfaction of the user and perceived sincerity of the response were measured. The results showed that users were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios. In the âno requested audio resourceâ scenario, humor had no impact on the satisfaction or sincerity. But in the âcannot understandâ scenario, humor decreased perceived sincerity."
      },
      {
        "source": "A pharmacophore analysis approach was used to investigate and compare different classes of compounds relevant to the drug discovery process (specifically, drug molecules, compounds in high throughput screening libraries, combinatorial chemistry building blocks and nondrug molecules). Significant differences were observed between the pharmacophore profiles obtained for the drug molecules and those obtained for the high-throughput screening compounds, which appear to be closely related to the nondrug pharmacophore distribution. It is suggested that the analysis of pharmacophore profiles could be used as an additional tool for the property-based optimization of compound selection and library design processes, thus improving the odds of success in lead discovery projects.",
        "prediction": "A pharmacophore analysis approach was used to investigate and compare different classes of compounds relevant to the drug discovery process (specifically, drug molecules, compounds in high throughput screening libraries, combinatorial chemistry building blocks, and nondrug molecules). There were important differences between the pharmacophore profiles of drug molecules and those from high-throughput screening compounds, which seem to be closely linked to the distribution of nondrug pharmacophores. This analysis of pharmacophore profiles could serve as an additional tool for improving the property-based optimization of compound selection and library design processes, thus increasing the chances of success in lead discovery projects.",
        "reference": "A pharmacophore analysis investigated and compared different compounds of the drug discovery process. Significant differences were observed between the pharmacophore profiles of the drug molecules and the high-throughput screening compounds, which appear to be related to the nondrug pharmacophore distribution. It is suggested that the analysis could be used as an additional tool for the optimization of compound selection and library design processes.."
      },
      {
        "source": "Annotation of bioassay protocols using semantic web vocabulary is a way to make experiment descriptions machine-readable. Protocols are communicated using concise scientific English, which precludes most kinds of analysis by software algorithms. Given the availability of a sufficiently expressive ontology, some or all of the pertinent information can be captured by asserting a series of facts, expressed as semantic web triples (subject, predicate, object). With appropriate annotation, assays can be searched, clustered, tagged and evaluated in a multitude of ways, analogous to other segments of drug discovery informatics. The BioAssay Ontology (BAO) has been previously designed for this express purpose, and provides a layered hierarchy of meaningful terms which can be linked to.",
        "prediction": "Annotation of bioassay protocols using semantic web vocabulary is a way to make experiment descriptions machine-readable. Protocols are written in clear scientific English, which makes it hard for software algorithms to analyze them effectively. Given the availability of a sufficiently expressive ontology, some or all of the pertinent information can be captured by asserting a series of facts, expressed as semantic web triples subject, predicate, object. With appropriate annotation, assays can be searched, clustered, tagged, and evaluated in many ways, similar to other aspects of drug discovery informatics. The BioAssay Ontology BAO has been designed for this purpose and provides a layered hierarchy of meaningful terms to link to",
        "reference": "Annotation of bioassay protocols with web vocabulary can make experiment descriptions machine-readable. Protocols use concise scientific English which prevents most of analysis by software algorithms. There is a sufficient ontology, so the pertinent information can be written using semantic web triples (subject, predicate, object). With appropriate annotation, assays can be searched, clustered, tagged and evaluated. The BioAssay Ontology (BAO) has been designed for this purpose, and provides many meaningful terms."
      },
      {
        "source": "Next generation sequencing (NGS) produces massive datasets consisting of billions of reads and up to thousands of samples. Subsequent bioinformatic analysis is typically done with the help of open source tools, where each application performs a single step towards the final result. This situation leaves the bioinformaticians with the tasks to combine the tools, manage the data files and meta-information, document the analysis, and ensure reproducibility.",
        "prediction": "Next generation sequencing (NGS) produces massive datasets consisting of billions of reads and up to thousands of samples. After that, bioinformatic analysis is usually done using open source tools, where each tool handles one step to reach the final result. This situation leaves bioinformaticians with the tasks of combining the tools, managing data files and meta-information, documenting the analysis, and ensuring reproducibility.",
        "reference": "Next generation sequencing (NGS) produces datasets of billions of reads and thousands of samples. The analysis is typically done with open source tools, performing a single step towards the final result. The bioinformaticians have to combine the tools, manage the files and information, document the analysis, and ensure reproducibility."
      },
      {
        "source": "SPSS Clementinel2.0 statistical software was used to mine the association rules between Etiology and traditional Chinese medicine (TCM), Syndromes and TCM, Symptoms and TCM. The classic Apriori algorithm is useful to mine cases of influenza treated by contemporary famous old Chinese medicine.",
        "prediction": "SPSS Clementine 2.0 software was used to find connections between the causes of diseases traditional Chinese medicine TCM syndromes and symptoms Additionally the classic Apriori algorithm is helpful for analyzing cases of influenza treated by well-known contemporary Chinese medicine",
        "reference": "SPSS Clementinel2.0 statistical software was used to extract data and find relations between traditional Chinese medicine and other medicine. The classic Apriori algorithm is useful to find cases of influenza treated by old Chinese medicine."
      },
      {
        "source": "Identifying antimicrobial resistant (AMR) bacteria in metagenomics samples is essential for public health and food safety. Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and constructing the correlations between genotype and phenotype in humans and other species. a Bayesian framework for genotype estimation for mixtures of multiple bacteria, named as Genetic Polymorphisms Assignments (GPA) has reduced the false discovery rate (FDR) and mean absolute error (MAE) in single nucleotide variant (SNV) identification.",
        "prediction": "Finding antimicrobial resistant (AMR) bacteria in metagenomics samples is important for public health and food safety. Next-generation sequencing (NGS) technology is a valuable tool that finds genetic differences and helps us understand how genes are connected to traits in humans and other living things. Another method, called Genetic Polymorphisms Assignments (GPA), is used to determine the genetic makeup of various bacteria. This method has improved accuracy by reducing errors in identifying genetic variations.",
        "reference": "Identifying bacterias that are resistant to antimicrobial in samples of genetic material collected from the environment is essential for public health and food safety. Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and constructing the correlations between genotype (genetic code of an individual) and phenotype (physical characteristics of an indvidual) in humans and other species. The Genetic Polymorphism Assignements (GPA) is a framework which determines the genetic constitution of multiple bacteria while reducing the number of false positive results and improving the accuracy of calculations when identifying the variation of a single nucleotide."
      },
      {
        "source": "The CRISPR/Cas9 system was recently developed as a powerful and flexible technology for targeted genome engineering, including genome editing (altering the genetic sequence) and gene regulation (without altering the genetic sequence). These applications require the design of single guide RNAs (sgRNAs) that are efficient and specific. However, this remains challenging, as it requires the consideration of many criteria.",
        "prediction": "The CRISPR/Cas9 system is a new and useful tool for changing genes in specific ways. It can edit the genetic code or control gene activity without changing the code itself. These applications require designing single guide RNAs (sgRNAs) that work well and are precise. However, this remains challenging because it requires considering many criteria.",
        "reference": "The CRISPR/Cas9 system is a powerful technology for gene editing and gene regulation. These applications require the design of single guide RNAs (which are enzymes that can delete, insert or alter DNA) that are efficient and specific. However, this remains challenging, as it requires the consideration of many criteria."
      },
      {
        "source": "The hidden connection between these reports is that gene editing could be used to solve issues related to health care allocation. Improving the health of future generations might coincide with public health goals; it might improve the health of individuals and communities, and, if successful, might be seen as a public good. However, enhancing future generations will require In Vitro Fertilisation and Pre-implantation Genetic Diagnosis. Remarkably, the necessary involvement of women in an enhancing scenario has not been discussed by its proponents. The present discourse on moral obligations of future generations, although not referring to women, seems to imply that women might be required, morally, if not legally, to reproduce with IVF. Enhancing future generations will be gendered, unless the artificial womb is developed. These are challenging issues that require a wider perspective, of both women and men. Despite the lack of a unified feminist conclusion in the discussions about the merits and risks of human genome modification, there is an urgent need to clarify the role of women in this scenario.",
        "prediction": "The hidden connection between these reports is that gene editing could be used to solve issues related to health care allocation. Improving the health of future generations will need methods like In Vitro Fertilization and Pre-implantation Genetic Testing; this might enhance the health of individuals and communities, and, if successful, could be seen as a public good. However, the necessary involvement of women in this enhancement scenario has not been discussed by its proponents. The current discussion on moral obligations towards future generations, although not explicitly mentioning women, seems to imply that women may be required, morally, if not legally, to reproduce using IVF. Enhancing future generations will be gendered unless artificial wombs are developed. These are challenging issues that require broader perspectives from both women and men. Despite the absence of a unified feminist conclusion in the debate about the merits and risks of human genome modification, there is an urgent need to clarify the role of women in this context.",
        "reference": "Gene editing could be used to solve issues related to health care allocation. Improving the health of future generations might coincide with public health goals. However, enhancing future generations will require In Vitro Fertilisation (IVF) and Pre-implantation Genetic Diagnosis. The necessary involvement of women in an enhancing scenario has not been discussed. The discourse on moral obligations of future generations seems to imply that women might be required to reproduce with IVF. Enhancing future generations will be gendered, unless the artificial womb is developed. These are challenging issues that require a wider perspective, of both women and men. There are no unified feminist conclusion about the merits and risks of human genome modification. There is also an urgent need to clarify the role of women in this scenario."
      },
      {
        "source": "CRISPR-Cas is a tool that is widely used for gene editing. However, unexpected off-target effects may occur as a result of long-term nuclease activity. Anti-CRISPR proteins, which are powerful molecules that inhibit the CRISPR-Cas system, may have the potential to promote better utilization of the CRISPR-Cas system in gene editing, especially for gene therapy. Additionally, more in-depth research on these proteins would help researchers to better understand the co-evolution of bacteria and phages. Therefore, it is necessary to collect and integrate data on various types of anti-CRISPRs.",
        "prediction": "CRISPR-Cas is a tool that is widely used for gene editing. However, unexpected off-target effects may occur due to long-term nuclease activity. Anti-CRISPR proteins are strong molecules that can stop the CRISPR-Cas system. They could help improve the use of CRISPR-Cas in gene editing, especially in gene therapy. Additionally, more in-depth research on these proteins would aid researchers in better understanding the co-evolution of bacteria and phages. Therefore, it is necessary to collect and integrate data on various types of anti-CRISPRs.",
        "reference": "CRISPR-Cas is a tool used for gene editing. However, unintended genetic modifications may occur. Anti-CRISPR proteins (molecules that inhibit the CRISPR-Cas system) may improve utilization of the CRISPR-Cas system in gene editing, especially for gene therapy. More research on these proteins would help to understand the co-evolution of bacteria and bacteriophages (virus that infects and replicates within bacteria). It is necessary to collect and integrate data on various types of anti-CRISPRs."
      },
      {
        "source": "CRISPR has become a hot research area ever since its advent for its efficiency and specificity in editing almost every section of DNA sequences. Based on its function of gene perturbation, a variety of gene editing techniques have been developed to achieve different aims. The target locations of a DNA strain can be precisely broken and repaired, during which the genes can be removed, repaired, silenced, or activated. The high efficiency of CRISPR/Cas9 reagents preparation and the easiness of experiment conduction make it now a powerful tool of high-content screen.",
        "prediction": "CRISPR has become a hot research area ever since its advent for its efficiency and specificity in editing almost every section of DNA sequences. Because of how it affects genes, many different gene editing techniques have been created for various purposes. The target locations of a DNA strand can be precisely broken and repaired, allowing genes to be removed, repaired, silenced, or activated. The high efficiency of CRISPR/Cas9 reagent preparation and the ease of conducting experiments make it a powerful tool for high-content screening",
        "reference": "CRISPR is a popular research area known for its efficiency and specificity in editing DNA sequences. A variety of gene editing techniques have been developed for different aims. The target locations of a DNA strain can be precisely broken and repaired, during which the genes can be removed, repaired, silenced, or activated. The high efficiency of CRISPR/Cas9 reagents preparation and the easiness of experiment conduction make it a powerful tool."
      },
      {
        "source": "The CRISPR-Cpf1 system has been successfully applied in genome editing. However, target efficiency of the CRISPR-Cpf1 system varies among different gRNA sequences. Using machine learning technology, a SVM model was created to predict target efficiency for any given gRNAs. the first web service application, CRISPR-DT (CRISPR DNA Targeting), to help users design optimal gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and specificity is available.",
        "prediction": "The CRISPR-Cpf1 system has been successfully applied in genome editing. However, the effectiveness of the CRISPR-Cpf1 system can vary among different gRNA sequences. Using computer algorithms, a model was created to predict how well different gRNAs will work. Additionally, the first web service application, CRISPR-DT (CRISPR DNA Targeting), is available to help users design optimal gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and specificity.",
        "reference": "The CRISPR-Cpf1 system (a DNA-editing technology) has been successfully applied in gene editing. However target efficiency of the CRISPR-Cpf1 system varies among different gRNA (piece of RNA that serves as a guide to DNA-targeting enzymes) sequences. Using machine learning technology, a support-vector machine model (algorithm used for data classification) was created to predict the target efficiency for any given gRNAs. CRISPR-DT (CRISPR DNA Targeting) is available. It is the first web service application to help users design optimal gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and target specificity (recognition mecanism)."
      },
      {
        "source": "Emerging self-driving vehicles are vulnerable to different attacks due to the principle and the type of communication systems that are used in these vehicles. These vehicles are increasingly relying on external communication via vehicular ad hoc networks (VANETs). VANETs add new threats to self-driving vehicles that contribute to substantial challenges in autonomous systems. These communication systems render self-driving vehicles vulnerable to many types of malicious attacks, such as Sybil attacks, Denial of Service (DoS), black hole, grey hole and wormhole attacks. In this paper, we propose an intelligent security system designed to secure external communications for self-driving and semi self-driving cars. The hybrid detection system relies on the Back Propagation neural networks (BP), to detect a common type of attack in VANETs: Denial-of-Service (DoS). The experimental results show that the proposed BP-IDS is capable of identifying malicious vehicles in self-driving and semi self-driving vehicles.",
        "prediction": "Emerging self-driving vehicles are vulnerable to different attacks due to the principles and types of communication systems used in these vehicles. These vehicles are increasingly relying on external communication through vehicular ad hoc networks (VANETs), which introduce new threats and create significant challenges for autonomous systems. These communication systems make self-driving vehicles open to various harmful attacks, including Sybil attacks, Denial of Service (DoS), and black hole, grey hole, and wormhole attacks. In this paper, we propose an intelligent security system designed to protect external communications for self-driving and semi-self-driving cars. The hybrid detection system uses Back Propagation neural networks (BP) to identify common attacks in VANETs, particularly Denial-of-Service (DoS). Experimental results show that the proposed BP-IDS can effectively identify malicious vehicles in both self-driving and semi-self-driving vehicles.",
        "reference": "Self-driving vehicles are vulnerable to different attacks because of their communication systems. These vehicles use external communication via a network. This network add new threats to self-driving vehicles that contribute to the challenges in autonomous systems. With these communication systems, self-driving vehicles are vulnerable to many types of malicious attacks on the network. In this paper, we propose an intelligent security system to secure external communications for self-driving cars. The system will detect a common type of attack in the network: Denial-of-Service (attack trying to make network resource unavailable). The results show that the intrusion detection system is capable of identifying malicious vehicles in self-driving vehicles."
      },
      {
        "source": "Self-driving vehicle technologies are progressing rapidly and are expected to play a significant role in the future of transportation. One of the main challenges for self-driving vehicles on public roads is the safe cooperation and collaboration among multiple vehicles using sensor-based perception and inter-vehicle communications. When self-driving vehicles try to occupy the same spatial area simultaneously, they might collide with one another, might become deadlocked, or might slam on the brakes making it uncomfortable or unsafe for passengers in a self-driving vehicle. In this paper, we study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet. We present a safe protocol for merge points named Autonomous Vehicle Protocol for Merge Points, where self-driving vehicles use both vehicular communications and their own perception systems for cooperating with other self-driving and/or human-driven vehicles. Our simulation results show that our traffic protocol has higher traffic throughput, compared to simple traffic protocols, while ensuring safety.",
        "prediction": "Self-driving vehicle technologies are progressing rapidly and are expected to play a significant role in the future of transportation. One of the biggest challenges for self-driving cars on public roads is how to safely work together with other cars using sensors and communication systems. When these vehicles try to occupy the same space at the same time, they might collide, become deadlocked, or slam on the brakes, making it uncomfortable or unsafe for passengers. In this paper, we study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet. We present a safe protocol for these merge points called the Autonomous Vehicle Protocol for Merge Points. This protocol enables self-driving vehicles to cooperate using both vehicular communications and their own perception systems with other self-driving and human-driven vehicles. Our simulation results show that this traffic protocol has higher traffic throughput compared to simpler protocols, while also ensuring safety.",
        "reference": "Self-driving vehicle technologies are progressing and are expected to play a significant role in the future of transportation. A main challenge for self-driving vehicles on public roads is the safe cooperation, collaboration and communication with other vehicles. When self-driving vehicles are in the same area, they might collide, become blocked, or suddenly brake and make uncomfortable or unsafe the passengers. We study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet. We present a safe protocol where self-driving vehicles use both vehicular communications and their own perception systems for cooperating with other vehicles (self-driving or human-driven). Our simulation results show that our traffic protocol leads to a better traffic flow, while ensuring safety."
      },
      {
        "source": "This paper provides a holistic study of how stock prices vary in their response to financial disclosures across different topics. Thereby, we specifically shed light into the extensive amount of filings for which no a priori categorization of their content exists. For this purpose, we utilize an approach from data mining - namely, latent Dirichlet allocation - as a means of topic modeling. This technique facilitates our task of automatically categorizing, ex ante, the content of more than 70,000 regulatory 8-K filings from U.S. companies. We then evaluate the subsequent stock market reaction. Our empirical evidence suggests a considerable discrepancy among various types of news stories in terms of their relevance and impact on financial markets. For instance, we find a statistically significant abnormal return in response to earnings results and credit rating, but also for disclosures regarding business strategy, the health sector, as well as mergers and acquisitions. Our results yield findings that benefit managers, investors and policy-makers by indicating how regulatory filings should be structured and the topics most likely to precede changes in stock valuations.",
        "prediction": "This paper provides a holistic study of how stock prices vary in their response to financial disclosures across different topics. We specifically shed light on the extensive amount of filings for which no prior categorization of their content exists. We use a data mining method called latent Dirichlet allocation to help organize topics. This technique allows us to automatically categorize the content of more than 70,000 regulatory 8-K filings from U.S. companies. We then evaluate the subsequent stock market reaction. Our empirical evidence suggests a considerable discrepancy among various types of news stories in terms of their relevance and impact on financial markets. For instance, we find a statistically significant abnormal return in response to earnings results and credit ratings, as well as disclosures regarding business strategy, the health sector, and mergers and acquisitions. Our results provide valuable insights for managers, investors, and policy-makers by indicating how regulatory filings should be structured and which topics are most likely to affect changes in stock valuations.",
        "reference": "This paper studies how stock prices vary with financial disclosures. We particularly study the many uncategorized filings. We use latent Dirichlet allocation for topic modeling. This helps automatically predict the categories based on the content of 70,000 regulatory 8-K filings from U.S. companies, which announce significant events relevant to shareholders. We then evaluate the stock market reaction. Evidence suggests a large difference among types of news stories in relevance and impact on financial markets. For example, we find unusual returns in response to disclosures about earnings results, credit rating, business strategy, the health sector, mergers and acquisitions. Our results are useful for managers, investors and policy-makers. They show how to structure regulatory filings and which topics influence stock valuations."
      },
      {
        "source": "A significant problem of using deep learning techniques is the limited amount of data available for training. There are some datasets available for the popular problems like item recognition and classification for self-driving cars, however, it is very limited for the industrial robotics field. In previous work, we have trained a multi-objective Convolutional Neural Network (CNN) to identify the robot body in the image and estimate 3D positions of the joints by using just a 2D image, but it was limited to a range of robots produced by Universal Robots (UR). In this work, we extend our method to work with a new robot arm - Kuka LBR iiwa, which has a significantly different appearance and an additional joint. However, instead of collecting large datasets once again, we collect a number of smaller datasets containing a few hundred frames each and use transfer learning techniques on the CNN trained on UR robots to adapt it to a new robot having different shapes and visual features. We have proven that transfer learning is not only applicable in this field, but it requires smaller well-prepared training datasets, trains significantly faster and reaches similar accuracy compared to the original method, even improving it on some aspects.",
        "prediction": "A significant problem of using deep learning techniques is the limited amount of data available for training. While there are some datasets for popular tasks like item recognition and classification for self-driving cars, the data is very limited in the industrial robotics field. In previous work, we trained a type of deep learning model called a Convolutional Neural Network (CNN) to recognize the robot's body in pictures and estimate the 3D positions of its joints using only 2D images. However, this method was limited to a specific range of robots produced by Universal Robots (UR).\n\nIn this work, we extend our method to a new robot arm - the Kuka LBR iiwa, which has a significantly different appearance and an additional joint. Rather than collecting large datasets again, we gather several smaller datasets, each containing a few hundred frames. We then use transfer learning techniques on the CNN trained on UR robots to adapt it to the new robot with different shapes and visual features.\n\nWe have shown that transfer learning is not only applicable in this field, but it also requires smaller, well-prepared training datasets, trains significantly faster, and achieves similar or even improved accuracy compared to the original method in certain aspects.",
        "reference": "Limited data available for training affects the use of deep learning techniques. Datasets are available for problems such as item recognition and classification for self-driving cars, but very limited for industrial robotics. A multi-objective Convolutional Neural Network (CNN) was first trained to identify the robot in the image and find 3D positions of the joints using just a 2D image. But this only used robots made by Universal Robots (UR). Here we work with a new robot arm - Kuka LBR iiwa which looks very different and has an additional joint. We collect a number of smaller datasets and use transfer learning techniques on the CNN trained on UR robots to adapt it to a robot that looks different. Transfer learning requires smaller training datasets, learns faster and reaches similar or even better accuracy."
      },
      {
        "source": "We introduce Ignition: an end-to-end neural network architecture for training unconstrained self-driving vehicles in simulated environments. The model is a ResNet-18 variant, which is fed in images from the front of a simulated F1 car, and outputs optimal labels for steering, throttle, braking. Importantly, we never explicitly train the model to detect road features like the outline of a track or distance to other cars; instead, we illustrate that these latent features can be automatically encapsulated by the network.",
        "prediction": "We introduce Ignition an end-to-end neural network architecture for training unconstrained self-driving vehicles in simulated environments The model is a type of ResNet-18 which receives images from the front of a simulated F1 car and produces the best instructions for steering acceleration and braking Importantly we never explicitly train the model to detect road features like the outline of a track or the distance to other cars instead we show that these important features can be automatically captured by the network",
        "reference": "Ignition is a neural network for training unconstrained self-driving vehicles in simulated environments. This ResNet-18 variant model receives images from the front of a simulated car and uses them to steer, throttle, or brake appropriately. The model is not explicitly trained to detect road features such as track outline or distance to other cars, as these features can automatically be calculated by the network."
      },
      {
        "source": "As for the humanoid robots, the internal noise, which is generated by motors, fans and mechanical components when the robot is moving or shaking its body, severely degrades the performance of the speech recognition accuracy. In this paper, a novel speech recognition system robust to ego-noise for humanoid robots is proposed, in which on/off state of the motor is employed as auxiliary information for finding the relevant input features. For this, we consider the bottleneck features, which have been successfully applied to deep neural network (DNN) based automatic speech recognition (ASR) system. When learning the bottleneck features to catch, we first exploit the motor on/off state data as supplementary information in addition to the acoustic features as the input of the first deep neural network (DNN) for preliminary acoustic modeling. Then, the second DNN for primary acoustic modeling employs both the bottleneck features tossed from the first DNN and the acoustics features. When the proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, the experimental results show that achieve obvious improvement (11% relative) is achieved by our algorithm over the conventional systems.",
        "prediction": "As for the humanoid robots, the internal noise generated by motors, fans, and mechanical components when the robot is moving or shaking its body severely degrades the performance of speech recognition accuracy. This paper presents a new speech recognition system for humanoid robots that works well in noisy environments. It uses the motor's on/off status to help find important input features. We consider bottleneck features, which have been successfully applied to deep neural network (DNN)-based automatic speech recognition (ASR) systems. \n\nWhen learning these bottleneck features, we first use the motor on/off state data as additional information, along with acoustic features, as the input for the first deep neural network (DNN) for preliminary acoustic modeling. Then, the second DNN for primary acoustic modeling combines the bottleneck features from the first DNN with the acoustic features. \n\nWhen we evaluate the proposed method in terms of phoneme error rate (PER) on the TIMIT database, the experimental results show that our algorithm achieves a significant improvement of 11% relative to conventional systems.",
        "reference": "Internal noise generated by motors, fans and mechanical components severely decreases speech recognition accuracy, when the humanoid robot is moving or shaking its body. This paper presents a novel speech recognition system robust to ego-noise for humanoid robots. On/off state of the motor is used to find relevant input features. Bottleneck features have been successfully applied to automatic speech recognition (ASR) systems based on deep neural networks (DNN). The motor on/off state data and acoustic features are used as the input of the first deep neural network (DNN) for preliminary acoustic modeling. The second DNN for primary acoustic modeling uses both bottleneck features from the first DNN and acoustic ones. The proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, experimental results show that improvement (11% relative) is achieved by our algorithm over the conventional systems."
      },
      {
        "source": "Recognizing Traffic Signs using intelligent systems can drastically reduce the number of accidents happening world-wide. With the arrival of Self-driving cars it has become a staple challenge to solve the automatic recognition of Traffic and Hand-held signs in the major streets. Various machine learning techniques like Random Forest, SVM as well as deep learning models has been proposed for classifying traffic signs. Though they reach state-of-the-art performance on a particular data-set, but fall short of tackling multiple Traffic Sign Recognition benchmarks. In this paper, we propose a novel and one-for-all architecture that aces multiple benchmarks with better overall score than the state-of-the-art architectures. Our model is made of residual convolutional blocks with hierarchical dilated skip connections joined in steps. With this we score 99.33% Accuracy in German sign recognition benchmark and 99.17% Accuracy in Belgian traffic sign classification benchmark. Moreover, we propose a newly devised dilated residual learning representation technique which is very low in both memory and computational complexity.",
        "prediction": "Recognizing Traffic Signs using intelligent systems can drastically reduce the number of accidents happening worldwide. With the arrival of self-driving cars, it has become a significant challenge to solve the automatic recognition of traffic and hand-held signs on major streets. Different machine learning methods, such as Random Forest, Support Vector Machines (SVM), and deep learning models, have been suggested for recognizing traffic signs. Although these methods achieve state-of-the-art performance on specific datasets, they fall short of addressing multiple Traffic Sign Recognition benchmarks. \n\nIn this paper, we propose a novel and all-in-one architecture that excels in multiple benchmarks with a better overall score than existing state-of-the-art architectures. Our model consists of residual convolutional blocks with hierarchical dilated skip connections. Using this approach, we achieved 99.33% accuracy in the German sign recognition benchmark and 99.17% accuracy in the Belgian traffic sign classification benchmark. Additionally, we introduce a newly devised dilated residual learning representation technique that is very low in both memory and computational complexity.",
        "reference": "If intelligent systems recognize traffic signs, it can reduce car accidents. For self-driving cars, we need automatic recognition of traffic and hand signs. Machine learning techniques  could be used to classify traffic signs. They perform well on a particular dataset, but fail on multiple traffic sign recognition test datasets. We proposed a new and better method. This model is based on enhanced convolutional neural networks (a deep-learning approach often used for image recognition). This model was more than 99% correct on German and Belgian sign recognition datasets. This new model is very low in both memory and computational complexity."
      },
      {
        "source": "In this paper, we present a transfer learning method for the end-to-end control of self-driving cars, which enables a convolutional neural network (CNN) trained on a source domain to be utilized for the same task in a different target domain. A conventional CNN for the end-to-end control is designed to map a single front-facing camera image to a steering command. To enable the transfer learning, we let the CNN produce not only a steering command but also a lane departure level (LDL) by adding a new task module, which takes the output of the last convolutional layer as input. The CNN trained on the source domain, called source network, is then utilized to train another task module called target network, which also takes the output of the last convolutional layer of the source network and is trained to produce a steering command for the target domain. The steering commands from the source and target network are finally merged according to the LDL and the merged command is utilized for controlling a car in the target domain. To demonstrate the effectiveness of the proposed method, we utilized two simulators, TORCS and GTAV, for the source and the target domains, respectively. Experimental results show that the proposed method outperforms other baseline methods in terms of stable and safe control of cars.",
        "prediction": "In this paper, we present a transfer learning method for the end-to-end control of self-driving cars. This method allows a convolutional neural network (CNN) trained on a source domain to be utilized for the same task in a different target domain. A conventional CNN for end-to-end control is designed to map a single front-facing camera image to a steering command. To enable transfer learning, we have the CNN produce two outputs: a steering command and a lane departure level (LDL). We achieve this by adding a new part that uses the output from the last layer of the CNN. The CNN trained on the source domain, known as the source network, is then used to train another module called the target network. This target network also takes the output from the last convolutional layer of the source network and is trained to produce a steering command for the target domain. The steering commands from the source and target networks are finally merged based on the LDL, and the combined command is used to control a car in the target domain. To demonstrate the effectiveness of the proposed method, we utilized two simulators, TORCS and GTAV, for the source and target domains, respectively. Experimental results show that our method outperforms other baseline methods in terms of stable and safe control of cars.",
        "reference": "A transfer learning method to control self-driving cars is proposed, in which a convolutional neural network (CNN) is trained on one domain then used for the same task in a different domain. A conventional CNN is designed to map a single front-facing camera image to control a car. CNN produces a steering command and a lane departure level (LDL, mechanism designed to warn the driver when the vehicle begins to move out of its lane). To enable the transfer learning, a new task module takes the output of the last convolutional layer as input. The CNN trained on the source domain is then used to train the target network. It takes the output of the last convolutional layer of the source network and is trained to produce a steering command for the target domain. The steering commands from the source and target network are merged and used for car control in the target domain. Two simulators were used to evaluate the proposed method. The proposed method is more stable and safer for car control."
      },
      {
        "source": "This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE), a novel minimal simulation of a centralised financial market, based on a Limit Order Book (LOB) such as is common in major stock exchanges. Construction of BSE was motivated by the fact that most of the worldâs major financial markets have automated, with trading activity that previously was the responsibility of human traders now being performed by high-speed autonomous automated trading systems. Research aimed at understanding the dynamics of this new style of financial market is hampered by the fact that no operational real-world exchange is ever likely to allow experimental probing of that market while it is open and running live, forcing researchers to work primarily from time-series of past trading data. Similarly, university-level education of the engineers who can create next-generation automated trading systems requires that they have hands-on learning experience in a sufficiently realistic teaching environment. BSE as described here addresses both those needs: it has been successfully used for teaching and research in a leading UK university since 2012, and the BSE program code is freely available as open-source on GitHuB.",
        "prediction": "This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE), a novel minimal simulation of a centralised financial market based on a Limit Order Book (LOB) common in major stock exchanges. The construction of BSE was motivated by the fact that most of the worldâs major financial markets have automated, with trading activities that were once the responsibility of human traders now performed by high-speed autonomous trading systems. \n\nResearch on understanding how this new type of financial market works is difficult because no real-world exchange will allow experiments while it is open. As a result, researchers mainly rely on historical trading data. Moreover, university-level education for engineers who can create next-generation automated trading systems requires hands-on learning experience in a sufficiently realistic teaching environment. BSE addresses both of these needs: it has been successfully used for teaching and research at a leading UK university since 2012, and the BSE program code is freely available as open-source on GitHub.",
        "reference": "This paper describes the Bristol Stock Exchange (BSE), a minimal simulation of a centralised financial market based on a Limit Order Book (LOB), a type of order to buy or sell a security at a specific price or better. BSE was built because most of the financial markets became automated. Research tries to understand the dynamics of this automated financial markets but Trainee engineers also need a realistic learning experience to build automated trading systems. BSE has been successfully used for both teaching and research since 2012. BSE code is freely available on GitHuB."
      },
      {
        "source": "Once self-driving car becomes a reality and passengers are no longer worry about it, they will need to find new ways of entertainment. The simulation results show that the accuracy of our prediction for the contents need to be cached in the areas of the self-driving car is achieved at 98.04% and our approach can minimize delay. However, retrieving entertainment contents at the Data Center (DC) can hinder content delivery service due to high delay of car-to-DC communication. To address these challenges, we propose a deep learning based caching for self-driving car, by using Deep Learning approaches deployed on the Multi-access Edge Computing (MEC) structure. First, at DC, Multi-Layer Perceptron (MLP) is used to predict the probabilities of contents to be requested in specific areas. To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units. Second, in order to cache entertainment contents stylized for car passengersâ features such as age and gender, Convolutional Neural Network (CNN) is used to predict age and gender of passengers. Through this, the self-driving car can identify the contents need to be downloaded from the MEC server and cached. Finally, we formulate deep learning based caching in the self-driving car that enhances entertainment services as an optimization problem whose goal is to minimize content downloading delay. To solve the formulated problem, a Block Successive Majorization-Minimization (BS-MM) technique is applied.",
        "prediction": "Once self-driving cars become a reality and passengers no longer worry about them, they will need to find new ways of entertainment. The simulation results show that the accuracy of our prediction for the contents that need to be cached in the areas of the self-driving car is achieved at 98.04%, and our approach can minimize delay. However, retrieving entertainment contents at the Data Center (DC) can hinder content delivery services due to the high delay of car-to-DC communication. To address these challenges, we suggest a caching system for self-driving cars that uses deep learning methods on a Multi-access Edge Computing (MEC) setup.\n\nFirst, at the DC, a Multi-Layer Perceptron (MLP) is used to predict the probabilities of contents that will be requested in specific areas. To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units. Second, to cache entertainment contents tailored to car passengersâ features such as age and gender, a Convolutional Neural Network (CNN) is used to predict the age and gender of passengers. Through this process, the self-driving car can determine which contents need to be downloaded from the MEC server and cached. Finally, we formulate deep learning-based caching in the self-driving car as an optimization problem aimed at minimizing content downloading delay. To solve this problem, we apply a Block Successive Majorization-Minimization (BS-MM) technique.",
        "reference": "Once self-driving cars become reality and passengers no longer worry about it, they will need to find other forms of entertainment. Prediction accuracy was 98.04% for contents to be cached for self-driving cars. Such an approach can minimize delay. However, high communication delay can slow retrieval of entertainment content from Data Centers (DC). Self-driving cars can use deep learning caching to address these challenges. It is deployed on the Multi-access Edge Computing (MEC) structure that moves services from a centralized cloud to the network edges and closer to the customer. Multi-Layer Perceptron (MLP), a type of artificial neural network, is used to predict the content requested in specific areas. To reduce delay, MLP outputs are sent to MEC servers for roadside units. A Convolutional Neural Network (CNN) is used to predict passengersâ age and gender to cache adapted entertainment content. The self-driving car can therefore identify the contents to be downloaded and cached. Deep learning caching is formulated for the self-driving car to enhance entertainment services and minimize content downloading delay. A Block Successive Majorization-Minimization (BS-MM) technique solves the problem."
      },
      {
        "source": "Moral responsibility is a major concern in automated decision-making, with applications ranging from self-driving cars to kidney exchanges.",
        "prediction": "Moral responsibility is a major concern in decisions made by machines such as self-driving cars and kidney exchanges",
        "reference": "Moral responsibility is a major concern in automated decision-making, from self-driving cars to kidney transplants."
      },
      {
        "source": "A key problem for autonomous car navigation is the understanding, at an object level, of the current driving situation. Addressing this issue requires the extraction of meaningful information from on-board stereo imagery by classifying the fundamental elements of urban scenes into semantic categories that can more easily be interpreted and be reflected upon (streets, buildings, pedestrians, vehicles, signs, etc.). A probabilistic method is proposed to fuse a coarse prior 3D map data with stereo imagery classification. A novel fusion architecture based on the Stixel framework is presented for combining semantic pixel-wise segmentation from a convolutional neural network (CNN) with depth information obtained from stereo imagery while integrating coarse prior depth and label information. The proposed approach was tested on a manually labeled data set in urban environments. The results show that the classification accuracy of the fundamental elements composing the urban scene was significantly enhanced by this method compared to what is obtained from the semantic pixel-wise segmentation of a CNN alone.",
        "prediction": "A key problem for autonomous car navigation is the understanding, at an object level, of the current driving situation. Addressing this issue requires the extraction of meaningful information from on-board stereo imagery by classifying the fundamental elements of urban scenes into semantic categories that can more easily be interpreted and reflected upon streets, buildings, pedestrians, vehicles, signs, etc. A method based on probability is suggested to combine rough 3D map data with the classification of stereo images. A novel fusion architecture based on the Stixel framework is presented for merging semantic pixel-wise segmentation from a convolutional neural network CNN with depth information obtained from stereo imagery while integrating coarse prior depth and label information. The proposed approach was tested on a manually labeled data set in urban environments. The results show that the classification accuracy of the fundamental elements composing the urban scene was significantly enhanced by this method compared to what is obtained from the semantic pixel-wise segmentation of a CNN alone.",
        "reference": "A key problem for autonomous car navigation is the understanding of the environment while driving. It needs to extract information from the sensors and cameras and classify the elements into categories so it can be easily analysed (streets, buildings, pedestrians, vehicles, signs, etc.). A method is to fuse 3D map data with classification of the sensors and cameras. This system combine image segmentation (simplify the representation of an image to facilitate its analysis) and information obtained from sensors and cameras while integrating prior information. This approach was tested on manually entered data in urban environments. The results show that the classification of elements is more accurate with this method than the image segmentation alone."
      },
      {
        "source": "This paper proposes a MATLAB/Simulink benchmark suite for an open-source self-driving system based on Robot Operating System (ROS). One approach to the development of self-driving systems is the utilization of ROS which is an open-source middleware framework used in the development of robot applications. On the other hand, the popular approach in the automotive industry is the utilization of MATLAB/Simulink which is software for modeling, simulating, and analyzing. MATLAB/Simulink provides an interface between ROS and MATLAB/Simulink that enables to create functionalities of ROS-based robots in MATLAB/Simulink. However, it is not been fully utilized in the development of self-driving systems yet because there are not enough samples for self-driving, and it is difficult for developers to adopt co-development. Therefore, we provide a MATLAB/Simulink benchmark suite for a ROS-based self-driving system called Autoware. Autoware is popular open-source software that provides a complete set of self-driving modules. The provided benchmark contains MATLAB/Simulink samples available in Autoware. They help to design ROS-based self-driving systems using MATLAB/Simulink.",
        "prediction": "This paper proposes a MATLAB/Simulink benchmark suite for an open-source self-driving system based on the Robot Operating System (ROS) One approach to developing self-driving systems is the use of ROS which is an open-source middleware framework for robot application development Alternatively the common method used in the automotive industry is MATLAB/Simulink software for modeling simulating and analyzing MATLAB/Simulink provides an interface between ROS and itself enabling the creation of functionalities for ROS-based robots in MATLAB/Simulink However it has not yet been fully utilized in developing self-driving systems due to a lack of samples and challenges in co-development Therefore we provide a MATLAB/Simulink benchmark suite for a ROS-based self-driving system called Autoware Autoware is popular open-source software that offers a complete set of self-driving modules The benchmark includes MATLAB/Simulink samples available in Autoware which assist in designing ROS-based self-driving systems using MATLAB/Simulink",
        "reference": "This paper proposes MATLAB/Simulink tests for an open-source self-driving system based on Robot Operating System. One approach to the development of self-driving systems is the utilization of Robot Operating System (open-source software framework used in the development of robot applications). But the popular approach in the automotive industry is the utilization of MATLAB/Simulink (software for modeling, simulating, and analyzing). MATLAB/Simulink provides an interface that enables to create functionalities of robots (based on robot operating system). However, it is not fully utilized in the development of self-driving systems yet because there are not enough samples, and it is difficult for developers to adopt co-development. We provide MATLAB/Simulink tests for a self-driving system (based on robot operating system) called Autoware. Autoware is a popular open-source software that provides a complete set of self-driving modules. The provided tests contain MATLAB/Simulink samples available in Autoware. They help to design self-driving systems (based on robot operating system) using MATLAB/Simulink."
      },
      {
        "source": "The management of self-driving systems is becoming more complex as the development of self-driving technology progresses. One approach to the development of self-driving systems is the use of ROS; however, the system used in the automotive industry is typically designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving. These models are incompatible with ROS-based systems. To allow the two to be used in tandem, it is necessary to rewrite the C++ code and incorporate them into the ROS-based system, which makes development inefficient. Therefore, the proposed framework allows models created using MATLAB/Simulink to be used in a ROS-based self-driving system, thereby improving development efficiency. Furthermore, our evaluations of the proposed framework demonstrated its practical potential.",
        "prediction": "The management of self-driving systems is becoming more complex as the development of self-driving technology progresses. One approach to developing these systems is the use of ROS; however, the automotive industry typically uses MATLAB/Simulink to design systems, which can simulate and evaluate models for self-driving. These models are not compatible with ROS-based systems. To use both together, the C++ code needs to be rewritten and added to the ROS system, which slows down development. Therefore, the proposed framework allows models created using MATLAB/Simulink to work in a ROS-based self-driving system, thereby improving development efficiency. Furthermore, our evaluations of the proposed framework demonstrated its practical potential.",
        "reference": "The management of self-driving systems is becoming more complex as the development of self-driving technology progresses. Self-driving systems use Robot Operating System (open-source software framework used in the development of robot applications). However, in the automotive industry, the system is designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving. These models are incompatible with systems based on Robot Operating System. To use both, it is necessary to incorporate new code into the system based on Robot Operating System, which makes development inefficient. Therefore, the proposed framework allows models created using MATLAB/Simulink to be used in a self-driving system, which improve development efficiency. Furthermore, our evaluations of the proposed framework demonstrated its practical potential."
      },
      {
        "source": "Ensuring the safety of self-driving cars is important, but neither industry nor authorities have settled on a standard way to test them. Deploying self-driving cars for testing in regular traffic is a common, but costly and risky method, which has already caused fatalities. As a safer alternative, virtual tests, in which self-driving car software is tested in computer simulations, have been proposed. One cannot hope to sufficiently cover the huge number of possible driving situations self-driving cars must be tested for by manually creating such tests. Therefore, we developed AsFault, a tool for automatically generating virtual tests for systematically testing self-driving car software. We demonstrate AsFault by testing the lane keeping feature of an artificial intelligence-based self-driving car software, for which AsFault generates scenarios that cause it to drive off the road. A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw",
        "prediction": "Ensuring the safety of self-driving cars is important, but neither industry nor authorities have settled on a standard way to test them. Testing self-driving cars on regular roads is common, but it is expensive and dangerous, having led to deaths. As a safer alternative, virtual tests, where self-driving car software is tested in computer simulations, have been proposed. One cannot sufficiently cover the huge number of possible driving situations that self-driving cars must be tested for by manually creating such tests. Therefore, we developed AsFault, a tool for automatically generating virtual tests for systematically testing self-driving car software. We demonstrate AsFault by testing the lane-keeping feature of an artificial intelligence-based self-driving car software, generating scenarios that cause it to drive off the road. A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw",
        "reference": "Ensuring the safety of self-driving cars is important, but there is no standard way to test them. Testing self-driving cars in regular traffic is costly and risky, and has already caused fatalities. As a safer alternative, virtual tests (self-driving car software tested in computer simulations) have been proposed. To cover the huge number of possible driving situations, self-driving cars must be tested in manually created tests. We developed AsFault, a tool for automatically generating virtual tests for testing self-driving car software. We demonstrate AsFault by testing the lane keeping feature of a self-driving car software with scenarios going off the road. A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw"
      },
      {
        "source": "With the developing of the technology on self-driving, more and more L3 driverless vehicles are launched in market, people get opportunities to experience the self-driving cars in their daily life. As a result, there is a growing demand for the autopilot experience. Natural and efficient human-computer interaction can not only improve the driving experience, but also accelerate the process of self-driving commercialization. This paper discusses eye-movement interaction, voice interaction and gesture interaction in self-driving car, and analyzes the technology, advantages and disadvantages of the existing interaction modes, and prospect the future development trend of self-driving human-computer interaction.",
        "prediction": "With the developing technology of self-driving cars, more and more L3 driverless vehicles are launched in the market, giving people opportunities to experience self-driving cars in their daily lives. As a result, there is a growing demand for the autopilot experience. Good human-computer interaction can improve the driving experience and help self-driving technology become common more quickly. This paper discusses eye-movement, voice, and gesture interactions in self-driving cars, analyzes the technology, advantages, and disadvantages of the existing interaction modes, and explores the future development trend of self-driving human-computer interaction",
        "reference": "Self-driving technology is developing, more and more driverless vehicles are launched in market and accessible for people in their daily life. So there is a growing demand for the autopilot experience. Natural and efficient human-computer interaction can improve the driving experience and accelerate the process of self-driving commercialization. This paper discusses interactions with the eye, voice and gesture in self-driving car, analyzes the technology, the interaction modes, and considers the future of self-driving human-computer interaction."
      },
      {
        "source": "In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems. Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on highfidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle. It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios. The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1]. In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using vision-based imitation learning we obtain safer self-driving behavior.",
        "prediction": "In recent years self-driving vehicles have become more commonplace on public roads promising to bring safety and efficiency to modern transportation systems To increase the reliability of these vehicles on the road an extensive suite of software tests is required ideally performed on high-fidelity simulators where multiple vehicles and pedestrians interact with the self-driving vehicle It is therefore critical to ensure that self-driving software is tested against a wide range of challenging simulated driving scenarios The latest methods for creating these driving scenarios used by leading companies in the self-driving car industry still depend on human input In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies and increase the risk of collisions with simulated pedestrians and vehicles We show that by incorporating the generated scenarios into the training set of the self-driving policy and fine-tuning the policy using vision-based imitation learning we can achieve safer self-driving behavior",
        "reference": "Self-driving vehicles have become common on public roads, with the promise of a safe and efficient mode of transport. To be reliable, these vehicles need many software tests on simulators with interactions of multiple vehicles and pedestrians. It is essential that self-driving software is evaluated with many different challenging driving scenarios. The driving scenario generation still needs human contribution. We propose to automate the process and generate conflicting self-driving that expose weaknesses of self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. By incorporating the generated scenarios into the parameters of the self-driving policy, and by adjusting the policy with the imitation learning, we obtain safer self-driving behavior."
      },
      {
        "source": "At the brink of the introduction of self-driving vehicles, only little is known about how potential users perceive them. This is especially true for self-driving vehicles deployed in public transport services. In this study, the relative preferences for a trip with a self-driving bus is assessed compared to a trip with a regular bus, based on a stated preference experiment. Based on the responses of 282 respondents from the Netherlands and Germany, a discrete choice model is estimated as a Mixed Logit model including attitudes towards trust in self-driving vehicles and interest in technology. The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips. This is due to the finding that the value of travel time is about twice as high for the self-driving bus as for the regular bus for a short commuting trip. Findings from this study further suggest that the popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes. People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others. Preferences towards automated public transport services are expected to evolve along with the transition from demonstration pilots to their deployment in regular operations.",
        "prediction": "At the brink of the introduction of self-driving vehicles, only little is known about how potential users perceive them. This is especially true for self-driving vehicles deployed in public transport services. In this study, the relative preferences for a trip with a self-driving bus are assessed compared to a trip with a regular bus, based on a stated preference experiment. Using answers from 282 people in the Netherlands and Germany, we created a model that examines how much they trust self-driving vehicles and their interest in technology. The results show that public transport passengers currently prefer the self-driving bus over the regular bus only for short trips. This is because the time spent traveling on the self-driving bus is valued at about twice as much as the time on the regular bus for short trips. Findings from this study further suggest that the popularity of self-driving buses decreases with the presence of a human steward on board or if they are operated as a demand-responsive service with fixed routes. People who show a strong interest in technology or trust in automated vehicle technology tend to view the self-driving buses more positively than others. Preferences for automated public transport services are expected to evolve as the transition from demonstration pilots to their regular operation occurs.",
        "reference": "Little is known about how potential users perceive self-driving vehicles. This is especially true for self-driving vehicles in public transport services. In this study, the preferences between a trip in a self-driving bus and a regular bus were compared. The results of 282 participants were studied, including trust in self-driving vehicles and interest in technology. The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips. The preference is about twice as high for the self-driving bus as for the regular bus for a short commuting trip. The popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes. People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others. Preferences for automated public transport services are expected to evolve with their deployment in regular operations."
      },
      {
        "source": "In the wake of the on-going digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions. While the benefits of this transformation can be massive, there are also tremendous risks to our society. After the automation of many production processes and the creation of self-driving vehicles, the automation of society is next. This is moving us to a tipping point and to a crossroads: we must decide between a society in which the actions are determined in a top-down way and then implemented by coercion or manipulative technologies (such as personalized ads and nudging) or a society, in which decisions are taken in a free and participatory way and mutually coordinated. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. The fundaments of human dignity, autonomous decision-making, and democracies are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies, but also the basis of greater efficiency and success.",
        "prediction": "In the wake of the ongoing digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions. While the benefits of this transformation can be massive, there are also tremendous risks to our society. After the automation of many production processes and the creation of self-driving vehicles, the automation of society is next. This is moving us to a tipping point and to a crossroads: we must choose between a society where leaders make decisions enforced through pressure or persuasive technologies like targeted ads and nudging and a society where decisions are made freely with everyone working together. Modern information and communication systems ICT enable both options but favor the latter for economic and strategic reasons. The foundations of human dignity, autonomous decision-making, and democracies are shaking but I believe they need to be vigorously defended as they are not only core principles of livable societies but also the basis for greater efficiency and success.",
        "reference": "The on-going digital revolution will dramatically transform our economy and societal institutions. But this also presents risks for our society. Automation of society is coming. We must choose either between a society in which the actions are determined top-down by coercion or manipulative technologies (such as personalized ads) or in which decisions are taken freely and cooperatively. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. Foundations of human dignity, autonomous decision-making, and democracies are weakening. These core principles of society and the basis of greater efficiency and success need to be defended."
      },
      {
        "source": "This paper addresses the financial markets problem space with particular emphasis on trading systems seen in banking today. With the advent of modern computing, cross-regional trading transactions can now be executed within milliseconds, a reality that is impossible without the advancements of software systems technology. We then move on and discuss the anatomy of a trading system and how it fits in with the banks ecosystem of vital inter-working components.",
        "prediction": "This paper addresses the financial markets problem space with particular emphasis on trading systems seen in banking today. Thanks to modern computers, trading transactions between different regions can now happen in milliseconds, which wouldn't be possible without advances in software technology. Next, we will discuss the components of a trading system and how it fits into the bankâs ecosystem of important inter-working parts.",
        "reference": "This paper addresses problems of trading systems in banking. Modern computing allows cross-regional trading transactions within milliseconds. We then discuss how a trading system fits in with the bank ecosystem."
      },
      {
        "source": "In this paper we present queueing-theoretical methods for the modeling, analysis, and control of autonomous mobility-on-demand MOD systems wherein robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure acceptable quality of service throughout the network. We first cast an autonomous MOD system within a closed Jackson network model with passenger loss. The theoretical insights are used to design a robust, real-time rebalancing algorithm, which is applied to a case study of New York City and implemented on an eight-vehicle mobile robot testbed. The case study of New York shows that the current taxi demand in Manhattan can be met with about 8,000 robotic vehicles roughly 70% of the size of the current taxi fleet operating in Manhattan. Finally, we extend our queueing-theoretical setup to include congestion effects, and study the impact of autonomously rebalancing vehicles on overall congestion. Collectively, this paper provides a rigorous approach to the problem of system-wide coordination of autonomously driving vehicles, and provides one of the first characterizations of the sustainability benefits of robotic transportation networks.",
        "prediction": "In this paper, we present queueing-theoretical methods for modeling, analyzing, and controlling autonomous mobility-on-demand (MOD) systems, where robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure an acceptable quality of service throughout the network. We first describe an autonomous MOD system using a closed Jackson network model that accounts for passengers not being picked up. The theoretical insights gained are used to design a robust, real-time rebalancing algorithm, which we apply to a case study of New York City, implemented on an eight-vehicle mobile robot testbed. The case study reveals that the current taxi demand in Manhattan can be met with about 8,000 robotic vehicles, roughly 70% of the size of the current taxi fleet. Finally, we extend our queueing-theoretical setup to include congestion effects and study the impact of autonomously rebalancing vehicles on overall congestion. Collectively, this paper provides a rigorous approach to the problem of system-wide coordination of autonomously driving vehicles and offers one of the first characterizations of the sustainability benefits of robotic transportation networks.",
        "reference": "Queueing models are used for autonomous mobility-on-demand MOD systems. A queueing model is constructed so that queue lengths and waiting time can be predicted. In MOD systems,  robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure quality of service. We first cast an autonomous MOD system within a closed Jackson network model,a class of queueing network, with passenger loss. A real-time rebalancing algorithm is applied to a case study of New York City. It is implemented on an eight-vehicle mobile robot testbed. The current taxi demand in Manhattan can be met with about 8,000 robotic vehicles. It represents roughly 70% of the size of the current taxi fleet in Manhattan. Congestion effects are also included to study the impact of autonomously rebalancing vehicles on overall traffic jams. This paper describes the sustainability benefits of robotic transportation networks."
      },
      {
        "source": "Many model based techniques have been proposed in the literature for applying domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation. However sensor based robot control overcomes many of the difficulties of uncertain models and unknown environments which limit the domain of application of the previous methods. Furthermore, for service and manipulation tasks, it is more suitable to study the interaction between the robot and its environment at the contact point using the sensor based control, rather than specifying the joint positions and velocities required to achieve them.",
        "prediction": "Many model-based techniques have been proposed in the literature for applying domestic service tasks to humanoid robots, such as teleoperation, learning from demonstration, and imitation. However, robot control using sensors can solve many problems created by uncertain models and unknown environments, which can reduce the effectiveness of previous methods. Additionally, for service and manipulation tasks, it is more effective to examine how the robot interacts with its environment at the contact point using sensor-based control, rather than just focusing on the joint positions and speeds needed to complete those tasks.",
        "reference": "Model based techniques exist to apply domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation. Sensor based robot control overcomes difficulties of uncertain models and unknown environments. Interaction between the robot and its environment using the sensor based control is important."
      },
      {
        "source": "Inaccurate information, in the field of library and information science, is often regarded as a problem that needs to be corrected or simply understood as either misinformation or disinformation without further consideration. Misinformation and disinformation, however, may cause significant problems for users in online environments, where they are constantly exposed to an abundance of inaccurate and/or misleading information. This paper aims to establish conceptual groundwork for future empirical research by examining the relationships among information, misinformation, and disinformation. Our analysis extends to a discussion of cues to deception, as means for detecting misinformation and disinformation. We argue that misinformation and disinformation are related yet distinct sub-categories of information. Misinformation is a multifaceted concept, more complex than simply being inaccurate or incomplete, and disinformation does not always entail misinformation.",
        "prediction": "Inaccurate information, in the field of library and information science, is often seen as a problem that needs correction or is simply categorized as misinformation or disinformation without much thought. However, misinformation and disinformation can lead to significant issues for users in online environments, where they are constantly exposed to a lot of inaccurate and misleading information. This paper aims to lay the groundwork for future research by looking at the relationships among information, misinformation, and disinformation. Our analysis also includes a discussion on cues to deception, which can help in detecting misinformation and disinformation. We argue that misinformation and disinformation are related but distinct types of information. Misinformation is a complex idea; it is not just about being wrong or missing information, and disinformation is not always the same as misinformation.",
        "reference": "Inaccurate information is often regarded as a problem that needs to be corrected or simply understood as misinformation or disinformation without further consideration. Misinformation and disinformation may cause problems online because users are constantly exposed to inaccurate and/or false information. This paper aims to establish preliminary work for future research by examining the relationships among information, misinformation, and disinformation. Our analysis extends to a discussion of means for detecting misinformation and disinformation. We argue that misinformation and disinformation are related but distinct sub-categories of information. Misinformation is more complex than simply being inaccurate or incomplete, and disinformation does not always involve misinformation."
      },
      {
        "source": "The growth of social media provides a convenient communication scheme for people, but at the same time it becomes a hotbed of misinformation. The wide spread of misinformation over social media is injurious to public interest. We design a framework, which integrates collective intelligence and machine intelligence, to help identify misinformation. The basic idea is: (1) automatically index the expertise of users according to their microblog contents; and (2) match the experts with given suspected misinformation. By sending the suspected misinformation to appropriate experts, we can collect the assessments of experts to judge the credibility of information, and help refute misinformation. In this paper, we focus on expert finding for misinformation identification. We propose a tag-based method to index the expertise of microblog users with social tags. Experiments on a real world dataset demonstrate the effectiveness of our method for expert finding with respect to misinformation identification in microblogs.",
        "prediction": "The growth of social media provides a convenient way for people to communicate but at the same time it has become a hotbed of misinformation. The widespread misinformation on social media is harmful to the public interest. We create a system that uses both human knowledge and computer technology to help find misinformation. The basic idea is (1) automatically index the expertise of users based on their microblog content and (2) match the experts with suspected misinformation. By sending the suspected misinformation to the right experts we can gather their assessments to judge the credibility of the information and help refute false claims. In this paper we focus on expert finding for identifying misinformation. We propose a tag-based method to index the expertise of microblog users using social tags. Experiments on a real-world dataset demonstrate the effectiveness of our method for expert finding in relation to misinformation identification in microblogs.",
        "reference": "The growth of social media leads to better communication between people, but also propagation of misinformation. The wide spread of misinformation over social media have bad consequences for public interest. We design a framework to help identify misinformation. The idea is to index the expertise of users and to match the experts with given suspected misinformation. By sending the suspected misinformation to appropriate experts, they can judge the credibility of information, and help refute misinformation. In this paper, we focus on finding appropriate experts for misinformation identification. We propose a method to index the expertise of users with tags. Experiments on a real world dataset demonstrate the effectiveness of our method for expert finding for misinformation identification."
      },
      {
        "source": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the scarcity of misinformation in support of such research. This paper aims to address the aforementioned challenges by conceptualizing misinformation and enabling the interoperability of misinformation. In particular, a representation and a model of misinformation are proposed through surveying, synthesizing, and explicating existing work in the field. The ontology-supported misinformation model can not only guide future misinformation research but also lay the foundation for building a digital misinformation library by advancing our knowledge on misinformation and by improving its sharing, management, and reuse. In addition, we present a formal methodology for managing misinformation in a digital library, and suggest future research directions related to the misinformation model.",
        "prediction": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the scarcity of misinformation in support of such research. This paper aims to address these challenges by defining misinformation and making it easier to share and use. In particular, a representation and a model of misinformation are proposed through surveying, synthesizing, and explaining existing work in the field. The ontology-supported misinformation model can help guide future research and act as a foundation for creating a digital library of misinformation by advancing our knowledge of misinformation and improving how we share, manage, and reuse it. Additionally, we present a formal methodology for managing misinformation in a digital library and suggest future research directions related to the misinformation model.",
        "reference": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the rare misinformation data. This paper aims to address these challenges by conceptualizing misinformation and being able to completely understand and work on misinformation. A representation and a model of misinformation are proposed through existing work in the field. The model can guide future misinformation research and help building a digital misinformation library by advancing our knowledge on misinformation and by improving its sharing, management, and reuse. In addition, we present a methodology for managing misinformation in a digital library, and suggest future research directions."
      },
      {
        "source": "Online Social Networks OSNs have become increasingly popular means of information sharing among users. The spread of news regarding emergency events is common in OSNs and so is the spread of misinformation related to the event. We define as misinformation any false or inaccurate information that is spread either intentionally or unintentionally. In this paper we study the problem of misinformation identification in OSNs, and we focus in particular on the Twitter social network. Based on user and tweets characteristics, we build a misinformation detection model that identifies suspicious behavioral patterns and exploits supervised learning techniques to detect misinformation. Our extensive experimental results on 80294 unique tweets and 59660 users illustrate that our approach effectively identifies misinformation during emergencies. Furthermore, our model manages to timely identify misinformation, a feature that can be used to limit the spread of the misinformation.",
        "prediction": "Online Social Networks (OSNs) have become increasingly popular means of information sharing among users. The spread of news regarding emergency events is common in OSNs, and so is the spread of misinformation related to the event. We define misinformation as any false or inaccurate information that is spread either intentionally or unintentionally. In this paper, we study the problem of misinformation identification in OSNs, focusing in particular on the Twitter social network. We created a model that detects misinformation by analyzing user behavior and tweet characteristics, specifically looking for suspicious patterns, and using supervised learning methods. Our extensive experimental results on 80,294 unique tweets and 59,660 users illustrate that our approach effectively identifies misinformation during emergencies. Furthermore, our model manages to timely identify misinformation, a feature that can be used to limit the spread of the misinformation",
        "reference": "Social media have become popular means of information sharing. The spread of news regarding emergency events is common in social media but so is the spread of misinformation. Misinformation is any false or inaccurate information that is spread intentionally or not. In this paper we study the problem of misinformation identification in social media, and we focus in particular on Twitter. We build a misinformation detection model that identifies suspicious behavioral patterns and detect misinformation. We found 80294 unique tweets and 59660 users. It illustrates that our approach identifies misinformation during emergencies. Our model manages to timely identify misinformation, it can be used to limit the spread of the misinformation."
      },
      {
        "source": "The advent of WWW changed the way we can produce and access information. Recent studies showed that users tend to select information that is consistent with their system of beliefs, forming polarized groups of like-minded people around shared narratives where dissenting information is ignored. In this environment, users cooperate to frame and reinforce their shared narrative making any attempt at debunking inefficient. Such a configuration occurs even in the consumption of news online, and considering that 63% of users access news directly form social media, one hypothesis is that more polarization allows for further spreading of misinformation. Along this path, we focus on the polarization of users around news outlets on Facebook in different European countries (Italy, France, Spain and Germany). First, we compare the page posting behavior and the users interacting patterns across countries and observe different posting, liking and commenting rates. Second, we explore the tendency of users to interact with different pages (i.e., selective exposure) and the emergence of polarized communities generated around specific pages.",
        "prediction": "The advent of the World Wide Web (WWW) has changed how we produce and access information. Recent studies found that people often choose information that matches their beliefs, creating groups of like-minded individuals around shared stories while ignoring opposing information. In this environment, users work together to frame and reinforce their shared narrative, making attempts to debunk misinformation ineffective. This situation arises even in how news is consumed online; considering that 63% of users access news directly from social media, one hypothesis is that increased polarization leads to the further spread of misinformation. In this context, we focus on the polarization of users around news outlets on Facebook in several European countries, including Italy, France, Spain, and Germany. First, we compare the page posting behaviors and user interaction patterns across these countries and observe varying rates of posting, liking, and commenting. Second, we explore how users tend to interact with different pages (known as selective exposure) and the emergence of polarized communities forming around specific pages.",
        "reference": "The WWW changed the ways we can produce and access information. Users tend to select information that agrees with their beliefs. They form polarized groups of like-minded people sharing narratives that ignore contradicting information. Here, users reinforce their shared narratives and can resist debunking This is the case with online news. Because 63% of users access news from social media, polarization could increase misinfomation spread. We focus on polarisation of Facebook news consumers in different European countries. Posting, liking and commenting rates differ across countries. We look at how users interact with different pages and polarized communities form around specific pages."
      },
      {
        "source": "We find that Italy is the most polarized country, followed by France, Germany and lastly Spain. Finally, we present a variation of the Bounded Confidence Model to simulate the emergence of these communities by considering the usersu0027 engagement and trust on the news. Our findings suggest that trust in information broadcaster plays a pivotal role against polarization of users online.",
        "prediction": "We find that Italy is the most polarized country followed by France Germany and lastly Spain Finally we present a version of the Bounded Confidence Model to show how these communities form by looking at how much users engage with and trust the news Our findings suggest that trust in information broadcasters plays a crucial role in reducing the polarization of users online",
        "reference": "Italy is the most polarized country, then France, Germany and Spain. A variant of the Bounded Confidence Model simulates the emergence of these communities by considering user engagement and trust in the news. Trust in an information source plays a major role against polarization of users online."
      },
      {
        "source": "Online social media provide users with unprecedented opportunities to engage with diverse opinions. We discuss the policy implications of our model, highlighting the downside of debunking strategies and suggesting alternative strategies to contrast misinformation. Simultaneously, they allow the spread of misinformation by empowering individuals to self-select the narratives they want to be exposed to, both through active (confirmation bias) and passive (personalized news algorithms) self-reinforcing mechanisms. A precise theoretical understanding of such trade-offs is still largely missing. We introduce a stylized social learning model where most participants in a network update their beliefs unbiasedly based on the arrival of new information, while a fraction of participants display confirmation bias, enabling them to reject news that are incongruent with their pre-existing beliefs. We show that this simple confirmation bias mechanism can generate permanent opinion polarisation. Furthermore, the model results in states where unbiased agents behave \"as if\" they were biased, due to their biased neighbours effectively functioning as gatekeepers, restricting their access to free and diverse information. We derive analytic results for the distribution of individual agentsâ beliefs, explicitly demonstrating the aforementioned trade-off between confirmation bias and social connectivity, which we further validate against US county-level data on the impact of Internet access on the formation of beliefs about global warming. Our findings indicate that confirmation bias in small doses may actually result in improved accuracy across individuals by preserving information diversity in a social network. However, results also indicate that when confirmation bias grows past an optimal value, accuracy declines as biased agents restrict information flow to subgroups.",
        "prediction": "Online social media provide users with unprecedented opportunities to engage with diverse opinions. We discuss the policy implications of our model, highlighting the downside of debunking strategies and suggesting alternative strategies to contrast misinformation. Simultaneously, they allow the spread of misinformation by empowering individuals to self-select the narratives they want to be exposed to, both through active confirmation bias and passive personalized news algorithms. A precise theoretical understanding of such trade-offs is still largely missing.\n\nWe introduce a stylized social learning model where most participants in a network update their beliefs unbiasedly based on new information, while a fraction of participants exhibit confirmation bias, enabling them to reject news that contradicts their pre-existing beliefs. We demonstrate that this straightforward confirmation bias can lead to lasting differences in people's opinions. Furthermore, our model shows that unbiased agents can behave as if they were biased, due to their biased neighbors acting as gatekeepers and limiting their access to free and diverse information.\n\nWe derive analytic results for the distribution of individual agentsâ beliefs, clearly illustrating the trade-off between confirmation bias and social connectivity. We further validate this against US county-level data on the impact of Internet access on beliefs about global warming. Our findings indicate that small doses of confirmation bias may actually improve accuracy by preserving information diversity in a social network. However, we also find that when confirmation bias grows too strong, accuracy declines as biased agents restrict information flow to subgroups.",
        "reference": "Social media give users opportunities to interact with different opinions. We discuss the meaning of our model for policy and the downsides of myth-busting We suggest alternatives to fight misinformation. But misinformation is spread via social media because individuals can search for information that confirms their beliefs and personalized news algorithms may supply it. Theoretical understanding of the balance between opportunities and misinformation is incomplete. We introduce a stylized social learning model. In this model, most participants in a network update their beliefs based on new information, while others show confirmation bias and can reject news that differs from their beliefs. This simple confirmation bias mechanism can create lasting opinion polarisation. Besides, in the model, unbiased people behave âas ifâ biased because biased neighbours limit their access to diverse information. With our model, we show the trade-off between confirmation bias and social connectivity. We validated the model using the data on how internet access influences beliefs on global warming. Small confirmation bias may even improve accuracy across individuals by keeping information diversity in a social network. But large confirmation bias lowers accuracy as biased individuals limit information flow to others."
      },
      {
        "source": "Superintelligence is a potential type of future artificial intelligence (AI) that is significantly more intelligent than humans in all major respects. If built, superintelligence could be a transformative event, with potential consequences that are massively beneficial or catastrophic. Meanwhile, the prospect of superintelligence is the subject of major ongoing debate, which includes a significant amount of misinformation. Superintelligence misinformation is potentially dangerous, ultimately leading bad decisions by the would-be developers of superintelligence and those who influence them. This paper surveys strategies to counter superintelligence misinformation. Two types of strategies are examined: strategies to prevent the spread of superintelligence misinformation and strategies to correct it after it has spread. In general, misinformation can be difficult to correct, suggesting a high value of strategies to prevent it. The strategies proposed can be applied to lay public attention to superintelligence, AI education programs, and efforts to build expert consensus.",
        "prediction": "Superintelligence is a potential type of future artificial intelligence (AI) that is significantly more intelligent than humans in all major respects. If built, superintelligence could be a transformative event, with potential consequences that are massively beneficial or catastrophic. Meanwhile, the prospect of superintelligence is the subject of major ongoing debate, which includes a significant amount of misinformation. False information about superintelligence can be dangerous, as it can lead to poor choices by those trying to create superintelligence and by the people who influence them. \n\nThis paper surveys strategies to counter superintelligence misinformation. Two types of strategies are examined: those aimed at preventing the spread of misinformation and those focused on correcting it after it has spread. In general, misinformation can be difficult to correct, suggesting a high value for strategies that prevent it. The proposed strategies can help raise public awareness about superintelligence, support AI education programs, and promote efforts to build expert consensus.",
        "reference": "Superintelligence is a potential future artificial intelligence (AI) significantly more intelligent than humans. Superintelligence could be a major event, with potential consequences that are beneficial or catastrophic. The prospect of superintelligence is the subject of major debate, which includes a lot of misinformation. Superintelligence misinformation could be dangerous, and lead to bad decisions by the people that could work on the project. This paper searches for strategies to counter superintelligence misinformation. Two strategies are examined: to prevent the spread of misinformation and to correct it after it has spread. Misinformation can be difficult to correct, so preventing it seems to be the best strategy. The strategies proposed can be used to bring public attention to superintelligence, AI education programs, and efforts to build expert consensus."
      },
      {
        "source": "The widespread online misinformation could cause public panic and serious economic damages. The misinformation containment problem aims at limiting the spread of misinformation in online social networks by launching competing campaigns. Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem for the case when an arbitrary number of cascades are allowed. First, we provide a formal model for multi-cascade diffusion and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of $\\\\Omega(2^{\\\\log^{1-\\\\epsilon}n^4})$ in polynomial time unless $NP \\\\subseteq DTIME(n^{\\\\polylog{n}})$. Third, we introduce several types of cascade priority that are frequently seen in real social networks. Finally, we design novel algorithms for solving the misinformation containment problem. The effectiveness of the proposed algorithm is supported by encouraging experimental results.",
        "prediction": "The widespread online misinformation could cause public panic and serious economic damages. The misinformation containment problem aims at limiting the spread of misinformation in online social networks by launching competing campaigns. Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem when an arbitrary number of cascades are allowed. \n\nFirst, we provide a formal model for multi-cascade diffusion and introduce an important concept called cascade priority. Second, we demonstrate that it is not possible to find a close enough solution to the misinformation containment problem in a reasonable amount of time unless a certain complexity theory condition is met. \n\nThird, we introduce several types of cascade priority that are frequently seen in real social networks. Finally, we design novel algorithms for solving the misinformation containment problem, and the effectiveness of our proposed algorithm is supported by encouraging experimental results.",
        "reference": "The online misinformation could cause public panic and serious economic damages. The goal of misinformation containment is to limit the spread of misinformation in online social networks by launching campaigns to counter misinformation. We present the first analysis of the misinformation containment problem with a random number of cascades (people observe the actions of others and then make the same choice) allowed. First, we provide a diffusion model and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of Î©(2log1âÏµn4) in polynomial time unless $NP \\subseteq DTIME(n^{\\polylog{n}})$ Third, we introduce several types of cascade priority that are frequently seen in social networks. Finally, we design algorithms for solving the misinformation containment problem. The proposed algorithm is effective and shows encouraging results."
      },
      {
        "source": "Yet contemporary work in Philosophy argues provisional belief in conspiracy theories isâat the veryâleast understandable (because conspiracies occur) and if we take an evidential approachâjudging individual conspiracy theories on their particular meritsâbelief in such theories turns out to be warranted in a range of cases. Drawing on this work, I examine the kinds of evidence typically associated with conspiracy theories, showing that the evidential problems typically associated with conspiracy theories are not unique to such theories. As such, if there is a problem with the conspiracy theoristâs use of evidence, it is one of principle: is the principle which guides their use of evidence somehow in error? I argue that whatever we might think about conspiracy theories generally, there is no prima facie case for a scepticism of conspiracy theories based purely on their use of evidence.",
        "prediction": "Yet contemporary work in Philosophy argues that provisional belief in conspiracy theories is at least understandable because conspiracies occur. If we look at the evidence and evaluate each conspiracy theory on its own, we find that believing in some of these theories can be justified in various situations. Drawing on this work, I examine the kinds of evidence typically associated with conspiracy theories, showing that the evidential problems often linked to them are not unique. As such, if there is a problem with how conspiracy theorists use evidence, it is a matter of principle: is the principle guiding their use of evidence somehow in error? I argue that whatever we might think about conspiracy theories generally, there is no clear reason to be skeptical of them based purely on their use of evidence.",
        "reference": "To believe in conspiracy theories is understandable as conspiracies occur and if we take an evidential approach, belief in such theories turns out to be warranted in a range of cases. Drawing on this work, I examine evidence associated with conspiracy theories, showing that the evidential problems are not unique to conspiracy theories. The problem with the use of evidence of conspiracy theorist could be the principle which guides their use of it. I argue that there is no ground to be suspicious of conspiracy theories as a whole, because those are based on evidence."
      },
      {
        "source": "Conspiracy theories have gained much academic and media attention recently, due to their large impact on public events. However, little is known about how conspiracy theories are produced and developed on social media. We present a qualitative study of conspiracy theorizing on Reddit during a public health crisis--the Zika virus outbreak. Using a mixed-methods approach including content analysis and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the Zika crisis, the conditions under which Zika conspiracy theories emerge, and the particular discursive strategies through which Zika conspiracy theories developed in online forums. Our analysis shows that conspiracy talk emerged as people attempted to make sense of a public health crisis, reflecting their emergent information needs and their pervasive distrust in formal sources of Zika information. Practical implications for social computing researchers, health practitioners, and policymakers are discussed.",
        "prediction": "Conspiracy theories have gained much academic and media attention recently due to their large impact on public events. However, little is known about how these theories are created and spread on social media. We present a qualitative study of conspiracy theorizing on Reddit during a public health crisisâthe Zika virus outbreak. We used different research methods, including looking at content and analyzing discussions, to find out what types of conspiracy theories appeared on Reddit during the Zika crisis. We also examined the conditions under which Zika conspiracy theories emerged and the specific ways these theories developed in online forums. Our analysis shows that conspiracy talk emerged as people attempted to make sense of a public health crisis, reflecting their information needs and their distrust of formal sources of Zika information. Practical implications for social computing researchers, health practitioners, and policymakers are discussed.",
        "reference": "Conspiracy theories have gained much attention recently, due to their large impact on public events. Little is known about how conspiracy theories are produced and developed on social media. We present a study of conspiracy theory creation on Reddit during a public health crisis. Using content and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the crisis, the conditions of their creation, and the strategies of their development in online forums. Our analysis shows that conspiracy talk come from people trying to make sense of a public health crisis, which reflect their information needs and their lack of confidence in formal sources of information. Implications for social computing researchers, health practitioners, and policymakers are discussed."
      },
      {
        "source": "Conspiracy theories are omnipresent in online discussions---whether to explain a late-breaking event that still lacks official report or to give voice to political dissent. Conspiracy theories evolve, multiply, and interconnect, further complicating efforts to understand them and to limit their propagation. It is therefore crucial to develop scalable methods to examine the nature of conspiratorial discussions in online communities. What do users talk about when they discuss conspiracy theories online? What are the recurring elements in their discussions? What do these elements tell us about the way users think? This work answers these questions by analyzing over ten years of discussions in r/conspiracy---an online community on Reddit dedicated to conspiratorial discussions. We focus on the key elements of a conspiracy theory: the conspiratorial agents, the actions they perform, and their targets. For example, a narrative-motif such as \\\"governmental agency-controls-communications\\\" represents the various ways in which multiple conspiratorial statements denote how governmental agencies control information. Thus, narrative-motifs expose commonalities between multiple conspiracy theories even when they refer to different events or circumstances. In the process, these representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about. Our approach enables a population-scale study of conspiracy theories in alternative news and social media with implications for understanding their adoption and combating their spread.",
        "prediction": "Conspiracy theories are omnipresent in online discussions whether to explain a late-breaking event that still lacks an official report or to give voice to political dissent Conspiracy theories evolve multiply and interconnect making it more difficult to understand them and limit their spread It is important to create ways to study conspiracy discussions in online groups What do users talk about when they discuss conspiracy theories online What are the recurring elements in their discussions What do these elements tell us about the way users think This work answers these questions by analyzing over ten years of discussions in r/conspiracy an online community on Reddit dedicated to conspiratorial discussions We focus on the key elements of a conspiracy theory the conspiratorial agents the actions they perform and their targets For example a narrative motif like governmental agency-controls-communications shows how various conspiratorial statements suggest that governmental agencies control information Thus these narrative motifs reveal common themes across multiple conspiracy theories even when they refer to different events or circumstances In this way these representations help us understand how users talk about conspiracy theories and provide insight into the topics they discuss Our approach enables a large-scale study of conspiracy theories in alternative news and social media with implications for understanding their acceptance and combating their spread",
        "reference": "Conspiracy theories are omnipresent in online discussions. Conspiracy theories evolve, multiply, and interconnect, complicating how to understand them and to limit their propagation. It is crucial to develop methods to examine the nature of these conspiratorial discussions. What do users talk about? What are the recurring elements in their discussions? What do these elements tell us about the way users think? This work answers these questions by analyzing over ten years of discussions in an online community on the social media Reddit dedicated to conspiratorial discussions. We focus on the key elements of a conspiracy theory: the conspiratorial agents, the actions they perform, and their targets. For example, a narrative-motif (an idea) such as \"governmental agency-controls-communications\" represents the various ways in which multiple conspiratorial statements suggest how governmental agencies control information. Narrative-motifs expose similarities between multiple conspiracy theories even when they refer to different events or circumstances. These representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about. Our approach enables a population-scale study of conspiracy theories in alternative news and social media and ways to understand them and limit their propagation."
      },
      {
        "source": "Blockchain technology is the underlying enabling technology developed for Bitcoin, the most common cryptocurrency. Blockchain technologies have become increasingly popular with the potential to become a powerful disruptive force. Individuals and organizations may benefit from blockchain with its ability to increase secure data exchange and to make that transaction simpler and easier between entities. We investigate factors that influence an individualu0027s intention to use a blockchain cryptocurrency. We develop a model of cryptocurrency adoption grounded in the theory of planned behavior (TPB) to: identify the determinants for the acceptance of cryptocurrency and explore the relative importance of each construct. We offer empirical evidence for a better theoretical understanding of cryptocurrency adoption with practical implications in an e-government context.",
        "prediction": "Blockchain technology is the underlying enabling technology developed for Bitcoin the most common cryptocurrency Blockchain technologies have become increasingly popular with the potential to become a powerful disruptive force Individuals and organizations may benefit from blockchain because it increases secure data exchange and makes transactions simpler and easier between entities We create a model to understand how people decide to use cryptocurrency based on the theory of planned behavior TPB This helps us identify factors that influence cryptocurrency acceptance and look at how important each factor is We offer empirical evidence that enhances our understanding of cryptocurrency adoption with practical implications in an e-government context",
        "reference": "Blockchain technology is a technology developed for Bitcoin, the most common cryptocurrency. Blockchain technologies have become popular with the potential to become a powerful disruptive force. People and organizations may use it to increase secure data exchange and make transactions simpler and easier. We investigate what influence people to use a blockchain cryptocurrency. We develop a model of cryptocurrency adoption to identify how cryptocurrency is accepted. Our evidence allow a better understanding of cryptocurrency adoption."
      },
      {
        "source": "With the introduction of memory-bound cryptocurrencies, such as Monero, the implementation of mining code in browser-based JavaScript has become a worthwhile alternative to dedicated mining rigs. Based on this technology, a new form of parasitic computing, widely called cryptojacking or drive-by mining, has gained momentum in the web. A cryptojacking site abuses the computing resources of its visitors to covertly mine for cryptocurrencies. In this paper, we systematically explore this phenomenon. For this, we propose a 3-phase analysis approach, which enables us to identify mining scripts and conduct a large-scale study on the prevalence of cryptojacking in the Alexa 1 million websites. We find that cryptojacking is common, with currently 1 out of 500 sites hosting a mining script. Moreover, we perform several secondary analyses to gain insight into the cryptojacking landscape, including a measurement of code characteristics, an estimate of expected mining revenue, and an evaluation of current blacklist-based countermeasures.",
        "prediction": "With the introduction of memory-bound cryptocurrencies such as Monero the implementation of mining code in browser-based JavaScript has become a worthwhile alternative to dedicated mining rigs Based on this technology a new form of parasitic computing widely called cryptojacking or drive-by mining has gained momentum on the web A cryptojacking site takes advantage of its visitors' computers to secretly mine for cryptocurrencies In this paper we systematically explore this phenomenon through a proposed 3-phase analysis approach This approach enables us to identify mining scripts and conduct a large-scale study on the prevalence of cryptojacking in the Alexa 1 million websites Our findings indicate that cryptojacking is common with currently 1 out of 500 sites hosting a mining script Moreover we perform several secondary analyses to gain insight into the cryptojacking landscape including measuring code characteristics estimating expected mining revenue and evaluating current blacklist-based countermeasures",
        "reference": "Memory-bound cryptocurrencies like Monero can be mined  from a browser with JavaScript, better than with a dedicated rig. However, this technology enables cryptojacking, whereby a site covertly mines for cryptocurrencies on its visitorsâ computers. We propose a new approach to identify mining scripts. The approach was evaluated on Alexa 1 websites. Cryptojacking is common, as 1 in 500 sites host a mining script. We also measured code characteristics, estimated mining revenue, and evaluated blacklist-based countermeasures."
      },
      {
        "source": "The rise of modern blockchains has facilitated the emergence of smart contracts: autonomous programs that live and run on the blockchain. Smart contracts have seen a rapid climb to prominence, with applications predicted in law, business, commerce, and governance.  contracts :[39],\"are commonly written in a high-level language such as Ethereumu0027s Solidity, and translated to compact low-level bytecode for deployment on the blockchain. Once deployed, the bytecode is autonomously executed, usually by a %Turing-complete virtual machine. As with all programs, smart contracts can be highly vulnerable to malicious attacks due to deficient programming methodologies, languages, and toolchains, including buggy compilers. At the same time, smart contracts :[39],\"are also high-value targets, often commanding large amounts of cryptocurrency. Hence, developers and auditors need security frameworks capable of analysing low-level bytecode to detect potential security vulnerabilities. In this paper, we present Vandal: a security analysis framework for Ethereum smart contracts. Vandal consists of an analysis pipeline that converts low-level Ethereum Virtual Machine (EVM) bytecode to semantic logic relations. Users of the framework can express security analyses in a declarative fashion: a security analysis is expressed in a logic specification written in the \\souffle language.",
        "prediction": "The rise of modern blockchains has facilitated the emergence of smart contracts autonomous programs that live and run on the blockchain Smart contracts have seen a rapid climb to prominence with applications predicted in law business commerce and governance Smart contracts are usually written in a high-level programming language called Solidity used for the Ethereum blockchain and are then converted into a compact low-level form known as bytecode for use on the blockchain Once deployed the bytecode is autonomously executed usually by a Turing-complete virtual machine As with all programs smart contracts can be highly vulnerable to malicious attacks due to deficient programming methodologies languages and toolchains including buggy compilers At the same time smart contracts are also high-value targets often commanding large amounts of cryptocurrency Hence developers and auditors need security frameworks capable of analyzing low-level bytecode to detect potential security vulnerabilities In this paper we present Vandal a security analysis framework for Ethereum smart contracts Vandal consists of an analysis pipeline that converts low-level Ethereum Virtual Machine EVM bytecode to semantic logic relations Users of the framework can express security analyses in a clear manner a security analysis is expressed in a logic specification written in the Souffle language",
        "reference": "Smart contracts have appeared thanks to blockchain technology. These autonomous programs are used in law, business, commerce, and governance. Smart contracts are written in a high-level language such as Ethereumâs Solidity and translated to bytecode. that live and run on the blockchain are predicted in Once deployed on the blockchain, the bytecode is autonomous. Smart contracts are vulnerable to malicious attacks due to poor programming, languages and toolchains Smart contracts can command large amounts of cryptocurrency. Developers and auditors need frameworks to detect security vulnerabilities. Vandal is a security analysis framework for Ethereum smart contracts. Vandal converts Ethereum Virtual Machine bytecode to semantic logic relations. Users can express security analyses in the SoufflÃ© language."
      },
      {
        "source": "Vandal is both fast and robust, successfully analysing over 95\\% of all 141k unique contracts with an average runtime of 4.15 seconds; outperforming the current state of the art tools---Oyente, EthIR, Mythril, and Rattle---under equivalent conditions.",
        "prediction": "Vandal is both fast and robust. It successfully analyzes more than 95% of the 141,000 unique contracts in an average time of 4.15 seconds, outperforming the current state-of-the-art toolsâOyente, EthIR, Mythril, and Rattleâunder similar conditions",
        "reference": "Vandal is both efficient (95% accuracy), fast (141k in 4.15 s) and robust. It outperforms the state of the art tools like Oyente, EthIR, Mythril, and Rattle"
      },
      {
        "source": "As Bitcoinu0027s popularity has grown over the decade since its creation, it has become an increasingly attractive target for adversaries of all kinds.",
        "prediction": "As Bitcoin's popularity has grown over the decade since its creation, it has become an increasingly attractive target for adversaries of all kinds.",
        "reference": "One of the most powerful potential adversaries is the country of China, which has expressed adversarial positions regarding the cryptocurrency and demonstrated powerful capabilities to influence it."
      },
      {
        "source": "For decentralised P2P networks, it is very important to have a mechanism in place that allows the nodes to control resource usage and prevent flooding and denial-of-service attacks with spam. In this paper, we discuss and compare the different approaches to fully decentralised resource control that are used by projects in the cryptocurrency space. The introduced methods are then applied to design a decentralised exchange for Namecoin names (or more generally, crypto assets) as an example.",
        "prediction": "For decentralised P2P networks, it is very important to have a mechanism in place that allows the nodes to manage resource use and stop spam that can overwhelm the network and block service. In this paper, we discuss and compare various approaches to fully decentralised resource control used by projects in the cryptocurrency space. The methods introduced are then applied to design a decentralised exchange for Namecoin names, or more generally, for crypto assets, as an example.",
        "reference": "In decentralised P2P networks nodes need a way  to control resource usage and prevent flooding and denial-of-service attacks. We compared different approaches to decentralised resource control in cryptocurrency projects. We designed a decentralised exchange for crypto assets, for  example Namecoin names, with these methods."
      },
      {
        "source": "Cryptocurrency is a rapid developing financial technology innovation which has attracted a large number of people around the world. The high-speed evolution, radical price fluctuations of cryptocurrency, and the inconsistent attitudes of monetary authorities in different countries have triggered panic and chain reactions towards the application and adoption of cryptocurrency and have caused public security related events. In this paper, we analyze the dynamics and systemic risk of the cryptocurrency market based on the public available price history. Furthermore, consistent with public perception, our quantitative analysis reveals that the cryptocurrency market is relatively fragile and unstable.",
        "prediction": "Cryptocurrency is a rapidly developing financial technology innovation that has attracted a large number of people around the world. The high-speed evolution, radical price fluctuations of cryptocurrency, and the inconsistent attitudes of monetary authorities in different countries have triggered panic and chain reactions towards the application and adoption of cryptocurrency and have caused public security related events. In this paper, we analyze the dynamics and systemic risk of the cryptocurrency market based on the publicly available price history. Also, based on what the public thinks, our quantitative analysis reveals that the cryptocurrency market is relatively fragile and unstable.",
        "reference": "Cryptocurrency is a financial technology innovation which has attracted many people around the world. The high-speed evolution, radical price fluctuations of cryptocurrency, and the inconsistent attitudes of monetary authorities in different countries have caused panic. In this paper, we analyze the dynamics and risks of the cryptocurrency market. Consistent with public perception, our analysis reveals that the cryptocurrency market is fragile and unstable."
      },
      {
        "source": "Cryptocurrency was built initially as a possible implementation of digital currency, then various derivatives were created in a variety of fields such as financial transactions, capital management, and even nonmonetary applications. This paper aims to offer analytical insights to help understand cryptocurrency by treating it as a financial asset. We position cryptocurrency by comparing its dynamic characteristics with two traditional and massively adopted financial assets: foreign exchange and stock. Our investigation suggests that the dynamics of cryptocurrency are more similar to stock. As to the robustness and clustering structure, our analysis shows cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market.",
        "prediction": "Cryptocurrency was initially created as a way to implement digital currency, and since then, various derivatives have emerged in different areas such as financial transactions, capital management, and even non-monetary applications. This paper aims to provide analytical insights to help understand cryptocurrency by treating it as a financial asset. We compare cryptocurrency's characteristics with those of two widely adopted financial assets: foreign exchange and stock. Our study shows that the behavior of cryptocurrency is more like that of stocks. However, our analysis indicates that the cryptocurrency market is weaker than the stock market, which makes it a high-risk investment.",
        "reference": "Cryptocurrency was initially an implementation of digital currency, then derivatives were created in various fields. This paper aims to help understand cryptocurrency. We compared cryptocurrency with foreign exchange and stock. Our investigation suggests that cryptocurrency is similar to stock. Our analysis shows that cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market."
      },
      {
        "source": "The smart device owning rate such as smart phone and smart watch is higher than ever before and mobile payment has become one of the major payment methods in many different areas. At the same time, blockchain-based cryptocurrency is becoming a nonnegligible type of currency and the total value of all types of cryptocurrency has reached USD 200 billion. Therefore, it is a natural demand to support cryptocurrency payment on mobile devices. Considering the poor infrastructure and low penetration of financial service in developing countries, this combination is especially attractive. The high storage cost and payment processing latency are the two main obstacles for mobile payment using cryptocurrency. We propose two different schemes for cryptocurrency mobile payment, one involves a centralized bank and the other one does not require any centralized party. We also provide a solution for the bank to meet KYC (know your customer)/AML (antimoney laundering) compliance requirements when it is involved in cryptocurrency mobile payment processing.",
        "prediction": "The smart device ownership rate including smartphones and smartwatches is higher than ever before and mobile payment has become one of the major payment methods in many different areas. At the same time blockchain-based cryptocurrency is becoming an important type of money and its total value has reached USD 200 billion. Therefore it is a natural demand to support cryptocurrency payments on mobile devices. Considering the poor infrastructure and low penetration of financial services in developing countries this combination is especially attractive. However the high storage costs and payment processing latency are the two main obstacles to mobile payments using cryptocurrency. We propose two different schemes for cryptocurrency mobile payment one involves a centralized bank while the other does not require any centralized party. Additionally we provide a solution for the bank to meet KYC know your customer and AML anti-money laundering compliance requirements when it is involved in cryptocurrency mobile payment processing.",
        "reference": "The owning rate of smart devices is higher than ever before and mobile payment has become a major payment method. Cryptocurrency is becoming an important type of currency and the total value of cryptocurrencies has reached USD 200 billion. Therefore, support of cryptocurrency payment on mobile devices is a natural demand. Considering the poor infrastructure and the low usage of financial service in developing countries, this combination is especially attractive. The high storage cost and payment processing latency are two obstacles for cryptocurrency mobile payment. We propose two solutions, one with a centralized bank and the other one without any centralized party. We also provide a solution for the bank to meet KYC (know your customer)/AML (antimoney laundering) expectations about cryptocurrency mobile payment."
      },
      {
        "source": "Motivated by recent financial crises significant research efforts have been put into studying contagion effects and herding behaviour in financial markets. Much less has been said about influence of financial news on financial markets. We propose a novel measure of collective behaviour in financial news on the Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic risk indicator. We evaluate the NCI on financial documents from large Web news sources on a daily basis from October 2011 to July 2013 and analyse the interplay between financial markets and financially related news. We hypothesized that strong cohesion in financial news reflects movements in the financial markets. Cohesiveness is more general and robust measure of systemic risk expressed in news, than measures based on simple occurrences of specific terms. Our results indicate that cohesiveness in the financial news is highly correlated with and driven by volatility on the financial markets.",
        "prediction": "Motivated by recent financial crises, significant research efforts have been put into studying contagion effects and herding behaviour in financial markets. Much less attention has been given to the influence of financial news on these markets. In this context, we propose a novel measure of collective behaviour in financial news on the Web called the News Cohesiveness Index (NCI), which we show can serve as a systemic risk indicator. We evaluate the NCI on financial documents from large Web news sources daily, from October 2011 to July 2013, and analyze the interplay between financial markets and finance-related news. We hypothesized that strong cohesion in financial news reflects movements in the financial markets. Notably, cohesiveness is a broader and stronger measure of systemic risk in news compared to measures that only focus on the simple occurrence of specific words. Our results indicate that cohesiveness in financial news is highly correlated with and driven by volatility in the financial markets.",
        "reference": "Motivated by recent financial crises, research efforts have been put into studying contagion effects (spread of market disturbances) and herding behaviour (individuals acting collectively without centralized direction) in financial markets. Much less has been said about influence of financial news on financial markets. We propose a measure of collective behaviour in financial news on the Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic risk indicator, which signals probability of financial system crises. We evaluate the NCI on financial documents from Web news sources and analyse the relation between financial markets and financial news. We hypothesized that strong cohesion in financial news reflects variations in the financial markets. Cohesiveness is a better measure of systemic risk expressed in news, than measures based on simple occurrences of specific terms. Our results show that cohesiveness in the financial news is highly correlated with variations in the financial markets."
      },
      {
        "source": "In this paper, I propose a methodology to study the comovement between the entropy of different financial markets. The entropy is derived using singular value decomposition of the components of stock market indices in financial markets from selected developed economies, i.e., France, Germany, the United Kingdom, and the United States. I study how a shock in the entropy in the United States affects the entropy in the other financial markets. I also model the entropy using a dynamic factor model and derive a common factor behind the entropy movements in these four markets.",
        "prediction": "In this paper, I propose a methodology to study the comovement between the entropy of different financial markets. The entropy is calculated using a method called singular value decomposition, which analyzes stock market indices from selected developed countries, such as France, Germany, the United Kingdom, and the United States. I explore how a shock in the entropy in the United States affects the entropy in the other financial markets. Additionally, I model the entropy using a dynamic factor model to identify a common factor behind the movements in entropy across these four markets.",
        "reference": "In this paper, I propose a methodology to study the comovement (correlation on profits on investment) between the entropy (randomness and uncertainty) of different financial markets. The entropy is based on the components measuring the stock market in financial markets from selected developed economies (France, Germany, the United Kingdom, and the United States). I study how a shock in the entropy in the United States affects the entropy in the other financial markets. I also model the entropy using different time variables and obtain a common factor behind the entropy movements in these four markets."
      },
      {
        "source": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones, and fraudsters have evolved with them. Smartphones are packed with functionality that can easily be used for data theft or inappropriate contact with other parties - none of which passes through company-owned systems, and is to all intents and purposes 'off the grid'. Employers need to be aware of these risks when devices are issued, along with ensuring that processes are in place when suspicions are raised, explains Philip Ridley of CCL-Forensics. Detecting 'tech-savvy' corporate fraudsters is a constant game of catch-up. It's not only about playing catch-up with the intellect, motives and awareness of the e-fraudster, but also the technologies that can be misused. What's more, the methods through which the technology can be manipulated to secrete, disguise and protect fraudulent activities - all while staying away from corporate networks where they can readily be monitored and detected - are constantly evolving. This means a company's intellectual property and sensitive data is at risk of sabotage or just good old-fashioned theft.",
        "prediction": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones and fraudsters have evolved with them. Smartphones are packed with functionality that can easily be used for data theft or inappropriate contact with other parties - none of which passes through company-owned systems making it effectively 'off the grid'. Employers need to be aware of these risks when issuing devices and must ensure that processes are in place when suspicions arise explains Philip Ridley of CCL-Forensics. Detecting skilled corporate fraudsters is always challenging. It involves not just understanding the intelligence and motives of fraudsters but also keeping up with the technologies they misuse. Moreover the methods through which technology can be manipulated to hide disguise and protect fraudulent activities while staying away from corporate networks where they can be monitored are constantly evolving. This means a company's intellectual property and sensitive data is at risk of sabotage or traditional theft.",
        "reference": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones, and fraudsters have evolved with them. Smartphones have functionalities that can be used for data theft or inappropriate contact with other parties. They are out of the systems of the company and are not monitored or controlled. Employers need to be aware of these risks when devices are delivered and have processes when suspicions are raised. Detecting fraudsters with computer skills is a constant game of catch-up. It's not only about playing catch-up with the cyberfraudster, but also the technologies that can be misused. Moreover, the methods assisting fraudulent activities (still out of reach of company systems) are constantly evolving. This means a company's intellectual property and sensitive data is at risk of sabotage or theft."
      },
      {
        "source": "Phishers continue to alter the source code of the web pages used in their attacks to mimic changes to legitimate websites of spoofed organizations and to avoid detection by phishing countermeasures. Manipulations can be as subtle as source code changes or as apparent as adding or removing significant content. To appropriately respond to these changes to phishing campaigns, a cadre of file matching algorithms is implemented to detect phishing websites based on their content, employing a custom data set consisting of 17,992 phishing attacks targeting 159 different brands. The results of the experiments using a variety of different content-based approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate.",
        "prediction": "Phishers continue to alter the source code of the web pages they use in their attacks to mimic changes to legitimate websites of spoofed organizations and to avoid detection by phishing countermeasures. These manipulations can be as subtle as changing the source code or as obvious as adding or removing important content. To respond to these changes in phishing campaigns, a group of algorithms is used to detect phishing websites by analyzing their content. They utilize a customized data set that includes 17,992 phishing attacks aimed at 159 different brands. The results from experiments with various content-based approaches show that some can achieve a detection rate of over 90% while keeping a low false positive rate.",
        "reference": "Phishers, people who attempt to trick people over the internet to steal their money, continue to modify the web pages used in their attacks to imitate websites of spoofed organizations and to avoid detection by phishing countermeasures. Manipulations can be as subtle as changing the source code, which is the programming instructions, or as apparent as adding or removing significant content. To respond to these changes to phishing campaigns, algorithms are used to detect phishing websites based on their content, employing a data set consisting of 17,992 phishing attacks targeting 159 different brands. The results of the experiments using different approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate."
      },
      {
        "source": "Mobile devices are very common in everyoneâs day-to- day life. Nowadays such devices come with many features of desktop or laptop. Hence people can use these devices for diverse applications. As the acceptability and usability of such devices are very high, there are chances that these devices can be used for illegal activities. The percentage of mobile phones or smart phones involved in cyber crimes is in hike. So it becomes necessary to digitally analyze such devices requiring cyber forensics tools. This paper discusses different types of digital evidence present in Microsoftâs Windows Mobile smart phones and an agent based approach for logically acquiring such devices. Also it describes a tool developed for forensically acquiring and analyzing Windows Mobile devices and WinCE PDAs.",
        "prediction": "Mobile devices are very common in everyoneâs day-to-day life. Nowadays, these devices come with many features of desktop and laptop computers, allowing people to use them for a variety of applications. Since many people use these devices, they might also be used for illegal activities. The percentage of mobile phones or smartphones involved in cyber crimes is increasing. Therefore, it becomes necessary to analyze these devices digitally using cyber forensics tools. This paper discusses different types of digital evidence found in Microsoftâs Windows Mobile smartphones and presents an agent-based approach for logically acquiring such devices. Additionally, it describes a tool developed for forensically acquiring and analyzing Windows Mobile devices and WinCE PDAs",
        "reference": "Mobile devices are very common in everyoneâs day-to-day life. Nowadays such devices come with many features of computers. People can use these devices for diverse applications. There are chances that these devices can be used for illegal activities. The percentage of mobile phones or smart phones involved in cyber crimes is increasing. So it becomes necessary to digitally analyze such devices with cyber forensics tools. This paper discusses different types of digital evidence present in Microsoftâs Windows Mobile smart phones and how to acquire such devices. Also it describes a forensic tool for acquiring and analyzing Windows Mobile devices and personal digital assistants."
      },
      {
        "source": "Detection of different types of image editing operations carried out on an image is an important problem in image forensics. It gives the information about the processing history of an image, and also can expose forgeries present in an image. There have been a few methods proposed to detect different types of image editing operations in a single framework. However, all the operations have to be known a priori in the training phase. But, in real-forensics scenarios it may not be possible to know about the editing operations carried out on an image. To solve this problem, we propose a novel deep learning-based method which can differentiate between different types of image editing operations. The proposed method classifies image patches in a pair-wise fashion as either similarly or differently processed using a deep siamese neural network. Once the network learns feature that can discriminate between different image editing operations, it can differentiate between different image editing operations not present in the training stage. The experimental results show the efficacy of the proposed method in detecting/discriminating different image editing operations.",
        "prediction": "Detection of different types of image editing operations on an image is an important problem in image forensics. This process provides information about the processing history of an image and can also reveal forgeries. Several methods have been proposed to detect various types of image editing operations within a single framework. However, these methods require prior knowledge of all operations during the training phase. In real-forensics scenarios, it may not be possible to know all the editing operations performed on an image ahead of time. \n\nTo address this issue, we propose a novel deep learning-based method that can differentiate between various types of image editing operations. Our method compares image patches in pairs to determine if they are processed in the same way or differently, using a deep siamese neural network. Once the network learns the features that distinguish between different image editing operations, it can also identify editing operations not included in the training stage. The experimental results demonstrate the effectiveness of our proposed method in detecting and distinguishing different image editing operations.",
        "reference": "Detection of image editing is an important task in image forensics. The edit history of an image can expose forgeries in the image. Various methods have been proposed to detect image editing operations. However all of the possible types of image manipulation must be known in advance. But, in the real world, manipulations on images are sometimes unknowable. A novel deep learning-based method can distinguish between different types of image editing operations. This method uses a deep siamese neural network to compare images two by two. Using deep learning, the computer can learn to see features of edited images as compared to unedited and learn to differentiate between different image editing operations. This method works to find out what editing an image has undergone."
      },
      {
        "source": "The increasing prevalence of Internet of Things (IoT) devices has made it inevitable that their pertinence to digital forensic investigations will increase into the foreseeable future. These devices produced by various vendors often posses limited standard interfaces for communication, such as USB ports or WiFi/Bluetooth wireless interfaces. Meanwhile, with an increasing mainstream focus on the security and privacy of user data, built-in encryption is becoming commonplace in consumer-level computing devices, and IoT devices are no exception. Under these circumstances, a significant challenge is presented to digital forensic investigations where data from IoT devices needs to be analysed. This work explores the electromagnetic (EM) side-channel analysis literature for the purpose of assisting digital forensic investigations on IoT devices. EM side-channel analysis is a technique where unintentional electromagnetic emissions are used for eavesdropping on the operations and data handling of computing devices. The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require, and must result in, no modification to the target device. The literature on various EM side-channel analysis attack techniques are discussed â selected on the basis of their applicability in IoT device investigation scenarios. The insight gained from the background study is used to identify promising future applications of the technique for digital forensic analysis on IoT devices â potentially progressing a wide variety of currently hindered digital investigations.",
        "prediction": "The increasing prevalence of Internet of Things IoT devices has made it inevitable that their relevance to digital forensic investigations will grow in the foreseeable future These devices produced by various vendors often possess limited standard interfaces for communication such as USB ports or WiFiBluetooth wireless interfaces Meanwhile with a rising focus on the security and privacy of user data built-in encryption is becoming common in consumer-level computing devices and IoT devices are no exception This creates a big challenge for digital forensic investigations because they need to analyze data from IoT devices This work explores the literature on electromagnetic EM side-channel analysis to assist digital forensic investigations on IoT devices EM side-channel analysis is a technique that uses unintentional electromagnetic emissions to eavesdrop on the operations and data handling of computing devices The non-intrusive nature of EM side-channel approaches makes them a viable option for assisting digital forensic investigations as these methods require no modification to the target device The literature on various EM side-channel analysis attack techniques is discussed selected based on their applicability in IoT device investigation scenarios The insights gained from this background study are used to identify promising future applications of the technique for digital forensic analysis on IoT devices potentially advancing a wide variety of currently hindered digital investigations",
        "reference": "Internet of Things (IoT) devices (devices connected to the internet, collecting and sharing data) will be used in digital forensic investigations in the future. These devices have limited interfaces for communication, such as USB ports or WiFi/Bluetooth wireless interfaces. Meanwhile, with an increasing focus on the security and privacy of user data, built-in encryption (which encode information) is becoming commonplace in devices. This presents a significant challenge to digital forensic investigations, where data from IoT devices needs to be analysed. This work explores the electromagnetic (EM) side-channel analysis literature for the purpose of assisting digital forensic investigations on IoT devices. EM side-channel analysis is a technique where electromagnetic emissions are used for eavesdropping on the operations and data handling of devices. The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require no modification to the target device. The literature on various EM side-channel analysis attack techniques are discussed â selected according to their applicability in IoT device investigations. The data obtained from our survey are used to identify promising future applications of the technique for digital forensic analysis on IoT devices."
      },
      {
        "source": "The malicious alteration of machine time is a big challenge in computer forensics. Performance figures show the feasibility of our proposal. Detecting such changes and reconstructing the actual timeline of events is of paramount importance. However, this can be difficult since the attacker has many opportunities and means to hide such changes. In particular, cloud computing, host and guest machine time can be manipulated in various ways by an attacker. Guest virtual machines are especially vulnerable to attacks coming from their (more privileged) host. As such, it is important to guarantee the timeline integrity of both hosts and guests in a cloud, or at least to ensure that the alteration of such timeline does not go undetected. In this paper we survey the issues related to host and guest machine time integrity in the cloud. Further, we describe a novel architecture for host and guest time alteration detection and correction/resilience with respect to compromised hosts and guests. The proposed framework has been implemented on an especially built simulator.",
        "prediction": "The malicious alteration of machine time is a big challenge in computer forensics. Performance figures show the feasibility of our proposal. Detecting such changes and reconstructing the actual timeline of events is of paramount importance. However, this can be difficult since attackers have many opportunities to hide these changes. Specifically, an attacker can change the time of cloud computing systems and the time of host and guest machines in different ways. Guest virtual machines are especially vulnerable to attacks coming from their more privileged hosts. Therefore, it is important to ensure the timeline integrity of both hosts and guests in a cloud environment or to at least guarantee that any alterations go undetected. In this paper, we survey the issues related to host and guest machine time integrity in the cloud. Further, we describe a novel architecture for detecting and correcting time alterations while maintaining resilience against compromised hosts and guests. The proposed framework has been implemented on a specially built simulator",
        "reference": "Machine timestamp falsification can be used in cyber attacks. The algorithm detects manipulations effectively. That is why it is important to detect such changes and to reconstruct the actual timeline of events. However, the hacker can try to hide their tracks. In cloud computing, hackers can manipulate host and guest machine time. Guest virtual machines use computing resources provided by a physical machine called a host. Guest virtual machines are especially vulnerable to attacks coming from their host. That is why the timeline integrity of both hosts and guests in a cloud is important. Any manipulation of such a timeline should be detected. In this paper we survey the issues related to host and guest machine time integrity in the cloud. A new algorithm is proposed to detect host and guest time manipulations and to correct or reject them. A simulator has been built for this purpose."
      },
      {
        "source": "Image tampering, being readily facilitated and proliferated by todayâs digital techniques, is increasingly causing problems regarding the authenticity of images. As the most popular multimedia data, JPEG images can be easily tampered without leaving any clues; therefore, JPEG-based forensics , including the detection of double compression, interpolation, rotation, etc., has become an active research topic in multimedia forensics. Nevertheless, the interesting issue of detecting image tampering and its related operations by using the same quantization matrix has not been fully investigated. Aiming to detect such forgery manipulations under the same quantization matrix, we propose a detection method by using shift-recompression -based reshuffle characteristic features. The learning classifiers are applied for classification. Our experimental results indicate that the approach is indeed highly effective in detecting image tampering and relevant manipulations with the same quantization matrix.",
        "prediction": "Image tampering, facilitated and proliferated by todayâs digital techniques, increasingly poses problems regarding the authenticity of images. As the most popular type of multimedia data, JPEG images can be easily tampered with, often without leaving any clues. As a result, JPEG forensics, which examines issues such as double compression, interpolation, and rotation, has become an important area of research in multimedia forensics. However, the essential issue of detecting image tampering and related activities that use the same quantization matrix has not been fully explored. To address this gap, we suggest a method to detect forgery techniques that use the same quantization matrix by using unique features from shift-recompression. We employ learning classifiers to categorize the data. Our experimental results demonstrate that this approach is highly effective in detecting image tampering and related manipulations that involve the same quantization matrix.",
        "reference": "Image tampering has become a serious problem with the advancement of digital techniques. JPEG images can be easily manipulated without leaving any clues. This is why researchers are trying to develop methods for JPEG image manipulation detection. However, methods based on image compression techniques, like quantization, are rarely applied. To detect such manipulations, we propose a detection method to identify inconsistencies in the quantization matrix caused by the manipulation. Then machine learning algorithms are applied to detect image manipulation. Experimental results show that the approach is highly effective in detecting image tampering."
      },
      {
        "source": "In this paper, we present a novel approach to accurately calibrate the kinematic model of a humanoid based on observations of its monocular camera. Our technique estimates the parameters of the complete model, consisting of the joint angle offsets of the whole body including the legs, as well as the camera extrinsic and intrinsic parameters. Furthermore, we developed an approach to automatically select a subset of configurations for the calibration process that yields a good trade-off between the number of observations and accuracy. Further, our approach to configuration selection yields substantially better optimization results compared to randomly chosen viable configurations. Hence, our system only requires a reduced number of configurations to achieve accurate results. Our optimization is general and the implementation, which is available online, can easily be applied to different humanoids.",
        "prediction": "In this paper, we present a novel approach to accurately calibrate the kinematic model of a humanoid based on observations from its monocular camera. Our technique calculates the settings of a full model, which includes the joint angle adjustments for the entire body, including the legs, along with the external and internal settings of the camera. Furthermore, we developed a method to automatically select a subset of configurations for the calibration process that strikes a good balance between the number of observations and accuracy. Our approach to configuration selection also yields significantly better optimization results compared to randomly chosen viable configurations. As a result, our system only requires a reduced number of configurations to achieve accurate outcomes. Our optimization is general, and the implementation, which is available online, can be easily applied to different humanoids.",
        "reference": "In this paper, we present a novel approach to accurately calibrate a humanoid and its motions (robot with human form or characteristics) based on observations of its camera. Our technique estimates the parameters of the complete model, consisting of the joint angle offsets and the camera parameters. We developed an approach to automatically select configurations for the calibration process that produces a good compromise between the number of observations and accuracy. Our approach to configuration selection generates better optimization results compared to randomly chosen viable configurations. Thus, our system only requires a reduced number of configurations to achieve accurate results. Our optimization is general and the implementation, which is available online, can easily be applied to different humanoids."
      },
      {
        "source": "In this paper, we present an integrated navigation system that allows humanoid robots to autonomously navigate in unknown, cluttered environments. From the data of an onboard consumer-grade depth camera, our system estimates the robot's pose to compensate for drift of odometry and maintains a heightmap representation of the environment. Based on this model, our system iteratively computes sequences of safe actions including footsteps and whole-body motions, leading the robot to target locations. To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles. As we demonstrate in experiments with a Nao humanoid, our system leads to robust navigation in cluttered environments and the robot is able to traverse highly challenging passages.",
        "prediction": "In this paper, we present an integrated navigation system that allows humanoid robots to autonomously navigate in unknown, cluttered environments. Our system uses data from a consumer-grade depth camera attached to the robot to determine its pose, correct for drift in its movement, and create a height map of the environment. Using this model, our system repeatedly plans safe actions, such as steps and movements, to guide the robot to its target locations. To efficiently check for collisions during planning, we developed a new method that takes into account the shape of the robot and the nearby obstacles. As we demonstrate in experiments with a Nao humanoid robot, our system enables robust navigation in cluttered environments, allowing the robot to traverse highly challenging passages.",
        "reference": "In this paper, we present a navigation system that allows humanoid robots (robots with human form or characteristics) to autonomously navigate in unknown, cluttered environments. From the data of a camera which can judge depth and distance, our system estimates the robotâs position and maintains a height representation of the environment. Our system determines safe actions (including footsteps and body motions) leading the robot to target locations. To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles. As we demonstrate in experiments, our system allows the robot to navigate in clustered environments and traverse challenging passages."
      },
      {
        "source": "In this paper, we introduce an approach to efficient robot navigation through cluttered indoor environments. We propose to estimate local obstacle densities based on already detected objects and use them to predict traversal costs corresponding to potential obstacles in regions not yet observable by the robot's sensors. By taking into account the predicted costs for path planning, the robot is then able to navigate in a more foresighted manner and reduces the risk of getting stuck in cluttered regions. As the experimental results demonstrate, our method enables the robot to efficiently navigate through environments containing cluttered regions and achieves significantly shorter completion times compared to a standard approach not using any prediction.",
        "prediction": "In this paper, we introduce an approach to efficient robot navigation through cluttered indoor environments. We propose to calculate how many obstacles are nearby using objects we have already found and use that information to guess how difficult it will be to move past potential obstacles in areas that the robot's sensors can't see yet. By considering these predicted costs in path planning, the robot can navigate in a more foresighted manner, reducing the risk of getting stuck in cluttered regions. As the experimental results demonstrate, our method enables the robot to efficiently navigate through environments with cluttered areas and achieves significantly shorter completion times compared to a standard approach that does not use any prediction.",
        "reference": "In this paper, we introduce an approach for robot to navigate through cluttered indoor environments. We propose to estimate obstacles based on already detected objects and use them to predict potential obstacles in regions not yet observable by the robot. The robot is then able to navigate in a more anticipated manner and reduces the risk of getting stuck. Our method enables the robot to efficiently navigate through cluttered environments and faster than a standard approach not using any prediction."
      },
      {
        "source": "In many situations, users walk on typical paths between specific destinations at which the service of a mobile robot is needed. Depending on the environment and the paths, step-by-step following of the human might not be the optimal solution since better paths for the robot exist. We propose to perform a prediction about the human's future movements and use this information in a reinforcement learning framework to generate foresighted navigation actions for the robot. Since frequent occlusions of the human will occur due to obstacles and the robot's constrained field of view, the estimate about the humans's position and the prediction of the next destination are affected by uncertainty. Our approach deals with such situations by explicitly considering occlusions in the reward function such that the robot automatically considers to execute actions to get the human in its field of view. We show in simulated and real-world experiments that our technique leads to significantly shorter paths compared to an approach in which the robot always tries to closely follow the user and, additionally, can handle occlusions.",
        "prediction": "In many situations, users walk on typical paths between specific destinations where the service of a mobile robot is needed. Depending on the environment and the paths, following the human step-by-step might not be the best solution, as there could be better paths for the robot to take. We propose predicting the human's future movements and using this information within a reinforcement learning framework to generate effective navigation actions for the robot. Frequent occlusions of the human will occur due to obstacles and the robot's limited field of view, affecting both the estimate of the human's position and the prediction of their next destination. Our approach addresses these challenges by factoring in occlusions in the reward system, so the robot considers actions that will bring the human into its view. We demonstrate through simulated and real-world experiments that our technique results in significantly shorter paths compared to approaches where the robot always tries to closely follow the user, while also effectively handling occlusions.",
        "reference": "In many situations, users walk on typical paths between specific destinations at which the service of a mobile robot is needed. Depending on the environment and the paths, following the human might not be the optimal solution because better paths for the robot exist. We propose to predict the humanâs future movements and use this information to generate navigation actions for the robot. The estimation of the humanâs position and the prediction of the next destination are uncertain because of the occlusions due to obstacles and the robotâs limited field of view. Our approach deals with considering occlusions so the robot automatically considers to execute actions to get the human in its field of view. We show that our technique leads to significantly shorter paths compared to an approach in which the robot follows the user and, additionally, can handle occlusions."
      },
      {
        "source": "An autonomous service robot often first has to search for a user to carry out a desired task. This is a challenging problem, especially when this person moves around since the robotâs field of view is constrained and the environment structure typically poses further visibility constraints that influence the perception of the user. In this paper, we propose a novel method that computes the likelihood of the userâs observability at each possible location in the environment based on Monte Carlo simulations. As the robot needs time to reach the possible search locations, we take this time as well as the visibility constraints into account when computing effective search locations. In this way, the robot can choose the next search location that has the maximum expected observability of the user. Our experiments in various simulated environments demonstrate that our approach leads to a significantly shorter search time compared to a greedy approach with background information.",
        "prediction": "An autonomous service robot often first has to search for a user to carry out a desired task. This is a challenging problem, especially when the person moves around, as the robot has a limited view, making it harder to see the person due to the layout of the environment. In this paper, we propose a novel method that computes the likelihood of the userâs observability at each possible location in the environment based on Monte Carlo simulations. As the robot needs time to reach the possible search locations, we consider this time as well as the visibility constraints when determining effective search locations. This way, the robot can choose the next search location that offers the maximum expected observability of the user. Our experiments in various simulated environments demonstrate that our approach leads to a significantly shorter search time compared to a greedy approach that uses background information.",
        "reference": "An autonomous service robot often first has to search for a user to execute a task. This is a challenging problem, especially when this person moves around because the robotâs field of view is limited. The environment also poses visibility limitations that influence the perception of the user. In this paper, we propose a method that estimate the userâs observability in the environment. When estimating effective search locations, we take into account the time for the robot to reach the search location and the visibility limitations. In this way, the robot can choose the next search location that has the maximum expected observability of the user. Our experiments demonstrate that our approach leads to a significantly shorter search time compared to other approach."
      },
      {
        "source": "Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments. Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions. For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information. Considering dynamic obstacles introduces another level of complexity, since they can lead to necessary replanning or collisions at later stages. In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be efficiently planned in real time at low CPU cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.",
        "prediction": "Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments. Most robots, such as humanoids and smaller wheeled robots, rely on planar regions. For humanoids, a simple 2D map of the environment is not enough for planning paths because they can step over or onto objects, so they need information about height. Additionally, considering dynamic obstacles introduces another level of complexity, as these obstacles can lead to necessary replanning or collisions at later stages. In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, allowing paths to be efficiently planned in real time at low CPU cost. We demonstrate in simulations and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and enables foresighted real-time 3D footstep planning",
        "reference": "Perception of the environment is necessary for mobile robots to navigate safely in dynamic environments. Most robots (humanoids and wheeled robots) rely on planar regions. For humanoids (robots with human form or characteristics), a 2D map is not sufficient because they can step over and onto objects, so they need height information. Dynamic obstacles bring another level of complexity, because it can lead to necessary replanning or collisions. In this paper, we present a framework that extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be planned in real time at low processor cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms and allows for real-time 3D footstep planning."
      },
      {
        "source": "In this paper, a lab automation drone notional concept is introduced. Here, a robotic limb is attached to a robotic rotorcraft. The limb's gripper allows the unmanned aerial vehicle to dexterously manipulate objects such as micro-arrays and test tubes often used in high throughput systems (HTS). The resulting drone could augment existing HTS operations. The 6 degree-of-freedom (DOF) arm and gripper design are presented. Test-and-evaluation approach and results are also given.",
        "prediction": "In this paper, a concept for a lab automation drone is introduced. Here, a robotic limb is attached to a rotorcraft. The gripper on the robotic limb lets the drone skillfully handle small items like micro-arrays and test tubes that are commonly used in high-throughput systems HTS. This resulting drone could help improve existing HTS operations. The design of the 6 degree-of-freedom DOF arm and gripper is presented, along with the test-and-evaluation approach and results",
        "reference": "In this paper, a concept of lab automation drone is introduced. Here, a robotic arm is attached to a drone. The armâs gripper allows the drone to manipulate objects such as chips and test tubes often used in scientific experimentations like high throughput systems. The drone could augment existing high throughput systems operations. The 6 degree-of-freedom arm and gripper design are presented. Results of evaluations and tests are also given."
      },
      {
        "source": "Robot companionship has become more popular in past years. However, humanoid gait might be somewhat unstable for these applications. Even with miniature humanoids, falls occur frequently. Thus, wheel attachments have been added onto a miniature humanoid, so it can move faster and with more stability than walking. In addition, with such attachments a robot can switch from walking to rolling when necessary. DARwIn-OP is a humanoid robot that has been used as an experimentation and performance evaluation platform. This paper discusses preliminary work regarding robot companionship applications by using a miniature humanoid capable of fetching different toys based on voice command.",
        "prediction": "Robot companionship has become more popular in past years. However, humanoid gait might be somewhat unstable for these applications. Even with small humanoid robots, falls occur frequently. To address this, wheel attachments have been added to these robots, allowing them to move faster and more steadily than by walking. Additionally, with these attachments, a robot can switch from walking to rolling when necessary. DARwIn-OP is a humanoid robot that has been used as a platform for experimentation and performance evaluation. This paper discusses preliminary work regarding robot companionship applications using a miniature humanoid capable of fetching different toys based on voice command.",
        "reference": "Robot companionship has become more popular in past years. However, humanoid (robots with human form or characteristics) walking might be unstable. Even with miniature humanoids, falls occur frequently. Wheels have been added onto a miniature humanoid, so it can move faster and with more stability than walking. With wheels, a robot can switch from walking to rolling when necessary. DARwIn-OP is a humanoid robot that has been used for experimentation and evaluation. This paper discusses preliminary work for robot companionship applications by using a miniature humanoid capable of fetching different toys based on voice command."
      },
      {
        "source": "In the modern era of automation and robotics, autonomous vehicles are currently the focus of academic and industrial research. The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6m/sec. We present the same results in this research and compare them with other state-of-the-art methods of vision and learning based navigation. With the ever increasing number of unmanned aerial vehicles getting involved in activities in the civilian and commercial domain, there is an increased need for autonomy in these systems too. Due to guidelines set by the governments regarding the operation ceiling of civil drones, road-tracking based navigation is garnering interest. In an attempt to achieve the above mentioned tasks, we propose an imitation learning based, data-driven solution to UAV autonomy for navigating through city streets by learning to fly by imitating an expert pilot. Derived from the classic image classification algorithms, our classifier has been constructed in the form of a fast 39-layered Inception model, that evaluates the presence of roads using the tomographic reconstructions of the input frames. Based on the Inception-v3 architecture, our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning. The data used for training the system has been captured from the drone, by flying it in and around urban and semi-urban streets, by experts having at least 6-8 years of flying experience. Permissions were taken from required authorities who made sure that minimal risk (to pedestrians) is involved in the data collection process. With the extensive amount of drone data that we collected, we have been able to navigate successfully through roads without crashing or overshooting, with an accuracy of 98.44%.",
        "prediction": "In the modern era of automation and robotics autonomous vehicles are currently the focus of academic and industrial research The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6 m/sec In this research we present the same results and compare them with other state-of-the-art methods of vision and learning-based navigation As the number of unmanned aerial vehicles increases in civilian and commercial activities the need for autonomy in these systems also grows Due to government guidelines on the operation ceiling of civil drones road-tracking-based navigation is gaining interest\n\nTo achieve these tasks we propose a data-driven imitation learning-based solution for UAV autonomy enabling navigation through city streets by mimicking an expert pilot Our classifier is based on traditional image classification algorithms and is built as a fast 39-layer Inception model It checks for the presence of roads using detailed images from the input frames Based on the Inception-v3 architecture our system outperforms many existing models for imitation learning in terms of processing complexity and accuracy\n\nThe data used for training the system was captured by flying the drone in and around urban and semi-urban streets piloted by experts with 6 to 8 years of flying experience Permissions were obtained from the relevant authorities to ensure minimal risk to pedestrians during data collection With the extensive amount of drone data we collected we successfully navigated through roads without crashing or overshooting achieving an accuracy of 98.44%",
        "reference": "Current academic and industrial research is interested in autonomous vehicles. MAVNet computational efficiency enables the drone to fly up to 6m/sec. The solution is compared with other recent methods. Drones are increasingly used in the civilian and commercial domain and need to be autonomous. Governments set guidelines on the operation ceiling of civil drones. So, road-tracking based navigation is attracting interest. Researchers propose data-driven solutions allowing drones to autonomously navigate city streets, learning to fly by imitating an expert pilot. The algorithm, based on the Inception model, detects roads using tomographic reconstructions. The Inception model is an extension of classic image classification algorithms. The Inception-v3 architecture has better accuracy than many existing models of imitation learning. The data used for training the system was captured from the drone over urban streets, navigated by an expert pilot. Data collection requires special permission to ensure pedestrian security. The drone can navigate successfully through roads without crashing or overshooting; its accuracy is 98.44%."
      },
      {
        "source": "Advances in electronics and sensor technology have widened the scopes of networked drones to include applications as diverse as surveillance, video recording, operations, entertainment/advertising, signal emission, transportation, and delivery. These applications and services require video recording for their operations. Large drones are used singly in missions while small ones are used in formations or swarms. The small drones are proving to be useful in civilian applications. Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones. To develop group display applications, a real-time drone formation control for group display is proposed. Simulation shows that drone formation can display messages effectively.",
        "prediction": "Improvements in electronics and sensor technology have expanded the use of networked drones to many areas such as surveillance video recording various operations entertainment advertising signal broadcasting transportation and delivery. These applications and services require video recording for their operations. Large drones are typically used for individual missions while small drones are often used in formations or swarms. The small drones are proving to be useful in civilian applications. The consideration of small drones for uses such as group flight entertainment and signal broadcasting has led to the deployment of networked drones. To develop group display applications a real-time drone formation control for group display is proposed. Simulations show that drone formations can effectively display messages",
        "reference": "Advances in technology allowed drones to be used for surveillance, video recording, operations, entertainment/advertising, signal emission, transportation, and delivery. These applications and services require video recording. Large drones are used individually while small ones are used in groups. The small drones are proving to be useful in civilian applications. Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones. To develop group display applications, a real-time drone formation control for group display is proposed. Simulation shows that drone formation can display messages effectively."
      },
      {
        "source": "This study focuses on the digital marketing capabilities of tourism SMEs. The study addresses the question of how the use of ICT-based tools benefit the organisational capabilities of a company. By adopting marketing as a set-of-skills approach, the study provides new insights into the existing tourism literature on e-marketing. Initial findings indicate that the digital marketing capabilities of companies are transformed through ICT-based uptake. Four major capabilities were identified, each of which evolves as a result of using the tools. A key finding of the study is that the use of ICT-based tools transforms digital marketing capabilities from a set of abilities that enables tourism SMEs not only to float in a web-marketing stream, but also to lead such a stream.",
        "prediction": "This study focuses on the digital marketing capabilities of tourism SMEs. It looks at how using ICT tools helps improve a company's skills. By adopting marketing as a set-of-skills approach, the study provides new insights into the existing tourism literature on e-marketing. Initial findings indicate that the digital marketing capabilities of companies are transformed through the use of ICT tools. Four major capabilities were identified, each evolving as a result of using these tools. A key finding of the study is that the use of ICT tools transforms digital marketing capabilities, enabling tourism SMEs not only to navigate the web-marketing landscape but also to lead in it",
        "reference": "This study focuses on the digital marketing capabilities of tourism small and medium-sized enterprises (SMEs). The study questions on how information and communication technology (ICT) tools can help the organisational capabilities of a company. The study provides new insights from tourism studies on digital marketing. Findings show that digital marketing capabilities of companies are transformed by ICT tools. Four major capabilities were identified, each of which evolves as a result of using the tools. A key finding of the study is that ICT tools transform these capabilities in a set of abilities for SMEs in web-marketing."
      },
      {
        "source": "The prevalence and rapid development of the Internet and mobile technology in recent decades has revamped our living styles and daily habits. To ride on the digital trend, more business activities have been engaged in the digital world. Marketing and advertising is one of typical business areas that is transformed digitally. The rise of Key Opinion Leaders (KOLs), social media platforms, and Omni-channel retailing have attracted countless business entities to consider the adoption of digital marketing tools for promoting and advertising their brands and products. However, with the increasing diversity of the types of digital marketing tools, they must be carefully selected based on a multiple number of criterion. In this paper, a fuzzy-AHP method is proposed and developed for assisting industry practitioners in systematically and effectively evaluate and select proper digital marketing tool(s) for adoption. The developed method not only streamlines the internal business process of digital marketing tool selection, but it also increases the practitioner's effectiveness of achieving the pre-defined strategic marketing objectives.",
        "prediction": "The prevalence and rapid development of the Internet and mobile technology in recent decades have revamped our living styles and daily habits. To keep up with the digital trend, more business activities have moved into the digital world. Marketing and advertising are typical areas of business that have been transformed digitally. The growth of influencers, social media platforms, and multi-channel selling has led many businesses to consider using digital marketing tools to promote their brands and products. However, with the increasing variety of digital marketing tools available, careful selection based on multiple criteria is essential. In this paper, a fuzzy-AHP method is proposed and developed to assist industry practitioners in systematically and effectively evaluating and selecting appropriate digital marketing tool(s) for adoption. This method not only streamlines the internal business process of selecting digital marketing tools but also enhances practitioners' effectiveness in achieving their predefined strategic marketing objectives.",
        "reference": "The development of the Internet and mobile technology in recent decades has modified our living styles and daily habits. More business activities have been engaged in the digital world. Marketing and advertising is one of typical business areas that is transformed digitally. Many businesses consider the adoption of digital marketing tools for their promotion and advertisement, due to the rise of Key Opinion Leaders (person with expert status and influence), social media platforms, and Omni-channel retailing (multiple channels but a uniform experience for the customer). However, with the increasing diversity of digital marketing tools, they must be carefully selected. In this paper, a method to organize and analyze complex decisions is proposed and developed for assisting businesses to evaluate and select appropriate digital marketing tools. The developed method rationalizes and simplifies the process of digital marketing tool selection. It also increases effectiveness of achieving strategic marketing objectives."
      },
      {
        "source": "In this paper we revisit a topic originally discussed in 1955, namely the lack of direct evidence that muscle hypertrophy from exercise plays an important role in increasing strength. To this day, long-term adaptations in strength are thought to be primarily contingent on changes in muscle size. Given this assumption, there has been considerable attention placed on programs designed to allow for maximization of both muscle size and strength. However, the conclusion that a change in muscle size affects a change in strength is surprisingly based on little evidence. We suggest that these changes may be completely separate phenomena based on: (1) the weak correlation between the change in muscle size and the change in muscle strength after training; (2) the loss of muscle mass with detraining, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load resistance training, yet divergent results in strength.",
        "prediction": "In this paper, we revisit a topic originally discussed in 1955: the lack of direct evidence that muscle hypertrophy from exercise plays an important role in increasing strength. To this day, long-term adaptations in strength are thought to primarily depend on changes in muscle size. Given this assumption, considerable attention has been given to programs designed to maximize both muscle size and strength. However, the belief that increasing muscle size leads to increased strength is surprisingly supported by very little evidence. We suggest that these changes may be completely separate phenomena based on: (1) the weak correlation between changes in muscle size and muscle strength after training; (2) the loss of muscle mass with detraining, yet the maintenance of muscle strength; and (3) the similar muscle growth observed between low-load and high-load resistance training, yet divergent results in strength.",
        "reference": "In this paper we revisit a topic originally discussed in 1955, namely the lack of evidence that muscle growth plays an important role in increasing strength. To this day, long-term adaptations in strength are thought to be related to changes in muscle size. Given this assumption, training programs made for increasing both muscle size and strength were popular. However, the conclusion that a change in muscle size has an influence on strength is surprisingly based on little evidence. We suggest that these changes may be based on: (1) the weak correlation between the change in muscle size and the change in muscle strength after training; (2) the loss of muscle mass with the interruption of training, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load strength training, yet different results in strength."
      },
      {
        "source": "Low-intensity occlusion (50-100 mm hg) training provides a unique beneficial training mode for promoting muscle hypertrophy. Training at intensities as low as 20% 1 repetition maximum with moderate vascular occlusion results in muscle hypertrophy in as little as 3 weeks. A typical exercise prescription calls for 3 to 5 sets to volitional fatigue with short rest periods. The metabolic buildup causes positive physiologic reactions, specifically a rise in growth hormone that is higher than levels found with higher intensities. Occlusion training is applicable for those who are unable to sustain high loads due to joint pain, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts.",
        "prediction": "Low-intensity occlusion (50-100 mm hg) training provides a unique beneficial training mode for promoting muscle hypertrophy. Training at intensities as low as 20% of one repetition maximum with moderate vascular occlusion results in muscle hypertrophy in as little as 3 weeks. A typical exercise prescription calls for 3 to 5 sets to volitional fatigue with short rest periods. The buildup of substances during exercise leads to good effects in the body, particularly an increase in growth hormone, which is greater than what occurs with more intense workouts. Occlusion training is especially useful for those who cannot handle high loads due to joint pain, postoperative recovery, cardiac rehabilitation, athletes who are unloading, and astronauts.",
        "reference": "Low-intensity occlusion training, which is a training method with blood flow restriction, provides a unique beneficial training mode for muscle growth. Training at intensities as low as 20% of maximum strength with moderate occlusion results in muscle growth in 3 weeks. A typical exercise consists of 3 to 5 sets to muscle failure with short rest periods. The metabolic accumulation causes positive physiologic reactions, specifically a rise in growth hormone, which is one of the main hormone responsible of muscle growth, that is higher than levels found with higher intensities. Occlusion training is applicable for those who are unable to sustain high loads due to joint pain, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts."
      },
      {
        "source": "Current dogma suggests aerobic exercise training has minimal effect on skeletal muscle size. We and others have demonstrated that aerobic exercise acutely and chronically alters protein metabolism and induces skeletal muscle hypertrophy. These findings promote an antithesis to the status quo by providing novel perspective on skeletal muscle mass regulation and insight into exercise-countermeasures for populations prone to muscle loss.",
        "prediction": "Current dogma suggests aerobic exercise training has minimal effect on skeletal muscle size. We and others have demonstrated that aerobic exercise changes how proteins are processed in the body both right away and over time and helps muscles grow. These findings challenge the traditional view by providing a new perspective on how muscle mass is regulated and offering insights into exercise strategies for people at risk of muscle loss.",
        "reference": "Current belief suggests cardio exercise training has minimal effect on muscle size. We and others have demonstrated that cardio exercise alters protein metabolism (responsible for protein synthesis and muscle growth) and induces muscle growth. These findings against the current belief provide a novel perspective on muscle mass regulation and insight into exercise to prevent muscle loss."
      },
      {
        "source": "Stretch training is widely used in a variety of fitness-related capacities such as increasing joint range of motion, preventing contractures and alleviating injuries. Moreover, some researches indicate that stretch training may induce muscle hypertrophy; however, studies on the topic have been primarily relegated to animal and in vitro models. The purpose of this brief review was to evaluate whether stretch training is a viable strategy to induce muscle hypertrophy in humans. Of the 10 studies identified, 3 observed some significantly positive effects of stretch training on muscle structure. Intriguingly, in these studies, the stretching was carried out with an apparatus that aided in its performance, or with an external overload. Of the 5 available studies that integrated stretching into a resistance training programme, 2 applied the stretching in the interset rest period and were the ones that showed enhanced muscle growth. In conclusion, passive, low-intensity stretch does not appear to confer beneficial changes in muscle size and architecture; alternatively, albeit limited evidence suggests that when stretching is done with a certain degree of tensile strain (particularly when loaded, or added between active muscle contractions) may elicit muscle hypertrophy.",
        "prediction": "Stretch training is widely used in a variety of fitness-related capacities such as increasing joint range of motion preventing contractures and alleviating injuries. Some studies suggest that stretch training can help muscles grow; however most research has mainly been done on animals and in lab settings. This brief review aims to evaluate whether stretch training is a viable strategy to promote muscle growth in humans. Of the 10 studies identified 3 reported significantly positive effects of stretch training on muscle structure. Interestingly in these studies stretching was performed using an apparatus that assisted in the process or with an external load. Among the 5 available studies that included stretching in a resistance training program 2 applied stretching during rest periods between sets and showed enhanced muscle growth. In conclusion passive low-intensity stretching does not seem to bring beneficial changes in muscle size and structure. However limited evidence suggests that stretching with a certain degree of tension especially when loaded or added between active muscle contractions may encourage muscle growth.",
        "reference": "Stretch training is used in a variety of fitness capacities such as increasing flexibility, preventing contractures (shortening of muscle) and reduce injuries. Moreover, some researches indicate that stretch training may induce muscle growth. The purpose of this review was to evaluate if stretch training is a viable strategy to induce muscle growth in humans. Of the 10 studies identified, 3 observed positive effects of stretch training on muscles. In these studies, the stretching was performed with external help like equipment or load. Of the 5 available studies that integrated stretching into strength training, 2 applied the stretching in the rest period between the sets and were the ones that showed enhanced muscle growth. In conclusion, passive, low-intensity stretch does not appear to produce beneficial changes in muscles but evidence suggests that when stretching is done with a certain intensity (particularly when loaded, or added between active muscle contractions), it may induce muscle growth."
      },
      {
        "source": "Cycle training is widely performed as a major part of any exercise program seeking to improve aerobic capacity and cardiovascular health. However, the effect of cycle training on muscle size and strength gain still requires further insight, even though it is known that professional cyclists display larger muscle size compared to controls. Therefore, the purpose of this review is to discuss the effects of cycle training on muscle size and strength of the lower extremity and the possible mechanisms for increasing muscle size with cycle training. It is plausible that cycle training requires a longer period to significantly increase muscle size compared to typical resistance training due to a much slower hypertrophy rate. Cycle training induces muscle hypertrophy similarly between young and older age groups, while strength gain seems to favor older adults, which suggests that the probability for improving in muscle quality appears to be higher in older adults compared to young adults. For young adults, higher-intensity intermittent cycling may be required to achieve strength gains. It also appears that muscle hypertrophy induced by cycle training results from the positive changes in muscle protein net balance.",
        "prediction": "Cycle training is widely performed as a major part of any exercise program aimed at improving aerobic capacity and cardiovascular health. However, the effects of cycle training on muscle size and strength still need further exploration, even though it is known that professional cyclists tend to have larger muscles compared to those who do not cycle. Therefore, this review will discuss the impact of cycle training on the muscle size and strength of the lower body, as well as the possible mechanisms for increasing muscle size through this type of training. \n\nIt is likely that cycle training takes longer to noticeably increase muscle size than regular weight training because it promotes muscle growth at a slower rate. Cycle training induces muscle hypertrophy similarly in both young and older individuals, while strength gains tend to favor older adults. This suggests that older adults may have a higher likelihood of improving muscle quality compared to younger adults. For younger individuals, higher-intensity intermittent cycling may be necessary to achieve strength gains. Additionally, it seems that muscle hypertrophy from cycle training is related to positive changes in muscle protein net balance.",
        "reference": "Cycling training is performed as a major part of any training program which objective is to improve cardiovascular capacities and health. However, the effect of cycling training on muscle size and strength still requires a better comprehension. Therefore, the purpose of this review is to discuss the effects of cycling training on muscle size and strength of the legs and the possible mechanisms for increasing muscle size with cycling training. It is plausible that cycling training requires a longer period to significantly increase muscle size compared to strength training due to a much slower muscle growth rate. Cycling training induces muscle growth similarly between young and older people, while strength gain seems to favor older adults. For young adults, series of high-intensity cycling may be required to achieve strength gains. It also appears that muscle growth induced by cycling training results from the positive changes in protein balance, which is the balance between protein intake which leads to muscle growth and protein loss which leads to muscle loss)."
      },
      {
        "source": "Resistance training is the most effective method to increase muscle mass. It has also been shown to promote many health benefits. Although it is deemed safe and of clinical relevance for treating and preventing a vast number of diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies. Similarly, an inverted U-shaped relationship between training dose/volume and physiological response has been hypothesized to exist. However, the majority of available evidence supports a clear dose-response relationship between resistance training volume and physiological responses, such as muscle hypertrophy and health outcomes. Additionally, there is a paucity of data to support the inverted U-shaped response. The overarching principle argued herein is that volume is the most easily modifiable variable that has the most evidenced-based response with important repercussions, be these muscle hypertrophy or health-related outcomes.",
        "prediction": "Resistance training is the most effective method to increase muscle mass and has been shown to promote many health benefits. Although it is deemed safe and of clinical relevance for treating and preventing a vast number of diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies. Similarly, an inverted U-shaped relationship between training dose/volume and physiological response has been hypothesized to exist. However, most evidence supports a clear dose-response relationship between resistance training volume and physiological responses, such as muscle hypertrophy and health outcomes. Moreover, there is a lack of data to support the inverted U-shaped response. The overarching principle argued herein is that volume is the most easily modifiable variable that has the most evidenced-based response with important repercussions, be these muscle hypertrophy or health-related outcomes.",
        "reference": "Strength training is the most effective method to increase muscle mass. It has also been shown to promote many health benefits. Although it is helpful for treating and preventing diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies. Similarly, an inverted U-shaped relationship (which means that the efficiency increases until a point, and then starts decreasing) between training volume and physiological response has been hypothesized to exist. However, evidence supports a clear correlation between resistance training volume (number of exercises, sets, etc.) and physiological responses, such as muscle growth and health outcomes. Additionally, there is a lack of data to support the inverted U-shaped response. The principle suggested is that volume is the most easily modifiable variable that has the most important response, for muscle growth or health outcomes."
      },
      {
        "source": "Although the effects of short versus long inter-set rest intervals in resistance training on measures of muscle hypertrophy have been investigated in several studies, the findings are equivocal and the practical implications remain unclear. Current evidence indicates that both short and long inter-set rest intervals may be useful when training for achieving gains in muscle hypertrophy. Novel findings involving trained participants using measures sensitive to detect changes in muscle hypertrophy suggest a possible advantage for the use of long rest intervals to elicit hypertrophic effects. However, due to the paucity of studies with similar designs, further research is needed to provide a clear differentiation between these two approaches.",
        "prediction": "Although the effects of short versus long inter-set rest intervals in resistance training on measures of muscle hypertrophy have been investigated in several studies, the findings are unclear and the practical implications remain ambiguous. Current evidence suggests that both short and long rest intervals can be helpful for building muscle. Novel findings involving trained participants using sensitive measures to detect changes in muscle hypertrophy suggest a possible advantage for longer rest intervals in promoting muscle growth. However, due to the lack of studies with similar designs, further research is needed to clearly differentiate between these two approaches.",
        "reference": "The effects of short versus long rest intervals between sets in strength training on muscle growth have been investigated in several studies but the findings and the practical implications are unclear. Current evidence indicates that both short and long rest intervals may be useful for muscle growth. Novel findings suggest for trained people a possible advantage for the use of long rest intervals to induce muscle growth. However, due to the lack of studies with similar methodologies, further research is needed to provide a clear differentiation between these two approaches."
      },
      {
        "source": "Memory is a process in which information is encoded, stored, and retrieved. For vertebrates, the modern view has been that it occurs only in the brain. This review describes a cellular memory in skeletal muscle in which hypertrophy is 'remembered' such that a fibre that has previously been large, but subsequently lost its mass, can regain mass faster than naive fibres. A new cell biological model based on the literature, with the most reliable methods for identifying myonuclei, can explain this phenomenon. According to this model, previously untrained fibres recruit myonuclei from activated satellite cells before hypertrophic growth. Even if subsequently subjected to grave atrophy, the higher number of myonuclei is retained, and the myonuclei seem to be protected against the elevated apoptotic activity observed in atrophying muscle tissue. Fibres that have acquired a higher number of myonuclei grow faster when subjected to overload exercise, thus the nuclei represent a functionally important 'memory' of previous strength. This memory might be very long lasting in humans, as myonuclei are stable for at least 15 years and might even be permanent. However, myonuclei are harder to recruit in the elderly, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice.",
        "prediction": "Memory is a process in which information is encoded, stored, and retrieved. For vertebrates, the modern view has been that it occurs only in the brain. This review explains that skeletal muscle can 'remember' its growth. When a muscle fiber has been large but then shrinks, it can grow back faster than new, untrained fibers. A new cell biological model based on the literature, with the most reliable methods for identifying myonuclei, can explain this phenomenon. According to this model, previously untrained fibers recruit myonuclei from activated satellite cells before they grow larger. Even if they undergo significant shrinkage later, the higher number of myonuclei is retained, and these myonuclei seem to be protected from the increased cell death often seen in shrinking muscle tissue. Fibers that have more myonuclei can grow faster when subjected to overload exercise; thus, these nuclei represent an important 'memory' of previous strength. This memory might be very long-lasting in humans, as myonuclei are stable for at least 15 years and might even last permanently. However, in older adults, it is harder to recruit myonuclei, and if this long-lasting muscle memory also exists in humans, then early strength training should be considered public health advice.",
        "reference": "Memory is a process in which information is encoded, stored, and retrieved. For vertebrates, it has been said that it occurs only in the brain. This review describes a cellular memory in muscles in which muscle growth is 'remembered' such that a fibre that has lost its mass, can regain it faster than untrained fibres. A new model, with the most reliable methods for identifying myonuclei (nuclei in muscle fiber), can explain this phenomenon. According to this model, previously untrained fibres recruit myonuclei from activated satellite cells (quiescent cells acting as a reserve population of cells for regeneration of muscle) before muscle growth. Even after grave muscle loss, the higher number of myonuclei is retained, and the myonuclei seem to be protected against programmed cell death observed during muscle loss. Fibres that have acquired a higher number of myonuclei grow faster during strength exercise, thus the nuclei represent a functionally important 'memory' of previous strength. This memory might be very long lasting in humans, as myonuclei are stable for at least 15 years and might even be permanent. However, myonuclei are harder to recruit for old people, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice."
      },
      {
        "source": "It has been hypothesized that eating small, frequent meals enhances fat loss and helps to achieve better weight maintenance. Several observational studies lend support to this hypothesis, with an inverse relationship noted between the frequency of eating and adiposity. The purpose of this narrative review is to present and discuss a meta-analysis with regression that evaluated experimental research on meal frequency with respect to changes in fat mass and lean mass. Feeding frequency was positively associated with reductions in fat mass and body fat percentage as well as an increase in fat-free mass. However, sensitivity analysis of the data showed that the positive findings were the product of a single study, casting doubt as to whether more frequent meals confer beneficial effects on body composition. In conclusion, although the initial results of this meta-analysis suggest a potential benefit of increased feeding frequencies for enhancing body composition, these findings need to be interpreted with circumspection.",
        "prediction": "It has been hypothesized that eating small, frequent meals enhances fat loss and helps to achieve better weight maintenance. Several observational studies lend support to this hypothesis, with an inverse relationship noted between the frequency of eating and adiposity. The purpose of this review is to show and discuss a study that looked at research on how often people eat and its effects on body fat and muscle mass. Feeding frequency was linked to reductions in fat mass and body fat percentage, as well as an increase in fat-free mass. However, a detailed analysis of the data showed that these positive findings came from a single study, raising questions about whether eating more frequently really helps improve body composition. In conclusion, while the initial findings suggest potential benefits of increased feeding frequency for enhancing body composition, these results should be interpreted with caution.",
        "reference": "It has been hypothesized that eating small, frequent meals enhances fat loss and helps for better weight maintenance. Several studies support this hypothesis, with a link between the frequency of eating and being overweight. This review aims to present and discuss a research on meal frequency with respect to changes in body mass. Eating frequency was positively associated with reductions in fat mass and increasing in fat-free mass. However, the positive findings were the product of a single study, leaving a doubt about the beneficial effect of frequent meals on body composition. In conclusion, although the initial results suggest a potential benefit of increased eating frequencies for enhancing body composition, these findings need to be carefully interpreted."
      },
      {
        "source": "Inactive adults experience a 3% to 8% loss of muscle mass per decade, accompanied by resting metabolic rate reduction and fat accumulation. Ten weeks of resistance training may increase lean weight by 1.4 kg, increase resting metabolic rate by 7%, and reduce fat weight by 1.8 kg. Benefits of resistance training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem. Resistance training may assist prevention and management of type 2 diabetes by decreasing visceral fat, reducing HbA1c, increasing the density of glucose transporter type 4, and improving insulin sensitivity. Resistance training may enhance cardiovascular health, by reducing resting blood pressure, decreasing low-density lipoprotein cholesterol and triglycerides, and increasing high-density lipoprotein cholesterol. Resistance training may promote bone development, with studies showing 1% to 3% increase in bone mineral density. Resistance training may be effective for reducing low back pain and easing discomfort associated with arthritis and fibromyalgia and has been shown to reverse specific aging factors in skeletal muscle.",
        "prediction": "Inactive adults experience a 3% to 8% loss of muscle mass per decade, accompanied by a reduction in resting metabolic rate and fat accumulation. Ten weeks of resistance training may increase lean weight by 1.4 kg, boost the resting metabolic rate by 7%, and reduce fat weight by 1.8 kg. Benefits of resistance training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem. Additionally, resistance training can help prevent and manage type 2 diabetes by lowering belly fat, reducing a blood sugar marker called HbA1c, increasing a protein that helps cells absorb sugar, and improving the body's response to insulin. Furthermore, resistance training can enhance heart health by lowering resting blood pressure, reducing bad cholesterol and fats in the blood, and increasing good cholesterol. It may also promote bone development, with studies showing a 1% to 3% increase in bone mineral density. Additionally, resistance training may effectively reduce low back pain and ease discomfort associated with arthritis and fibromyalgia, and has been shown to reverse certain aging factors in skeletal muscle.",
        "reference": "Per decade, inactive adults experience a muscle loss of 3% to 8%, a reduction of resting metabolic rate (energy consumed by the body at rest) and fat accumulation. Ten weeks of strength training may increase fat-free mass by 1.4 kg, resting metabolic rate by 7%, and reduce fat weight by 1.8 kg. Benefits of strength training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem. Strength training may assist prevention and management of type 2 diabetes by decreasing abdominal fat, reducing HbA1c which is a form of hemoglobin linked to a sugar, increasing the density of glucose transporter type 4, and improving insulin sensitivity. Strength training may enhance cardiovascular health, by reducing resting blood pressure, decreasing 'bad' cholesterol and triglycerides (main constituents of body fat), and increasing 'good' cholesterol. Strength training may promote bone development, with studies showing 1% to 3% increase in bone mineral density. Strength training may be effective for reducing low back pain, joint and muscle pain, and reverse specific aging factors in muscles."
      },
      {
        "source": "We hypothesized that compared to post-exercise protein intake, co-ingestion of alcohol would down-regulate translation initiation signaling and decrease rates of MPS.",
        "prediction": "We hypothesized that compared to post-exercise protein intake, drinking alcohol at the same time would reduce the signals for starting protein production and lower the rates of muscle protein synthesis",
        "reference": "We assumed that consumption of protein and alcohol (compared to protein only) would reduce protein synthesis."
      },
      {
        "source": "Eight healthy physically active male subjects (age 21.4Â±4.8 yr, body mass (BM) 79.3Â±11.9 kg, peak oxygen uptake (VO2peak) 48.1Â±4.8 mLÂ·kgâ1Â·minâ1, leg extension one repetition maximum (1RM) 104Â±20 kg; values are mean Â± SD) who had been participating in regular exercise (3 times wkâ1 for >6 months) volunteered for this study.",
        "prediction": "Eight healthy physically active male subjects (age 21.4Â±4.8 yr, body weight averaging about 79.3 kg with a variation of around 11.9 kg, the maximum amount of oxygen the body can use during exercise is about 48.1 mL per kilogram of body weight per minute, and the maximum weight the subjects could lift in a single leg extension exercise was about 104 kg, with a variation of 20 kg; values are mean Â± SD) who had been participating in regular exercise (3 times a week for more than 6 months) volunteered for this study",
        "reference": "Eight healthy physically active men (3 trainings per week for at least 6 months) volunteered for this study."
      },
      {
        "source": "The study employed a randomized counter-balanced, cross-over design in which each subject completed bouts of consecutive resistance, continuous and intermittent high-intensity exercise with either post-exercise ingestion of alcohol-carbohydrate (ALC-CHO), alcohol-protein (ALC-PRO) or protein only (PRO) beverages on three separate occasions.",
        "prediction": "The study used a method where subjects took part in exercises that included consecutive resistance training and both continuous and intermittent high-intensity workouts. After these exercises, they consumed either alcohol-carbohydrate (ALC-CHO), alcohol-protein (ALC-PRO), or protein-only (PRO) beverages on three separate occasions",
        "reference": "Subjects did high intensity exercise and just after consumed an alcohol-carbohydrate, an alcohol-protein or a protein drink in three separate occasions."
      },
      {
        "source": "Resistance exercise consisted of eight sets of five repetitions at â¼80% of 1RM.",
        "prediction": "Resistance exercise involved eight sets of five repetitions at about 80% of a person's maximum lifting weight for one repetition",
        "reference": "Training consisted of eight sets of five repetitions of leg extension at 80% of their maximum strength."
      },
      {
        "source": "After completion of the final set, subjects rested for 5 min before commencing 30 min of continuous cycling at â¼63% PPO (â¼70% VO2peak).",
        "prediction": "After completing the final set, subjects rested for 5 minutes before starting 30 minutes of steady cycling at about 63% of their maximum power output, which is roughly 70% of their peak oxygen uptake",
        "reference": "After 5 minutes rest, subjects cycled for 30 minutes at medium intensity,"
      },
      {
        "source": "Upon completion, subjects rested on the bike for 2 min before undertaking 10Ã30 s high intensity intervals at â¼110% of PPO, with 30 s active recovery (â¼50% PPO) between each work bout.",
        "prediction": "Upon completion, subjects rested on the bike for 2 minutes before performing 10 sets of 30-second high-intensity intervals at about 110% of peak performance output with 30 seconds of active recovery at about 50% of peak performance output between each work bout",
        "reference": "then 5 minutes at high intensity."
      },
      {
        "source": "Immediately following exercise and after 4 h recovery, subjects ingested a 500 mL solution of either protein (PRO, 25 g whey protein powder; ISO8, Musashi, Melbourne, VIC Australia) or an energy-match in the form of CHO (25 g maltodextrin, International Health Investments, Helensvale, QLD Australia).",
        "prediction": "Immediately following exercise and after 4 hours of recovery, subjects ingested a 500 mL solution of either protein (25 grams of whey protein powder from ISO8, Musashi, Melbourne, Australia) or an equal amount of carbohydrates (25 g maltodextrin).",
        "reference": "Immediately following exercise and after 4 h recovery, subjects consumed a 500mL drink of protein or carbohydrates."
      },
      {
        "source": "Furthermore, a CHO-based meal (1.5 gÂ·kgâ1 BM) was consumed â¼2 h post-exercise, immediately after the muscle biopsy, according to recommendations for post-exercise glycogen recovery [24].",
        "prediction": "Furthermore a carbohydrate-based meal 1.5 g per kilogram of body mass was consumed approximately 2 hours after exercise immediately following the muscle biopsy as recommended for post-exercise glycogen recovery 24",
        "reference": "A carbohydrate meal was consumed 2 h after exercise, according to recommendation for glycogen recovery."
      },
      {
        "source": "The 8 h time frame represents an important phase of post-exercise recovery [1] as well as the period during which blood alcohol concentrations are likely to be elevated by a post-event drinking binge [14].",
        "prediction": "The 8-hour time frame is an important phase of post-exercise recovery and is also the time when alcohol levels in the blood are usually higher due to drinking after an event",
        "reference": "The 8 h period after exercise is an important phase for recovery but also the period during which blood alcohol level may be the highest after excessive consumption of alcohol."
      },
      {
        "source": "The alcohol ingestion protocol (1.5 gÂ·kgâ1 BM; 12Â±2 standard drinks) began 1 h post-exercise and was consumed in 6 equal volumes of 1 part vodka (â¼60 mL) to four parts orange juice (â¼240 mL, 1.8 g CHOÂ·kgâ1 BM) during a 3 h period.",
        "prediction": "The alcohol ingestion protocol began 1 hour after exercise and involved consuming 1.5 grams of alcohol for each kilogram of body weight, which is about 12 standard drinks. This was done in 6 equal portions, with 1 part vodka (about 60 mL) mixed with four parts orange juice (about 240 mL, which is 1.8 grams of carbohydrates per kilogram of body weight) over a period of 3 hours.",
        "reference": "The alcohol consumption started 1 h after exercise with 6 drinks (60mL of vodka and 240mL of orange juice) and during 3 h."
      },
      {
        "source": "The focus of the early post-exercise period (i.e., 1â8 h) is to enhance physiological processes that are critical for reversing the exercise-induced disturbances to homeostasis and physiological function and for promoting adaptations to training [1].",
        "prediction": "The focus of the early post-exercise period i.e. 1â8 h is to enhance physiological processes that are critical for correcting the problems caused by exercise on the body's balance and functions as well as for promoting adaptations to training 1",
        "reference": "The period after exercise (1-8h) enhances the body's processes that reverse the effects of the exercise and promotes adaptation to the training."
      },
      {
        "source": "For the PRO condition, orange juice was consumed with a matched volume of water in place of the alcohol.",
        "prediction": "For the PRO condition orange juice was drunk along with the same amount of water instead of alcohol",
        "reference": "For the protein drink, orange juice was consumed with water instead of alcohol."
      },
      {
        "source": "Subjects ingested the beverages within 5 min every 30 min.",
        "prediction": "Participants drank the beverages every 30 minutes within a time frame of 5 minutes",
        "reference": "Subjects consumed the drinks in 5 minutes every 30 minutes."
      },
      {
        "source": "Blood, cell signaling and mRNA data were analyzed by two-way ANOVA (two factor: time Ã treatment) with repeated measures and myofibrillar protein synthesis was analyzed by one-way ANOVA with repeated measures.",
        "prediction": "Blood cell signaling and mRNA data were analyzed using a statistical method called two-way ANOVA which studied the combined effects of time and treatment while making measurements at several points Additionally myofibrillar protein synthesis was analyzed using one-way ANOVA with repeated measures",
        "reference": "Data (blood, protein synthesis, responses, etc.) were analyzed several times for the 3 different consumptions of drinks."
      },
      {
        "source": "The first novel finding of this study was that mTOR signaling and rates of myofibrillar protein synthesis (MPS) following concurrent resistance, continuous and intermittent high-intensity exercise, designed to mimic the metabolic profile of many team sports, were impaired during the early (8 h) recovery phase by the ingestion of large amounts (1.5 gâ¢kgâ1 BM) of alcohol.",
        "prediction": "The first novel finding of this study was that mTOR signaling and rates of myofibrillar protein synthesis (MPS) following concurrent resistance and continuous and intermittent high-intensity exercises, which are meant to mimic the metabolic processes of team sports, were impaired during the early (8 h) recovery phase due to the ingestion of large amounts (1.5 gâ¢kgâ1 BM) of alcohol.",
        "reference": "The first finding of this study was that the mTOR enzyme (responsible for muscle growth) and protein synthesis (after exercise) were reduced by an excessive alcohol consumption during the 8 h period of recovery."
      },
      {
        "source": "These outcomes were most evident (37% reduction in rates of MPS) when alcohol was consumed in the absence of post-exercise protein intake, as is likely to occur when intoxication reduces the athlete's compliance to sound recovery practices.",
        "prediction": "These outcomes were most evident 37% reduction in rates of MPS when alcohol was drunk without having protein after exercising which is likely to happen when intoxication makes athletes less likely to follow good recovery practices",
        "reference": "Consequences were most evident when alcohol was consumed without protein (37 % reduction of protein synthesis)."
      },
      {
        "source": "However, a second finding was that even when protein was consumed in amounts shown to be optimally effective to stimulate MPS [8] during post-exercise recovery, the intake of alcohol reduced MPS by â¼24%, representing only a partial ârescueâ of the anabolic response compared with protein alone.",
        "prediction": "However, a second finding was that even when protein was taken in amounts shown to be optimally effective for boosting muscle protein synthesis (MPS) during post-exercise recovery, drinking alcohol decreased MPS by about 24% and only provided a partial improvement in the body's ability to build muscle compared to just having protein.",
        "reference": "A second finding was that even with protein consumption, alcohol reduced protein synthesis by around 24%."
      },
      {
        "source": "The mechanistic target of rapamycin complex 1 (mTORC1) is a central node for integrating nutrient (i.e. amino acid) and exercise/contraction signal transduction [31], [32].",
        "prediction": "The mechanistic target of rapamycin complex 1 (mTORC1) is important for linking nutrients like amino acids to exercise signals [31], [32]",
        "reference": "mTOR is important in absorption of nutrients (like amino acids) and in sending signals to the body to produce an effort."
      },
      {
        "source": "In conclusion, the current data provide the novel observation that alcohol impairs the response of MPS in exercise recovery in human skeletal muscle despite optimal nutrient provision.",
        "prediction": "In conclusion the current data show that alcohol impairs Muscle Protein Synthesis MPS during recovery from exercise in human skeletal muscle even when nutrients are provided optimally",
        "reference": "The data from this study show that alcohol reduce the protein synthesis after exercise even with an optimal consumption of nutrients."
      },
      {
        "source": "The quantity of alcohol consumed in the current study was based on amounts reported during binge drinking by athletes.",
        "prediction": "The quantity of alcohol consumed in the current study was based on the amounts athletes reported drinking during binge drinking",
        "reference": "The quantity of alcohol consumed in this study was based on consumption by athletes during binge drinking."
      },
      {
        "source": "However, published reports suggest intakes of some individuals can be significantly greater [9], [50], which is of concern for many reasons related to health and safety [13].",
        "prediction": "However published reports suggest that some individuals may have much greater intakes which raises many health and safety concerns",
        "reference": "However, reports show that some individuals can consume higher quantities, which is a concern for health and safety issues."
      },
      {
        "source": "Recommended nutritional strategies to maximize recovery in skeletal muscle include protein for enhancing rates of protein synthesis and carbohydrate for replenishing glycogen stores [2],[3].",
        "prediction": "Recommended nutritional strategies to maximize recovery in skeletal muscle include protein to help build muscle and carbohydrates to restore energy stores",
        "reference": "Nutritional strategies to optimize muscle recovery include proteins which are recommended to allow protein synthesis (production of new proteins which improve, for example, muscle mass) and carbohydrates to recharge glycogen stores (energy storage)."
      },
      {
        "source": "Regrettably, there has been difficulty in finding an educational message with alcohol consumption related to sports performance that has resonance with athletes.",
        "prediction": "Unfortunately it has been difficult to find a message about alcohol use in sports that athletes can relate to",
        "reference": "Regrettably, it is difficult to find an educational message about alcohol consumption and sport performances that speaks to athletes."
      },
      {
        "source": "Given the need to promote protein synthesis that underpins adaptation, repair and regeneration of skeletal muscle the results of the current study provide clear evidence of impaired recovery when alcohol is consumed after concurrent (resistance, continuous and intermittent high-intensity) exercise even in the presence of optimal nutritional conditions.",
        "prediction": "Given the need to promote protein synthesis that supports adaptation repair and regeneration of skeletal muscle the results of the current study provide clear evidence that consuming alcohol after various types of exercise such as strength training continuous and short bursts of high effort leads to poor recovery even when optimal nutritional conditions are present",
        "reference": "Considering the importance of protein synthesis (adaptation, repair and regeneration of muscles), the results of this study provide evidence of reduced recovery when alcohol is consumed after exercise, even with an optimal consumption of nutrients."
      },
      {
        "source": "We propose our data is of paramount interest to athletes and coaches.",
        "prediction": "We propose our data is very important to athletes and coaches",
        "reference": "We consider our data crucial for athletes and coaches."
      },
      {
        "source": "Our findings provide an evidence-base for a message of moderation in alcohol intake to promote recovery after exercise with the potential to alter current sports culture and athlete practices.",
        "prediction": "Our findings support the idea of drinking alcohol in moderation which can help promote recovery after exercise and may change current sports culture and athlete practices",
        "reference": "Our findings provide evidence for a message of moderation in alcohol consumption to promote recovery after exercise, with the potential to change sport cultures and athlete practices."
      },
      {
        "source": "Muscle contraction and the intake of leucine-rich protein sources activate independent but complimentary signaling responses that converge at the mechanistic target of rapamycin (mTOR) to stimulate protein translation enhancing rates of muscle protein synthesis [4]â[6].",
        "prediction": "Muscle contraction and eating protein-rich foods that are high in leucine activate distinct but connected signaling pathways that converge at the mechanistic target of rapamycin (mTOR), which helps increase muscle protein production. This process enhances the body's ability to efficiently produce muscle protein",
        "reference": "Muscle contraction and consumption of leucine-rich protein (essential amino acid composing proteins) induce reactions which increase the protein synthesis."
      },
      {
        "source": "The ingestion of â¼20â25 g of high quality protein soon after exercise [7], repeated every 4 h [8] has been shown to maximise the anabolic response in skeletal muscle.",
        "prediction": "The ingestion of about 20 to 25 grams of high quality protein soon after exercise, repeated every 4 hours, has been found to increase muscle growth",
        "reference": "Consumption of 20-25 g of high quality protein after exercise and repeated every 4 h showed an optimal anabolic response (increasing muscle mass) of the muscles."
      },
      {
        "source": "The cultural environment surrounding some sports often involves the intake of large amounts of alcohol after training and competition, with athletes in several team sports being particularly at risk of âbinge drinkingâ practices [9]â[11].",
        "prediction": "The cultural environment around some sports often includes drinking a lot of alcohol after training and competitions. Athletes in several team sports are particularly at risk of engaging in binge drinking practices",
        "reference": "Several studies showed that athletes are more likely to drink alcohol to excess (50-65% drink above dangerous level)."
      },
      {
        "source": "The outcomes of binge drinking after exercise are likely to include the direct effect of alcohol on physiological processes as well as the indirect effect on the athlete's recovery due to not eating or resting adequately as a result of intoxication.",
        "prediction": "The outcomes of binge drinking after exercise are likely to include the immediate effects of alcohol on how the body works, as well as the indirect effects on the athlete's recovery from not eating or resting adequately due to intoxication",
        "reference": "Consequences of an excessive consumption after exercise are direct effect on the body but also indirect effect on the recovery due to an inappropriate eating and rest."
      },
      {
        "source": "Although the concurrent consumption of carbohydrate can partially offset the deleterious effects of alcohol intake on post-exercise glycogen resynthesis [14], the effect of alcohol consumption on muscle protein synthesis is unknown.",
        "prediction": "Although the harmful effects of drinking alcohol on the recovery of energy stores after exercise can be partially offset by the concurrent consumption of carbohydrate [14], we don't know how drinking alcohol affects muscle protein building",
        "reference": "Consumption of carbohydrates can partially counter balance the effects of alcohol on the recharge of glycogen stores but the effect on muscle protein synthesis are unknown."
      },
      {
        "source": "The aim of the current study was to determine the effect of alcohol intake on anabolic cell signaling and rates of myofibrillar protein synthesis (MPS) in humans during recovery from a bout of strenuous exercise approximating stresses an athlete may experience in training and performance for various team sports such as various football and rugby codes, and court sports.",
        "prediction": "The aim of the current study was to determine the effect of alcohol consumption on cell activity and the production of muscle proteins in humans during recovery from intense exercise that reflects the stresses an athlete may experience in training and performance for various team sports, including football, rugby, and court sports.",
        "reference": "The aim of this study was to determine the effect of alcohol on anabolism and protein synthesis in humans during recovery following an effort an athlete could do (in rugby or football for example)."
      },
      {
        "source": "Human aging results in a variety of changes to skeletal muscle. Sarcopenia is the age-associated loss of muscle mass and is one of the main contributors to musculoskeletal impairments in the elderly. Previous research has demonstrated that resistance training can attenuate skeletal muscle function deficits in older adults, however few articles have focused on the effects of resistance training on functional mobility. The purpose of this systematic review was to 1) present the current state of literature regarding the effects of resistance training on functional mobility outcomes for older adults with skeletal muscle function deficits and 2) provide clinicians with practical guidelines that can be used with seniors during resistance training, or to encourage exercise. We set forth evidence that resistance training can attenuate age-related changes in functional mobility, including improvements in gait speed, static and dynamic balance, and fall risk reduction. Older adults should be encouraged to participate in progressive resistance training activities, and should be admonished to move along a continuum of exercise from immobility, toward the recommended daily amounts of activity.",
        "prediction": "Human aging results in a variety of changes to skeletal muscle. Sarcopenia is the loss of muscle mass that happens with age and it is one of the main causes of movement problems in older people. Previous research has shown that resistance training can help improve muscle function in older adults however few articles have focused on how resistance training affects functional mobility. The purpose of this systematic review was to 1 present the current research on the effects of resistance training on functional mobility outcomes for older adults with muscle function deficits and 2 provide clinicians with practical guidelines for working with seniors during resistance training or encouraging exercise. We provide evidence that resistance training can reduce age-related changes in functional mobility including improvements in gait speed balance both static and dynamic and a lower risk of falls. Older adults should be encouraged to participate in progressive resistance training activities and to increase their exercise levels gradually moving from immobility toward the recommended daily amounts of activity",
        "reference": "Human aging results in a variety of changes to muscles. Sarcopenia is the age-associated muscle loss and is one of the main contributors to muscle disorders in older adults. Previous research has demonstrated that strength training can attenuate muscle function deficits in older adults, however few articles have focused on the effects of strength training on mobility. The purpose of this review was to present the effects of strength training on mobility for older adults with muscle function deficits and to provide guidelines that can be used with seniors during strength training. We present evidence that strength training can attenuate age-related changes in mobility, including improvements in walking speed, static and dynamic balance, and fall risk reduction. Older adults should be encouraged to participate in strength training activities, and should avoid immobility."
      },
      {
        "source": "Maximizing the hypertrophic response to resistance training (RT) is thought to be best achieved by proper manipulation of exercise program variables including exercise selection, exercise order, length of rest intervals, intensity of maximal load, and training volume. An often overlooked variable that also may impact muscle growth is repetition duration. Duration amounts to the sum total of the concentric, eccentric, and isometric components of a repetition, and is predicated on the tempo at which the repetition is performed. We conducted a systematic review and meta-analysis to determine whether alterations in repetition duration can amplify the hypertrophic response to RT. Results indicate that hypertrophic outcomes are similar when training with repetition durations ranging from 0.5 to 8 s. From a practical standpoint it would seem that a fairly wide range of repetition durations can be employed if the primary goal is to maximize muscle growth. Findings suggest that training at volitionally very slow durations (>10s per repetition) is inferior from a hypertrophy standpoint, although a lack of controlled studies on the topic makes it difficult to draw definitive conclusions.",
        "prediction": "Maximizing the hypertrophic response to resistance training (RT) is thought to be best achieved by properly manipulating exercise program variables, including exercise selection, exercise order, length of rest intervals, intensity of maximal load, and training volume. An often overlooked variable that may also impact muscle growth is repetition duration. Duration is the total time taken for the lifting (concentric), lowering (eccentric), and holding (isometric) parts of a repetition, and it depends on how fast you perform the repetition. We conducted a systematic review and meta-analysis to determine whether changes in repetition duration can enhance the hypertrophic response to RT. Results indicate that hypertrophic outcomes are similar when training with repetition durations ranging from 0.5 to 8 seconds. From a practical standpoint, it seems that a fairly wide range of repetition durations can be used if the primary goal is to maximize muscle growth. Our findings suggest that training at very slow durations (greater than 10 seconds per repetition) is less effective for hypertrophy, although a lack of controlled studies on this topic makes it difficult to draw definitive conclusions.",
        "reference": "Maximizing the muscle growth following strength training can be done by manipulating variables like exercise selection, exercise order, rest intervals, intensity of maximal load, and training volume (number of exercises, sets, etc.). A neglected variable that also may impact muscle growth is repetition duration. Total duration of a repetition is the sum of the contraction, the lengthening and isometric (static contraction) and is based on the tempo. We conducted a review and analysis of multiple studies to determine if modification of repetition duration can amplify the muscle growth. Results indicate that muscle growth is similar when training with repetition durations from 0.5 to 8 s. Using a wide range of repetition durations can be employed if the primary goal is to maximize muscle growth. Findings suggest that training at very slow durations (>10s per repetition) is less efficient for muscle growth, although a lack of studies on the topic makes it difficult to draw definitive conclusions."
      },
      {
        "source": "Recovery from exercise refers to the time period between the end of a bout of exercise and the subsequent return to a resting or recovered state. It also refers to specific physiological processes or states occurring after exercise that are distinct from the physiology of either the exercising or the resting states. In this context, recovery of the cardiovascular system after exercise occurs across a period of minutes to hours, during which many characteristics of the system, even how it is controlled, change over time. Some of these changes may be necessary for long-term adaptation to exercise training, yet some can lead to cardiovascular instability during recovery. Furthermore, some of these changes may provide insight into when the cardiovascular system has recovered from prior training and is physiologically ready for additional training stress. This review focuses on the most consistently observed hemodynamic adjustments and the underlying causes that drive cardiovascular recovery and will highlight how they differ following resistance and aerobic exercise. Primary emphasis will be placed on the hypotensive effect of aerobic and resistance exercise and associated mechanisms that have clinical relevance, but if left unchecked, can progress to symptomatic hypotension and syncope. Finally, we focus on the practical application of this information to strategies to maximize the benefits of cardiovascular recovery, or minimize the vulnerabilities of this state. We will explore appropriate field measures, and discuss to what extent these can guide an athlete's training.",
        "prediction": "Recovery from exercise refers to the time period between the end of a bout of exercise and the subsequent return to a resting or recovered state. It also refers to specific physiological processes or states occurring after exercise that are distinct from the physiology of either the exercising or the resting states. In this context recovery of the cardiovascular system after exercise occurs across a period of minutes to hours during which many characteristics of the system even how it is controlled change over time. Some of these changes can help us understand when the cardiovascular system has recovered from previous training and is ready for more exercise. While some of these changes may be necessary for long-term adaptation to exercise training others can lead to cardiovascular instability during recovery. Furthermore this recovery can provide insights into when the cardiovascular system is prepared for additional training stress. This review focuses on the most consistently observed hemodynamic adjustments and the underlying causes that drive cardiovascular recovery highlighting how these differ following resistance and aerobic exercise. Primary emphasis will be placed on the hypotensive effect of aerobic and resistance exercise and associated mechanisms that have clinical relevance which if left unchecked can progress to symptomatic hypotension and syncope. Finally we focus on the practical application of this information to strategies that maximize the benefits of cardiovascular recovery or minimize the vulnerabilities of this state. We will explore appropriate field measures and discuss how these can guide an athlete's training.",
        "reference": "Recovery from exercise refers to the time period between the end of exercise and the return to a resting or recovered state. It also refers to specific physiological processes occurring after exercise. Recovery of the cardiovascular system occurs across a period of minutes to hours, during which many characteristics of the system change over time. Some of these changes may be necessary for long-term adaptation to exercise training, yet some can lead to cardiovascular instability during recovery. These changes may provide insight into when the cardiovascular system has recovered and is physiologically ready for additional training. This review focuses on the most consistently observed blood flow adjustments and the causes that drive cardiovascular recovery and how they differ following strength and cardio exercise. First we focus on the effect leading to low blood pressure of cardio and strength exercise and associated mechanisms, which can progress to symptomatic hypotension (low blood pressure) and fainting. Finally, we focus on the practical application to maximize the benefits of cardiovascular recovery, or minimize the vulnerabilities. We will explore measures, and discuss how these can guide an athlete's training."
      },
      {
        "source": "Exercise and physical activity are increasingly becoming key tools in the treatment and prevention of several medical conditions including arthritis and diabetes; this notion has been termed \"exercise as medicine\". Exercise has favorable effects on reducing cardiovascular risk, inflammation, cachexia, and hypertension, in addition to increasing physical functioning, strength, and cardio-respiratory capacity. Chronic kidney disease, a condition that affects around 10% of the population, is often overlooked as a target for exercise-based therapy. Despite the vast range of severity in kidney disease (e.g., pre-dialysis, dialysis, transplant), exercise has a potential role in all patients suffering from the condition. In this review, we summarise the important role exercise may have in the clinical management of kidney disease and how this form of 'medicine' should be best administered and 'prescribed'.",
        "prediction": "Exercise and physical activity are increasingly becoming key tools in the treatment and prevention of several medical conditions including arthritis and diabetes; this notion has been termed \"exercise as medicine.\" Exercise helps lower risks for heart problems, reduces inflammation, fights weight loss due to illness, and lowers high blood pressure. It also improves physical ability, strength, and heart and lung fitness. Chronic kidney disease, which affects around 10% of the population, is often overlooked as a target for exercise-based therapy. Despite the vast range of severity in kidney disease (e.g., pre-dialysis, dialysis, transplant), exercise has a potential role in all patients suffering from the condition. In this review, we summarise the important role exercise may have in the clinical management of kidney disease and how this form of 'medicine' should be best administered and 'prescribed'",
        "reference": "Exercise and physical activity are key tools in the treatment and prevention of several medical conditions including joint disorders and diabetes. Exercise can reduce cardiovascular risk, inflammation, illness causing muscle loss, and hypertension, in addition to increasing physical functioning, strength, and cardio-respiratory capacity. Chronic kidney disease, a condition that affects around 10% of the population, is often neglected as a target for exercise-based therapy. Despite the vast range of severity in kidney disease, exercise has a potential role in all patients suffering from the condition. In this review, we summarise the potential important role of exercise in the management of kidney disease and how this form of 'medicine' should be used."
      },
      {
        "source": "Blood flow restriction (BFR) is an effective clinical intervention used to increase strength in healthy individuals. However, its effects on pain and function in individuals with knee pain are unknown. Objective: To determine the effectiveness of adding BFR to resistance exercise for pain relief and improvement of function in patients with knee pain. Methods: Systematic review with meta-analysis of randomized clinical trials. Randomized clinical trials that compared resistance exercise with or without BFR to treat knee pain and function in individuals older than 18 years of age with knee pain were included. The pooled standardized mean difference (SMD) estimate showed that resistance exercises with BFR was not more effective than resistance exercises for reducing pain (SMD: -0.37cm, 95% CI=-0.93, 0.19) and improving knee function (SMD=-0.23 points, 95% CI=-0.71, 0.26) in patients with knee pain.",
        "prediction": "Blood flow restriction (BFR) is an effective clinical intervention used to increase strength in healthy individuals. However, its effects on pain and function in individuals with knee pain are unknown. Objective: To determine the effectiveness of adding BFR to resistance exercise for pain relief and improvement of function in patients with knee pain. Methods: Systematic review with meta-analysis of randomized clinical trials. Randomized clinical trials that compared resistance exercise with or without BFR to treat knee pain and function in individuals older than 18 years of age with knee pain were included. The analysis indicated that resistance exercises with blood flow restriction (BFR) were not more effective than resistance exercises alone in reducing pain or improving knee function in patients with knee pain. The results showed a pain reduction of -0.37 cm and a change in knee function scores of -0.23 points.",
        "reference": "Exercise with blood flow restriction (BFR) is used to increase strength in healthy individuals. However, its effects on individuals with knee pain are unknown. The objective is to determine the effectiveness of adding BFR to strength exercise for pain relief and improvement of function in patients with knee pain. We conducted a review and analysis of multiple studies. Studies that compared strength exercise with or without BFR to treat knee pain and function. The results showed that resistance exercises with BFR was not more effective than strength exercises for reducing pain and improving knee function in patients with knee pain."
      },
      {
        "source": "In Japan, there were an estimated 43 million patients with hypertension in 2010. The management of this condition is given the highest priority in disease control, and the importance of lifestyle changes for the prevention and treatment of hypertension has been recognized in Japan. In particular, emphasis has been placed on increasing the levels of activities of daily living and physical exercise (sports). In this literature review, we examined appropriate exercise prescriptions (e.g., type, intensity, duration per session, and frequency) for the prevention and treatment of hypertension as described in Japanese and foreign articles. This review recommends safe and effective whole-body aerobic exercise at moderate intensity (i.e., 50-65% of maximum oxygen intake, 30-60 min per session, 3-4 times a week) that primarily focuses on the major muscle groups for the prevention and treatment of hypertension. Resistance exercise should be performed at low-intensity without breath-holding and should be used as supplementary exercise, but resistance exercise is contraindicated in patients with hypertension who have chest symptoms such as chest pain.",
        "prediction": "In Japan, there were an estimated 43 million patients with hypertension in 2010. The management of this condition is given the highest priority in disease control, and the importance of lifestyle changes for preventing and treating hypertension has been recognized in Japan. In particular, there has been an emphasis on increasing daily activities and physical exercise sports. In this literature review, we examined appropriate exercise prescriptions such as type, intensity, duration per session, and frequency for the prevention and treatment of hypertension as described in Japanese and foreign articles. This review suggests safe and effective whole-body aerobic exercise at a moderate level 50-65% of maximum oxygen use for 30-60 minutes 3-4 times a week focusing on major muscle groups to help prevent and treat hypertension. Resistance exercise should be performed at low intensity without breath-holding and should be used as supplementary exercise however it is contraindicated in patients with hypertension who experience chest symptoms such as chest pain",
        "reference": "In Japan, 43 million patients had high blood pressure in 2010. The management of this condition and the importance of lifestyle changes for the prevention and treatment of high blood pressure has been recognized in Japan. In particular, increasing the levels of activities of daily living and physical exercise. In this review, we examined appropriate exercise prescriptions (e.g., type, intensity, duration per session, and frequency) for the prevention and treatment of high blood pressure. This review recommends full body cardio exercise at moderate intensity (i.e., 50-65% of maximum intensity, 30-60 min per session, 3-4 times a week) that focuses on the major muscle groups. Strength exercise should be performed at low-intensity without breath-holding and should be used as supplementary exercise, but it is contraindicated in patients with high blood pressure who have chest symptoms such as chest pain."
      },
      {
        "source": "Physical activity has proved to be an effective means of preventing several diseases and improving general health. Common sense advices call for late inception of intense, strength training-related activities, like weight lifting and plyometrics, which are usually postponed at the end of the growth age, even among sport practitioners. However, such advices seem to have a mainly anecdotal nature. Current literature does not seem to have any particular aversion against the practice of strength training by children and adolescents, provided that some safety rules are followed, like medical clearance, proper instruction from a qualified professional and progressive overload. At the same time, several studies provide consistent findings supporting the benefits of repeated, intense physical efforts in young subjects. Improved motor skills and body composition, in terms of increased fat free mass, reduced fat mass and enhanced bone health, have been extensively documented, especially if sport practice began early, when the subjects were pubescent. It can be therefore concluded that strength training is a relatively safe and healthy practice for children and adolescents.",
        "prediction": "Physical activity has proved to be an effective means of preventing several diseases and improving general health Common advice suggests delaying intense strength training activities like weight lifting and plyometrics until the end of the growth period even for athletes However this advice seems to be largely based on anecdote Current research shows no strong opposition to strength training for children and teenagers as long as safety rules are followed such as obtaining medical approval getting proper instruction from a qualified expert and gradually increasing the training intensity At the same time several studies provide consistent findings supporting the benefits of repeated intense physical efforts in young individuals Improved motor skills and body composition including increased fat-free mass reduced fat mass and enhanced bone health have been well documented especially when sports practice begins early during puberty Therefore it can be concluded that strength training is a relatively safe and healthy practice for children and adolescents",
        "reference": "Physical activity has many benefits like preventing diseases and improving general health. In popular opinion, it is recommended to start intense physical activities like weight lifting and plyometrics (exercises like sprint and jumps) after adolescence. But this advice does not seem to be based on facts. We did not find any recommendation against strength training at a young age if it is well supervised with safety rules, medical clearance, proper instruction from a professional and progressive overload (gradual increase of stress on muscle and nervous system). Several studies showed many benefits of repeated, intense physical efforts in young people. Improved motor skills and body composition (muscle mass increased, fat mass decreased, healthier bone) were found in studies, especially if sport practice began during puberty. We can conclude that strength training is a safe and healthy practice for children and adolescents."
      },
      {
        "source": "recently, there has been a renewed public interest in IFast. Given the importance of nutrition in optimizing athletic performance, there is a concern about the effects of IFast on athletics. Looking at high-intensity, endurance, and resistance exercises, studies have been varied but are uniform in showing that there is no benefit to athletic performance while fasting.",
        "prediction": "Recently there has been renewed public interest in IFast Given the importance of nutrition in optimizing athletic performance people are worried about how IFast may affect athletes Studies on high-intensity endurance and resistance exercises have varied but they all show that there is no benefit to athletic performance while fasting",
        "reference": "Nowadays, people are interested in intermittent fasting (an eating pattern where you cycle between periods of eating and fasting) Nutrition is important for the optimization of sport performance so there is a concern about the effects of intermittent fasting on performance. Studies showed that there are no benefit in high-intensity, endurance or strength training while fasting."
      },
      {
        "source": "Nearly every physically active person encounters periods in which the time available for exercise is limited (e.g., personal, family, or business conflicts). During such periods, the goal of physical training may be to simply maintain (rather than improve) physical performance. Similarly, certain special populations may desire to maintain performance for prolonged periods, namely athletes (during the competitive season and off-season) and military personnel (during deployment). In general populations, endurance performance can be maintained for up to 15 weeks when training frequency is reduced to as little as 2 sessions per week or when exercise volume is reduced by 33â66% (as low as 13â26 minutes per session), as long as exercise intensity (exercising heart rate) is maintained. Strength and muscle size (at least in younger populations) can be maintained for up to 32 weeks with as little as 1 session of strength training per week and 1 set per exercise, as long as exercise intensity (relative load) is maintained; whereas, in older populations, maintaining muscle size may require up to 2 sessions per week and 2â3 sets per exercise, while maintaining exercise intensity. Our primary conclusion is that exercise intensity seems to be the key variable for maintaining physical performance over time, despite relatively large reductions in exercise frequency and volume.",
        "prediction": "Nearly every physically active person encounters periods when the time available for exercise is limited due to personal family or business conflicts During these times the goal of physical training may be to simply maintain rather than improve physical performance Certain groups such as athletes during their competitive and off-seasons and military personnel during deployment may also want to maintain their performance over extended periods \n\nEndurance performance can be maintained for up to 15 weeks if individuals reduce their training to just 2 sessions per week or decrease their exercise volume by 33â66% which equates to exercising for only 13â26 minutes per session as long as they keep their exercise intensity heart rate high \n\nStrength and muscle size can be maintained for up to 32 weeks in younger individuals with just 1 session of strength training per week and 1 set per exercise provided they maintain exercise intensity relative load In older populations maintaining muscle size may require up to 2 sessions per week and 2â3 sets per exercise while still keeping exercise intensity in mind \n\nOur primary conclusion is that exercise intensity appears to be the key factor for maintaining physical performance over time despite significant reductions in exercise frequency and volume",
        "reference": "Physically active people encounter periods with limited time available for exercise. During such periods, the goal of training may be to simply maintain physical performance. Some people may also desire to maintain performance for prolonged periods, like athletes during competitive season or militaries during deployment. Endurance performance can be maintained for up to 15 weeks with 2 trainings per week, or with a reduction of 13â26 minutes per training, as long as exercise intensity (exercising heart rate) is maintained. Strength and muscle size can be maintained for up to 32 weeks with 1 strength training per week and 1 set per exercise, as long as exercise intensity (load) is maintained. In older populations, maintaining muscle size may require up to 2 trainings per week and 2â3 sets per exercise, while maintaining exercise intensity. Exercise intensity seems to be the key variable for maintaining physical performance, even with reduction of frequency and volume (number of exercises, sets, etc.)"
      },
      {
        "source": "Nutrient timing is a popular nutritional strategy that involves the consumption of combinations of nutrients--primarily protein and carbohydrate--in and around an exercise session. Some have claimed that this approach can produce dramatic improvements in body composition. It has even been postulated that the timing of nutritional consumption may be more important than the absolute daily intake of nutrients. The post-exercise period is widely considered the most critical part of nutrient timing. Theoretically, consuming the proper ratio of nutrients during this time not only initiates the rebuilding of damaged muscle tissue and restoration of energy reserves, but it does so in a supercompensated fashion that enhances both body composition and exercise performance. Several researchers have made reference to an anabolic âwindow of opportunityâ whereby a limited time exists after training to optimize training-related muscular adaptations. However, the importance - and even the existence - of a post-exercise âwindowâ can vary according to a number of factors. Not only is nutrient timing research open to question in terms of applicability, but recent evidence has directly challenged the classical view of the relevance of post-exercise nutritional intake with respect to anabolism.",
        "prediction": "Nutrient timing is a popular nutritional strategy that involves consuming combinations of nutrientsâprimarily protein and carbohydratesâaround exercise sessions. Some people claim that this approach can lead to significant improvements in body composition. It has even been suggested that the timing of nutritional intake may be more important than the total daily amount of nutrients consumed. The post-exercise period is widely considered the most critical part of nutrient timing. In theory, eating the right balance of nutrients during this time helps repair damaged muscles and restore energy. It also improves body shape and exercise performance. Several researchers refer to an anabolic âwindow of opportunity,â which suggests that there is a limited time after training to optimize muscle adaptation from exercise. However, the importanceâand even the existenceâof this post-exercise âwindowâ can vary based on several factors. Additionally, while nutrient timing research remains debated, recent evidence has challenged the traditional view regarding the relevance of post-exercise nutritional intake for building muscle",
        "reference": "Nutrient timing is a popular nutritional strategy that involves the consumption of combinations of nutrients around an exercise session. Some people say that this approach can produce dramatic improvements in body composition. It has even been hypothesized that the timing may be more important than the total daily intake of nutrients. The post-exercise period is considered the most important part of nutrient timing. In theory, consuming the proper ratio of nutrients during this time allows the rebuilding of damaged muscle tissue and restoration of energy reserves, but also enhances both body composition and exercise performance. Researchers have made reference to an anabolic âwindow of opportunityâ (a limited time after training to optimize muscular adaptations). However, the importance - and even the existence - of a post-exercise âwindowâ can vary according to a number of factors. Research is uncertain about the applicability of nutrient timing. Besides, the relevance of post-exercise nutritional intake concerning anabolism (increasing muscle mass) has been challenged by recent evidence."
      },
      {
        "source": "Lack of time is among the more commonly reported barriers for abstention from exercise programs. The aim of this review was to determine how strength training can be most effectively carried out in a time-efficient manner by critically evaluating research on acute training variables, advanced training techniques, and the need for warm-up and stretching. When programming strength training for optimum time-efficiency we recommend prioritizing bilateral, multi-joint exercises that include full dynamic movements (i.e. both eccentric and concentric muscle actions), and to perform a minimum of one leg pressing exercise (e.g. squats), one upper-body pulling exercise (e.g. pull-up) and one upper-body pushing exercise (e.g. bench press). Exercises can be performed with machines and/or free weights based on training goals, availability, and personal preferences. Weekly training volume is more important than training frequency and we recommend performing a minimum of 4 weekly sets per muscle group using a 6â15 RM loading range (15â40 repetitions can be used if training is performed to volitional failure). Advanced training techniques, such as supersets, drop sets and rest-pause training roughly halves training time compared to traditional training, while maintaining training volume. However, these methods are probably better at inducing hypertrophy than muscular strength, and more research is needed on longitudinal training effects. Finally, we advise restricting the warm-up to exercise-specific warm-ups, and only prioritize stretching if the goal of training is to increase flexibility.",
        "prediction": "Lack of time is among the more commonly reported barriers to participating in exercise programs. The aim of this review was to determine how strength training can be effectively carried out in a time-efficient manner by critically evaluating research on training variables, advanced techniques, and the need for warm-up and stretching. When planning strength training to save time, we suggest focusing on exercises that use both sides of the body and involve multiple joints. This means doing full movements that work the muscles in different ways, including at least one leg exercise like squats, one pulling exercise like pull-ups, and one pushing exercise like bench press. Exercises can be done with machines and/or free weights depending on individual goals, availability, and preferences. Weekly training volume is more important than frequency, and we recommend performing a minimum of 4 weekly sets per muscle group within a 6-15 RM loading range 15-40 repetitions can be used if training is done to voluntary failure. Advanced training techniques such as supersets, drop sets, and rest-pause training can roughly halve training time compared to traditional methods while maintaining training volume. However, these techniques may be better for increasing muscle size hypertrophy rather than strength, and more research is needed on long-term training effects. Finally, we advise limiting warm-ups to exercise-specific activities and only prioritizing stretching if the goal is to improve flexibility.",
        "reference": "Lack of time is one of the most common reason for not exercising. The aim of this review was to determine how strength training can be time-efficient by evaluating research on training variables, advanced training techniques, and the need for warm-up and stretching. We recommend choosing bilateral (with the two arms or legs), multi-joint (multiple joints involved) exercises that include full dynamic movements and to perform a minimum of one leg pressing exercise (e.g. squats), one pulling exercise (e.g. pull-up) and one pushing exercise (e.g. bench press). Exercises can be performed with machines and/or free weights. Weekly training volume (number of exercises, sets, etc.) is more important than training frequency and we recommend a minimum of 4 weekly sets per muscle group using a load that permits to do 6 to 15 repetitions. Advanced training techniques like combining exercises with no rest or shortening the rest time while using lighter weights can cuts the training time in half, while maintaining training volume. However, these methods are probably better to increase muscle mass than strength. Finally, we advise exercise-specific warm-ups, and stretching only if the goal of training is to increase flexibility."
      },
      {
        "source": "Training frequency is considered an important variable in the hypertrophic response to regimented resistance exercise. The purpose of this paper was to conduct a systematic review and meta-analysis of experimental studies designed to investigate the effects of weekly training frequency on hypertrophic adaptations. Results showed no significant difference between higher and lower frequency on a volume-equated basis. Meta-regression analysis of non-volume-equated studies showed a significant effect favoring higher frequencies, although the overall difference in magnitude of effect between frequencies of 1 and 3+ days per week was modest. In conclusion, there is strong evidence that resistance training frequency does not significantly or meaningfully impact muscle hypertrophy when volume is equated. Thus, for a given training volume, individuals can choose a weekly frequency per muscle groups based on personal preference.",
        "prediction": "Training frequency is considered an important variable in the hypertrophic response to regimented resistance exercise. The purpose of this paper was to conduct a systematic review and meta-analysis of experimental studies designed to investigate the effects of weekly training frequency on hypertrophic adaptations. Results showed no significant difference between higher and lower frequency on a volume-equated basis. Additionally, an analysis of studies that did not consider training volume showed that higher training frequencies had a positive effect. However, the difference in impact between training once a week and three or more times a week was small. In conclusion, there is strong evidence that resistance training frequency does not significantly or meaningfully impact muscle hypertrophy when volume is equated. Thus, for a given training volume, individuals can choose a weekly frequency per muscle group based on personal preference.",
        "reference": "Training frequency is an important variable for hypertrophy (increasing muscle mass) in strength training. The purpose of this paper was to conduct a review and analysis of multiple studies investigating the effects of weekly training frequency on hypertrophy. Results showed no significant difference between higher and lower frequency with the same training volume (number of exercises, sets, etc.). Analysis of studies with different training volumes showed better results for higher frequencies, although the difference between frequencies of 1 and 3+ days per week was small. In conclusion, there is strong evidence that resistance training frequency does not significantly impact muscle hypertrophy when training volume is the same. Thus, for a given training volume, individuals can choose a weekly frequency per muscle groups based on personal preference."
      },
      {
        "source": "A variety of specialized training techniques have been advocated as a means to heighten muscle growth. Forced repetitions/drop sets, supersets, and heavy negatives, in particular, have been purported to enhance the hypertrophic response to resistance exercise. This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to resistance training programs.",
        "prediction": "A variety of specialized training techniques have been advocated as a means to heighten muscle growth. Techniques like forced repetitions, drop sets, supersets, and heavy negatives are said to help increase muscle growth during resistance training. This article will explore how these techniques may promote muscle growth and provide insights into their possible applications in resistance training programs.",
        "reference": "A variety of training techniques have been suggested to support muscle growth. Forced repetitions/drop sets (use lighter weight or receiving help to continue the set), supersets (combining exercises with no rest), and heavy negatives (lowering phase of the lift), are pretended to enhance hypertrophy (increasing muscle mass). This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to strength training."
      },
      {
        "source": "The quest to increase lean body mass is widely pursued by those who lift weights. Research is lacking, however, as to the best approach for maximizing exercise-induced muscle growth. Bodybuilders generally train with moderate loads and fairly short rest intervals that induce high amounts of metabolic stress. Powerlifters, on the other hand, routinely train with high-intensity loads and lengthy rest periods between sets. Although both groups are known to display impressive muscularity, it is not clear which method is superior for hypertrophic gains. It has been shown that many factors mediate the hypertrophic process and that mechanical tension, muscle damage, and metabolic stress all can play a role in exercise-induced muscle growth. Therefore, the purpose of this paper is twofold: (a) to extensively review the literature as to the mechanisms of muscle hypertrophy and their application to exercise training and (b) to draw conclusions from the research as to the optimal protocol for maximizing muscle growth.",
        "prediction": "The quest to increase lean body mass is widely pursued by those who lift weights. Research is lacking, however, as to the best approach for maximizing exercise-induced muscle growth. Bodybuilders generally train with moderate weights and relatively short rest periods, resulting in high amounts of metabolic stress. Powerlifters, on the other hand, often train with heavy weights and take longer breaks between sets. Both groups are known to have strong muscles, but it's unclear which training method leads to better muscle growth. Many factors influence the muscle growth process, including mechanical tension, muscle damage, and metabolic stress, all of which can affect exercise-induced muscle growth. Therefore, the purpose of this paper is twofold: to extensively review the literature regarding the mechanisms of muscle hypertrophy and how they apply to exercise training and to draw conclusions from the research about the best protocol for maximizing muscle growth.",
        "reference": "Increasing muscle mass is the goal of many people who lift weights. Research is lacking, however, as to the optimal way to induce muscle growth. Bodybuilders train with moderate loads and short rest intervals. Powerlifters, on the other hand, train with high-intensity loads and lengthy rest periods. Although both groups are known to display impressive muscularity, it is not clear which method is superior for increasing muscle mass. It has been shown that many factors mediate the process of muscle growth and that mechanical tension, muscle damage, and metabolic stress all can play a role in muscle growth. Therefore, the purpose of this paper is to review the literature as to the mechanisms of muscle hypertrophy and their application to exercise training and to draw conclusions from the research as to the optimal way to induce muscle growth."
      }
    ]
  ],
  "non_iterative": [
    {
      "SARI": 38.25962460383747,
      "BLEU": 0.18237393367894444,
      "FKGL": 11.662857142857144
    },
    [
      {
        "source": "Abstract   Novel technological advances in mobile devices and applications can be exploited in wildfire confrontation, enabling end-users to easily conduct several everyday tasks, such as access to data and information, sharing of intelligence and coordination of personnel and vehicles. This work describes an innovative mobile application for wildfire information management that operates on Windows Phone devices and acts as a complementary tool to the web-based version of the AEGIS platform for wildfire prevention and management. Several tasks can be accomplished from the AEGIS App, such as routing, spatial search for closest facilities and firefighting support infrastructures, access to weather data and visualization of fire management data (water sources, gas refill stations, evacuation sites etc.). An innovative feature of AEGIS App is the support of these tasks by a digital assistant for artificial intelligence named Cortana (developed by Microsoft for Windows Phone devices), that allows information utilization through voice commands. The application is to be used by firefighting personnel in Greece and is potentially expected to contribute towards a more sophisticated transferring of information and knowledge between wildfire confrontation operation centers and firefighting units in the field.",
        "prediction": "This paper presents a new mobile app designed for wildfire management that works on Windows Phone devices. It complements the web-based AEGIS platform, helping users perform tasks like finding nearby facilities, accessing weather data, and visualizing fire management information such as water sources and evacuation sites. A unique feature of the AEGIS App is its integration with Cortana, an AI assistant from Microsoft, which helps users with voice commands. The app aims to improve communication and information sharing between wildfire operation centers and firefighting teams in Greece.",
        "reference": "Novel mobile devices and applications can be used in wildfire confrontation by helping users to access data and information and coordinate personnel and vehicles. This paper describes a new Windows Phone application for wildfire information management which is complementary to the web version of the AEGIS platform for wildfire prevention and management. The AEGIS App can be used for searching for the closest firefighting infrastructures, as well as access to weather data, and visualization of water sources, gas refill stations, evacuation sites, etc. The AEGIS App supports these tasks through voice commands with Microsoft Cortana (AI digital assistant for Windows Phone).Â  The application is designed for firefighters in Greece but it can help communication between wildfire coordination and local firefighting units."
      },
      {
        "source": "In recent years, mobile technologies have developed and applied in education fields, and some mobile emerging carriers with mobile technologies include a personal digital assistant (PDA), smart phone, and e-book. Some of the mobile carriers combines context-aware technologies or involve into wireless network environments to make effective use through the combination of learning scenarios and technologies, and then provide students new learning experiences differed from the past learning. In view of the application of mobile technology in education, some previous studies have addressed that mobile learning is a meaningful learning that can improve the interaction between students and the situations and reach the purposes of learning. In the main stream of mobile learning, using mobile carriers with suitable learning methods or strategies in mobile learning activities for different students to enhance learning have gradually become a important and concern issue. The purpose of this study is to investigate the learning achievement and learning attitude of elementary school students on a campus plant learning activity when they use mobile carriers and competitive learning strategies. The experimental results show that the competitive learning group of students have better learning performance than non-competitive learning group of students. After completing the learning activity, the two groups of students presented high positive attitudes towards learning.",
        "prediction": "In recent years, mobile technologies like personal digital assistants, smartphones, and e-books have been increasingly used in education. These mobile devices often work with context-aware technologies and wireless networks to create new learning experiences for students. Research shows that mobile learning can enhance interaction between students and their environment, leading to better learning outcomes. A key focus in mobile learning is using the right mobile tools and teaching methods for different students to improve their learning. This study looks at how elementary school students perform and feel about learning when using mobile devices and competitive learning strategies during a campus plant activity. The results indicate that students who participated in competitive learning performed better than those who did not. Both groups of students showed positive attitudes towards their learning after the activity.",
        "reference": "Mobile technologies, such as personal digital assistants (PDA), smartphones, and e-books, are increasingly used in the educational field. Some mobile carriers combine learning scenarios and context-aware technologies or wireless network environments providing students with new learning experiences. Mobile learning is effective as it can improve the interaction between students and situations. An important question in the mobile learning field is how to enhance learning through the use of mobile carriers with suitable learning methods in student activities. This study investigates learning achievement and attitude of elementary school students when they use mobile carriers and competitive learning strategies during campus plant learning activities. The competitive learning group of students has better learning performance than the non-competitive one. After the activity, both groups of students were positive about learning."
      },
      {
        "source": "This paper proposes an electrophysiological wireless patient monitoring system which integrates a Wireless ECG signal transmitter, GPS device and a mobile phone to acquire physiological signals and transmit them to a local server via Bluetooth wireless technology. Four kinds of monitor units were specially designed for a wireless communication, including a control center , a local monitor unit, mobile devices (personal digital assistant; PDA), and a Web page (for both patient and doctor). The use of various monitor units is created to fulfill different medical personnel requirements and wishes. This application was developed to promote the mobility and flexibility for the patients and also for the medical personnel, which further will improve both the quality of health care and lifestyle of the patient.",
        "prediction": "This paper presents a wireless patient monitoring system that uses a Wireless ECG signal transmitter, GPS device, and mobile phone to collect physiological signals and send them to a local server using Bluetooth technology. Four types of monitoring units were created for this system: a control center, a local monitor unit, mobile devices like PDAs, and a web page for both patients and doctors. These units are designed to meet the needs and preferences of different medical staff. The application aims to enhance mobility and flexibility for both patients and healthcare workers, leading to better quality of care and improved patient lifestyles.",
        "reference": "This paper suggests a system to monitor patients wirelessly using a device that transmits ECG signals, a GPS device, and a mobile phone. The signals are sent to a local server via Bluetooth technology. Four types of monitor units were created for wireless communication: a control center, a local monitor unit, mobile devices such as personal digital assistants (PDA), and a web page accessible to both patients and doctors. Various monitor units are used to satisfy different medical personnel needs. This application was developed to boost the quality of healthcare and patient lifestyle by increasing mobility and flexibility for both patients and medical personnel."
      },
      {
        "source": "As various kinds of output devices emerged, such as highresolution printers or a display of PDA(Personal Digital Assistant), the importance of high-quality resolution conversion has been increasing. This paper proposes a new method for enlarging image with high quality. One of the largest problems on image enlargement is the exaggeration of the jaggy edges. To remedy this problem, we propose a new interpolation method, which uses artificial neural network to determine the optimal values of interpolated pixels. The experimental results are shown and evaluated. The effectiveness of our methods is discussed by comparing with the conventional methods.",
        "prediction": "As various output devices like high-resolution printers and PDAs became popular, the need for high-quality image resizing grew. This paper presents a new method for enlarging images without losing quality. A major issue with image enlargement is the appearance of jagged edges. To address this, we introduce a new interpolation method that uses artificial neural networks to find the best values for the pixels being added. We show and evaluate our experimental results, comparing the effectiveness of our method to traditional approaches.",
        "reference": "The rise of output devices like high-resolution printers and PDA displays has increased the need for high-quality resolution conversion. The paper proposes a new method to make images bigger while maintaining high quality. The main issue with enlarging images is that jagged edges can become exaggerated. To solve this problem, we suggest a new method that helps us to estimate the value of the newly generated pixels using a neural network. The experiment's results are presented and analyzed. We evaluate the effectiveness of our methods by comparing them to traditional approaches."
      },
      {
        "source": "A significative percentage of the human population suffer from impairments in their capacity to distinguish or even see colours. For them, everyday tasks like navigating through a train or metro network map becomes demanding. We present a novel technique for extracting colour information from everyday natural stimuli and presenting it to visually impaired users as pleasant, non-invasive sound. This technique was implemented inside a Personal Digital Assistant (PDA) portable device. In this implementation, colour information is extracted from the input image and categorised according to how human observers segment the colour space. This information is subsequently converted into sound and sent to the user via speakers or headphones. In the original implementation, it is possible for the user to send its feedback to reconfigure the system, however several features such as these were not implemented because the current technology is limited.We are confident that the full implementation will be possible in the near future as PDA technology improves.",
        "prediction": "Many people have difficulty seeing or telling colors apart. For them, tasks like reading train or metro maps can be hard. We have developed a new technique to help visually impaired users understand color information through pleasant sounds. This technique is built into a portable device similar to a Personal Digital Assistant (PDA). It works by extracting color information from images and organizing it the way people generally perceive colors. This color data is then turned into sounds that users can hear through speakers or headphones. In the initial version, users could provide feedback to adjust the system, but this feature wasn't fully implemented due to current technology limitations. We believe that as PDA technology advances, a complete version will become available soon.",
        "reference": "A significant percentage of people have trouble differentiating or seeing colors. Simple tasks like using a train or subway map can be difficult for them. We introduce a new method to help visually impaired users perceive color information using non-invasive, pleasant sounds generated from everyday stimuli. We put this technique into a portable device called a Personal Digital Assistant (PDA). In this implementation, we extract color information from the input image and organize it based on how people perceive color. Then, the information is changed into sound and sent to the user through speakers or headphones. In the first version, the user could give feedback to change the system, but we couldn't add all the features due to technology limitations. We believe that we can add all the features soon as PDA technology advances."
      },
      {
        "source": "Inappropriate use of medicines increases the risk of hospital admissions for the elderly. Not only does this lead to unnecessary suffering for the patients but also incurs a great financial cost to the society. A medicine decision support system in a Personal Digital Assistant (PDA), with a barcode reader, can provide an overview of the patientsu0027 complete medicine use, and detect unsuitable drugs and drug combinations. Focusing on the elderly, our aim was to evaluate if a mobile medicine decision support system with a barcode reader is useful and user-friendly for nurses in home care. The participants received a comprehensive overview from the patientsu0027 medicine use and noted drug-drug interactions, therapeutic duplications and warnings for drugs unsuitable for elderly people. The nurses regarded that the decision support system increased prevention and safety, was useful and user-friendly. Our findings suggest that most of the content and functions were regarded as important. Therefore, this decision support system might be a useful tool for district nurses.",
        "prediction": "Using medicines incorrectly can lead to more hospital visits for older adults, causing them unnecessary pain and costing society money. A mobile medicine decision support system with a barcode reader can help caregivers see all the medicines patients are taking and identify harmful drug combinations. This study focused on older people and looked at whether this mobile system is helpful and easy for nurses who provide home care. The nurses found that the system offered a clear overview of patients' medication, highlighted dangerous drug interactions, and flagged medicines that are not suitable for older adults. They believed this system improved prevention and safety and was both useful and easy to use. Overall, the key features and functions of the system were seen as important, suggesting it could be a valuable tool for nurses in the community.",
        "reference": "Misusing medicines can make older people more likely to end up in the hospital. This causes patient suffering and financial cost to society. A support system for medicine decision, with a bar code reader, in a PDA can help identify inappropriate medication use and combinations by providing a complete overview of the patient's medication The goal was to evaluate if a mobile medicine decision support system with a barcode reader is helpful and easy to use for home care nurses working specially with older patients. The participants were provided with a complete overview of the patient's medication usage, and identified any drug interactions, duplicated medications, and any warnings about drugs that are not suitable for elderly patients. The nurses found the decision support system to be helpful, and easy to use, and improving the prevention and safety measures. Our results indicate that the majority of the content and features were considered significant. So, this system could be helpful for district nurses."
      },
      {
        "source": " :[0],\"access to patient appointment schedules can help clinicians manage time and problems better. Many large health care organizations manage clinical appointment scheduling via enterprise resource scheduling systems which are poorly accessible by clinicians. Also, staff other than the clinicianu0027s personal assistant(s) may manage scheduling, making it difficult for clinicians to stay informed of changes. Many a clinician today uses a personal digital assistant (PDA) containing basic calendaring functionality. Our âPalmOversiteâ project demonstrates the feasibility of integrating enterprise appointment schedule information into a PDA calendar, making schedule information much more readily available to the clinician.",
        "prediction": "Access to patient appointment schedules can help doctors manage their time and issues more effectively. Many big healthcare organizations use complex systems to schedule appointments that are not easy for doctors to access. Often, people other than the doctorâs personal assistant handle the scheduling, which can leave doctors unaware of any changes. Many doctors use a personal digital assistant (PDA) that has basic calendar features. Our project called âPalmOversiteâ shows that it is possible to link appointment schedule information from these systems into a PDA calendar, making this information much easier for doctors to access.",
        "reference": "Knowing patients' appointment schedules can help clinicians manage time and problems more effectively. Healthcare organizations often use enterprise resource scheduling systems for clinical appointment scheduling, but these systems may not be easily accessible by clinicians. Moreover, scheduling may not only be handled by the clinician's assistant(s), creating challenges for clinicians to stay updated on any changes. Many clinicians today use a personal digital assistant (PDA) with a basic calendar. Our project called 'PalmOversite' shows the practicability of integrating enterprise appointment schedule information into a PDA calendar. This makes it easier for clinicians to access their schedule information."
      },
      {
        "source": "Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of multidrug-resistant tuberculosis (MDR-TB) patients in Peru, in conjunction with the Peruvian National TB Program (NTP). Monthly bacteriology tests, which must be collected from health establishments located across this major city, are an integral part of this treatment. Currently, a SES employee visits each health establishment to collect this information by hand, process it and type it into an electronic medical record system  this :[81],\"paper, we describe the development and implementation of a personal digital assistant (PDA)-based electronic system to collect, verify and upload monthly bacteriology data into the PIH-EMR. After an initial implementation period, we performed a pilot study to test the use of this system. We completed a baseline assessment in two health districts and then implemented the electronic system in one of the districts while the control site continued to use the paper-based system during the same period. The PDA-based system had a processing time of 6.2 days, significantly lower than measurements for both the baseline [54.8] and control sites [64.4] (both pu003c0.0001). It was also able to reduce the frequency of discrepancy from 10.1% to 2.8% (pu003c0.0001) and receive positive feedback from the users. Finally, the systemâs cost would be recuperated in three months from time savings due to increased work efficiency. This system will be the subject of a larger study to determine its impact on delays, errors and costs.",
        "prediction": "Partners In Health and its partner organization in Lima, Peru, Socios En Salud, are treating most patients with multidrug-resistant tuberculosis in the country. They work alongside the Peruvian National TB Program. A key part of this treatment involves monthly tests that are collected from various health centers in the city. Currently, a worker from Socios En Salud goes to each health center to gather this data, process it, and enter it into a digital medical record system. In this paper, we describe a new electronic system that uses a personal digital assistant to collect, check, and upload bacteriology data. After we introduced the system, we did a pilot study to test it. We assessed the situation in two health districts and then used the new electronic system in one district while the other continued with the traditional paper method. The PDA-based system processed data in 6.2 days, which is much faster than the 54.8 days for the baseline and 64.4 days for the control site. It also reduced errors from 10.1% to 2.8% and received positive feedback from users. The costs of this system will be recovered in three months due to increased efficiency. We plan to conduct a larger study to see how it affects delays, errors, and costs.",
        "reference": "PIH (Partners In Health) and SES (Socios En Salud) provide treatment for most of the MDR-TB (multidrug-resistant tuberculosis) patients in Peru along with the Peruvian NTP (National TB Program). Monthly bacteriology tests are necessary for this treatment and must be collected from various health establishments located throughout the city. An employee from SES is currently going to each health establishment and collecting monthly bacteriology test results by hand, processing them, and typing them into an electronic medical record system. In this paper, we explain how we made a digital system using a personal digital assistant (PDA) to gather, check, and upload monthly bacteriology data into the PIH-EMR (Partners In Health Electronic Medical Record).  After an initial period of putting the system into action, we conducted a test study to evaluate the effectiveness of using this system. We first evaluated the current system in two health districts, then introduced the electronic system in one district while the other continued using the paper-based system during the same time. The PDA-based system took only 6.2 days to process, which was significantly lower than both the baseline (54.8) and control sites (64.4) (both less than 0.0001). The PDA-based system reduced differences from 10.1% to 2.8% and received positive feedback from users. The system would pay for itself in three months due to increased efficiency and time savings. A larger study will be conducted to assess the impact of this system on delays, errors, and costs."
      },
      {
        "source": "In order to facilitate knowledge transfer between specialists and generalists and between experts and novices, and to promote interdisciplinary communication, there is a need to provide methods and tools for doing so. This interdisciplinary research team developed and evaluated a decision support tool (DST) on a personal digital assistant (PDA) for cardiac tele-triage/tele-consultation when the presenting problem was chest pain. The combined human factors methods of cognitive work analysis during the requirements-gathering phase and ecological interface design during the design phase were used to develop the DST. A pilot clinical trial was conducted at a quaternary cardiac care hospital over a 3-month period. During this time, the DST was used by the nine nursing coordinators who provide tele-triage/tele-consultation 24/7. This clinical trial validated the design and demonstrated its usefulness to advanced cardiac care nurses, its potential for use by nurses less experienced in cardiac care, and for its potential use in an interdisciplinary team environment.",
        "prediction": "To improve communication between experts and beginners, there is a need for tools and methods. An interdisciplinary research team created and tested a decision support tool (DST) on a personal digital assistant (PDA) for managing chest pain cases. They used human factors methods to gather requirements and design the tool. A pilot clinical trial took place at a specialized cardiac care hospital over three months. During this period, nine nursing coordinators used the DST for tele-triage and tele-consultation around the clock. The trial confirmed that the DST was useful for experienced cardiac care nurses and showed promise for less experienced nurses and for use in team settings.",
        "reference": "To improve communication between specialists, generalists, experts, and novices and encourage interdisciplinary collaboration, we need to develop methods and tools. An interdisciplinary research team created and tested a decision support tool (DST) on a personal digital assistant (PDA) to aid cardiac tele-triage/tele-consultation for patients with chest pain. To create the DST (Decision Support Tool), we used both cognitive work analysis and ecological interface design methods during the requirements-gathering and design phases. A trial was done for 3 months at a quaternary cardiac care hospital During the trial, nine nursing coordinators used DST for 24/7 tele-triage/tele-consultation. This clinical trial confirmed that the design is useful for advanced cardiac care nurses, as well as for less experienced nurses and interdisciplinary teams."
      },
      {
        "source": "This paper presents M-CALL, a mobile computer-assisted language learning courseware for Korean language learners. Since conventional computer-assisted language learning is often boring, it exploits a cyber pet game to increase the learnerâs interest. M-CALL runs on a personal digital assistant with public wireless LAN for mobile learning. It grows a cyber pet by solving problems of Korean language learning. Korean Proficiency Test (KPT), a nationally certified Korean language test, was used as problem sets. It consists of cyber pet game, mobile learning courseware, mobile learning system, and mobile tutoring. It provides various functions for Korean language learning. Currently, the prototype M-CALL was designed and partly implemented between mobile PDA and personal computer.",
        "prediction": "This paper introduces M-CALL, a mobile language learning tool for people studying Korean. Traditional language learning programs can be dull, so M-CALL uses a virtual pet game to make it more engaging. It works on a personal digital assistant with public Wi-Fi for learning on the go. In the game, users care for a virtual pet by completing Korean language challenges. The challenges are based on the Korean Proficiency Test, a recognized language assessment. M-CALL includes the pet game, a mobile course, a learning system, and tutoring features. It offers different functions to help with learning Korean. So far, a prototype of M-CALL has been developed and partially implemented on both a PDA and a personal computer.",
        "reference": "M-CALL is a mobile courseware for Korean language learners. It incorporates a cyber pet game to make it more engaging for learners than traditional computer-assisted language learning methods. M-CALL is a mobile learning system that uses a personal digital assistant with public wireless LAN (Computer network in small geographic areas). A cyber pet is raised while solving problems related to Korean language learning. The KPT, a nationally recognized exam for Korean language proficiency, served as the source material for the problem sets. It includes a virtual pet game, a mobile course for learning, a mobile learning platform, and mobile tutoring. It offers multiple features for learning Korean. Right now, a preliminary version of M-CALL has been developed and partially implemented for use on both mobile PDAs and personal computers."
      },
      {
        "source": "This study compared text entry performance of two stylus-driven soft keyboards for use in hand-held computing devices: the QWERTY and the T9. Participants transcribed text presented on a computer screen into a personal digital assistant (PDA) using a stylus and one of these two keyboards. We introduced a new psychophysical technique for measuring transcription rate that provides a composite measure of speed and accuracy. Using this technique, we calculated the maximum transcription rate for each keyboard. The results show that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9 keyboardâs apparent superior physical characteristics. An ancillary experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in visual scanning time due to perceptual grouping of the letters on the keys. Together these findings imply that the QWERTY keyboard layout remains the most effective of the currently available designs for stylus tapping on soft keyboards.",
        "prediction": "This study looked at how well two stylus-based soft keyboards perform for handheld devices: the QWERTY and the T9. Participants typed text shown on a computer screen into a personal digital assistant using a stylus and one of the keyboards. We used a new method to measure how fast and accurately people could type. Our findings showed that people typed faster with the QWERTY keyboard than with the T9, even though the T9 has better physical design. An additional experiment suggested that the T9's slower performance might be due to longer time spent looking at the letters on the keys. Overall, these results indicate that the QWERTY layout is the best choice for stylus typing on soft keyboards.",
        "reference": "This study compared two onscreen keyboards, the QWERTY and the T9, for text entry performance on hand-held computing devices. Participants used a stylus to input text on a PDA using either a QWERTY or T9 keyboard in this study. We created a new way to measure transcription rate that considers both speed and accuracy together. We used this method to determine the fastest possible typing speed for each keyboard. The study found that the QWERTY keyboard had a higher transcription rate than the T9 keyboard, even though the T9 keyboard was physically better. Another test showed that the T9 keyboard's lower performance might be because the grouped letters on its keys require more visual scanning time. Overall, these results suggest that, among the current options, the QWERTY keyboard layout is still the most efficient for typing on touch screens with a stylus."
      },
      {
        "source": "The proliferation of mobile devices such as smart phones and Personal Digital Assistant (PDA) opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system). In Mcommerce systems, we still see many common components that we have in standard E-commerce applications, such as web servers and database servers. However, these new applications raise some unique challenges. For example, the limitations of mobile devices (e.g., small screen size and reduced CPU performance) implies that software development is partly different from desktop applications. Questions which are posed when designing M-commerce system include: âWhat kind of information do the users want to access via mobile devices?â, âHow can we provide useful applications with limited user input facility?â, âHow can we test a distributed M-commerce system?â In this paper, we discuss about some software development issues for mobile commerce systems from our experiences while developing an M-commerce system for tourists. Our prototype, easyHotel, is an useful software that allows booking hotel rooms via mobile phones.",
        "prediction": "The rise of mobile devices like smartphones and PDAs has created new opportunities for mobile E-commerce, or M-commerce. M-commerce systems share some common features with regular E-commerce applications, such as web servers and database servers. However, they also face unique challenges. For instance, mobile devices have limitations like small screens and lower processing power, which means that developing software for them is different from making it for desktop computers. Key questions in designing M-commerce systems include what information users want on their mobile devices, how to create useful applications with limited input options, and how to test these systems. In this paper, we explore some software development issues we've encountered while creating an M-commerce system for tourists. Our prototype, easyHotel, is a helpful tool that lets users book hotel rooms using their mobile phones.",
        "reference": "The increasing use of mobile devices like smartphones and PDAs provides opportunities for the development of new mobile e-commerce systems, also known as M-commerce (Mobile-commerce) systems. M-commerce systems share several components with traditional E-commerce applications, such as web servers and database servers. However, these new applications present some distinct challenges. For example, due to mobile devices' limitations, such as smaller screens and weaker processors (also called CPUs), software development for mobile applications is partially different from desktop applications. Designing an M-commerce system involves asking questions such as: \"What information do users want on mobile devices?\", \"How can we create useful apps with limited user input?\", and \"How do we test a distributed M-commerce system?\" In this paper, we share our experiences developing an M-commerce system for tourists and discuss software development issues for such systems. Our software prototype, easyHotel, is a helpful application enabling users to book hotel rooms through their mobile phones."
      },
      {
        "source": "It is widely acknowledged that information such as web content should be adapted for mobile platforms to account for restrictions in mobile environments. As emerging mobile platforms such as different kinds of Personal Digital Assistant (PDA) tend to vary largely in their capabilities, we suggest that adaptation should be platform-specific. Common approaches for content adaptation are automated conversion and explicit specification of adapted content, with a trade-off between quality and development/maintenance effort. As alternative avoiding this trade-off, we propose a simple object-oriented framework for content adaptation. To facilitate the use of this framework in the Web, we base our approach on the object-oriented WebComposition model and its XML-based implementation WCML. We apply our object-oriented approach to an example application to demonstrate how object-oriented specification of platform-adapted content reduces development/maintenance effort.",
        "prediction": "It is important to adjust web content for mobile devices because mobile environments have certain limitations. Different types of Personal Digital Assistants (PDAs) have varying capabilities, so we recommend that adaptations be tailored to each platform. Common methods for adapting content include automated conversion and manually specifying the content, but these come with a balance between quality and the effort needed for development and maintenance. To avoid this balance issue, we suggest a straightforward object-oriented framework for content adaptation. Our method is based on the object-oriented WebComposition model and its XML-based implementation called WCML. We demonstrate our approach through an example to show how using this object-oriented method for platform-specific content can lower the effort required for development and maintenance.",
        "reference": "It is widely recognized that information, such as web content, should be adjusted for mobile platforms to accommodate the limitations of mobile environments. As new mobile platforms, such as various types of PDAs, differ significantly in their capabilities, we propose that adaptation should be tailored to each platform. Common methods for content adaptation involve automated conversion or explicitly specifying adapted content, balancing the trade-off between quality and the effort required for development and maintenance. Instead of making this trade-off, we suggest using a straightforward object-oriented framework for content adaptation. To make this framework more accessible for use on the web, we build our approach on the object-oriented WebComposition model and its implementation, WCML, which is an application of XML. We use our object-oriented framework in an example application to show how specifying platform-adapted content using an object-oriented approach can lower development and maintenance costs."
      },
      {
        "source": "In monitoring a patientu0027s real-time vital signs through Body Area Networks (BAN), rich data sources are communicated to medical practitioners. It is essential that data is delivered in timely-context aware manner. In this paper a system is designed for patients with cardiac disorders, with an emphasis on the design of the sensing device and communication scheme chosen. Several existing wearable physiological devices (Patient Sensing Device â PSD) used in the Healthcare systems are bulky in design and are not flexible and comfortable for the elderly patients. Presented is a unique flexible, as well as detachable PSD for the comfort of patients. Also discussed is a model for transmission, storage and processing of patient related data, which ensures periodic logging of patient data without saturating communication networks. A proof of concept prototype has been developed and implemented to enable transmission of Electrocardiogram (ECG) signal and body temperature of a patient, which can be expanded to include other vital signs. Communication between a mobile smart-phone and the ECG and temperature acquisition apparatus is implemented Bluetooth. The presented Data Management System â Periodic Model (DMS â PM) is designed to manage wireless interface of sensor units with the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a Smart phone making use of the existing GSM network.",
        "prediction": "This paper discusses a system for monitoring the vital signs of patients with heart issues using Body Area Networks. It highlights the importance of delivering data quickly and in a relevant way. Current wearable devices for healthcare are often heavy and uncomfortable for older patients. This study introduces a new flexible and detachable device that improves patient comfort. It also describes a model for managing patient data that logs information regularly without overwhelming communication networks. A prototype has been created to transmit ECG signals and body temperature, with plans to add other vital signs in the future. The system uses Bluetooth for communication between a smart phone and the device. The Data Management System manages the wireless connection of the sensors with the patient records at a medical provider using existing mobile networks.",
        "reference": "Medical practitioners can access a wealth of data sources by using Body Area Networks (BAN) to monitor a patient's real-time vital signs. A BAN refers to a network of wearable or implantable devices worn on or attached to the human body for various purposes. Timely and context-aware delivery of data is crucial. This paper presents a system specifically designed for patients with cardiac disorders, focusing on the design of the sensing device and communication scheme selected. Many of the current wearable physiological devices used in healthcare systems, known as Patient Sensing Devices (PSD), are bulky and uncomfortable for elderly patients due to their inflexible design. We introduce a unique Patient Sensing Device (PSD) that is both flexible and detachable, designed for patient comfort. We also propose a model for transmitting, storing, and processing patient-related data that ensures regular logging of data without overwhelming communication networks. We have developed and implemented a proof-of-concept prototype that can transmit a patient's Electrocardiogram (ECG) signal and body temperature, potentially expanding to other vital signs. Communication between a mobile smartphone and the ECG and temperature acquisition apparatus is achieved via Bluetooth. The Data Management System - Periodic Model (DMS - PM) introduced here is created to facilitate the wireless connection between sensor units and the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a smartphone, utilizing the existing GSM network."
      },
      {
        "source": "Advancement of wireless and mobile technology has enabled additional platforms to support learning in a single learning space. Current trend integrates usage of mobile terminals such as smart PDA (personal digital assistant) in a learning system. Such devices can communicate with wireless mobile terminal and realize the intelligence exchange with its surroundings [1]. A LOCH (Language Learning Outside the Classroom) system named One Day Trip is developed to assist overseas students to learn Japanese in real life situations with the help of a PDA. This paper proposes the implementation with Knowledge Management (KM) concepts in the system to aid the teacher and learners in the learning environment.",
        "prediction": "The growth of wireless and mobile technology has created new ways to support learning in one space. A current trend is using mobile devices like smart PDAs in education. These devices can connect with wireless networks and share information with their surroundings. A system called One Day Trip, which focuses on learning Japanese outside the classroom, has been developed for international students using a PDA. This paper suggests using Knowledge Management concepts in the system to help both teachers and students in the learning process.",
        "reference": "Wireless and mobile technology progress has allowed more platforms to facilitate learning within a unified space. The current trend is to use mobile devices, such as smart PDAs, in learning systems. These devices can communicate wirelessly with mobile terminals and exchange information with the surrounding environment One Day Trip is a language learning system called LOCH (Language Learning Outside the Classroom), designed to help foreign students learn Japanese in real-life situations using a PDA. This paper suggests incorporating Knowledge Management (KM) concepts in the One Day Trip system to support both the teacher and learners in the learning environment."
      },
      {
        "source": "In recent years, we have developed applications for teaching both wired and wireless networking. These applications have been written for the Cybiko personal digital assistant, an inexpensive alternative to other hardware. Unfortunately, the Cybiko PDA was recently discontinued. As a result, these applications had to be ported to other platforms to remain useful. Instead of porting each application to individual platforms, which would prove to be extremely time consuming because of other APIu0027s and networking protocols, we created the Vassar College Messaging Layer. This layer abstracts the Cybiko networking structure and interface, allowing Cybiko applications to be ported to other platforms with minimal code alteration.",
        "prediction": "In recent years, we created applications to teach both wired and wireless networking. These applications were made for the Cybiko personal digital assistant, which was a budget-friendly option. However, the Cybiko PDA has been discontinued. This meant we had to move these applications to other platforms to keep them useful. Rather than adjusting each application individually, which would take a lot of time due to different systems and networking rules, we developed the Vassar College Messaging Layer. This layer simplifies the Cybiko networking design and interface, making it easier to adapt Cybiko applications to other platforms with little code changes.",
        "reference": "In recent years, we have created applications for teaching both wired and wireless networking. These applications are designed for the Cybiko personal digital assistant, which offers a cost-effective alternative to other hardware options. The Cybiko PDA was discontinued recently. Consequently, these applications needed to be adapted to other platforms to maintain their usefulness. To avoid the time-consuming task of porting each application to various platforms due to different APIs and networking protocols, we developed the Vassar College Messaging Layer. This layer simplifies the Cybiko networking structure and interface, making it easier to adapt Cybiko applications to different platforms without needing to make significant changes to the code."
      },
      {
        "source": "Unlike many other classes of hardware, smartcards do not have the ability to communicate securely with the user. Deprived of means to keep the owner informed, the positive properties of smartcards are difficult to utilize. We explore the area at the border between smartcards and other, more powerful (and thus more useful), machines. On the other side of this border we find the Personal Digital Assistant  :[66],\"our view, to be useful as an extension of the usersu0027 private sphere, a machine must at least have enough functionality and resources to create trustworthy digital signatures (to speak for the user, as it were). A less resourceful machine can merely act as a memory prothesis, helping the owner remembering addresses and phone  are :[121],\"designed to be tamper resistant, and as such they seem ideal as a minimal machine. However, trustworthy digital signatures can not be created by smartcards alone, simply because the user does not know what is given to the card for  :[163],\"order to be trusted--that is, being able to make trustworthy digital signatures--a smartcard must be supported by some infrastructure outside the card proper. We explore what must be included in such an infrastructure, and demonstrate that trustworthy digital signatures can in fact be made using a standard  :[211],\"argue that based on this fact, nontrivial distributed systems can be constructed by utilizing smartcards; a nontrivial system is one where holders of smartcards are \"first class citizens\". Asserting that a smartcard can act as a trusted machine gives new opportunities for designers of user-centric  that smartcards are :[257],\"here to stay, finding ways to apply them in constructive manners is prudent.",
        "prediction": "Smartcards are different from many other types of hardware because they cannot securely communicate with their users. This lack of communication makes it hard to fully use the advantages of smartcards. We look at the relationship between smartcards and more advanced devices like Personal Digital Assistants. To be helpful as an extension of a user's private life, a device needs enough power to create trustworthy digital signatures, which represent the user. Simple devices mainly serve as tools to help users remember things like addresses and phone numbers. While smartcards are designed to resist tampering and may seem ideal as basic devices, they cannot create trustworthy digital signatures on their own. For a smartcard to be trusted, it needs support from an external system. We examine what this system should include and show that it is possible to create trustworthy digital signatures with a standard setup. We argue that, because of this, we can build complex systems that treat smartcard users as important participants. Recognizing that smartcards are likely to remain in use, it is wise to find constructive ways to apply them.",
        "reference": "Smartcards lack the capability to communicate with the user in a secure manner, unlike other hardware classes. (Smart cards are small, portable devices that have a special chip inside. They can store and process information securely.) Without a way to keep the owner updated, it becomes challenging to take advantage of the useful features of smart cards. We look at how smart cards and powerful machines can be combined to make even better devices. We believe that Personal Digital Assistants (PDAs) are more useful than smartcards because they can extend the user's private sphere. PDAs have enough functionality and resources to create trustworthy digital signatures, which can speak for the user. A less resourceful machine can serve as a memory aid, assisting the owner in remembering addresses and phone numbers, such as [121]. These machines are designed to be tamper-resistant, making them suitable for a minimalistic purpose. To create trustworthy digital signatures, a smartcard needs support from infrastructure outside the card itself. This is because the user is not aware of what information is given to the card, making it impossible for the card to be trusted solely on its own. We investigate the necessary components of this infrastructure and show that reliable digital signatures can indeed be created using a standard method [211]. We propose that smartcards can be utilized to build nontrivial distributed systems, where smartcard holders are considered important participants or \"first class citizens\". Claiming that smartcards can function as trusted machines opens up fresh possibilities for designers focused on user-centric approaches. It is evident that smartcards are here to stay, so it is wise for designers to explore and implement them in meaningful ways."
      },
      {
        "source": "In this paper we present the main features of a system that we have developed and that provides a new kind of tele-assistance service to elderly people.apart from the functionalities offered by the current tele-assistance services, also provides a high quality, anywhere and at any time assistance. We rate the assistance as high quality because allows the monitoring of vital signs and a local detection of anomalous situations by the device that the person carries in real time. Therefore, it sends alarms autonomously when  this paper we :[84],\"explain the three main functionalities offered by AINGERU: universal assistance anywhere and at any time, monitoring of vital signs irrespective of location or time and remote monitoring by allowing authorized external persons to consult data about monitored persons using the Internet. Moreover we show how those functionalities are achieved by making use of PDAs (Personal Digital Assistant), wireless communication, Semantic Web, Web services and agent technologies.",
        "prediction": "In this paper we describe a system we developed that offers a new type of tele-assistance service for elderly people. Unlike existing services, it provides high-quality assistance anytime and anywhere. We consider the assistance high quality because it tracks vital signs and can detect unusual situations in real-time with the device worn by the person. This device autonomously sends alarms when needed. We explain three main features of AINGERU: universal assistance available anytime, monitoring vital signs regardless of location, and remote monitoring that lets approved individuals access monitored data via the Internet. We also discuss how these features are achieved using PDAs, wireless communication, Semantic Web, Web services, and agent technologies.",
        "reference": "This paper introduces a new tele-assistance service for elderly people that goes beyond existing services by offering high-quality assistance anywhere and anytime. Our system provides high-quality assistance because it allows real-time monitoring of vital signs and local detection of anomalous situations through the device carried by the person. We explain the three main functions of AINGERU in this paper: universal assistance anywhere and at any time, monitoring vital signs regardless of location or time, and remote monitoring that allows authorized external individuals to access data about monitored persons via the internet. We use PDAs, wireless communication, Semantic Web (aims to enhance the World Wide Web by adding meaning to the information available online), Web services, and agent technologies to achieve the aforementioned functionalities."
      },
      {
        "source": "Objective: To evaluate the effectiveness of a personal digital assistant (PDA)âbased clinical decision support system (CDSS) on nonsteroidal anti-inflammatory drug (NSAID) prescribing safety in the outpatient  :[26],\"The design was a randomized, controlled trial conducted in a university-based resident clinic. Internal medicine residents received a PDA-based CDSS suite. For intervention residents, the CDSS included a prediction rule for NSAID-related gastrointestinal risk assessment and treatment recommendations. Unannounced standardized patients (SPs) trained to portray musculoskeletal symptoms presented to study physicians. Safety outcomes were assessed from the prescriptions given to the SPs. Each prescription was reviewed by a committee of clinicians blinded to participant, intervention group assignment, and baseline or follow-up  :[108],\"Prescriptions were judged as safe or unsafe. :[26],\"The main outcome measure was the differential change in unsafe prescribing of NSAIDs for the intervention versus the control  :[135],\"At baseline, the mean proportion of cases per physician with unsafe prescriptions for the two groups was similar (0.27 vs. 0.29, p u003e 0.05). Controlling for baseline performance, intervention participants prescribed more safely than controls after receiving the CDSS (0.23 vs. 0.45 [F = 4.24, p u003c 0.05]). With the CDSS, intervention participants documented more complete assessment of patient gastrointestinal risk from  :[198],\"Participants provided with a PDA-based CDSS for NSAID prescribing made fewer unsafe treatment decisions than participants without the CDSS.",
        "prediction": "The study aimed to see how effective a smartphone-based support system is for safely prescribing NSAIDs in outpatient care. It was a controlled trial at a university clinic where internal medicine residents used this system. The system provided guidelines to assess gastrointestinal risks linked to NSAIDs and gave treatment suggestions. Trained actors mimicking patients with muscle issues visited the doctors to assess safety in drug prescriptions. A group of blinded clinicians reviewed these prescriptions to determine if they were safe or unsafe. The key result was how unsafe prescribing rates changed between the group using the support system and the control group. Initially, both groups had similar rates of unsafe prescriptions. However, after using the support system, the group that received it prescribed more safely than the control group. Those using the system also made more thorough evaluations of patient gastrointestinal risks. Overall, residents using the smartphone support system made fewer unsafe prescribing decisions compared to those who did not.",
        "reference": "We did a study to test if a clinical decision support system (CDSS) on a personal digital assistant (PDA) could improve the safety of prescribing nonsteroidal anti-inflammatory drugs (NSAIDs) in outpatient clinics. We conducted a randomized, controlled trial in a university-based resident clinic. Residents in internal medicine were given a CDSS suite based on PDA. Intervention residents were provided with a CDSS that had a prediction rule for assessing gastrointestinal risk related to NSAIDs and recommendations for treatment. Trained individuals, known as standardized patients (SPs), who were equipped with musculoskeletal symptoms, interacted with the physicians participating in the study without prior notification. The study evaluated the safety outcomes of prescriptions given to standardized patients portraying musculoskeletal symptoms. A committee of clinicians who didn't know about the participant, intervention group assignment, or the baseline or follow-up data reviewed each prescription. They determined whether a prescription was safe or unsafe. The study aimed to see if the PDA-based CDSS would result in a reduction of unsafe prescribing of NSAIDs. The main outcome measured the difference in unsafe prescribing between the intervention and control groups. At the beginning of the study, both groups had a similar proportion of unsafe prescriptions. (0.27 vs 0.29) After controlling for the baseline performance, it was found that those who received the CDSS suite prescribed nonsteroidal anti-inflammatory drugs more safely than those who didn't (0.23 vs 0.45, with statistical significance). Participants who had access to the CDSS through a PDA documented a more comprehensive assessment of gastrointestinal risk in patients. Moreover, the presence of the CDSS resulted in fewer unsafe treatment decisions compared to participants who did not have access to the CDSS."
      },
      {
        "source": "Recently pedestrian navigation has been studied by many researchers, which provides pedestrians with a similar function of car navigation. On the other hand, a 3dimensional (3D) map, which is one of major themes in machine vision research, has been utilized as a simulation tool in city and landscape planning, and other engineering fields. The 3D maps will give more intuitive information compared to conventional 2-dimensional (2D) ones. In this paper we first propose pedestrian navigation based on 3D maps, and describe technologies required and its use situations. Secondly we compare effectiveness of 2D and 3D maps for navigation by object search experiments under conditions: 3D maps with and without texture; display sizes corresponding to a mobile phone and PDA (Personal Digital Assistant). The experimental results show that 3D maps with texture on mobile phone display size, and 3D maps without texture on PDA display size are superior to 2D maps in search time and error rate. From these results, we can say the effectiveness of 3D maps in pedestrian navigation.",
        "prediction": "Recently, many researchers have focused on pedestrian navigation, which helps people find their way similar to car navigation. A key part of this research involves 3D maps, which are useful for city and landscape planning and provide better visual information than traditional 2D maps. In this paper, we first introduce pedestrian navigation using 3D maps, explaining the necessary technology and different usage scenarios. We then compare the effectiveness of 2D and 3D maps through object search experiments. These experiments tested 3D maps with and without textures, and on displays sized for mobile phones and PDAs. The results showed that 3D maps with textures on mobile phone screens, and those without textures on PDA screens, performed better than 2D maps in terms of search time and error rates. This indicates that 3D maps are more effective for pedestrian navigation.",
        "reference": "Recently many researchers have studied pedestrian navigation, which is similar to car navigation but designed for pedestrians. A 3D map is widely used in machine vision research and various engineering fields, such as city and landscape planning, as a simulation tool. 3D maps are more intuitive than 2D maps. In this paper, we suggest using 3D maps for pedestrian navigation and explain the necessary technology and possible scenarios for its application. We will conduct object search experiments to compare the effectiveness of 2D and 3D maps for navigation. The experiments will consider the following conditions: 3D maps with and without texture, and display sizes equivalent to a mobile phone and a Personal Digital Assistant (PDA). The results of the experiment suggest that 3D maps with texture on a mobile phone display and 3D maps without texture on a PDA display are better than 2D maps in terms of search time and error rate. Based on these results, we can conclude that 3D maps are effective for pedestrian navigation."
      },
      {
        "source": "Mobile agents are a competitive concept of client-server computing and are especially suitable in mobile environments, that are characterized by low bandwidth communication facilities and ad hoc connection/disconnection to stationary systems. They can be used for information retrieval and information filtering, in which case they evaluate replies and return only the relevant data. Mobile agents as a metaphor of active objects are created on a mobile device such as a Personal Digital Assistant (PDA), will be launched into the information galaxy and are fulfilling the mobile user âs task on the services available on networked stationary systems. One transmission channel for these itinerant agents is email. This paper introduces Active M 3 as an example of an active mail framework, which can be regarded as a first approach in authoring mobile agents in a graphical interactive manner. Active M 3 integrates two known concepts: active mail and multimedia mail.",
        "prediction": "Mobile agents are a modern approach to client-server computing, especially useful in mobile settings with limited connectivity. They help with finding and filtering information by only sending back relevant data. These agents can be created on mobile devices like PDAs and perform tasks using services from stationary systems connected to a network. One way to send these agents is through email. This paper presents Active M 3, a framework for creating mobile agents in a user-friendly way. Active M 3 combines two existing ideas: active mail and multimedia mail.",
        "reference": "Mobile agents are a competitive concept in client-server computing, particularly well-suited for mobile environments. These environments are characterized by limited bandwidth communication and the frequent connection and disconnection to stationary systems. They can be utilized for information retrieval and filtering, where they assess responses and provide only the pertinent data. Mobile agents act like active objects that can be created on a mobile device like a PDA. They are sent out to perform tasks on the networked stationary systems and fulfill the user's needs. Email serves as a transmission channel for these mobile agents. This paper presents Active M 3, which is an active mail framework that allows users to create mobile agents using a graphical interface. Active M3 is a framework that combines two concepts: active mail and multimedia mail."
      },
      {
        "source": "Digital Video Broadcasting â Handheld (DVB-H) is a technology developed as an extension of Digital Video Broadcasting â Terrestrial (DVB-T) with additional features that make it suitable for delivery to mobile devices such as phones and Personal Digital Assistant (PDAs). This paper deals with the conditions of receiving digital video broadcast type services in mobile handheld devices. The DVB-H standard is introduced and the key technology elements on data link layer and physical layer are discussed in some details. Finally the DVB-H terminal and network design is described.",
        "prediction": "Digital Video Broadcasting â Handheld (DVB-H) is a technology that improves Digital Video Broadcasting â Terrestrial (DVB-T) to work better on mobile devices like phones and PDAs. This paper discusses how to receive digital video broadcasts on these handheld devices. It introduces the DVB-H standard and talks about important technology aspects related to data transmission and physical components. Lastly, it explains how to design DVB-H terminals and networks.",
        "reference": "DVB-H is a technology based on DVB-T that is designed for delivering content to mobile devices like phones and PDAs. This paper discusses how digital video broadcast services can be received on mobile handheld devices. The introduction of the DVB-H standard includes a discussion of key technology elements on the data link layer and physical layer, providing some detailed information. This paper also covers the design of DVB-H terminals and networks."
      },
      {
        "source": "Summary form only given, as follows. We present a design for a low cost but powerful and high speed communications device powered by IDTu0027s RV4640 as its processing engine. The device can achieve very high speed, thanks to the PCI bus compatible IDT ATM NIC. The device could be used as a two way pager, a set-top box, an Internet terminal, a personal digital assistant or as a video phone. The RV4640 is a very affordable 64 bit RISC processor that executes 175 dhrystone MIPS at 133 MHz. The RV4640 can be connected to a System Interface Chip which will provide I/O and memory control. The IDT77903 ATM card is a full duplexed 25 Mbps NIC with a PCI bus interface and it costs less than $100 (US). Integrating this card into our device as a network interface will make highspeed videoconferencing and multimedia applications easily implementable.",
        "prediction": "We have designed a powerful and affordable communication device using IDT's RV4640 processor. This device can operate at high speeds because it uses the PCI bus compatible IDT ATM NIC. It can function as a two-way pager, set-top box, Internet terminal, personal digital assistant, or video phone. The RV4640 is an inexpensive 64-bit RISC processor that runs at 133 MHz and executes 175 dhrystone MIPS. It connects to a System Interface Chip for I/O and memory control. The IDT77903 ATM card is a network interface card that supports 25 Mbps and costs under $100. By adding this card, our device can easily support high-speed videoconferencing and multimedia applications.",
        "reference": "Summary provided in the following. We propose a low-cost and high-speed communication device that uses IDT's RV4640 as the processing engine. This device is designed with IDT's RV4640 as the processing engine and can achieve high speed due to the PCI bus (a type of computer bus that simplifies the communication between computer components by providing a standardized interface) compatible IDT ATM NIC. This device can serve multiple purposes such as a two-way pager, set-top box, Internet terminal, personal digital assistant, or video phone. The RV4640 is a low-cost 64-bit RISC processor that runs at 133 MHz and can execute 175 dhrystone MIPS. The RV4640 can connect to a System Interface Chip for I/O (a specialized integrated circuit designed to facilitate communication between a computer system and its external devices) and memory control. The IDT77903 ATM card, which costs less than $100 (US), is a NIC with a PCI bus interface that is capable of full duplexing at 25 Mbps. Using the IDT77903 ATM card as a network interface in our device will make it easy to implement high-speed videoconferencing and multimedia applications."
      },
      {
        "source": "Dr. Who is a Microsoft research project aiming at creating a speech-centric multimodal interaction framework, which serves as the foundation for the NET natural user interface. The paper discusses MiPadu0027s design, implementation work in progress, and preliminary user study in comparison to the existing pen-based PDA interface. MiPad is the application prototype that demonstrates compelling user advantages for wireless personal digital assistant (PDA) devices, MiPad fully integrates continuous speech recognition (CSR) and spoken language understanding (SLU) to enable users to accomplish many common tasks using a multimodal interface and wireless technologies. It tries to solve the problem of pecking with tiny styluses or typing on minuscule keyboards in todayu0027s PDAs. Unlike a cellular phone, MiPad avoids speech-only interaction. It incorporates a built-in microphone that activates whenever a field is selected. As a user taps the screen or uses a built in roller to navigate, the tapping action narrows the number of possible instructions for spoken word understanding. MiPad currently runs on a Windows CE Pocket PC with a Windows 2000 machine where speech recognition is performed. The Dr Who CSR engine uses a unified CFG and n-gram language model. The Dr Who SLU engine is based on a robust chart parser and a plan-based dialog manager.",
        "prediction": "Dr. Who is a Microsoft research project focused on creating a system that allows people to interact with devices mainly through speech. This system will be the basis for the NET natural user interface. The paper describes the design and ongoing work of an application called MiPad, as well as early user studies comparing it to current pen-based personal digital assistants (PDAs). MiPad shows advantages for wireless PDAs by combining continuous speech recognition and spoken language understanding. This allows users to do many tasks using voice and touch without needing to type or use small styluses. Unlike cellular phones, MiPad does not rely solely on speech; it has a microphone that turns on when a user selects a field. As users tap on the screen or use a roller to scroll, their actions help determine what to recognize in their spoken commands. MiPad runs on a Windows CE Pocket PC connected to a Windows 2000 computer for speech recognition. The Dr. Who speech recognition engine uses a combined approach with specific language models, and the speech understanding system is based on advanced parsing and dialog management techniques.",
        "reference": "Dr. Who is a Microsoft research project that aims to create a speech-focused system for interacting with technology. This system will serve as the foundation for a natural user interface called NET. The paper discusses MiPad's design and implementation, which are still in progress, as well as a preliminary user study comparing it to existing pen-based PDA interfaces. MiPad is a prototype application that shows how wireless personal digital assistants (PDAs) can benefit from integrating continuous speech recognition (CSR) and spoken language understanding (SLU) technologies. This allows users to perform common tasks using a multimodal interface and wireless technology. It aims to solve the issue of having to use small styluses or type on tiny keyboards on modern PDAs. MiPad does not rely solely on speech interaction, unlike a cellular phone. MiPad has a built-in microphone that turns on when a field is selected. When a user taps the screen or utilizes a built-in roller for navigation, this action reduces the range of potential instructions for spoken word comprehension. MiPad is currently operating on a Windows CE Pocket PC, with speech recognition being carried out on a Windows 2000 machine. The Windows CE Pocket PC is a PDA that runs the Windows Embedded Compact operating system. The Dr Who CSR engine combines a CFG and an n-gram language model. The Dr Who SLU engine uses a chart parser and a plan-based dialog manager."
      },
      {
        "source": "Little is known about how viable new mobile applications emerge in complex commercial environments. Research in the sociology of technology suggests that the evolution of new applications is a process of social interaction between multiple constituencies, aiming to create a common definition of mobile technology problems and solutions that is obvious only in retrospect. This theory is illustrated by the early evolution of the personal digital assistant (PDA). According to this view, established technological communities attempt to impose their own definitions of key problems and solutions on new mobile technology, thereby forcing newer players to provide a \"total system\" that completely redefines a new application area.",
        "prediction": "We don't know much about how new mobile apps come about in complex business settings. Research in the sociology of technology shows that the development of new apps happens through social interactions among different groups. They work together to create a shared understanding of the problems and solutions related to mobile technology, which often seems clear only after the fact. This idea is shown through the early development of personal digital assistants (PDAs). In this view, established tech communities try to define important problems and solutions for new mobile technologies, which pushes new companies to create comprehensive systems that change the way we think about new application areas.",
        "reference": "We don't know much about how new mobile apps succeed in complicated business environments. Research in the sociology of technology indicates that the development of new applications involves social interaction among different groups. These groups work together to establish a shared understanding of mobile technology challenges and solutions, which often becomes clear only in hindsight. The PDA's early evolution exemplifies this theory. This idea suggests that existing technology groups try to define the problems and solutions for new mobile tech, which puts pressure on new players to create a total system that redefines the application area."
      },
      {
        "source": "In the ubiquitous environment, mobile terminals like personal digital assistant or cellular phone are used to access the Web. We implemented the procedures in a ubiquitous/universal passive viewer (u-PaV) system that transforms Web content into passive viewing content that is especially useful for mobile terminals. Extracting images and text from Web content, u-PaV generates a Macromedia Flash file, which is a popular multimedia format. Although the presentation of Web content depends on the terminal type, the Web interface of mobile terminals is designed almost the same as that of personal computers. However, comparing mobile and desktop terminals, some difference in device characteristics, such as screen resolution or sound faithfulness, affect the presentation on the terminal. Moreover, when changing the access style between interactive and passive, the presentation should be adjusted for the terminal type because the lacking information is usually not perceived after transformation. To adjust the play style of Web content to the terminal type, we developed a method for visual presentation. First, using keyword analysis, we represent the emotional aspect of a Web page by adjusting the background color of the screen. Second, we emphasize the subject of the content by the logotype of the keyword. Third, we segment the picture of the content into pieces and present one after another using visual effects. These procedures can be applied to any type of terminal.",
        "prediction": "In a connected environment, mobile devices like smartphones and tablets are used to access the Internet. We created a system called u-PaV that changes web content into a form suitable for easy viewing on these devices. This system extracts images and text from webpages and turns them into a Macromedia Flash file, a popular multimedia format. While mobile devices and personal computers have similar web interfaces, there are differences like screen size and sound quality that impact how content is shown. Additionally, when switching from interactive to passive viewing, the content needs to be adjusted for each device since some information might be missed after transformation. To tailor the web content presentation for different devices, we developed several methods. First, we use keyword analysis to change the background color based on the emotional tone of the webpage. Second, we highlight the main topic using a bold keyword design. Third, we break images into sections and display them one at a time with visual effects. These techniques work on any type of device.",
        "reference": "In the ubiquitous environment, devices like personal digital assistants or cell phones are used to access the Internet. We created a system called ubiquitous/universal passive viewer (u-PaV) that converts Web content into a format suitable for easy viewing on mobile devices. u-PaV takes text and images from the Web and creates a multimedia file in Macromedia Flash format, a widely used multimedia format. Mobile devices and personal computers have similar Web interfaces, although they may look different depending on the device. Mobile and desktop terminals have some differences in device characteristics, such as screen resolution and sound quality, which can affect how content is presented on the device. When switching between interactive and passive access styles, the presentation needs to be adjusted for the device type because some information may be lost during transformation and not noticed by the user. We developed a visual presentation method to customize how Web content is displayed based on the device type. First, we analyze keywords to capture the emotional tone of a web page and adjust the screen's background color accordingly. Then, we use the keyword's logo to highlight the main subject of the content. Finally, we divide the content's image into sections and present them one by one using visual effects. These steps can be used on any type of device."
      },
      {
        "source": "We have developed two-way location aware system, named as âThe Beijing Explorerâ, which exchanged positioning information and usersâ situation to one another using a PDA (Personal Digital Assistant) with built-in wireless LAN and a GPS (Global Positioning System) receiver in real time. Users can see their position and their chats on the screen of a PDA using the system real-timely. The system was used for the guidance of the Palace Museum (Forbidden City) in Beijing, China. We carried on experiments two times using the system. The results of experiments show that the service using positioning data and sharing contents were valuable and interesting. The correct positioning information is important for the guidance system.",
        "prediction": "We created a two-way location-aware system called \"The Beijing Explorer\" that shares location information and user interactions in real time. This system works through a PDA that has a wireless connection and a GPS receiver. Users can view their location and chat messages on the PDA screen. It was tested at the Palace Museum in Beijing, China, with two experiments conducted. The results indicated that the service, which uses location data and content sharing, was valuable and engaging. Accurate location information is crucial for the guidance system.",
        "reference": "We created a location-aware system called \"The Beijing Explorer\" that uses a PDA with wireless LAN and GPS to exchange positioning and user information in real-time. Users can view their position and chats in real-time on the PDA screen when using the system. The system was used to guide visitors at the Palace Museum (Forbidden City) in Beijing, China. We conducted two experiments using the system. The experiment results indicate that the service was useful and engaging because it shared positioning data and content. Accurate positioning information is crucial for the guidance system."
      },
      {
        "source": "A truly personal machine, called a private machine and implemented as a Personal Digital Assistant (PDA), is fundamentally different from traditional machines. It is personal and private in an unprecedented manner, and its modus operandi is such that network and power failures will not be rare. Designing distributed systems where PDAs are treated as \"first class citizens\" is a  private :[59],\"assets (electronic money, keys for authentication and opening doors) will be stored in PDAs. Ownership and control of these :[59],\"assets and the media that store and communicate them should remain with the user. This must be reflected in the design of systems for private  :[105],\"introduce the \"open-ended argument\" to describe the design strategy we used for designing a system that is designed to reveal information to the user (as opposed to hide it). We argue and show that when systems are designed this way, the user (a human) is better able to control the system and his personal data, as he can make better decisions than the system itself based on qualitative assessment of the provided information. The system we have designed and implemented under this design guidelines is presented and discussed.",
        "prediction": "A private machine, like a Personal Digital Assistant (PDA), is different from regular machines because it prioritizes personal and private use. These machines can have network and power issues. When designing systems that include PDAs as important tools, it is crucial to keep user data, like electronic money and keys, safe and within the user's control. The design should allow for the user to access and understand their information rather than hiding it. This approach helps users manage their personal data better and make wiser decisions. We have created a system based on these principles and will discuss how it works.",
        "reference": "A Personal Digital Assistant (PDA) used as a private machine, is fundamentally distinct from traditional machines because it is a personalized device. It offers an unprecedented level of personal and private experience, and its operation is designed to handle network and power failures, which are expected to occur frequently. In designing distributed systems, PDAs are given high importance and treated as \"first class citizens\". This means that important assets like electronic money and authentication keys will be stored in PDAs. The user should retain ownership and control of these assets and the media that stores and communicates them. This principle should be incorporated into the design of private systems. We introduced the concept of the \"open-ended argument\" to describe our design strategy, which focuses on creating systems that are intended to provide information to the user rather than hiding it. We argue and demonstrate that when systems are designed in this manner, the user (a human) gains improved control over both the system and their personal data. By enabling users to make decisions based on qualitative assessment of the information provided, they are better equipped to make informed choices compared to relying solely on the system's automated decisions. We have created a system based on the design guidelines and we will explain it."
      },
      {
        "source": "Depression is under recognized in a variety of pediatric settings. The purpose of this paper is to describe the development and initial evaluation of a personal digital assistant (PDA)-based decision support system (DSS) for pediatric depression screening in ages 8 to 18 years of age by pediatric advanced practice nurse (APN) students. Three aspects are described: selection of depression screening instrument; integration of the instrument into the PDA; and quantitative (usage) and qualitative (focus group) evaluation. Only one third of eligible patients were screened. Twenty percent of those screened were identified as at risk for mood disorder. The barriers to screening identified through focus groups included a lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor motivation and comfort, as well as perceived or real cultural barriers. Suggestions for educational, research, and interventions to integrate clinical based PDA-based screening are discussed.",
        "prediction": "Depression is often not recognized in children and teens. This paper talks about creating and evaluating a decision support system using a personal digital assistant for screening depression in kids aged 8 to 18, aimed at pediatric nurse students. It covers three main points: choosing a screening tool, how to add it to the PDA, and how to evaluate its use and effectiveness through surveys and focus groups. Only one third of eligible patients were screened, and 20% of those screened were found to be at risk for mood disorders. Focus groups revealed barriers to screening, such as not having enough time, knowledge, guidelines, resources for referrals, problems with PDA usability, and issues with preceptor support and cultural perceptions. The paper suggests ways to improve education, research, and practices to better implement PDA-based screening in clinical settings.",
        "reference": "Depression often goes unnoticed in many pediatric settings. This paper aims to explain the creation and early assessment of a decision support system (DSS) that uses personal digital assistants (PDAs) for screening pediatric depression among children aged 8 to 18 years, carried out by pediatric advanced practice nurse (APN) students. Three aspects are discussed: choosing a depression screening tool, incorporating the tool into the PDA, and evaluating it through quantitative (usage) and qualitative (focus group) assessments. Only one third of eligible patients were screened. 20% of the screened patients were found to be at risk for a mood disorder. Barriers to screening were identified through focus groups, including lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor motivation and comfort, and cultural barriers. The paper discusses suggestions for integrating PDA-based screening into clinical practice through education, research, and interventions."
      },
      {
        "source": "This study explored the potential of the application of wireless and mobile computing technologies to be used in improving the efficiency of patient care and education and future developments in information and communication technologies to support healthcare professionals and medical students in healthcare research, medical education and training. The design used for this study was a systematic review of published materials obtained from EMBASE and MEDLINE online databases, and the Cochrane Library database, including personal observations. Today, more than 50% of healthcare professionals and medical students are using Personal Digital Assistant with expected growth of more than 75% by year-end 2007. In addition, wireless and mobile computing technologies allows Personal Digital Assistant to connect directly to networks or the Internet. Studies relating to processes of patient care and should evaluate mobile computing technologies as a potential timesaving tool. Wireless and mobile computing technologies is only beginning to take its first step in improving patient care and education. They have shown a positive impact on patient safety, health care efficiency, and ultimately patient satisfaction.",
        "prediction": "This study looked at how wireless and mobile computing can enhance patient care and education. It also examines how future technology could help healthcare workers and students in research and training. The research involved reviewing published studies from online databases like EMBASE, MEDLINE, and the Cochrane Library, along with personal observations. Currently, over 50% of healthcare professionals and students use Personal Digital Assistants (PDAs), and this number is expected to rise to more than 75% by the end of 2007. These technologies enable PDAs to connect directly to networks or the Internet. Research on patient care processes should consider mobile computing as a tool that can save time. Wireless and mobile computing technologies are just starting to make a difference in patient care and education. They have been shown to improve patient safety, healthcare efficiency, and overall patient satisfaction.",
        "reference": "This study examined how wireless and mobile computing technologies can enhance patient care and education. It also explored how advancements in information and communication technologies can support healthcare professionals and medical students in research, education, and training. We conducted a systematic review for this study, analyzing published materials from databases such as EMBASE, MEDLINE, and the Cochrane Library, as well as personal observations. Over 50% of healthcare professionals and medical students currently use Personal Digital Assistants, and this number is expected to grow by more than 75% by the end of 2007. Wireless and mobile computing technologies enable Personal Digital Assistants to connect directly to networks or the Internet. Studies should examine whether mobile computing technologies can save time in patient care processes. Wireless and mobile computing technologies are still in the early stages of improving patient care and education. These technologies have positively impacted patient safety, healthcare efficiency, and patient satisfaction."
      },
      {
        "source": "Nursing students can learn many things through practical training by experiencing actual medical practice and by coming in contact with patients. Therefore practical training is an effective learning opportunity for developing the practical nursing care ability of nursing students. Moreover, at hospitals, which are important training facilities, with regard to medical safety, the use of learning tools that produce electrical waves is not possible. So, we created a learning support environment that facilitates the imagination of nursing techniques, and enables effective preparation, review, and learning at anytime and anywhere using a portable digital assistant (PDA) device for practical training. As described in this paper, we report on the outline of the educational materials named \"digital nursing dictionary\" that we developed and the evaluation of the practices using it.",
        "prediction": "Nursing students can learn a lot through hands-on training by working with patients. This practical training helps them develop their nursing skills. However, hospitals, which are crucial for training, cannot use tools that produce electrical waves due to medical safety concerns. To assist learning, we created a supportive environment that encourages nursing practice imagination and allows students to study effectively using a portable digital assistant (PDA). This paper discusses the educational materials we developed called the \"digital nursing dictionary\" and evaluates their use in practical training.",
        "reference": "Nursing students can learn through practical training and by interacting with patients in real medical settings. Practical training is effective for developing the practical nursing care ability of nursing students. Moreover, hospitals, which are important training facilities, do not allow the use of learning tools that produce electrical waves due to medical safety concerns. We developed a learning support environment that helps nursing students visualize and practice techniques. It allows for convenient preparation, review, and learning using a portable digital assistant (PDA) device, enabling anytime and anywhere practical training. We developed an educational tool called the 'digital nursing dictionary' and evaluated its effectiveness, as outlined in this paper."
      },
      {
        "source": "Limitation in display size and resolution on mobile devices is one of the main obstacles for wide-spread use of web applications in a wireless environment. Web pages are often too large for a PDA (Personal Digital Assistant) screen to present. The same problem exists for devices with low resolution such as WebTV. Manual reconstruction of web pages for these devices would ease the problem; however, the large variation of display capabilities will greatly increase the burden of web page designers since they have to customize a web page for each possible display device. In this paper, we propose a document segmentation and presentation system. The system automatically divides a web document into a number of logical segments based on the screen size and the structure and content of the document. Additional information such as overviews and summaries is also extracted to facilitate navigation. The system presents the segments and structural information of a web document to make full use of the screen for information finding.",
        "prediction": "The small size and low resolution of mobile device screens make it hard to use web applications effectively. Many web pages are too large for devices like PDAs and WebTVs. It would help if web pages were manually adjusted for different devices, but this is challenging for designers because there are so many types of screens. In this paper, we suggest a system that automatically divides web documents into smaller parts based on the screen size and content. The system also gathers important details like summaries to help users navigate better. It presents these parts and the structure of the document to use the screen space efficiently.",
        "reference": "Small screens and low resolutions on mobile devices are a major obstacle for the widespread adoption of web applications in a wireless environment. PDA screens are often too small to display entire web pages. Low-resolution devices like WebTV face the same problem. Manually reconstructing web pages for these devices would help, but the wide range of display capabilities would make it challenging for web page designers as they would have to customize each web page for every possible display device, increasing their workload. This paper suggests a system for segmenting and presenting documents. The system divides a web document into logical segments automatically, using information about the screen size, document structure, and content. The system also extracts summaries and overviews to make navigation easier. The system optimizes the use of the screen for information finding by showing the segments and structure of a web document."
      },
      {
        "source": "Take 8-bit microcontroller (C8051F005) as the nucleus and study a kind of voltage harmonic monitor device that satisfies the long-range monitor. The harmonic analysis algorithm adopts Fast Fourier Transform (FFT). This device has two work modes: ânativeâ and âremoteâ. It also can communicate with monitor center through telephone line, serial port, IC card, PDA (Personal Digital Assistant), etc.",
        "prediction": "This study focuses on a voltage harmonic monitor device using an 8-bit microcontroller (C8051F005) for long-range monitoring. The device analyzes harmonics using the Fast Fourier Transform (FFT) algorithm. It has two modes of operation: \"native\" and \"remote.\" Additionally, it can connect to a monitoring center through various methods like telephone lines, serial ports, IC cards, and PDAs (Personal Digital Assistants).",
        "reference": "Study a voltage harmonic monitor device for long-range monitoring using the 8-bit microcontroller C8051F005 as the core. The harmonic analysis uses FFT. The device has two modes: \"native\" and \"remote\". It can communicate with a monitoring center via different methods such as telephone line, serial port, IC card, and PDA (Personal Digital Assistant)."
      },
      {
        "source": "With network and small screen device improvements, such as wireless abilities, increased memory and CPU speeds, users are no longer limited by location when accessing on-line information. We are interested in studying the effect of users switching from a large screen device, such as a desktop or laptop to use the same web page on a small device, in this case a PDA (Personal Digital Assistant). We discuss three common transformation approaches for display of web pages on the small screen: Direct Migration, Linear and Overview. We introduce a new Overview method, called the Gateway, for use on the small screen that exploits a userâs familiarity of a web page. The users in an initial study prefer using the Gateway and Direct Migration approach for web pages previously used on the large screen, despite the common Linear approach used by many web sites.",
        "prediction": "Improvements in networks and small screen devices like PDAs have made it easier for users to access online information from anywhere. This study looks at how users change from using larger screens like desktops or laptops to smaller devices while viewing the same web pages. We explore three ways to display web pages on small screens: Direct Migration, Linear, and Overview. We also present a new Overview method called the Gateway that leverages users' familiarity with a web page. In an initial study, users preferred the Gateway and Direct Migration methods for web pages they had previously used on larger screens, even though many websites commonly use the Linear approach.",
        "reference": "Improvements in network and small-screen devices, such as wireless capabilities, faster CPU speeds, and increased memory, have eliminated location restrictions for accessing online information. We want to study the impact of users switching from a desktop or laptop to a PDA (Personal Digital Assistant) when accessing the same web page. We are looking at three common ways to display web pages on small screens: Direct Migration, Linear, and Overview. Gateway is our new Overview method for small screens that use the user's familiarity with a web page. Many websites use the Linear method, but an initial study showed that users prefer using the Gateway and the Direct Migration method for web pages."
      },
      {
        "source": "The limitations and constraints of mobile systems need to be adequately addressed in software development. We have been developing a taxonomy of risks based on SEIu0027s risk questionnaire and applied it during the development of a negotiation support system for a Personal Digital Assistant (PDA). In our planned research, we will explore how we can better integrate existing risk management strategies and Agile Methods (AM).",
        "prediction": "We need to consider the limitations of mobile systems when developing software. We created a list of risks using a questionnaire from SEI and used it while developing a negotiation support system for a PDA. In our future research, we plan to find ways to better combine current risk management methods with Agile Methods.",
        "reference": "During software development, restrictions due to mobile systems need to be addressed. Based on SEI's risk questionnaire, we developed a classification of risks and applied it while developing a negotiation support system for a PDA. Risk management strategies and Agile Methods and how we can integrate them better will be studied in our future research."
      },
      {
        "source": "Expansions of mobile services and private data have required increased level of protection. Speaker recognition, one of the biometric technologies, arises lots of research interests for its simple, cheap and convenient characteristics. In this paper, a robust speaker recognition system which facilitates reliable authentication with multi-channel voices is presented. A large multi-channel corpus, including mobile phone, personal digital assistant (PDA), telephone and microphone, is collected to evaluate the system performance.",
        "prediction": "The growth of mobile services and personal data has made better protection necessary. Speaker recognition is a popular biometric technology because it is easy to use, affordable, and convenient. This paper presents a strong speaker recognition system that can reliably authenticate voices from multiple sources. A large collection of recorded voices from mobile phones, PDAs, telephones, and microphones is used to test how well the system works.",
        "reference": "The growth of mobile services and private data necessitates higher levels of protection. Speaker recognition, a technology using the voice of users to identify them, leads to a lot of research interest because of its simple, cheap, and convenient characteristics. This work presents a powerful speaker recognition system that makes the authentification with multi-channel voices easier. Data are collected on mobile phones, PDAs, telephones, and microphones to evaluate the system's performance."
      },
      {
        "source": "This paper presents a method to generate unique and nevertheless highly random pseudonyms in a distributed environment. More precisely, each user can now generate his pseudonym locally in his personal security environment, e.g. in his smart card or his personal digital assistant. There is no need for any information interchange between issuing parties or global data (especially keys), except unique identifiers for each user and each device of the system. Additionally the holder can prove, that he generated a specific pseudonym without revealing his identity and he can reveal his identity by disclosing the pseudonym. Whereas the verifier of a disclosed pseudonym can be sure, that the presenter of the pseudonym is the holder of the pseudonym (i.e. the person which originally generated it). The identifier of the user and the identifier of the useru0027s device will be used to generate unique pseudonyms, but to ensure pseudonymity, both components will be stored in the pseudonym in encrypted form.",
        "prediction": "This paper describes a way for users to create unique and random pseudonyms on their own devices, like smart cards or personal digital assistants. Users don't need to share any data or keys with others, except for unique identifiers for themselves and their devices. Users can prove they made a specific pseudonym without revealing their identity and can identify themselves by sharing the pseudonym. When someone shows a pseudonym, it can be confirmed that they are the original creator. The user and device identifiers will help create unique pseudonyms, but to keep them private, both will be encrypted in the pseudonym.",
        "reference": "This work presents a method to generate unique and random pseudonyms in a distributed system. Every user can now create his pseudonym locally in their own personal security environment, e.g. in his chip card or PDA. No information exchange is required between issuing parties or global data, except for unique identifiers for each user and device in the system. The holder can also prove that he generated a distinct pseudonym without revealing his identity; by divulging it, he can reveal his identity. In that case, the verifier of a divulgated pseudonym can be sure that the one who presents the pseudonym is holding it. (i.e. the person that originally created it) The user identifier and device's identifier will be used to create unique pseudonyms but to ensure anonymity with pseudonyms, both identifiers will be stored within the pseudonym in encrypted form."
      },
      {
        "source": "In todayu0027s mobile information society, location-based services play an increasingly important role. These services are to be accessed by users with a mobile end device for the use of city maps, route planning, navigation, or traffic information. Mobile end devices, however, do not have computing power or storage capacity comparable to that of a personal computer or laptop. These deficits can be bypassed by employing special methods in development of the respective applications. This paper outlines the experience gained in the development of a prototype for route computation in public transport networks to be used on a personal digital assistant. Subdivision of the route computation process into various steps for minimizing the computation expenditure on the mobile end device plays a significant role.",
        "prediction": "In today's mobile information society, location-based services are becoming more important. Users can access these services on mobile devices for city maps, route planning, navigation, and traffic information. However, mobile devices have less computing power and storage than personal computers or laptops. Special methods can help overcome these limitations in developing applications. This paper shares experiences from creating a prototype for route planning in public transport networks for a personal digital assistant. Breaking down the route computation into steps is key to reducing the processing required on mobile devices.",
        "reference": "Location-based service's role in today's mobile information society is increasing . Users can access city maps, route planning, navigation, or traffic information with their mobile devices. Compared to laptops or personal computers, mobile devices do not have the same computing power or storage capacity. This shortage can be overcome by using specific methods during the development of the respective application. This paper shows the gained experience from developing a prototype designed for a PDA that calculates routes in public transport networks. Dividing the route computation process into multiple steps to reduce the computational load on the mobile device is crucial."
      },
      {
        "source": "DIANE is a digital assistant system that aims to fasten the doctor access to various informations at the hospital such as health care facility, medical records, and also human resource data. The fasten access could be achieved by implementing face recognition and live streaming as part of the digital assistant system.",
        "prediction": "DIANE is a digital assistant system that helps doctors quickly access information in hospitals like health care facilities, medical records, and human resource data. This quick access is possible by using face recognition and live streaming features.",
        "reference": "DIANE is a digital assistant system that allows the doctor a faster access patient and hospital information. This could be done with face recognition and live streaming."
      },
      {
        "source": "Digital assistants are emerging to become more prevalent in our daily lives. In interacting with these assistants, users may engage in multiple tasks within a short period of time.",
        "prediction": "Digital assistants are becoming more common in our daily lives. When using these assistants, people often work on several tasks quickly.",
        "reference": "Digital assistants are becoming popular in our daily lives. It will allow users to do multiple tasks in a faster way."
      },
      {
        "source": "As extensive experimental research has shown individuals suffer from diverse biases in decision-making. In our paper we analyze the effects of decision-making biases of managers in collaborative decision processes on organizational performance. In the simulations, managerial decisions which are based on different levels of organizational complexity and different incentive systems suffer from biases known from descriptive decision theory. The results illustrate how biases in combination with each other and in different organizational contexts affect organizational performance. We find that, contrary to intuition, some combinations of biases significantly improve organizational performance while these biases negatively affect organizational performance when they occur separately. This might evoke considerations whether decision-making should be as rational as possible.",
        "prediction": "Research shows that people often have different biases when making decisions. In our study, we look at how these biases affect managers working together and how it impacts the organizationâs performance. Our simulations reveal that when managers make decisions based on varying levels of complexity and incentive systems, they experience biases similar to those described in decision theory. The findings demonstrate that some bias combinations can actually enhance organizational performance, even though these biases harm performance when they happen alone. This raises questions about whether decision-making should always aim to be completely rational.",
        "reference": "Research showed that people suffer from diverse biases (disproportionate weight in favor of or against an idea) in decision-making. We analyzed the effects of decision-making biases of managers on organizational performance. In the simulations, managers decisions which are based on organizational skills and rules, suffer from several known biases. The results illustrate how combined biases in different contexts affect organizational performance. Contrary to expectations, some combinations of biases improve organizational performance. However, when they occur separately, they decrease performance. This raises questions about the importance of rationality in decision-making."
      },
      {
        "source": "Big data, the enhanced ability to collect, store and analyze previously unimaginable quantities of data in tremendous speed and with negligible costs, delivers immense benefits in marketing efficiency, healthcare, environmental protection, national security and more. The central tenets of the current privacy framework, the principles of data minimization and purpose limitation, are severely strained by the big data technological and business reality. As we increasingly interact with these artificial agents in unsupervised settings, with no human mediators, their seeming autonomy and increasingly sophisticated functionality and behavior, raises legal and philosophical questions. The focus on the machine is a distraction from the debate surrounding data driven ethical dilemmas, such as privacy, fairness and discrimination. The machine may exacerbate, enable, or simply draw attention to the ethical challenges, but it is humans who must be held accountable. Policymakers should seek to devise agreed-upon guidelines for ethical data analysis and profiling. Such guidelines would address the use of legal and technical mechanisms to obfuscate data; criteria for calling out unethical, if not illegal, behavior; categories of privacy and non-privacy harms; and strategies for empowering individuals through access to data in intelligible form.",
        "prediction": "Big data allows us to collect, store, and analyze large amounts of information quickly and cheaply. This brings many benefits in areas like marketing, healthcare, and security. However, the current privacy rules, which emphasize minimizing data usage and limiting its purpose, struggle to keep up with big data technologies. As we interact more with AI systems that operate without human control, important legal and ethical questions arise. Focusing too much on the machines can distract us from critical issues like privacy, fairness, and discrimination. While machines can highlight these ethical challenges, humans must be responsible for addressing them. Policymakers need to create clear guidelines for ethical data use, including ways to obscure data, identify unethical behavior, understand privacy harms, and give people better access to their data in understandable formats.",
        "reference": "Big data (the ability to collect, store and analyze huge quantities of data in a really fast and cheap way) offers immense benefits in marketing, healthcare, environment, national security and more. The principles of privacy, limitation of data collection and use are stretched by the business and technological reality of big data. Our increasing interactions with these technologies without human supervision, and their growing autonomy, functionality and behavior raises legal and philosophical questions. The focus on the machine is a distraction from the debate on ethical dilemmas about data like privacy, fairness and discrimination. The machine may influence the ethical challenges, but the humans must remain responsible. Responsible people should find guidelines for ethical data analysis and collection. These guidelines would deal with mechanisms to protect data, criteria about unethical or illegal behavior, privacy harms, and strategies to give people access to data."
      },
      {
        "source": "Amazon's Echo, and Apple's Siri have drawn attention from different user groups; however, these existing commercial VUIs support limited language options for users including native English speakers and non-native English speakers. we conducted a usability study of the Google Home Smart Speaker with 20 participants including native English and non-native English speakers to understand their differences in using the Google Home Smart Speaker. The findings show that compared with their counterparts, the native English speakers had better and more positive user experiences in interacting with the device. It also shows that users' English language proficiency plays an important role in interacting with VUIs. The findings from this study can create insights for VUI designers and developers for implementing multiple language options and better voice recognition algorithms in VUIs for different user groups across the world.",
        "prediction": "Amazon's Echo and Apple's Siri have attracted different user groups but have limited language support for both native and non-native English speakers. We studied the Google Home Smart Speaker with 20 participants, including both types of speakers, to see how they used it. The results showed that native English speakers generally had a better experience interacting with the device. This also highlighted that a user's English proficiency is important in using voice user interfaces (VUIs). The insights from this study can help VUI designers and developers create better language options and voice recognition systems for diverse user groups around the world.",
        "reference": "The VUIs (voice user interface) like Amazonâs Echo or Appleâs Siri are popular nowadays. However, they have limited language options for users. We studied the usability of the Google Home Smart Speaker with native and non-native English speakers to understand their differences in using this device. The results show that the native English speakers had a better experience with the device than the non-native. It also shows that language skills play an important role. The results of this study can help VUI developers for improving language options and voice recognition in the devices."
      },
      {
        "source": "the smart speakers cannot distinguish human voice from machine voice. a method to identify which of human or machine is sending voice commands to a smart speaker is desired. to prevent such machine-voice based attacks to a smart speaker in absence of residents, we propose a system consisting of a speaker and a microphone array to detect the existence of a human nearby, supposing it can be incorporated in a smart speaker in the future.",
        "prediction": "Smart speakers struggle to tell the difference between human voices and machine-generated voices. We need a way to identify if a human or a machine is giving voice commands. To stop attacks using machine voices when no one is home, we suggest a system that uses a speaker and a microphone array to detect if a human is close by. This system could be added to smart speakers in the future.",
        "reference": "The smart speakers cannot differentiate between human voice and machine voice. A method to identify if the voice command is from a human or a machine is required. We propose a system composed of a speaker and microphones to detect the presence of humans. It could help to prevent attacks on a smart speaker with a machine voice in absence of residents"
      },
      {
        "source": "As smart speakers with voice interaction capability permeate continuously in the world, more and more people will gradually get used to the new interaction mediumâvoice. Although speech recognition, natural language processing (NLP) have been greatly improved over the past few years, users still may encounter errors from time to time like âcannot understandâ, âno requested audio resource (such as music)â, which can frustrate users. Therefore, when an error message is reported, it is vital that the smart speaker gives an effective and proper response. However, currently the response strategies adopted by leading smart speaker brands in China differed mainly on two dimensions: âapology or notâ and âhumor or neutralâ. We explored userâs preference of response strategies under two error scenariosâââcannot understandâ and âno requested audio resourceâ. Two dependent variables (satisfaction and perceived sincerity of response) were measured. The results showed that participants were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios. In the âno requested audio resourceâ scenario, humor had no significant impact on the perception of satisfaction and sincerity. But in the âcannot understandâ scenario, humorous expression decreased perceived sincerity.",
        "prediction": "As smart speakers with voice interaction become more common, people are getting used to using voice for interaction. Even though speech recognition and natural language processing have improved recently, users still face issues like âcannot understandâ or âno requested audio resource,â which can be frustrating. It is important for smart speakers to respond effectively when there is an error. Currently, major smart speaker brands in China have different response strategies mainly based on two factors: whether they apologize and whether they use humor or remain neutral. We studied user preferences for these responses in two error situations: âcannot understandâ and âno requested audio resource.â We measured user satisfaction and how sincere they felt the responses were. The results showed that users felt more satisfied and saw the responses as more sincere when the smart speaker apologized in both situations. In the âno requested audio resourceâ situation, humor did not significantly affect satisfaction or sincerity. However, in the âcannot understandâ scenario, using humor made the responses seem less sincere.",
        "reference": "Smart speakers are becoming popular around the world and people will get used to this new way of interacting with the voice. Even with the progress of speech recognition and natural language processing (interactions between computers and human language), users may still get errors like âcannot understandâ or âno requested audio resourceâ which can frustrate users. So, it is important that the smart speaker gives an effective and proper response during an error message. The responses of the most popular brand of smart speakers are based on 2 elements, apology and humor. We studied userâs preference in two error scenarios : âcannot understandâ and âno requested resourceâ Satisfaction of the user and perceived sincerity of the response were measured. The results showed that users were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios. In the âno requested audio resourceâ scenario, humor had no impact on the satisfaction or sincerity. But in the âcannot understandâ scenario, humor decreased perceived sincerity."
      },
      {
        "source": "A pharmacophore analysis approach was used to investigate and compare different classes of compounds relevant to the drug discovery process (specifically, drug molecules, compounds in high throughput screening libraries, combinatorial chemistry building blocks and nondrug molecules). Significant differences were observed between the pharmacophore profiles obtained for the drug molecules and those obtained for the high-throughput screening compounds, which appear to be closely related to the nondrug pharmacophore distribution. It is suggested that the analysis of pharmacophore profiles could be used as an additional tool for the property-based optimization of compound selection and library design processes, thus improving the odds of success in lead discovery projects.",
        "prediction": "A pharmacophore analysis was used to study and compare different types of compounds important for drug discovery. This includes drug molecules, compounds in screening libraries, building blocks from combinatorial chemistry, and nondrug molecules. The study found notable differences between the pharmacophore profiles of drug molecules and those from high-throughput screening, which appear related to the profiles of nondrug molecules. It is proposed that looking at these pharmacophore profiles could help improve the selection of compounds and the design of libraries, increasing the chances of success in finding new drug leads.",
        "reference": "A pharmacophore analysis investigated and compared different compounds of the drug discovery process. Significant differences were observed between the pharmacophore profiles of the drug molecules and the high-throughput screening compounds, which appear to be related to the nondrug pharmacophore distribution. It is suggested that the analysis could be used as an additional tool for the optimization of compound selection and library design processes.."
      },
      {
        "source": "Annotation of bioassay protocols using semantic web vocabulary is a way to make experiment descriptions machine-readable. Protocols are communicated using concise scientific English, which precludes most kinds of analysis by software algorithms. Given the availability of a sufficiently expressive ontology, some or all of the pertinent information can be captured by asserting a series of facts, expressed as semantic web triples (subject, predicate, object). With appropriate annotation, assays can be searched, clustered, tagged and evaluated in a multitude of ways, analogous to other segments of drug discovery informatics. The BioAssay Ontology (BAO) has been previously designed for this express purpose, and provides a layered hierarchy of meaningful terms which can be linked to.",
        "prediction": "Using semantic web vocabulary to annotate bioassay protocols helps make experiment descriptions understandable by computers. Scientific English is often too concise for software to analyze, but with a good enough ontology, important information can be represented through a series of facts in the form of semantic web triples (subject, predicate, object). Proper annotation allows assays to be searched, grouped, tagged, and analyzed in various ways, similar to other areas in drug discovery data analysis. The BioAssay Ontology (BAO) was specifically created for this purpose and offers a structured hierarchy of meaningful terms that can be connected to.",
        "reference": "Annotation of bioassay protocols with web vocabulary can make experiment descriptions machine-readable. Protocols use concise scientific English which prevents most of analysis by software algorithms. There is a sufficient ontology, so the pertinent information can be written using semantic web triples (subject, predicate, object). With appropriate annotation, assays can be searched, clustered, tagged and evaluated. The BioAssay Ontology (BAO) has been designed for this purpose, and provides many meaningful terms."
      },
      {
        "source": "Next generation sequencing (NGS) produces massive datasets consisting of billions of reads and up to thousands of samples. Subsequent bioinformatic analysis is typically done with the help of open source tools, where each application performs a single step towards the final result. This situation leaves the bioinformaticians with the tasks to combine the tools, manage the data files and meta-information, document the analysis, and ensure reproducibility.",
        "prediction": "Next generation sequencing creates huge amounts of data made up of billions of readings and many samples. Bioinformatic analysis usually relies on open source tools that each handle one part of the process. This means bioinformaticians need to connect these tools, organize data files and their descriptions, keep records of the analysis, and make sure the results can be repeated.",
        "reference": "Next generation sequencing (NGS) produces datasets of billions of reads and thousands of samples. The analysis is typically done with open source tools, performing a single step towards the final result. The bioinformaticians have to combine the tools, manage the files and information, document the analysis, and ensure reproducibility."
      },
      {
        "source": "SPSS Clementinel2.0 statistical software was used to mine the association rules between Etiology and traditional Chinese medicine (TCM), Syndromes and TCM, Symptoms and TCM. The classic Apriori algorithm is useful to mine cases of influenza treated by contemporary famous old Chinese medicine.",
        "prediction": "SPSS Clementine 2.0 software was used to find patterns between the causes of diseases, traditional Chinese medicine (TCM), health conditions in TCM, and symptoms with TCM. The well-known Apriori algorithm helps to analyze cases of influenza treated by well-known traditional Chinese medicine practitioners.",
        "reference": "SPSS Clementinel2.0 statistical software was used to extract data and find relations between traditional Chinese medicine and other medicine. The classic Apriori algorithm is useful to find cases of influenza treated by old Chinese medicine."
      },
      {
        "source": "Identifying antimicrobial resistant (AMR) bacteria in metagenomics samples is essential for public health and food safety. Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and constructing the correlations between genotype and phenotype in humans and other species. a Bayesian framework for genotype estimation for mixtures of multiple bacteria, named as Genetic Polymorphisms Assignments (GPA) has reduced the false discovery rate (FDR) and mean absolute error (MAE) in single nucleotide variant (SNV) identification.",
        "prediction": "Finding antimicrobial resistant bacteria in samples is important for public health and food safety. Next-generation sequencing technology helps in understanding genetic differences and links between genes and traits in humans and other species. A method called Genetic Polymorphisms Assignments improves the accuracy of identifying genetic variations, reducing errors in detection.",
        "reference": "Identifying bacterias that are resistant to antimicrobial in samples of genetic material collected from the environment is essential for public health and food safety. Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and constructing the correlations between genotype (genetic code of an individual) and phenotype (physical characteristics of an indvidual) in humans and other species. The Genetic Polymorphism Assignements (GPA) is a framework which determines the genetic constitution of multiple bacteria while reducing the number of false positive results and improving the accuracy of calculations when identifying the variation of a single nucleotide."
      },
      {
        "source": "The CRISPR/Cas9 system was recently developed as a powerful and flexible technology for targeted genome engineering, including genome editing (altering the genetic sequence) and gene regulation (without altering the genetic sequence). These applications require the design of single guide RNAs (sgRNAs) that are efficient and specific. However, this remains challenging, as it requires the consideration of many criteria.",
        "prediction": "The CRISPR/Cas9 system is a new and effective tool for changing genes and controlling gene activity. To use it effectively, we need to create specific single guide RNAs (sgRNAs) which can be difficult because there are many factors to consider.",
        "reference": "The CRISPR/Cas9 system is a powerful technology for gene editing and gene regulation. These applications require the design of single guide RNAs (which are enzymes that can delete, insert or alter DNA) that are efficient and specific. However, this remains challenging, as it requires the consideration of many criteria."
      },
      {
        "source": "The hidden connection between these reports is that gene editing could be used to solve issues related to health care allocation. Improving the health of future generations might coincide with public health goals; it might improve the health of individuals and communities, and, if successful, might be seen as a public good. However, enhancing future generations will require In Vitro Fertilisation and Pre-implantation Genetic Diagnosis. Remarkably, the necessary involvement of women in an enhancing scenario has not been discussed by its proponents. The present discourse on moral obligations of future generations, although not referring to women, seems to imply that women might be required, morally, if not legally, to reproduce with IVF. Enhancing future generations will be gendered, unless the artificial womb is developed. These are challenging issues that require a wider perspective, of both women and men. Despite the lack of a unified feminist conclusion in the discussions about the merits and risks of human genome modification, there is an urgent need to clarify the role of women in this scenario.",
        "prediction": "The connection between these reports is that gene editing could help with health care allocation. Improving the health of future generations might align with public health goals. It could benefit individuals and communities and might be seen as a public good. However, enhancing future generations will need In Vitro Fertilisation and Pre-implantation Genetic Diagnosis. Interestingly, the need for women in this scenario has not been addressed by its supporters. The current discussions about the moral responsibilities toward future generations suggest that women may need to use IVF, even if not legally required. Enhancing future generations will involve gender issues unless artificial wombs are created. These are complex problems that need to consider both women's and men's perspectives. Although there is no single feminist view on the pros and cons of human genome editing, it is crucial to clarify the role of women in this context.",
        "reference": "Gene editing could be used to solve issues related to health care allocation. Improving the health of future generations might coincide with public health goals. However, enhancing future generations will require In Vitro Fertilisation (IVF) and Pre-implantation Genetic Diagnosis. The necessary involvement of women in an enhancing scenario has not been discussed. The discourse on moral obligations of future generations seems to imply that women might be required to reproduce with IVF. Enhancing future generations will be gendered, unless the artificial womb is developed. These are challenging issues that require a wider perspective, of both women and men. There are no unified feminist conclusion about the merits and risks of human genome modification. There is also an urgent need to clarify the role of women in this scenario."
      },
      {
        "source": "CRISPR-Cas is a tool that is widely used for gene editing. However, unexpected off-target effects may occur as a result of long-term nuclease activity. Anti-CRISPR proteins, which are powerful molecules that inhibit the CRISPR-Cas system, may have the potential to promote better utilization of the CRISPR-Cas system in gene editing, especially for gene therapy. Additionally, more in-depth research on these proteins would help researchers to better understand the co-evolution of bacteria and phages. Therefore, it is necessary to collect and integrate data on various types of anti-CRISPRs.",
        "prediction": "CRISPR-Cas is a popular tool for editing genes but can sometimes cause unintended effects over time. Anti-CRISPR proteins are strong molecules that can block the CRISPR-Cas system and might improve its use in gene editing, particularly in gene therapy. More research on these proteins could help scientists understand how bacteria and viruses interact and evolve together. Therefore, it is important to gather and combine information on different types of anti-CRISPRs.",
        "reference": "CRISPR-Cas is a tool used for gene editing. However, unintended genetic modifications may occur. Anti-CRISPR proteins (molecules that inhibit the CRISPR-Cas system) may improve utilization of the CRISPR-Cas system in gene editing, especially for gene therapy. More research on these proteins would help to understand the co-evolution of bacteria and bacteriophages (virus that infects and replicates within bacteria). It is necessary to collect and integrate data on various types of anti-CRISPRs."
      },
      {
        "source": "CRISPR has become a hot research area ever since its advent for its efficiency and specificity in editing almost every section of DNA sequences. Based on its function of gene perturbation, a variety of gene editing techniques have been developed to achieve different aims. The target locations of a DNA strain can be precisely broken and repaired, during which the genes can be removed, repaired, silenced, or activated. The high efficiency of CRISPR/Cas9 reagents preparation and the easiness of experiment conduction make it now a powerful tool of high-content screen.",
        "prediction": "CRISPR is an exciting area of research because it can efficiently and accurately edit DNA sequences. This has led to the development of various gene editing techniques for different purposes. Scientists can precisely cut and fix specific parts of DNA, allowing them to remove, repair, silence, or activate genes. The easy preparation of CRISPR/Cas9 tools and straightforward experiment procedures make it a powerful method for large-scale testing.",
        "reference": "CRISPR is a popular research area known for its efficiency and specificity in editing DNA sequences. A variety of gene editing techniques have been developed for different aims. The target locations of a DNA strain can be precisely broken and repaired, during which the genes can be removed, repaired, silenced, or activated. The high efficiency of CRISPR/Cas9 reagents preparation and the easiness of experiment conduction make it a powerful tool."
      },
      {
        "source": "The CRISPR-Cpf1 system has been successfully applied in genome editing. However, target efficiency of the CRISPR-Cpf1 system varies among different gRNA sequences. Using machine learning technology, a SVM model was created to predict target efficiency for any given gRNAs. the first web service application, CRISPR-DT (CRISPR DNA Targeting), to help users design optimal gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and specificity is available.",
        "prediction": "The CRISPR-Cpf1 system is useful for editing genes but its effectiveness can differ based on the gRNA sequences used. A machine learning model called SVM was developed to predict how well these gRNAs will work. There is now a web application called CRISPR-DT that helps users create the best gRNAs for the CRISPR-Cpf1 system by looking at both how effective they are and their specificity.",
        "reference": "The CRISPR-Cpf1 system (a DNA-editing technology) has been successfully applied in gene editing. However target efficiency of the CRISPR-Cpf1 system varies among different gRNA (piece of RNA that serves as a guide to DNA-targeting enzymes) sequences. Using machine learning technology, a support-vector machine model (algorithm used for data classification) was created to predict the target efficiency for any given gRNAs. CRISPR-DT (CRISPR DNA Targeting) is available. It is the first web service application to help users design optimal gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and target specificity (recognition mecanism)."
      },
      {
        "source": "Emerging self-driving vehicles are vulnerable to different attacks due to the principle and the type of communication systems that are used in these vehicles. These vehicles are increasingly relying on external communication via vehicular ad hoc networks (VANETs). VANETs add new threats to self-driving vehicles that contribute to substantial challenges in autonomous systems. These communication systems render self-driving vehicles vulnerable to many types of malicious attacks, such as Sybil attacks, Denial of Service (DoS), black hole, grey hole and wormhole attacks. In this paper, we propose an intelligent security system designed to secure external communications for self-driving and semi self-driving cars. The hybrid detection system relies on the Back Propagation neural networks (BP), to detect a common type of attack in VANETs: Denial-of-Service (DoS). The experimental results show that the proposed BP-IDS is capable of identifying malicious vehicles in self-driving and semi self-driving vehicles.",
        "prediction": "Self-driving vehicles can be attacked due to how they communicate with each other and external systems. They often use a type of communication network called vehicular ad hoc networks (VANETs), which can introduce new security threats. These threats include various types of attacks like Sybil, Denial of Service (DoS), black hole, grey hole, and wormhole attacks. This paper introduces a smart security system aimed at protecting the communication of self-driving and semi self-driving cars. The system uses Back Propagation neural networks (BP) to detect common attacks, particularly Denial-of-Service (DoS) attacks. Results from experiments show that this BP-based Intrusion Detection System (BP-IDS) can successfully identify harmful vehicles in self-driving and semi self-driving cars.",
        "reference": "Self-driving vehicles are vulnerable to different attacks because of their communication systems. These vehicles use external communication via a network. This network add new threats to self-driving vehicles that contribute to the challenges in autonomous systems. With these communication systems, self-driving vehicles are vulnerable to many types of malicious attacks on the network. In this paper, we propose an intelligent security system to secure external communications for self-driving cars. The system will detect a common type of attack in the network: Denial-of-Service (attack trying to make network resource unavailable). The results show that the intrusion detection system is capable of identifying malicious vehicles in self-driving vehicles."
      },
      {
        "source": "Self-driving vehicle technologies are progressing rapidly and are expected to play a significant role in the future of transportation. One of the main challenges for self-driving vehicles on public roads is the safe cooperation and collaboration among multiple vehicles using sensor-based perception and inter-vehicle communications. When self-driving vehicles try to occupy the same spatial area simultaneously, they might collide with one another, might become deadlocked, or might slam on the brakes making it uncomfortable or unsafe for passengers in a self-driving vehicle. In this paper, we study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet. We present a safe protocol for merge points named Autonomous Vehicle Protocol for Merge Points, where self-driving vehicles use both vehicular communications and their own perception systems for cooperating with other self-driving and/or human-driven vehicles. Our simulation results show that our traffic protocol has higher traffic throughput, compared to simple traffic protocols, while ensuring safety.",
        "prediction": "Self-driving vehicle technology is advancing quickly and will be important for future transportation. A major challenge for these vehicles on public roads is how they can work safely together, especially when they need to share the same space. If they attempt to occupy the same area, they could crash, get stuck, or stop suddenly, which could be unsafe for passengers. This paper examines how self-driving vehicles can safely navigate merge points, where two lanes with different priority meet. We introduce a safety protocol called the Autonomous Vehicle Protocol for Merge Points, which allows self-driving vehicles to communicate with each other and use their own sensors to cooperate with both self-driving and human-driven vehicles. Our simulation results indicate that our traffic protocol allows for more vehicles to move through without losing safety compared to simpler traffic protocols.",
        "reference": "Self-driving vehicle technologies are progressing and are expected to play a significant role in the future of transportation. A main challenge for self-driving vehicles on public roads is the safe cooperation, collaboration and communication with other vehicles. When self-driving vehicles are in the same area, they might collide, become blocked, or suddenly brake and make uncomfortable or unsafe the passengers. We study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet. We present a safe protocol where self-driving vehicles use both vehicular communications and their own perception systems for cooperating with other vehicles (self-driving or human-driven). Our simulation results show that our traffic protocol leads to a better traffic flow, while ensuring safety."
      },
      {
        "source": "This paper provides a holistic study of how stock prices vary in their response to financial disclosures across different topics. Thereby, we specifically shed light into the extensive amount of filings for which no a priori categorization of their content exists. For this purpose, we utilize an approach from data mining - namely, latent Dirichlet allocation - as a means of topic modeling. This technique facilitates our task of automatically categorizing, ex ante, the content of more than 70,000 regulatory 8-K filings from U.S. companies. We then evaluate the subsequent stock market reaction. Our empirical evidence suggests a considerable discrepancy among various types of news stories in terms of their relevance and impact on financial markets. For instance, we find a statistically significant abnormal return in response to earnings results and credit rating, but also for disclosures regarding business strategy, the health sector, as well as mergers and acquisitions. Our results yield findings that benefit managers, investors and policy-makers by indicating how regulatory filings should be structured and the topics most likely to precede changes in stock valuations.",
        "prediction": "This paper studies how stock prices react to different types of financial information. We focus on a large number of filings that are not previously categorized. To do this, we use a data mining technique called latent Dirichlet allocation for topic modeling. This method helps us automatically categorize over 70,000 regulatory 8-K filings from U.S. companies and then assess the stock market's response. Our findings show that different types of news have varying effects on financial markets. For example, we see significant market reactions to earnings reports, credit ratings, business strategies, health sector news, and mergers and acquisitions. These results provide useful insights for managers, investors, and policymakers about how to structure regulatory filings and identify topics that can influence stock prices.",
        "reference": "This paper studies how stock prices vary with financial disclosures. We particularly study the many uncategorized filings. We use latent Dirichlet allocation for topic modeling. This helps automatically predict the categories based on the content of 70,000 regulatory 8-K filings from U.S. companies, which announce significant events relevant to shareholders. We then evaluate the stock market reaction. Evidence suggests a large difference among types of news stories in relevance and impact on financial markets. For example, we find unusual returns in response to disclosures about earnings results, credit rating, business strategy, the health sector, mergers and acquisitions. Our results are useful for managers, investors and policy-makers. They show how to structure regulatory filings and which topics influence stock valuations."
      },
      {
        "source": "A significant problem of using deep learning techniques is the limited amount of data available for training. There are some datasets available for the popular problems like item recognition and classification for self-driving cars, however, it is very limited for the industrial robotics field. In previous work, we have trained a multi-objective Convolutional Neural Network (CNN) to identify the robot body in the image and estimate 3D positions of the joints by using just a 2D image, but it was limited to a range of robots produced by Universal Robots (UR). In this work, we extend our method to work with a new robot arm - Kuka LBR iiwa, which has a significantly different appearance and an additional joint. However, instead of collecting large datasets once again, we collect a number of smaller datasets containing a few hundred frames each and use transfer learning techniques on the CNN trained on UR robots to adapt it to a new robot having different shapes and visual features. We have proven that transfer learning is not only applicable in this field, but it requires smaller well-prepared training datasets, trains significantly faster and reaches similar accuracy compared to the original method, even improving it on some aspects.",
        "prediction": "A big challenge in using deep learning is the lack of enough training data. While there are some datasets for popular areas like item recognition in self-driving cars, data is limited for industrial robotics. In earlier work, we trained a special kind of Convolutional Neural Network (CNN) to recognize the body of a robot in images and estimate the positions of its joints using just a 2D image. This was limited to robots made by Universal Robots. In this study, we improve our method to work with a different robot arm called Kuka LBR iiwa, which looks different and has an extra joint. Instead of gathering large datasets again, we collect smaller datasets with a few hundred frames each and apply transfer learning techniques using the CNN trained on UR robots. This helps adapt the model to the new robot's different shapes and features. We show that transfer learning works well in this area, needs smaller and well-organized datasets, trains much faster, and achieves similar or even better accuracy compared to the earlier method.",
        "reference": "Limited data available for training affects the use of deep learning techniques. Datasets are available for problems such as item recognition and classification for self-driving cars, but very limited for industrial robotics. A multi-objective Convolutional Neural Network (CNN) was first trained to identify the robot in the image and find 3D positions of the joints using just a 2D image. But this only used robots made by Universal Robots (UR). Here we work with a new robot arm - Kuka LBR iiwa which looks very different and has an additional joint. We collect a number of smaller datasets and use transfer learning techniques on the CNN trained on UR robots to adapt it to a robot that looks different. Transfer learning requires smaller training datasets, learns faster and reaches similar or even better accuracy."
      },
      {
        "source": "We introduce Ignition: an end-to-end neural network architecture for training unconstrained self-driving vehicles in simulated environments. The model is a ResNet-18 variant, which is fed in images from the front of a simulated F1 car, and outputs optimal labels for steering, throttle, braking. Importantly, we never explicitly train the model to detect road features like the outline of a track or distance to other cars; instead, we illustrate that these latent features can be automatically encapsulated by the network.",
        "prediction": "We present Ignition, a complete neural network system designed to train self-driving cars in simulated settings. This model is based on ResNet-18 and takes images from the front of a simulated Formula 1 car. It produces the best actions for steering, accelerating, and braking. Notably, we do not specifically teach the model to recognize road details like the track edges or distance to other cars. Instead, we show that the network can learn these important details on its own.",
        "reference": "Ignition is a neural network for training unconstrained self-driving vehicles in simulated environments. This ResNet-18 variant model receives images from the front of a simulated car and uses them to steer, throttle, or brake appropriately. The model is not explicitly trained to detect road features such as track outline or distance to other cars, as these features can automatically be calculated by the network."
      },
      {
        "source": "As for the humanoid robots, the internal noise, which is generated by motors, fans and mechanical components when the robot is moving or shaking its body, severely degrades the performance of the speech recognition accuracy. In this paper, a novel speech recognition system robust to ego-noise for humanoid robots is proposed, in which on/off state of the motor is employed as auxiliary information for finding the relevant input features. For this, we consider the bottleneck features, which have been successfully applied to deep neural network (DNN) based automatic speech recognition (ASR) system. When learning the bottleneck features to catch, we first exploit the motor on/off state data as supplementary information in addition to the acoustic features as the input of the first deep neural network (DNN) for preliminary acoustic modeling. Then, the second DNN for primary acoustic modeling employs both the bottleneck features tossed from the first DNN and the acoustics features. When the proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, the experimental results show that achieve obvious improvement (11% relative) is achieved by our algorithm over the conventional systems.",
        "prediction": "Humanoid robots produce internal noise from their motors and mechanical parts while moving, which makes it harder for them to understand speech. This paper presents a new speech recognition system that can cope with this noise by using the motor's on/off state to help identify important input features. We focus on specific features, called bottleneck features, that work well with deep neural networks for automatic speech recognition. To develop these features, we first use the motor's on/off data along with sound data as input for the first deep neural network to create a basic model. Then, the second deep neural network combines both the bottleneck features from the first network and the sound data for more accurate modeling. Tests show that our system significantly reduces errors in recognizing phonemes, improving performance by 11% compared to traditional methods.",
        "reference": "Internal noise generated by motors, fans and mechanical components severely decreases speech recognition accuracy, when the humanoid robot is moving or shaking its body. This paper presents a novel speech recognition system robust to ego-noise for humanoid robots. On/off state of the motor is used to find relevant input features. Bottleneck features have been successfully applied to automatic speech recognition (ASR) systems based on deep neural networks (DNN). The motor on/off state data and acoustic features are used as the input of the first deep neural network (DNN) for preliminary acoustic modeling. The second DNN for primary acoustic modeling uses both bottleneck features from the first DNN and acoustic ones. The proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, experimental results show that improvement (11% relative) is achieved by our algorithm over the conventional systems."
      },
      {
        "source": "Recognizing Traffic Signs using intelligent systems can drastically reduce the number of accidents happening world-wide. With the arrival of Self-driving cars it has become a staple challenge to solve the automatic recognition of Traffic and Hand-held signs in the major streets. Various machine learning techniques like Random Forest, SVM as well as deep learning models has been proposed for classifying traffic signs. Though they reach state-of-the-art performance on a particular data-set, but fall short of tackling multiple Traffic Sign Recognition benchmarks. In this paper, we propose a novel and one-for-all architecture that aces multiple benchmarks with better overall score than the state-of-the-art architectures. Our model is made of residual convolutional blocks with hierarchical dilated skip connections joined in steps. With this we score 99.33% Accuracy in German sign recognition benchmark and 99.17% Accuracy in Belgian traffic sign classification benchmark. Moreover, we propose a newly devised dilated residual learning representation technique which is very low in both memory and computational complexity.",
        "prediction": "Using intelligent systems to recognize traffic signs can greatly help reduce accidents worldwide. With self-driving cars becoming popular, automatically recognizing traffic and handheld signs on roads is an important challenge. Several machine learning methods like Random Forest and SVM, as well as deep learning models, have been suggested for classifying traffic signs. While these methods perform well on specific datasets, they do not effectively handle various Traffic Sign Recognition tests. In this paper, we introduce a new architecture that performs well across multiple tests with a better overall score than existing methods. Our model consists of residual convolutional blocks with special connections that help improve performance. We achieved 99.33% accuracy in recognizing German signs and 99.17% accuracy in classifying Belgian traffic signs. Additionally, we present a new technique that uses dilated residual learning, which requires less memory and computational power.",
        "reference": "If intelligent systems recognize traffic signs, it can reduce car accidents. For self-driving cars, we need automatic recognition of traffic and hand signs. Machine learning techniques  could be used to classify traffic signs. They perform well on a particular dataset, but fail on multiple traffic sign recognition test datasets. We proposed a new and better method. This model is based on enhanced convolutional neural networks (a deep-learning approach often used for image recognition). This model was more than 99% correct on German and Belgian sign recognition datasets. This new model is very low in both memory and computational complexity."
      },
      {
        "source": "In this paper, we present a transfer learning method for the end-to-end control of self-driving cars, which enables a convolutional neural network (CNN) trained on a source domain to be utilized for the same task in a different target domain. A conventional CNN for the end-to-end control is designed to map a single front-facing camera image to a steering command. To enable the transfer learning, we let the CNN produce not only a steering command but also a lane departure level (LDL) by adding a new task module, which takes the output of the last convolutional layer as input. The CNN trained on the source domain, called source network, is then utilized to train another task module called target network, which also takes the output of the last convolutional layer of the source network and is trained to produce a steering command for the target domain. The steering commands from the source and target network are finally merged according to the LDL and the merged command is utilized for controlling a car in the target domain. To demonstrate the effectiveness of the proposed method, we utilized two simulators, TORCS and GTAV, for the source and the target domains, respectively. Experimental results show that the proposed method outperforms other baseline methods in terms of stable and safe control of cars.",
        "prediction": "In this paper, we introduce a method for improving self-driving car control using transfer learning. This allows a convolutional neural network (CNN) trained in one area to be used for similar tasks in another area. Normally, a CNN for this task uses images from a front-facing camera to decide how to steer the car. To enable transfer learning, we modify the CNN so that it predicts not just the steering direction but also how likely the car is to leave its lane. This is done by adding a new module that processes the output of the CNN's last layer. The CNN trained in the first area is called the source network, and we use it to train a second module called the target network. The target network also uses the output from the source network to decide steering for the new area. Finally, we combine the steering instructions from both networks based on the lane departure level to control the car. We tested our method using two simulators, TORCS and GTAV, for the source and target areas. Results show that our method is better than others at ensuring stable and safe driving.",
        "reference": "A transfer learning method to control self-driving cars is proposed, in which a convolutional neural network (CNN) is trained on one domain then used for the same task in a different domain. A conventional CNN is designed to map a single front-facing camera image to control a car. CNN produces a steering command and a lane departure level (LDL, mechanism designed to warn the driver when the vehicle begins to move out of its lane). To enable the transfer learning, a new task module takes the output of the last convolutional layer as input. The CNN trained on the source domain is then used to train the target network. It takes the output of the last convolutional layer of the source network and is trained to produce a steering command for the target domain. The steering commands from the source and target network are merged and used for car control in the target domain. Two simulators were used to evaluate the proposed method. The proposed method is more stable and safer for car control."
      },
      {
        "source": "This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE), a novel minimal simulation of a centralised financial market, based on a Limit Order Book (LOB) such as is common in major stock exchanges. Construction of BSE was motivated by the fact that most of the worldâs major financial markets have automated, with trading activity that previously was the responsibility of human traders now being performed by high-speed autonomous automated trading systems. Research aimed at understanding the dynamics of this new style of financial market is hampered by the fact that no operational real-world exchange is ever likely to allow experimental probing of that market while it is open and running live, forcing researchers to work primarily from time-series of past trading data. Similarly, university-level education of the engineers who can create next-generation automated trading systems requires that they have hands-on learning experience in a sufficiently realistic teaching environment. BSE as described here addresses both those needs: it has been successfully used for teaching and research in a leading UK university since 2012, and the BSE program code is freely available as open-source on GitHuB.",
        "prediction": "This paper explains how the Bristol Stock Exchange (BSE) was designed and implemented as a simple simulation of a centralized financial market. This simulation is based on a Limit Order Book, similar to those used in big stock exchanges. The BSE was created because many major financial markets are now automated. Trading that used to be done by people is now handled by fast automated systems. It is difficult for researchers to study these new financial markets because real exchanges do not allow experiments while they are operating. Instead, researchers mostly rely on past trading data. Additionally, future engineers who will create automated trading systems need hands-on experience in realistic settings. The BSE meets both of these needs. It has been used for teaching and research at a top UK university since 2012, and its code is available for free on GitHub.",
        "reference": "This paper describes the Bristol Stock Exchange (BSE), a minimal simulation of a centralised financial market based on a Limit Order Book (LOB), a type of order to buy or sell a security at a specific price or better. BSE was built because most of the financial markets became automated. Research tries to understand the dynamics of this automated financial markets but Trainee engineers also need a realistic learning experience to build automated trading systems. BSE has been successfully used for both teaching and research since 2012. BSE code is freely available on GitHuB."
      },
      {
        "source": "Once self-driving car becomes a reality and passengers are no longer worry about it, they will need to find new ways of entertainment. The simulation results show that the accuracy of our prediction for the contents need to be cached in the areas of the self-driving car is achieved at 98.04% and our approach can minimize delay. However, retrieving entertainment contents at the Data Center (DC) can hinder content delivery service due to high delay of car-to-DC communication. To address these challenges, we propose a deep learning based caching for self-driving car, by using Deep Learning approaches deployed on the Multi-access Edge Computing (MEC) structure. First, at DC, Multi-Layer Perceptron (MLP) is used to predict the probabilities of contents to be requested in specific areas. To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units. Second, in order to cache entertainment contents stylized for car passengersâ features such as age and gender, Convolutional Neural Network (CNN) is used to predict age and gender of passengers. Through this, the self-driving car can identify the contents need to be downloaded from the MEC server and cached. Finally, we formulate deep learning based caching in the self-driving car that enhances entertainment services as an optimization problem whose goal is to minimize content downloading delay. To solve the formulated problem, a Block Successive Majorization-Minimization (BS-MM) technique is applied.",
        "prediction": "When self-driving cars become common, passengers will look for new ways to be entertained. Our simulation shows we can accurately predict what content will be needed at a rate of 98.04% and our method can reduce delays. However, getting entertainment content from the Data Center can cause delays because of slow communication between the car and the Data Center. To solve these issues, we suggest a deep learning method for caching content in self-driving cars using a system called Multi-access Edge Computing. First, we use a type of model called Multi-Layer Perceptron to predict which content will be requested in certain areas. To cut down on delays, we save these predictions in servers near the road. Next, to customize entertainment for passengers based on their age and gender, we use a Convolutional Neural Network to determine these features. This helps the self-driving car know what content to download and store. Finally, we treat the caching of entertainment content as an optimization problem aimed at reducing download delays and use a specific technique called Block Successive Majorization-Minimization to solve it.",
        "reference": "Once self-driving cars become reality and passengers no longer worry about it, they will need to find other forms of entertainment. Prediction accuracy was 98.04% for contents to be cached for self-driving cars. Such an approach can minimize delay. However, high communication delay can slow retrieval of entertainment content from Data Centers (DC). Self-driving cars can use deep learning caching to address these challenges. It is deployed on the Multi-access Edge Computing (MEC) structure that moves services from a centralized cloud to the network edges and closer to the customer. Multi-Layer Perceptron (MLP), a type of artificial neural network, is used to predict the content requested in specific areas. To reduce delay, MLP outputs are sent to MEC servers for roadside units. A Convolutional Neural Network (CNN) is used to predict passengersâ age and gender to cache adapted entertainment content. The self-driving car can therefore identify the contents to be downloaded and cached. Deep learning caching is formulated for the self-driving car to enhance entertainment services and minimize content downloading delay. A Block Successive Majorization-Minimization (BS-MM) technique solves the problem."
      },
      {
        "source": "Moral responsibility is a major concern in automated decision-making, with applications ranging from self-driving cars to kidney exchanges.",
        "prediction": "Moral responsibility is an important issue in automated decision-making, which includes areas like self-driving cars and kidney exchanges",
        "reference": "Moral responsibility is a major concern in automated decision-making, from self-driving cars to kidney transplants."
      },
      {
        "source": "A key problem for autonomous car navigation is the understanding, at an object level, of the current driving situation. Addressing this issue requires the extraction of meaningful information from on-board stereo imagery by classifying the fundamental elements of urban scenes into semantic categories that can more easily be interpreted and be reflected upon (streets, buildings, pedestrians, vehicles, signs, etc.). A probabilistic method is proposed to fuse a coarse prior 3D map data with stereo imagery classification. A novel fusion architecture based on the Stixel framework is presented for combining semantic pixel-wise segmentation from a convolutional neural network (CNN) with depth information obtained from stereo imagery while integrating coarse prior depth and label information. The proposed approach was tested on a manually labeled data set in urban environments. The results show that the classification accuracy of the fundamental elements composing the urban scene was significantly enhanced by this method compared to what is obtained from the semantic pixel-wise segmentation of a CNN alone.",
        "prediction": "A major challenge for self-driving cars is understanding their surroundings. This involves collecting useful information from on-board 3D images and categorizing important urban objects like streets, buildings, pedestrians, vehicles, and signs. This paper suggests a method to combine rough 3D map data with image analysis results. A new approach is introduced that merges detailed image segmentation from a convolutional neural network with depth data from 3D images, while also including rough depth and category information. The method was tested on labeled data in city settings. Results showed that it significantly improved the accuracy of identifying the key elements in the urban scene compared to using a CNN alone.",
        "reference": "A key problem for autonomous car navigation is the understanding of the environment while driving. It needs to extract information from the sensors and cameras and classify the elements into categories so it can be easily analysed (streets, buildings, pedestrians, vehicles, signs, etc.). A method is to fuse 3D map data with classification of the sensors and cameras. This system combine image segmentation (simplify the representation of an image to facilitate its analysis) and information obtained from sensors and cameras while integrating prior information. This approach was tested on manually entered data in urban environments. The results show that the classification of elements is more accurate with this method than the image segmentation alone."
      },
      {
        "source": "This paper proposes a MATLAB/Simulink benchmark suite for an open-source self-driving system based on Robot Operating System (ROS). One approach to the development of self-driving systems is the utilization of ROS which is an open-source middleware framework used in the development of robot applications. On the other hand, the popular approach in the automotive industry is the utilization of MATLAB/Simulink which is software for modeling, simulating, and analyzing. MATLAB/Simulink provides an interface between ROS and MATLAB/Simulink that enables to create functionalities of ROS-based robots in MATLAB/Simulink. However, it is not been fully utilized in the development of self-driving systems yet because there are not enough samples for self-driving, and it is difficult for developers to adopt co-development. Therefore, we provide a MATLAB/Simulink benchmark suite for a ROS-based self-driving system called Autoware. Autoware is popular open-source software that provides a complete set of self-driving modules. The provided benchmark contains MATLAB/Simulink samples available in Autoware. They help to design ROS-based self-driving systems using MATLAB/Simulink.",
        "prediction": "This paper presents a MATLAB/Simulink benchmark suite for creating a self-driving system using Robot Operating System (ROS). ROS is a free tool for building robot applications. In the automotive industry, the common software used is MATLAB/Simulink, which is for modeling and analyzing systems. MATLAB/Simulink can connect with ROS to help create the functions of ROS-based robots. However, it hasnât been widely used for self-driving systems yet because there arenât enough examples, and it's hard for developers to work together. To address this, we offer a benchmark suite in MATLAB/Simulink for the self-driving system called Autoware. Autoware is a well-known open-source software that has many modules for self-driving cars. The benchmark includes MATLAB/Simulink examples from Autoware to assist in designing ROS-based self-driving systems using MATLAB/Simulink.",
        "reference": "This paper proposes MATLAB/Simulink tests for an open-source self-driving system based on Robot Operating System. One approach to the development of self-driving systems is the utilization of Robot Operating System (open-source software framework used in the development of robot applications). But the popular approach in the automotive industry is the utilization of MATLAB/Simulink (software for modeling, simulating, and analyzing). MATLAB/Simulink provides an interface that enables to create functionalities of robots (based on robot operating system). However, it is not fully utilized in the development of self-driving systems yet because there are not enough samples, and it is difficult for developers to adopt co-development. We provide MATLAB/Simulink tests for a self-driving system (based on robot operating system) called Autoware. Autoware is a popular open-source software that provides a complete set of self-driving modules. The provided tests contain MATLAB/Simulink samples available in Autoware. They help to design self-driving systems (based on robot operating system) using MATLAB/Simulink."
      },
      {
        "source": "The management of self-driving systems is becoming more complex as the development of self-driving technology progresses. One approach to the development of self-driving systems is the use of ROS; however, the system used in the automotive industry is typically designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving. These models are incompatible with ROS-based systems. To allow the two to be used in tandem, it is necessary to rewrite the C++ code and incorporate them into the ROS-based system, which makes development inefficient. Therefore, the proposed framework allows models created using MATLAB/Simulink to be used in a ROS-based self-driving system, thereby improving development efficiency. Furthermore, our evaluations of the proposed framework demonstrated its practical potential.",
        "prediction": "Managing self-driving systems is becoming more complicated as technology develops. One way to create these systems is by using ROS, but the automotive industry usually uses MATLAB/Simulink for simulation and model evaluation. Unfortunately, these models don't work with ROS. To make them compatible, developers have to rewrite the C++ code, which slows down the process. The new framework allows models made with MATLAB/Simulink to be used in ROS-based self-driving systems, improving development efficiency. Our tests show that this framework has real potential.",
        "reference": "The management of self-driving systems is becoming more complex as the development of self-driving technology progresses. Self-driving systems use Robot Operating System (open-source software framework used in the development of robot applications). However, in the automotive industry, the system is designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving. These models are incompatible with systems based on Robot Operating System. To use both, it is necessary to incorporate new code into the system based on Robot Operating System, which makes development inefficient. Therefore, the proposed framework allows models created using MATLAB/Simulink to be used in a self-driving system, which improve development efficiency. Furthermore, our evaluations of the proposed framework demonstrated its practical potential."
      },
      {
        "source": "Ensuring the safety of self-driving cars is important, but neither industry nor authorities have settled on a standard way to test them. Deploying self-driving cars for testing in regular traffic is a common, but costly and risky method, which has already caused fatalities. As a safer alternative, virtual tests, in which self-driving car software is tested in computer simulations, have been proposed. One cannot hope to sufficiently cover the huge number of possible driving situations self-driving cars must be tested for by manually creating such tests. Therefore, we developed AsFault, a tool for automatically generating virtual tests for systematically testing self-driving car software. We demonstrate AsFault by testing the lane keeping feature of an artificial intelligence-based self-driving car software, for which AsFault generates scenarios that cause it to drive off the road. A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw",
        "prediction": "Making self-driving cars safe is very important, but there isn't a set way to test them. Testing self-driving cars on real roads is common but can be expensive and dangerous, leading to accidents. A safer option is to test the software in computer simulations. However, it's hard to create enough tests manually for all the different driving situations. To solve this, we created a tool called AsFault that can automatically generate these virtual tests. We show how AsFault works by testing the lane-keeping feature of a self-driving car's software, creating scenarios where it might drive off the road. A video showing AsFault in action can be found at: https://youtu.be/lJ1sa42VLDw",
        "reference": "Ensuring the safety of self-driving cars is important, but there is no standard way to test them. Testing self-driving cars in regular traffic is costly and risky, and has already caused fatalities. As a safer alternative, virtual tests (self-driving car software tested in computer simulations) have been proposed. To cover the huge number of possible driving situations, self-driving cars must be tested in manually created tests. We developed AsFault, a tool for automatically generating virtual tests for testing self-driving car software. We demonstrate AsFault by testing the lane keeping feature of a self-driving car software with scenarios going off the road. A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw"
      },
      {
        "source": "With the developing of the technology on self-driving, more and more L3 driverless vehicles are launched in market, people get opportunities to experience the self-driving cars in their daily life. As a result, there is a growing demand for the autopilot experience. Natural and efficient human-computer interaction can not only improve the driving experience, but also accelerate the process of self-driving commercialization. This paper discusses eye-movement interaction, voice interaction and gesture interaction in self-driving car, and analyzes the technology, advantages and disadvantages of the existing interaction modes, and prospect the future development trend of self-driving human-computer interaction.",
        "prediction": "As self-driving technology advances, more Level 3 driverless cars are being released, allowing people to try them in their daily lives. This has led to an increased interest in the autopilot experience. Effective interactions between humans and computers can enhance the driving experience and speed up the adoption of self-driving cars. This paper explores eye movement, voice, and gesture interactions in self-driving vehicles, discusses the strengths and weaknesses of these interaction methods, and looks at future trends in human-computer interaction for self-driving cars.",
        "reference": "Self-driving technology is developing, more and more driverless vehicles are launched in market and accessible for people in their daily life. So there is a growing demand for the autopilot experience. Natural and efficient human-computer interaction can improve the driving experience and accelerate the process of self-driving commercialization. This paper discusses interactions with the eye, voice and gesture in self-driving car, analyzes the technology, the interaction modes, and considers the future of self-driving human-computer interaction."
      },
      {
        "source": "In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems. Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on highfidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle. It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios. The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1]. In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using vision-based imitation learning we obtain safer self-driving behavior.",
        "prediction": "Self-driving cars are becoming more common on roads, promising to improve safety and efficiency in transportation. To make these cars reliable, it's important to perform extensive software tests, preferably using advanced simulators that mimic real-life interactions with other vehicles and pedestrians. Current methods for creating driving scenarios still need human input. This paper suggests automating this process using Bayesian optimization to create challenging situations for self-driving cars. These scenarios can reveal weaknesses in the car's programming and increase the chance of accidents. By adding these scenarios to the car's training data and refining the car's behavior through vision-based imitation learning, we can achieve safer self-driving performance.",
        "reference": "Self-driving vehicles have become common on public roads, with the promise of a safe and efficient mode of transport. To be reliable, these vehicles need many software tests on simulators with interactions of multiple vehicles and pedestrians. It is essential that self-driving software is evaluated with many different challenging driving scenarios. The driving scenario generation still needs human contribution. We propose to automate the process and generate conflicting self-driving that expose weaknesses of self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. By incorporating the generated scenarios into the parameters of the self-driving policy, and by adjusting the policy with the imitation learning, we obtain safer self-driving behavior."
      },
      {
        "source": "At the brink of the introduction of self-driving vehicles, only little is known about how potential users perceive them. This is especially true for self-driving vehicles deployed in public transport services. In this study, the relative preferences for a trip with a self-driving bus is assessed compared to a trip with a regular bus, based on a stated preference experiment. Based on the responses of 282 respondents from the Netherlands and Germany, a discrete choice model is estimated as a Mixed Logit model including attitudes towards trust in self-driving vehicles and interest in technology. The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips. This is due to the finding that the value of travel time is about twice as high for the self-driving bus as for the regular bus for a short commuting trip. Findings from this study further suggest that the popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes. People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others. Preferences towards automated public transport services are expected to evolve along with the transition from demonstration pilots to their deployment in regular operations.",
        "prediction": "As self-driving vehicles are being introduced, not much is known about how potential users view them, especially in public transport. This study examines how people prefer a trip with a self-driving bus compared to a regular bus using feedback from 282 people in the Netherlands and Germany. A Mixed Logit model was used to analyze attitudes towards trust in self-driving vehicles and interest in technology. The results indicate that public transport passengers currently prefer self-driving buses over regular buses, but only for short trips. This preference stems from the fact that people value travel time on self-driving buses about twice as much as on regular buses for short commutes. Moreover, the study suggests that the appeal of self-driving buses decreases when there is a human steward on board or when they operate as demand-responsive services with fixed routes. Those with a strong interest in technology or trust in automated vehicles tend to have a better view of self-driving buses. Preferences for automated public transport are expected to change as these services move from pilot programs to regular operation.",
        "reference": "Little is known about how potential users perceive self-driving vehicles. This is especially true for self-driving vehicles in public transport services. In this study, the preferences between a trip in a self-driving bus and a regular bus were compared. The results of 282 participants were studied, including trust in self-driving vehicles and interest in technology. The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips. The preference is about twice as high for the self-driving bus as for the regular bus for a short commuting trip. The popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes. People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others. Preferences for automated public transport services are expected to evolve with their deployment in regular operations."
      },
      {
        "source": "In the wake of the on-going digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions. While the benefits of this transformation can be massive, there are also tremendous risks to our society. After the automation of many production processes and the creation of self-driving vehicles, the automation of society is next. This is moving us to a tipping point and to a crossroads: we must decide between a society in which the actions are determined in a top-down way and then implemented by coercion or manipulative technologies (such as personalized ads and nudging) or a society, in which decisions are taken in a free and participatory way and mutually coordinated. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. The fundaments of human dignity, autonomous decision-making, and democracies are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies, but also the basis of greater efficiency and success.",
        "prediction": "The digital revolution is changing our economy and society significantly. While there are great benefits to these changes, there are also serious risks. Many production processes are being automated, and self-driving cars are becoming a reality. Next, society itself may be automated. This raises important choices: we can either have a society where decisions are made from the top down and enforced through forceful or manipulative methods like targeted advertising, or a society where decisions are made freely and collaboratively. Modern information and communication technologies support both options, but the second choice offers more economic and strategic advantages. The foundations of human dignity, the ability to make our own choices, and democracy are under threat, and we must actively defend these values, as they are essential for a thriving society and contribute to overall success.",
        "reference": "The on-going digital revolution will dramatically transform our economy and societal institutions. But this also presents risks for our society. Automation of society is coming. We must choose either between a society in which the actions are determined top-down by coercion or manipulative technologies (such as personalized ads) or in which decisions are taken freely and cooperatively. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. Foundations of human dignity, autonomous decision-making, and democracies are weakening. These core principles of society and the basis of greater efficiency and success need to be defended."
      },
      {
        "source": "This paper addresses the financial markets problem space with particular emphasis on trading systems seen in banking today. With the advent of modern computing, cross-regional trading transactions can now be executed within milliseconds, a reality that is impossible without the advancements of software systems technology. We then move on and discuss the anatomy of a trading system and how it fits in with the banks ecosystem of vital inter-working components.",
        "prediction": "This paper focuses on the financial markets, especially trading systems used in banks today. Thanks to modern computing, trading transactions across different regions can now happen in milliseconds, which is only possible because of software technology improvements. We then explore how a trading system is structured and how it connects with other important parts of a bank's ecosystem.",
        "reference": "This paper addresses problems of trading systems in banking. Modern computing allows cross-regional trading transactions within milliseconds. We then discuss how a trading system fits in with the bank ecosystem."
      },
      {
        "source": "In this paper we present queueing-theoretical methods for the modeling, analysis, and control of autonomous mobility-on-demand MOD systems wherein robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure acceptable quality of service throughout the network. We first cast an autonomous MOD system within a closed Jackson network model with passenger loss. The theoretical insights are used to design a robust, real-time rebalancing algorithm, which is applied to a case study of New York City and implemented on an eight-vehicle mobile robot testbed. The case study of New York shows that the current taxi demand in Manhattan can be met with about 8,000 robotic vehicles roughly 70% of the size of the current taxi fleet operating in Manhattan. Finally, we extend our queueing-theoretical setup to include congestion effects, and study the impact of autonomously rebalancing vehicles on overall congestion. Collectively, this paper provides a rigorous approach to the problem of system-wide coordination of autonomously driving vehicles, and provides one of the first characterizations of the sustainability benefits of robotic transportation networks.",
        "prediction": "This paper discusses methods for modeling, analyzing, and controlling on-demand transportation systems where self-driving vehicles transport customers in a city and adjust their locations to maintain good service. We first represent these systems using a closed network model that accounts for passenger loss. The findings help develop a strong real-time algorithm for vehicle repositioning, tested in New York City on eight mobile robots. The study indicates that about 8,000 robotic vehicles could meet the current taxi demand in Manhattan, which is about 70% of the existing taxi fleet. Additionally, we broaden our model to include traffic congestion and examine how the repositioning of self-driving vehicles affects overall traffic. Overall, this paper offers a thorough approach to managing autonomous vehicles and highlights the environmental benefits of robotic transportation systems.",
        "reference": "Queueing models are used for autonomous mobility-on-demand MOD systems. A queueing model is constructed so that queue lengths and waiting time can be predicted. In MOD systems,  robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure quality of service. We first cast an autonomous MOD system within a closed Jackson network model,a class of queueing network, with passenger loss. A real-time rebalancing algorithm is applied to a case study of New York City. It is implemented on an eight-vehicle mobile robot testbed. The current taxi demand in Manhattan can be met with about 8,000 robotic vehicles. It represents roughly 70% of the size of the current taxi fleet in Manhattan. Congestion effects are also included to study the impact of autonomously rebalancing vehicles on overall traffic jams. This paper describes the sustainability benefits of robotic transportation networks."
      },
      {
        "source": "Many model based techniques have been proposed in the literature for applying domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation. However sensor based robot control overcomes many of the difficulties of uncertain models and unknown environments which limit the domain of application of the previous methods. Furthermore, for service and manipulation tasks, it is more suitable to study the interaction between the robot and its environment at the contact point using the sensor based control, rather than specifying the joint positions and velocities required to achieve them.",
        "prediction": "Many techniques have been suggested for using humanoid robots for home tasks, like remote control and learning from examples. However, using sensors for robot control addresses many challenges posed by uncertain models and unknown surroundings, which limits the usefulness of earlier methods. For tasks involving service and manipulation, it's better to focus on how the robot interacts with its environment at the point of contact using sensor-based control, rather than just specifying the joint positions and speeds needed to complete the tasks.",
        "reference": "Model based techniques exist to apply domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation. Sensor based robot control overcomes difficulties of uncertain models and unknown environments. Interaction between the robot and its environment using the sensor based control is important."
      },
      {
        "source": "Inaccurate information, in the field of library and information science, is often regarded as a problem that needs to be corrected or simply understood as either misinformation or disinformation without further consideration. Misinformation and disinformation, however, may cause significant problems for users in online environments, where they are constantly exposed to an abundance of inaccurate and/or misleading information. This paper aims to establish conceptual groundwork for future empirical research by examining the relationships among information, misinformation, and disinformation. Our analysis extends to a discussion of cues to deception, as means for detecting misinformation and disinformation. We argue that misinformation and disinformation are related yet distinct sub-categories of information. Misinformation is a multifaceted concept, more complex than simply being inaccurate or incomplete, and disinformation does not always entail misinformation.",
        "prediction": "In library and information science, inaccurate information is often seen as a problem that needs fixing or is categorized as misinformation or disinformation. Misinformation and disinformation can create serious issues for users online who encounter a lot of misleading information. This paper aims to lay the groundwork for future research by exploring how information, misinformation, and disinformation relate to each other. We also discuss ways to identify dishonest information. We suggest that misinformation and disinformation are different types of information. Misinformation is more complicated than just being incorrect or incomplete, and disinformation does not always include misinformation.",
        "reference": "Inaccurate information is often regarded as a problem that needs to be corrected or simply understood as misinformation or disinformation without further consideration. Misinformation and disinformation may cause problems online because users are constantly exposed to inaccurate and/or false information. This paper aims to establish preliminary work for future research by examining the relationships among information, misinformation, and disinformation. Our analysis extends to a discussion of means for detecting misinformation and disinformation. We argue that misinformation and disinformation are related but distinct sub-categories of information. Misinformation is more complex than simply being inaccurate or incomplete, and disinformation does not always involve misinformation."
      },
      {
        "source": "The growth of social media provides a convenient communication scheme for people, but at the same time it becomes a hotbed of misinformation. The wide spread of misinformation over social media is injurious to public interest. We design a framework, which integrates collective intelligence and machine intelligence, to help identify misinformation. The basic idea is: (1) automatically index the expertise of users according to their microblog contents; and (2) match the experts with given suspected misinformation. By sending the suspected misinformation to appropriate experts, we can collect the assessments of experts to judge the credibility of information, and help refute misinformation. In this paper, we focus on expert finding for misinformation identification. We propose a tag-based method to index the expertise of microblog users with social tags. Experiments on a real world dataset demonstrate the effectiveness of our method for expert finding with respect to misinformation identification in microblogs.",
        "prediction": "Social media has made it easy for people to communicate, but it also spreads a lot of false information. This misinformation can harm the public. To address this issue, we created a system that combines collective intelligence (the knowledge of many people) and machine intelligence (computer analysis) to identify false information. Our main approach is to first categorize users based on what they write in their microblogs and then connect these users to suspected misinformation. By sending these false claims to the right experts, we can gather their opinions to assess the credibility of the information and help counteract the misinformation. In this paper, we focus on finding experts to help with identifying false information. We suggest a method that uses social tags to organize the knowledge of microblog users. Tests using real data show that our method is effective for finding experts to help identify misinformation in microblogs.",
        "reference": "The growth of social media leads to better communication between people, but also propagation of misinformation. The wide spread of misinformation over social media have bad consequences for public interest. We design a framework to help identify misinformation. The idea is to index the expertise of users and to match the experts with given suspected misinformation. By sending the suspected misinformation to appropriate experts, they can judge the credibility of information, and help refute misinformation. In this paper, we focus on finding appropriate experts for misinformation identification. We propose a method to index the expertise of users with tags. Experiments on a real world dataset demonstrate the effectiveness of our method for expert finding for misinformation identification."
      },
      {
        "source": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the scarcity of misinformation in support of such research. This paper aims to address the aforementioned challenges by conceptualizing misinformation and enabling the interoperability of misinformation. In particular, a representation and a model of misinformation are proposed through surveying, synthesizing, and explicating existing work in the field. The ontology-supported misinformation model can not only guide future misinformation research but also lay the foundation for building a digital misinformation library by advancing our knowledge on misinformation and by improving its sharing, management, and reuse. In addition, we present a formal methodology for managing misinformation in a digital library, and suggest future research directions related to the misinformation model.",
        "prediction": "Research on misinformation is increasingly recognized as important. However, the field faces two main challenges: a lack of theoretical models and not enough instances of misinformation for study. This paper seeks to tackle these issues by defining what misinformation is and suggesting ways to connect different types of misinformation. We propose a model based on a review and synthesis of existing research. This ontology-based model will not only help guide upcoming studies but also serve as a basis for creating a digital library of misinformation, enhancing how we understand, share, and manage misinformation. Furthermore, we outline a method for organizing misinformation within a digital library and recommend areas for future research related to our misinformation model.",
        "reference": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the rare misinformation data. This paper aims to address these challenges by conceptualizing misinformation and being able to completely understand and work on misinformation. A representation and a model of misinformation are proposed through existing work in the field. The model can guide future misinformation research and help building a digital misinformation library by advancing our knowledge on misinformation and by improving its sharing, management, and reuse. In addition, we present a methodology for managing misinformation in a digital library, and suggest future research directions."
      },
      {
        "source": "Online Social Networks OSNs have become increasingly popular means of information sharing among users. The spread of news regarding emergency events is common in OSNs and so is the spread of misinformation related to the event. We define as misinformation any false or inaccurate information that is spread either intentionally or unintentionally. In this paper we study the problem of misinformation identification in OSNs, and we focus in particular on the Twitter social network. Based on user and tweets characteristics, we build a misinformation detection model that identifies suspicious behavioral patterns and exploits supervised learning techniques to detect misinformation. Our extensive experimental results on 80294 unique tweets and 59660 users illustrate that our approach effectively identifies misinformation during emergencies. Furthermore, our model manages to timely identify misinformation, a feature that can be used to limit the spread of the misinformation.",
        "prediction": "Online social networks like Twitter are popular for sharing information. During emergencies, news and misinformation often spread on these platforms. Misinformation is any false or misleading information shared intentionally or accidentally. This paper focuses on finding misinformation in social networks, especially Twitter. We developed a detection model using the characteristics of users and tweets to spot suspicious behavior patterns. By applying supervised learning techniques, our model effectively identifies misinformation during emergencies. Our tests with 80294 tweets and 59660 users show that the model can quickly recognize misinformation, which helps reduce its spread.",
        "reference": "Social media have become popular means of information sharing. The spread of news regarding emergency events is common in social media but so is the spread of misinformation. Misinformation is any false or inaccurate information that is spread intentionally or not. In this paper we study the problem of misinformation identification in social media, and we focus in particular on Twitter. We build a misinformation detection model that identifies suspicious behavioral patterns and detect misinformation. We found 80294 unique tweets and 59660 users. It illustrates that our approach identifies misinformation during emergencies. Our model manages to timely identify misinformation, it can be used to limit the spread of the misinformation."
      },
      {
        "source": "The advent of WWW changed the way we can produce and access information. Recent studies showed that users tend to select information that is consistent with their system of beliefs, forming polarized groups of like-minded people around shared narratives where dissenting information is ignored. In this environment, users cooperate to frame and reinforce their shared narrative making any attempt at debunking inefficient. Such a configuration occurs even in the consumption of news online, and considering that 63% of users access news directly form social media, one hypothesis is that more polarization allows for further spreading of misinformation. Along this path, we focus on the polarization of users around news outlets on Facebook in different European countries (Italy, France, Spain and Germany). First, we compare the page posting behavior and the users interacting patterns across countries and observe different posting, liking and commenting rates. Second, we explore the tendency of users to interact with different pages (i.e., selective exposure) and the emergence of polarized communities generated around specific pages.",
        "prediction": "The rise of the World Wide Web has changed how we produce and access information. Recent studies show that people often choose information that matches their beliefs, resulting in groups of like-minded individuals who ignore opposing views. In this environment, users work together to strengthen their shared beliefs, making it hard to change their minds. This behavior is also seen in how people consume news online. Since 63% of users get news directly from social media, one idea is that increased polarization helps spread misinformation. We focus on how users become polarized around news sources on Facebook in four European countries: Italy, France, Spain, and Germany. First, we look at how often pages post and how users interact in different countries and notice varying rates of posting, liking, and commenting. Second, we investigate how users tend to interact with specific pages, leading to the creation of polarized communities around those pages.",
        "reference": "The WWW changed the ways we can produce and access information. Users tend to select information that agrees with their beliefs. They form polarized groups of like-minded people sharing narratives that ignore contradicting information. Here, users reinforce their shared narratives and can resist debunking This is the case with online news. Because 63% of users access news from social media, polarization could increase misinfomation spread. We focus on polarisation of Facebook news consumers in different European countries. Posting, liking and commenting rates differ across countries. We look at how users interact with different pages and polarized communities form around specific pages."
      },
      {
        "source": "We find that Italy is the most polarized country, followed by France, Germany and lastly Spain. Finally, we present a variation of the Bounded Confidence Model to simulate the emergence of these communities by considering the usersu0027 engagement and trust on the news. Our findings suggest that trust in information broadcaster plays a pivotal role against polarization of users online.",
        "prediction": "Italy is the most polarized country, followed by France, Germany, and then Spain. We introduce a modified version of the Bounded Confidence Model to simulate how these communities form based on users' engagement and trust in the news. Our findings show that trusting the information source is crucial in reducing online polarization among users.",
        "reference": "Italy is the most polarized country, then France, Germany and Spain. A variant of the Bounded Confidence Model simulates the emergence of these communities by considering user engagement and trust in the news. Trust in an information source plays a major role against polarization of users online."
      },
      {
        "source": "Online social media provide users with unprecedented opportunities to engage with diverse opinions. We discuss the policy implications of our model, highlighting the downside of debunking strategies and suggesting alternative strategies to contrast misinformation. Simultaneously, they allow the spread of misinformation by empowering individuals to self-select the narratives they want to be exposed to, both through active (confirmation bias) and passive (personalized news algorithms) self-reinforcing mechanisms. A precise theoretical understanding of such trade-offs is still largely missing. We introduce a stylized social learning model where most participants in a network update their beliefs unbiasedly based on the arrival of new information, while a fraction of participants display confirmation bias, enabling them to reject news that are incongruent with their pre-existing beliefs. We show that this simple confirmation bias mechanism can generate permanent opinion polarisation. Furthermore, the model results in states where unbiased agents behave \"as if\" they were biased, due to their biased neighbours effectively functioning as gatekeepers, restricting their access to free and diverse information. We derive analytic results for the distribution of individual agentsâ beliefs, explicitly demonstrating the aforementioned trade-off between confirmation bias and social connectivity, which we further validate against US county-level data on the impact of Internet access on the formation of beliefs about global warming. Our findings indicate that confirmation bias in small doses may actually result in improved accuracy across individuals by preserving information diversity in a social network. However, results also indicate that when confirmation bias grows past an optimal value, accuracy declines as biased agents restrict information flow to subgroups.",
        "prediction": "Social media allows users to engage with different opinions but also spreads misinformation. This happens because people tend to choose news that fits their beliefs, either actively (confirmation bias) or passively (personalized algorithms). We lack a clear understanding of how these choices affect beliefs. We present a social learning model where most people update their beliefs based on new information, while some ignore news that doesn't match their existing views. This behavior can lead to permanent divides in opinions. Additionally, even unbiased individuals can act as if they were biased when surrounded by biased people, limiting their access to varied information. Our analysis shows how the balance between confirmation bias and social connections affects people's beliefs, which we confirmed with data on internet access and views on global warming. Our study suggests that a small amount of confirmation bias can really help maintain diverse information in a social network, but if it goes too far, it can lower overall accuracy by restricting information to certain groups.",
        "reference": "Social media give users opportunities to interact with different opinions. We discuss the meaning of our model for policy and the downsides of myth-busting We suggest alternatives to fight misinformation. But misinformation is spread via social media because individuals can search for information that confirms their beliefs and personalized news algorithms may supply it. Theoretical understanding of the balance between opportunities and misinformation is incomplete. We introduce a stylized social learning model. In this model, most participants in a network update their beliefs based on new information, while others show confirmation bias and can reject news that differs from their beliefs. This simple confirmation bias mechanism can create lasting opinion polarisation. Besides, in the model, unbiased people behave âas ifâ biased because biased neighbours limit their access to diverse information. With our model, we show the trade-off between confirmation bias and social connectivity. We validated the model using the data on how internet access influences beliefs on global warming. Small confirmation bias may even improve accuracy across individuals by keeping information diversity in a social network. But large confirmation bias lowers accuracy as biased individuals limit information flow to others."
      },
      {
        "source": "Superintelligence is a potential type of future artificial intelligence (AI) that is significantly more intelligent than humans in all major respects. If built, superintelligence could be a transformative event, with potential consequences that are massively beneficial or catastrophic. Meanwhile, the prospect of superintelligence is the subject of major ongoing debate, which includes a significant amount of misinformation. Superintelligence misinformation is potentially dangerous, ultimately leading bad decisions by the would-be developers of superintelligence and those who influence them. This paper surveys strategies to counter superintelligence misinformation. Two types of strategies are examined: strategies to prevent the spread of superintelligence misinformation and strategies to correct it after it has spread. In general, misinformation can be difficult to correct, suggesting a high value of strategies to prevent it. The strategies proposed can be applied to lay public attention to superintelligence, AI education programs, and efforts to build expert consensus.",
        "prediction": "Superintelligence is a possible future form of artificial intelligence that would surpass human intelligence in many ways. If created, superintelligence could greatly change the world and have either positive or negative effects. There is a lot of debate about superintelligence, and unfortunately, there is also a lot of misinformation. This misinformation can lead to poor decisions by those who want to develop superintelligence and by those who influence them. This paper looks at ways to fight misinformation about superintelligence. It discusses two types of approaches: ways to stop misinformation from spreading and ways to fix it after it has spread. Generally, misinformation is hard to correct, so preventing it is very important. The suggested strategies can be used to inform the public about superintelligence, improve AI education, and promote agreement among experts.",
        "reference": "Superintelligence is a potential future artificial intelligence (AI) significantly more intelligent than humans. Superintelligence could be a major event, with potential consequences that are beneficial or catastrophic. The prospect of superintelligence is the subject of major debate, which includes a lot of misinformation. Superintelligence misinformation could be dangerous, and lead to bad decisions by the people that could work on the project. This paper searches for strategies to counter superintelligence misinformation. Two strategies are examined: to prevent the spread of misinformation and to correct it after it has spread. Misinformation can be difficult to correct, so preventing it seems to be the best strategy. The strategies proposed can be used to bring public attention to superintelligence, AI education programs, and efforts to build expert consensus."
      },
      {
        "source": "The widespread online misinformation could cause public panic and serious economic damages. The misinformation containment problem aims at limiting the spread of misinformation in online social networks by launching competing campaigns. Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem for the case when an arbitrary number of cascades are allowed. First, we provide a formal model for multi-cascade diffusion and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of $\\\\Omega(2^{\\\\log^{1-\\\\epsilon}n^4})$ in polynomial time unless $NP \\\\subseteq DTIME(n^{\\\\polylog{n}})$. Third, we introduce several types of cascade priority that are frequently seen in real social networks. Finally, we design novel algorithms for solving the misinformation containment problem. The effectiveness of the proposed algorithm is supported by encouraging experimental results.",
        "prediction": "Online misinformation can lead to public panic and economic problems. To tackle this issue, we look at how to limit the spread of misinformation in social networks by starting competing campaigns. We analyze the problem when multiple information flows, called cascades, can happen at once. First, we create a formal model to describe these multi-cascade situations and introduce the idea of cascade priority, which is crucial for our analysis. Next, we demonstrate that it is very challenging to approximate the solution to the misinformation containment problem unless certain complex conditions are met. We also identify several types of cascade priorities that often appear in real social networks. Finally, we propose new algorithms to address the misinformation containment problem, and we have positive experimental results that show these algorithms work well.",
        "reference": "The online misinformation could cause public panic and serious economic damages. The goal of misinformation containment is to limit the spread of misinformation in online social networks by launching campaigns to counter misinformation. We present the first analysis of the misinformation containment problem with a random number of cascades (people observe the actions of others and then make the same choice) allowed. First, we provide a diffusion model and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of Î©(2log1âÏµn4) in polynomial time unless $NP \\subseteq DTIME(n^{\\polylog{n}})$ Third, we introduce several types of cascade priority that are frequently seen in social networks. Finally, we design algorithms for solving the misinformation containment problem. The proposed algorithm is effective and shows encouraging results."
      },
      {
        "source": "Yet contemporary work in Philosophy argues provisional belief in conspiracy theories isâat the veryâleast understandable (because conspiracies occur) and if we take an evidential approachâjudging individual conspiracy theories on their particular meritsâbelief in such theories turns out to be warranted in a range of cases. Drawing on this work, I examine the kinds of evidence typically associated with conspiracy theories, showing that the evidential problems typically associated with conspiracy theories are not unique to such theories. As such, if there is a problem with the conspiracy theoristâs use of evidence, it is one of principle: is the principle which guides their use of evidence somehow in error? I argue that whatever we might think about conspiracy theories generally, there is no prima facie case for a scepticism of conspiracy theories based purely on their use of evidence.",
        "prediction": "Recent philosophy suggests that it's understandable to hold provisional beliefs in conspiracy theories since conspiracies do happen. Evaluating each conspiracy theory based on its own evidence shows that belief in these theories is justified in many situations. I look at the types of evidence usually linked to conspiracy theories, pointing out that the issues related to their evidence are not exclusive to them. The main question is whether the principle guiding how conspiracy theorists use evidence is flawed. I argue that, regardless of our views on conspiracy theories, there isn't a solid reason to doubt them just because of how they use evidence.",
        "reference": "To believe in conspiracy theories is understandable as conspiracies occur and if we take an evidential approach, belief in such theories turns out to be warranted in a range of cases. Drawing on this work, I examine evidence associated with conspiracy theories, showing that the evidential problems are not unique to conspiracy theories. The problem with the use of evidence of conspiracy theorist could be the principle which guides their use of it. I argue that there is no ground to be suspicious of conspiracy theories as a whole, because those are based on evidence."
      },
      {
        "source": "Conspiracy theories have gained much academic and media attention recently, due to their large impact on public events. However, little is known about how conspiracy theories are produced and developed on social media. We present a qualitative study of conspiracy theorizing on Reddit during a public health crisis--the Zika virus outbreak. Using a mixed-methods approach including content analysis and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the Zika crisis, the conditions under which Zika conspiracy theories emerge, and the particular discursive strategies through which Zika conspiracy theories developed in online forums. Our analysis shows that conspiracy talk emerged as people attempted to make sense of a public health crisis, reflecting their emergent information needs and their pervasive distrust in formal sources of Zika information. Practical implications for social computing researchers, health practitioners, and policymakers are discussed.",
        "prediction": "Conspiracy theories have recently received a lot of attention from researchers and the media because they significantly influence public events. However, we know little about how these theories form on social media. This study looks at conspiracy theories on Reddit during the Zika virus outbreak. We used content and discourse analysis to identify different types of conspiracy theories related to Zika, the conditions that led to their emergence, and how they were communicated in online discussions. Our findings show that conspiracy talk arose as people tried to understand the public health crisis, highlighting their need for information and their distrust of official Zika information. We discuss the practical implications of our findings for researchers, health professionals, and policymakers.",
        "reference": "Conspiracy theories have gained much attention recently, due to their large impact on public events. Little is known about how conspiracy theories are produced and developed on social media. We present a study of conspiracy theory creation on Reddit during a public health crisis. Using content and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the crisis, the conditions of their creation, and the strategies of their development in online forums. Our analysis shows that conspiracy talk come from people trying to make sense of a public health crisis, which reflect their information needs and their lack of confidence in formal sources of information. Implications for social computing researchers, health practitioners, and policymakers are discussed."
      },
      {
        "source": "Conspiracy theories are omnipresent in online discussions---whether to explain a late-breaking event that still lacks official report or to give voice to political dissent. Conspiracy theories evolve, multiply, and interconnect, further complicating efforts to understand them and to limit their propagation. It is therefore crucial to develop scalable methods to examine the nature of conspiratorial discussions in online communities. What do users talk about when they discuss conspiracy theories online? What are the recurring elements in their discussions? What do these elements tell us about the way users think? This work answers these questions by analyzing over ten years of discussions in r/conspiracy---an online community on Reddit dedicated to conspiratorial discussions. We focus on the key elements of a conspiracy theory: the conspiratorial agents, the actions they perform, and their targets. For example, a narrative-motif such as \\\"governmental agency-controls-communications\\\" represents the various ways in which multiple conspiratorial statements denote how governmental agencies control information. Thus, narrative-motifs expose commonalities between multiple conspiracy theories even when they refer to different events or circumstances. In the process, these representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about. Our approach enables a population-scale study of conspiracy theories in alternative news and social media with implications for understanding their adoption and combating their spread.",
        "prediction": "Conspiracy theories are common in online discussions, often used to explain recent events without official reports or to express political dissent. These theories change, grow, and connect, making it harder to understand and control their spread. It is important to create effective ways to study these discussions in online communities. What do users say when they talk about conspiracy theories? What patterns appear in their conversations? What do these patterns reveal about their thinking? This study looks at over ten years of discussions in r/conspiracy, a Reddit community focused on conspiracy theories. We analyze key aspects of conspiracy theories, such as the agents involved, their actions, and their targets. For example, a theme like \"governmental agency-controls-communications\" shows how different conspiracy statements suggest that governments control information. This theme highlights similarities among various conspiracy theories, even if they refer to different events. By examining these themes, we can better understand how users discuss conspiracy theories and what their conversations mean. Our method allows us to study conspiracy theories on a large scale in alternative news and social media, helping us understand their spread and how to address it.",
        "reference": "Conspiracy theories are omnipresent in online discussions. Conspiracy theories evolve, multiply, and interconnect, complicating how to understand them and to limit their propagation. It is crucial to develop methods to examine the nature of these conspiratorial discussions. What do users talk about? What are the recurring elements in their discussions? What do these elements tell us about the way users think? This work answers these questions by analyzing over ten years of discussions in an online community on the social media Reddit dedicated to conspiratorial discussions. We focus on the key elements of a conspiracy theory: the conspiratorial agents, the actions they perform, and their targets. For example, a narrative-motif (an idea) such as \"governmental agency-controls-communications\" represents the various ways in which multiple conspiratorial statements suggest how governmental agencies control information. Narrative-motifs expose similarities between multiple conspiracy theories even when they refer to different events or circumstances. These representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about. Our approach enables a population-scale study of conspiracy theories in alternative news and social media and ways to understand them and limit their propagation."
      },
      {
        "source": "Blockchain technology is the underlying enabling technology developed for Bitcoin, the most common cryptocurrency. Blockchain technologies have become increasingly popular with the potential to become a powerful disruptive force. Individuals and organizations may benefit from blockchain with its ability to increase secure data exchange and to make that transaction simpler and easier between entities. We investigate factors that influence an individualu0027s intention to use a blockchain cryptocurrency. We develop a model of cryptocurrency adoption grounded in the theory of planned behavior (TPB) to: identify the determinants for the acceptance of cryptocurrency and explore the relative importance of each construct. We offer empirical evidence for a better theoretical understanding of cryptocurrency adoption with practical implications in an e-government context.",
        "prediction": "Blockchain technology supports Bitcoin, which is the most popular cryptocurrency. Blockchain is gaining attention for its potential to disrupt various industries. It can help people and organizations securely share data and make transactions easier. In this study, we look at what factors affect whether someone decides to use a blockchain cryptocurrency. We create a model based on the theory of planned behavior to identify what influences cryptocurrency acceptance and assess the importance of these factors. Our findings provide deeper insights into cryptocurrency adoption and its practical use in e-government.",
        "reference": "Blockchain technology is a technology developed for Bitcoin, the most common cryptocurrency. Blockchain technologies have become popular with the potential to become a powerful disruptive force. People and organizations may use it to increase secure data exchange and make transactions simpler and easier. We investigate what influence people to use a blockchain cryptocurrency. We develop a model of cryptocurrency adoption to identify how cryptocurrency is accepted. Our evidence allow a better understanding of cryptocurrency adoption."
      },
      {
        "source": "With the introduction of memory-bound cryptocurrencies, such as Monero, the implementation of mining code in browser-based JavaScript has become a worthwhile alternative to dedicated mining rigs. Based on this technology, a new form of parasitic computing, widely called cryptojacking or drive-by mining, has gained momentum in the web. A cryptojacking site abuses the computing resources of its visitors to covertly mine for cryptocurrencies. In this paper, we systematically explore this phenomenon. For this, we propose a 3-phase analysis approach, which enables us to identify mining scripts and conduct a large-scale study on the prevalence of cryptojacking in the Alexa 1 million websites. We find that cryptojacking is common, with currently 1 out of 500 sites hosting a mining script. Moreover, we perform several secondary analyses to gain insight into the cryptojacking landscape, including a measurement of code characteristics, an estimate of expected mining revenue, and an evaluation of current blacklist-based countermeasures.",
        "prediction": "Memory-bound cryptocurrencies like Monero have made it possible to mine using browser-based JavaScript instead of dedicated mining computers. This has led to a new type of web abuse called cryptojacking or drive-by mining, where a website secretly uses its visitors' computing power to mine cryptocurrencies. In this paper, we investigate this issue using a three-phase analysis method to identify mining scripts and study how common cryptojacking is among the top one million websites listed by Alexa. Our results show that cryptojacking is quite common, with about 1 in 500 sites running a mining script. We also conduct additional analyses to understand the characteristics of the mining code, estimate potential earnings from mining, and evaluate current methods to block these activities.",
        "reference": "Memory-bound cryptocurrencies like Monero can be mined  from a browser with JavaScript, better than with a dedicated rig. However, this technology enables cryptojacking, whereby a site covertly mines for cryptocurrencies on its visitorsâ computers. We propose a new approach to identify mining scripts. The approach was evaluated on Alexa 1 websites. Cryptojacking is common, as 1 in 500 sites host a mining script. We also measured code characteristics, estimated mining revenue, and evaluated blacklist-based countermeasures."
      },
      {
        "source": "The rise of modern blockchains has facilitated the emergence of smart contracts: autonomous programs that live and run on the blockchain. Smart contracts have seen a rapid climb to prominence, with applications predicted in law, business, commerce, and governance.  contracts :[39],\"are commonly written in a high-level language such as Ethereumu0027s Solidity, and translated to compact low-level bytecode for deployment on the blockchain. Once deployed, the bytecode is autonomously executed, usually by a %Turing-complete virtual machine. As with all programs, smart contracts can be highly vulnerable to malicious attacks due to deficient programming methodologies, languages, and toolchains, including buggy compilers. At the same time, smart contracts :[39],\"are also high-value targets, often commanding large amounts of cryptocurrency. Hence, developers and auditors need security frameworks capable of analysing low-level bytecode to detect potential security vulnerabilities. In this paper, we present Vandal: a security analysis framework for Ethereum smart contracts. Vandal consists of an analysis pipeline that converts low-level Ethereum Virtual Machine (EVM) bytecode to semantic logic relations. Users of the framework can express security analyses in a declarative fashion: a security analysis is expressed in a logic specification written in the \\souffle language.",
        "prediction": "Modern blockchains have led to the creation of smart contracts, which are self-running programs on the blockchain. Smart contracts are becoming increasingly important, with potential uses in law, business, commerce, and governance. They are typically written in a high-level language like Solidity and converted into a compact form (bytecode) for use on the blockchain. Once deployed, this bytecode runs on a virtual machine. However, smart contracts can be vulnerable to attacks due to poor coding practices and can attract a lot of cryptocurrency, making them valuable targets. Developers and auditors need tools to analyze this bytecode for security issues. In this paper, we introduce Vandal, a security analysis framework for Ethereum smart contracts. Vandal has a process that changes Ethereum bytecode into logical relations. Users can perform security analyses using a logical specification written in the SoufflÃ© language.",
        "reference": "Smart contracts have appeared thanks to blockchain technology. These autonomous programs are used in law, business, commerce, and governance. Smart contracts are written in a high-level language such as Ethereumâs Solidity and translated to bytecode. that live and run on the blockchain are predicted in Once deployed on the blockchain, the bytecode is autonomous. Smart contracts are vulnerable to malicious attacks due to poor programming, languages and toolchains Smart contracts can command large amounts of cryptocurrency. Developers and auditors need frameworks to detect security vulnerabilities. Vandal is a security analysis framework for Ethereum smart contracts. Vandal converts Ethereum Virtual Machine bytecode to semantic logic relations. Users can express security analyses in the SoufflÃ© language."
      },
      {
        "source": "Vandal is both fast and robust, successfully analysing over 95\\% of all 141k unique contracts with an average runtime of 4.15 seconds; outperforming the current state of the art tools---Oyente, EthIR, Mythril, and Rattle---under equivalent conditions.",
        "prediction": "Vandal is a fast and reliable tool that can analyze more than 95% of 141,000 unique contracts, taking an average of 4.15 seconds per analysis. It performs better than other leading tools like Oyente, EthIR, Mythril, and Rattle under similar conditions.",
        "reference": "Vandal is both efficient (95% accuracy), fast (141k in 4.15 s) and robust. It outperforms the state of the art tools like Oyente, EthIR, Mythril, and Rattle"
      },
      {
        "source": "As Bitcoinu0027s popularity has grown over the decade since its creation, it has become an increasingly attractive target for adversaries of all kinds.",
        "prediction": "As Bitcoin has become more popular over the years, it has attracted the attention of various opponents.",
        "reference": "One of the most powerful potential adversaries is the country of China, which has expressed adversarial positions regarding the cryptocurrency and demonstrated powerful capabilities to influence it."
      },
      {
        "source": "For decentralised P2P networks, it is very important to have a mechanism in place that allows the nodes to control resource usage and prevent flooding and denial-of-service attacks with spam. In this paper, we discuss and compare the different approaches to fully decentralised resource control that are used by projects in the cryptocurrency space. The introduced methods are then applied to design a decentralised exchange for Namecoin names (or more generally, crypto assets) as an example.",
        "prediction": "In decentralized peer-to-peer networks, it's crucial to have a way for the nodes to manage resource use and stop problems like flooding and spam attacks. This paper talks about and compares various methods for fully decentralized resource control used by different cryptocurrency projects. These methods are then applied to create a decentralized exchange for Namecoin names or other crypto assets as an example.",
        "reference": "In decentralised P2P networks nodes need a way  to control resource usage and prevent flooding and denial-of-service attacks. We compared different approaches to decentralised resource control in cryptocurrency projects. We designed a decentralised exchange for crypto assets, for  example Namecoin names, with these methods."
      },
      {
        "source": "Cryptocurrency is a rapid developing financial technology innovation which has attracted a large number of people around the world. The high-speed evolution, radical price fluctuations of cryptocurrency, and the inconsistent attitudes of monetary authorities in different countries have triggered panic and chain reactions towards the application and adoption of cryptocurrency and have caused public security related events. In this paper, we analyze the dynamics and systemic risk of the cryptocurrency market based on the public available price history. Furthermore, consistent with public perception, our quantitative analysis reveals that the cryptocurrency market is relatively fragile and unstable.",
        "prediction": "Cryptocurrency is a fast-growing financial technology that has gained a lot of attention worldwide. Its rapid changes, sudden price swings, and varying responses from governments have led to public concern and security issues. This paper looks at the trends and risks in the cryptocurrency market using available price data. Our analysis shows that the cryptocurrency market is quite weak and unstable, matching what many people feel about it.",
        "reference": "Cryptocurrency is a financial technology innovation which has attracted many people around the world. The high-speed evolution, radical price fluctuations of cryptocurrency, and the inconsistent attitudes of monetary authorities in different countries have caused panic. In this paper, we analyze the dynamics and risks of the cryptocurrency market. Consistent with public perception, our analysis reveals that the cryptocurrency market is fragile and unstable."
      },
      {
        "source": "Cryptocurrency was built initially as a possible implementation of digital currency, then various derivatives were created in a variety of fields such as financial transactions, capital management, and even nonmonetary applications. This paper aims to offer analytical insights to help understand cryptocurrency by treating it as a financial asset. We position cryptocurrency by comparing its dynamic characteristics with two traditional and massively adopted financial assets: foreign exchange and stock. Our investigation suggests that the dynamics of cryptocurrency are more similar to stock. As to the robustness and clustering structure, our analysis shows cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market.",
        "prediction": "Cryptocurrency started as a digital currency but has since expanded into various uses, including finance and capital management. This paper looks at cryptocurrency as a financial asset, comparing it to foreign exchange and stocks. Our findings indicate that cryptocurrency behaves more like stocks. However, the cryptocurrency market is less stable and more fragile than the stock market, making it a high-risk investment.",
        "reference": "Cryptocurrency was initially an implementation of digital currency, then derivatives were created in various fields. This paper aims to help understand cryptocurrency. We compared cryptocurrency with foreign exchange and stock. Our investigation suggests that cryptocurrency is similar to stock. Our analysis shows that cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market."
      },
      {
        "source": "The smart device owning rate such as smart phone and smart watch is higher than ever before and mobile payment has become one of the major payment methods in many different areas. At the same time, blockchain-based cryptocurrency is becoming a nonnegligible type of currency and the total value of all types of cryptocurrency has reached USD 200 billion. Therefore, it is a natural demand to support cryptocurrency payment on mobile devices. Considering the poor infrastructure and low penetration of financial service in developing countries, this combination is especially attractive. The high storage cost and payment processing latency are the two main obstacles for mobile payment using cryptocurrency. We propose two different schemes for cryptocurrency mobile payment, one involves a centralized bank and the other one does not require any centralized party. We also provide a solution for the bank to meet KYC (know your customer)/AML (antimoney laundering) compliance requirements when it is involved in cryptocurrency mobile payment processing.",
        "prediction": "More people own smart devices like smartphones and smartwatches than ever before, and mobile payments have become a major way to pay for things. At the same time, cryptocurrencies based on blockchain technology are becoming increasingly important, with a total value of around 200 billion USD. This creates a need for mobile devices to support payments using cryptocurrencies. This is especially appealing in developing countries where financial services are limited. However, there are two main challenges: high costs for storing cryptocurrency and delays in processing payments. We suggest two approaches for mobile cryptocurrency payments: one that uses a central bank and another that operates without a central authority. We also offer a method for banks to adhere to KYC (know your customer) and AML (anti-money laundering) regulations when processing these types of payments.",
        "reference": "The owning rate of smart devices is higher than ever before and mobile payment has become a major payment method. Cryptocurrency is becoming an important type of currency and the total value of cryptocurrencies has reached USD 200 billion. Therefore, support of cryptocurrency payment on mobile devices is a natural demand. Considering the poor infrastructure and the low usage of financial service in developing countries, this combination is especially attractive. The high storage cost and payment processing latency are two obstacles for cryptocurrency mobile payment. We propose two solutions, one with a centralized bank and the other one without any centralized party. We also provide a solution for the bank to meet KYC (know your customer)/AML (antimoney laundering) expectations about cryptocurrency mobile payment."
      },
      {
        "source": "Motivated by recent financial crises significant research efforts have been put into studying contagion effects and herding behaviour in financial markets. Much less has been said about influence of financial news on financial markets. We propose a novel measure of collective behaviour in financial news on the Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic risk indicator. We evaluate the NCI on financial documents from large Web news sources on a daily basis from October 2011 to July 2013 and analyse the interplay between financial markets and financially related news. We hypothesized that strong cohesion in financial news reflects movements in the financial markets. Cohesiveness is more general and robust measure of systemic risk expressed in news, than measures based on simple occurrences of specific terms. Our results indicate that cohesiveness in the financial news is highly correlated with and driven by volatility on the financial markets.",
        "prediction": "Recent financial crises have led to more research on how contagion effects and herding behavior affect financial markets. However, there has been less focus on how financial news influences these markets. We present a new way to measure collective behavior in financial news online called the News Cohesiveness Index (NCI) and suggest it can serve as an indicator of systemic risk. We assess the NCI using financial articles from major news sources daily between October 2011 and July 2013, examining the relationship between financial markets and related news. We believe that strong cohesiveness in financial news is linked to changes in financial markets. This cohesiveness is a more reliable measure of systemic risk in news compared to just counting specific terms. Our findings show that the cohesiveness of financial news closely relates to and is influenced by market volatility.",
        "reference": "Motivated by recent financial crises, research efforts have been put into studying contagion effects (spread of market disturbances) and herding behaviour (individuals acting collectively without centralized direction) in financial markets. Much less has been said about influence of financial news on financial markets. We propose a measure of collective behaviour in financial news on the Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic risk indicator, which signals probability of financial system crises. We evaluate the NCI on financial documents from Web news sources and analyse the relation between financial markets and financial news. We hypothesized that strong cohesion in financial news reflects variations in the financial markets. Cohesiveness is a better measure of systemic risk expressed in news, than measures based on simple occurrences of specific terms. Our results show that cohesiveness in the financial news is highly correlated with variations in the financial markets."
      },
      {
        "source": "In this paper, I propose a methodology to study the comovement between the entropy of different financial markets. The entropy is derived using singular value decomposition of the components of stock market indices in financial markets from selected developed economies, i.e., France, Germany, the United Kingdom, and the United States. I study how a shock in the entropy in the United States affects the entropy in the other financial markets. I also model the entropy using a dynamic factor model and derive a common factor behind the entropy movements in these four markets.",
        "prediction": "In this paper, I present a method to examine how the entropy, or unpredictability, of different financial markets moves together. I calculate entropy using a technique called singular value decomposition based on stock market indices from developed countries like France, Germany, the UK, and the US. I explore how a change in entropy in the US influences entropy in the other markets. I also develop a model using a dynamic factor model to identify a common factor that explains the changes in entropy across these four markets.",
        "reference": "In this paper, I propose a methodology to study the comovement (correlation on profits on investment) between the entropy (randomness and uncertainty) of different financial markets. The entropy is based on the components measuring the stock market in financial markets from selected developed economies (France, Germany, the United Kingdom, and the United States). I study how a shock in the entropy in the United States affects the entropy in the other financial markets. I also model the entropy using different time variables and obtain a common factor behind the entropy movements in these four markets."
      },
      {
        "source": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones, and fraudsters have evolved with them. Smartphones are packed with functionality that can easily be used for data theft or inappropriate contact with other parties - none of which passes through company-owned systems, and is to all intents and purposes 'off the grid'. Employers need to be aware of these risks when devices are issued, along with ensuring that processes are in place when suspicions are raised, explains Philip Ridley of CCL-Forensics. Detecting 'tech-savvy' corporate fraudsters is a constant game of catch-up. It's not only about playing catch-up with the intellect, motives and awareness of the e-fraudster, but also the technologies that can be misused. What's more, the methods through which the technology can be manipulated to secrete, disguise and protect fraudulent activities - all while staying away from corporate networks where they can readily be monitored and detected - are constantly evolving. This means a company's intellectual property and sensitive data is at risk of sabotage or just good old-fashioned theft.",
        "prediction": "Using mobile phone forensics to investigate fraud is not new. However, as mobile phones have become smartphones, fraudsters have adapted as well. Smartphones have many features that can easily be used for stealing data or contacting others inappropriately, often without passing through company systems. Employers must understand these risks when providing devices and have procedures in place for when suspicions arise, according to Philip Ridley from CCL-Forensics. Finding tech-savvy fraudsters is an ongoing challenge. It involves not only keeping up with the skills and motivations of e-fraudsters but also the technologies they can misuse. Additionally, the ways in which technology can be used to hide or protect fraudulent activities, while avoiding detection by corporate networks, are continuously changing. This puts a company's sensitive data and intellectual property at risk of theft or sabotage.",
        "reference": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones, and fraudsters have evolved with them. Smartphones have functionalities that can be used for data theft or inappropriate contact with other parties. They are out of the systems of the company and are not monitored or controlled. Employers need to be aware of these risks when devices are delivered and have processes when suspicions are raised. Detecting fraudsters with computer skills is a constant game of catch-up. It's not only about playing catch-up with the cyberfraudster, but also the technologies that can be misused. Moreover, the methods assisting fraudulent activities (still out of reach of company systems) are constantly evolving. This means a company's intellectual property and sensitive data is at risk of sabotage or theft."
      },
      {
        "source": "Phishers continue to alter the source code of the web pages used in their attacks to mimic changes to legitimate websites of spoofed organizations and to avoid detection by phishing countermeasures. Manipulations can be as subtle as source code changes or as apparent as adding or removing significant content. To appropriately respond to these changes to phishing campaigns, a cadre of file matching algorithms is implemented to detect phishing websites based on their content, employing a custom data set consisting of 17,992 phishing attacks targeting 159 different brands. The results of the experiments using a variety of different content-based approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate.",
        "prediction": "Phishers keep changing the code of their fake web pages to look like real websites and to avoid being caught by anti-phishing tools. These changes can be small code tweaks or bigger changes like adding or removing important information. To counter these phishing tactics, a range of file matching algorithms is used to spot phishing websites based on their content, using a specific data set of 17,992 phishing attacks aimed at 159 brands. The tests with various content-based methods show that some can detect over 90% of phishing sites while keeping false positives low.",
        "reference": "Phishers, people who attempt to trick people over the internet to steal their money, continue to modify the web pages used in their attacks to imitate websites of spoofed organizations and to avoid detection by phishing countermeasures. Manipulations can be as subtle as changing the source code, which is the programming instructions, or as apparent as adding or removing significant content. To respond to these changes to phishing campaigns, algorithms are used to detect phishing websites based on their content, employing a data set consisting of 17,992 phishing attacks targeting 159 different brands. The results of the experiments using different approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate."
      },
      {
        "source": "Mobile devices are very common in everyoneâs day-to- day life. Nowadays such devices come with many features of desktop or laptop. Hence people can use these devices for diverse applications. As the acceptability and usability of such devices are very high, there are chances that these devices can be used for illegal activities. The percentage of mobile phones or smart phones involved in cyber crimes is in hike. So it becomes necessary to digitally analyze such devices requiring cyber forensics tools. This paper discusses different types of digital evidence present in Microsoftâs Windows Mobile smart phones and an agent based approach for logically acquiring such devices. Also it describes a tool developed for forensically acquiring and analyzing Windows Mobile devices and WinCE PDAs.",
        "prediction": "Mobile devices are very common in our daily lives. Today, these devices have many features similar to desktop or laptop computers. This allows people to use them for various applications. As a result, the popularity and ease of use of these devices have increased, leading to a rise in their misuse for illegal activities. The number of mobile phones or smartphones involved in cyber crimes is growing. Therefore, it is important to analyze these devices using cyber forensics tools. This paper talks about the different types of digital evidence found in Microsoftâs Windows Mobile smartphones and discusses an agent-based approach to logically acquire such devices. It also describes a tool created for forensically acquiring and analyzing Windows Mobile devices and WinCE PDAs.",
        "reference": "Mobile devices are very common in everyoneâs day-to-day life. Nowadays such devices come with many features of computers. People can use these devices for diverse applications. There are chances that these devices can be used for illegal activities. The percentage of mobile phones or smart phones involved in cyber crimes is increasing. So it becomes necessary to digitally analyze such devices with cyber forensics tools. This paper discusses different types of digital evidence present in Microsoftâs Windows Mobile smart phones and how to acquire such devices. Also it describes a forensic tool for acquiring and analyzing Windows Mobile devices and personal digital assistants."
      },
      {
        "source": "Detection of different types of image editing operations carried out on an image is an important problem in image forensics. It gives the information about the processing history of an image, and also can expose forgeries present in an image. There have been a few methods proposed to detect different types of image editing operations in a single framework. However, all the operations have to be known a priori in the training phase. But, in real-forensics scenarios it may not be possible to know about the editing operations carried out on an image. To solve this problem, we propose a novel deep learning-based method which can differentiate between different types of image editing operations. The proposed method classifies image patches in a pair-wise fashion as either similarly or differently processed using a deep siamese neural network. Once the network learns feature that can discriminate between different image editing operations, it can differentiate between different image editing operations not present in the training stage. The experimental results show the efficacy of the proposed method in detecting/discriminating different image editing operations.",
        "prediction": "Detecting different types of image edits is important in image forensics. It helps reveal the history of how an image was processed and can identify any forgeries. Some methods have been created to detect different editing types in one system, but these methods require knowing all possible edits beforehand. In real-life situations, we often don't know what edits were made. To address this, we propose a new deep learning method that can distinguish between various image editing types. Our method uses a special type of neural network that compares image sections to see if they were edited similarly or differently. Once the network learns to identify features that separate the editing types, it can also recognize edits not seen during training. Our tests show that this method is effective at detecting different image editing operations.",
        "reference": "Detection of image editing is an important task in image forensics. The edit history of an image can expose forgeries in the image. Various methods have been proposed to detect image editing operations. However all of the possible types of image manipulation must be known in advance. But, in the real world, manipulations on images are sometimes unknowable. A novel deep learning-based method can distinguish between different types of image editing operations. This method uses a deep siamese neural network to compare images two by two. Using deep learning, the computer can learn to see features of edited images as compared to unedited and learn to differentiate between different image editing operations. This method works to find out what editing an image has undergone."
      },
      {
        "source": "The increasing prevalence of Internet of Things (IoT) devices has made it inevitable that their pertinence to digital forensic investigations will increase into the foreseeable future. These devices produced by various vendors often posses limited standard interfaces for communication, such as USB ports or WiFi/Bluetooth wireless interfaces. Meanwhile, with an increasing mainstream focus on the security and privacy of user data, built-in encryption is becoming commonplace in consumer-level computing devices, and IoT devices are no exception. Under these circumstances, a significant challenge is presented to digital forensic investigations where data from IoT devices needs to be analysed. This work explores the electromagnetic (EM) side-channel analysis literature for the purpose of assisting digital forensic investigations on IoT devices. EM side-channel analysis is a technique where unintentional electromagnetic emissions are used for eavesdropping on the operations and data handling of computing devices. The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require, and must result in, no modification to the target device. The literature on various EM side-channel analysis attack techniques are discussed â selected on the basis of their applicability in IoT device investigation scenarios. The insight gained from the background study is used to identify promising future applications of the technique for digital forensic analysis on IoT devices â potentially progressing a wide variety of currently hindered digital investigations.",
        "prediction": "The rise of Internet of Things (IoT) devices means they will increasingly matter in digital forensic investigations. These devices, made by different companies, usually have limited ways to connect, like USB ports or WiFi/Bluetooth. As focus grows on the security and privacy of user data, encryption is now common in consumer devices, including IoT. This creates challenges for digital forensics when analyzing data from these devices. This study looks at electromagnetic (EM) side-channel analysis to help in investigating IoT devices. EM side-channel analysis is a method that uses unwanted electromagnetic signals to spy on how devices operate and manage data. Because this method does not alter the target device, it is a suitable option for digital forensic investigations. The study reviews various EM side-channel techniques that could be useful for investigating IoT devices. The findings suggest promising future uses of this method in digital forensics, which could help improve many ongoing investigations.",
        "reference": "Internet of Things (IoT) devices (devices connected to the internet, collecting and sharing data) will be used in digital forensic investigations in the future. These devices have limited interfaces for communication, such as USB ports or WiFi/Bluetooth wireless interfaces. Meanwhile, with an increasing focus on the security and privacy of user data, built-in encryption (which encode information) is becoming commonplace in devices. This presents a significant challenge to digital forensic investigations, where data from IoT devices needs to be analysed. This work explores the electromagnetic (EM) side-channel analysis literature for the purpose of assisting digital forensic investigations on IoT devices. EM side-channel analysis is a technique where electromagnetic emissions are used for eavesdropping on the operations and data handling of devices. The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require no modification to the target device. The literature on various EM side-channel analysis attack techniques are discussed â selected according to their applicability in IoT device investigations. The data obtained from our survey are used to identify promising future applications of the technique for digital forensic analysis on IoT devices."
      },
      {
        "source": "The malicious alteration of machine time is a big challenge in computer forensics. Performance figures show the feasibility of our proposal. Detecting such changes and reconstructing the actual timeline of events is of paramount importance. However, this can be difficult since the attacker has many opportunities and means to hide such changes. In particular, cloud computing, host and guest machine time can be manipulated in various ways by an attacker. Guest virtual machines are especially vulnerable to attacks coming from their (more privileged) host. As such, it is important to guarantee the timeline integrity of both hosts and guests in a cloud, or at least to ensure that the alteration of such timeline does not go undetected. In this paper we survey the issues related to host and guest machine time integrity in the cloud. Further, we describe a novel architecture for host and guest time alteration detection and correction/resilience with respect to compromised hosts and guests. The proposed framework has been implemented on an especially built simulator.",
        "prediction": "The manipulation of machine time is a significant problem in computer forensics. Our research shows that our solution is feasible. Detecting these changes and reconstructing the true order of events is very important. However, attackers can easily hide their changes. In cloud computing, both host and guest machine times can be tampered with in different ways. Guest virtual machines are particularly at risk from attacks by their more powerful host. Therefore, it is crucial to maintain the timeline integrity of both hosts and guests in the cloud or at least to ensure that any timeline changes are detected. In this paper, we examine the issues surrounding the integrity of host and guest machine times in the cloud. We also present a new system for detecting and correcting time alterations in both hosts and guests that may be compromised. We have implemented this proposed framework on a specially designed simulator.",
        "reference": "Machine timestamp falsification can be used in cyber attacks. The algorithm detects manipulations effectively. That is why it is important to detect such changes and to reconstruct the actual timeline of events. However, the hacker can try to hide their tracks. In cloud computing, hackers can manipulate host and guest machine time. Guest virtual machines use computing resources provided by a physical machine called a host. Guest virtual machines are especially vulnerable to attacks coming from their host. That is why the timeline integrity of both hosts and guests in a cloud is important. Any manipulation of such a timeline should be detected. In this paper we survey the issues related to host and guest machine time integrity in the cloud. A new algorithm is proposed to detect host and guest time manipulations and to correct or reject them. A simulator has been built for this purpose."
      },
      {
        "source": "Image tampering, being readily facilitated and proliferated by todayâs digital techniques, is increasingly causing problems regarding the authenticity of images. As the most popular multimedia data, JPEG images can be easily tampered without leaving any clues; therefore, JPEG-based forensics , including the detection of double compression, interpolation, rotation, etc., has become an active research topic in multimedia forensics. Nevertheless, the interesting issue of detecting image tampering and its related operations by using the same quantization matrix has not been fully investigated. Aiming to detect such forgery manipulations under the same quantization matrix, we propose a detection method by using shift-recompression -based reshuffle characteristic features. The learning classifiers are applied for classification. Our experimental results indicate that the approach is indeed highly effective in detecting image tampering and relevant manipulations with the same quantization matrix.",
        "prediction": "Image tampering has become easier with todayâs digital tools, leading to concerns about the authenticity of images. JPEG images, being the most common type, can be altered without leaving traces. This has made detecting changes in JPEGs, like double compression or rotation, a key area of research in multimedia forensics. However, there has not been enough focus on finding tampering that uses the same quantization matrix. To address this, we suggest a method that uses shift-recompression to identify these changes. We also use learning classifiers for classification. Our experiments show that this method is very effective at detecting image tampering and related changes that use the same quantization matrix.",
        "reference": "Image tampering has become a serious problem with the advancement of digital techniques. JPEG images can be easily manipulated without leaving any clues. This is why researchers are trying to develop methods for JPEG image manipulation detection. However, methods based on image compression techniques, like quantization, are rarely applied. To detect such manipulations, we propose a detection method to identify inconsistencies in the quantization matrix caused by the manipulation. Then machine learning algorithms are applied to detect image manipulation. Experimental results show that the approach is highly effective in detecting image tampering."
      },
      {
        "source": "In this paper, we present a novel approach to accurately calibrate the kinematic model of a humanoid based on observations of its monocular camera. Our technique estimates the parameters of the complete model, consisting of the joint angle offsets of the whole body including the legs, as well as the camera extrinsic and intrinsic parameters. Furthermore, we developed an approach to automatically select a subset of configurations for the calibration process that yields a good trade-off between the number of observations and accuracy. Further, our approach to configuration selection yields substantially better optimization results compared to randomly chosen viable configurations. Hence, our system only requires a reduced number of configurations to achieve accurate results. Our optimization is general and the implementation, which is available online, can easily be applied to different humanoids.",
        "prediction": "In this paper, we introduce a new way to accurately adjust the movement model of a humanoid robot using data from its single camera. Our method estimates various model parameters, including joint angles for the whole body and camera settings. We also created a way to automatically choose specific configurations for the calibration that balances the number of observations and accuracy. This method provides much better results than selecting configurations at random. As a result, our system needs fewer configurations to produce accurate results. Our optimization method is general, and the available online implementation can be easily used for different humanoid robots.",
        "reference": "In this paper, we present a novel approach to accurately calibrate a humanoid and its motions (robot with human form or characteristics) based on observations of its camera. Our technique estimates the parameters of the complete model, consisting of the joint angle offsets and the camera parameters. We developed an approach to automatically select configurations for the calibration process that produces a good compromise between the number of observations and accuracy. Our approach to configuration selection generates better optimization results compared to randomly chosen viable configurations. Thus, our system only requires a reduced number of configurations to achieve accurate results. Our optimization is general and the implementation, which is available online, can easily be applied to different humanoids."
      },
      {
        "source": "In this paper, we present an integrated navigation system that allows humanoid robots to autonomously navigate in unknown, cluttered environments. From the data of an onboard consumer-grade depth camera, our system estimates the robot's pose to compensate for drift of odometry and maintains a heightmap representation of the environment. Based on this model, our system iteratively computes sequences of safe actions including footsteps and whole-body motions, leading the robot to target locations. To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles. As we demonstrate in experiments with a Nao humanoid, our system leads to robust navigation in cluttered environments and the robot is able to traverse highly challenging passages.",
        "prediction": "This paper introduces a navigation system that helps humanoid robots move around by themselves in messy and unfamiliar spaces. The system uses data from a regular depth camera to figure out where the robot is and keeps a heightmap of the area. With this information, it calculates safe movements for the robot, like where to step and how to move its body, to reach specific goals. To avoid collisions during navigation, we created a new method that considers both the robot's shape and the obstacles around it. Our tests with a Nao humanoid robot show that this system works well in cluttered spaces, allowing the robot to handle difficult areas.",
        "reference": "In this paper, we present a navigation system that allows humanoid robots (robots with human form or characteristics) to autonomously navigate in unknown, cluttered environments. From the data of a camera which can judge depth and distance, our system estimates the robotâs position and maintains a height representation of the environment. Our system determines safe actions (including footsteps and body motions) leading the robot to target locations. To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles. As we demonstrate in experiments, our system allows the robot to navigate in clustered environments and traverse challenging passages."
      },
      {
        "source": "In this paper, we introduce an approach to efficient robot navigation through cluttered indoor environments. We propose to estimate local obstacle densities based on already detected objects and use them to predict traversal costs corresponding to potential obstacles in regions not yet observable by the robot's sensors. By taking into account the predicted costs for path planning, the robot is then able to navigate in a more foresighted manner and reduces the risk of getting stuck in cluttered regions. As the experimental results demonstrate, our method enables the robot to efficiently navigate through environments containing cluttered regions and achieves significantly shorter completion times compared to a standard approach not using any prediction.",
        "prediction": "This paper presents a method for robots to navigate effectively in messy indoor spaces. We suggest estimating how many obstacles are nearby based on objects the robot has already detected. This information helps predict the difficulty of moving through areas that the robot's sensors cannot yet see. By using these predictions for planning routes, the robot can navigate more carefully and is less likely to get stuck. The experiments show that our method allows the robot to move efficiently in cluttered areas and complete tasks much faster than traditional methods that do not use predictions.",
        "reference": "In this paper, we introduce an approach for robot to navigate through cluttered indoor environments. We propose to estimate obstacles based on already detected objects and use them to predict potential obstacles in regions not yet observable by the robot. The robot is then able to navigate in a more anticipated manner and reduces the risk of getting stuck. Our method enables the robot to efficiently navigate through cluttered environments and faster than a standard approach not using any prediction."
      },
      {
        "source": "In many situations, users walk on typical paths between specific destinations at which the service of a mobile robot is needed. Depending on the environment and the paths, step-by-step following of the human might not be the optimal solution since better paths for the robot exist. We propose to perform a prediction about the human's future movements and use this information in a reinforcement learning framework to generate foresighted navigation actions for the robot. Since frequent occlusions of the human will occur due to obstacles and the robot's constrained field of view, the estimate about the humans's position and the prediction of the next destination are affected by uncertainty. Our approach deals with such situations by explicitly considering occlusions in the reward function such that the robot automatically considers to execute actions to get the human in its field of view. We show in simulated and real-world experiments that our technique leads to significantly shorter paths compared to an approach in which the robot always tries to closely follow the user and, additionally, can handle occlusions.",
        "prediction": "Users often walk along specific paths to reach certain places where a mobile robot is needed. However, simply following a person might not be the best option because there may be better routes for the robot. We suggest predicting where a person will go next and using that information in a system that improves the robot's navigation. Since obstacles can block the robot's view of the person, it can be uncertain about the person's location and next destination. Our method addresses this by adjusting the reward system to encourage the robot to take actions that keep the person in sight. Our tests in both simulations and real-world scenarios show that this approach results in much shorter routes for the robot compared to just following the user closely, while also managing view obstructions effectively.",
        "reference": "In many situations, users walk on typical paths between specific destinations at which the service of a mobile robot is needed. Depending on the environment and the paths, following the human might not be the optimal solution because better paths for the robot exist. We propose to predict the humanâs future movements and use this information to generate navigation actions for the robot. The estimation of the humanâs position and the prediction of the next destination are uncertain because of the occlusions due to obstacles and the robotâs limited field of view. Our approach deals with considering occlusions so the robot automatically considers to execute actions to get the human in its field of view. We show that our technique leads to significantly shorter paths compared to an approach in which the robot follows the user and, additionally, can handle occlusions."
      },
      {
        "source": "An autonomous service robot often first has to search for a user to carry out a desired task. This is a challenging problem, especially when this person moves around since the robotâs field of view is constrained and the environment structure typically poses further visibility constraints that influence the perception of the user. In this paper, we propose a novel method that computes the likelihood of the userâs observability at each possible location in the environment based on Monte Carlo simulations. As the robot needs time to reach the possible search locations, we take this time as well as the visibility constraints into account when computing effective search locations. In this way, the robot can choose the next search location that has the maximum expected observability of the user. Our experiments in various simulated environments demonstrate that our approach leads to a significantly shorter search time compared to a greedy approach with background information.",
        "prediction": "An autonomous service robot often has to find a user to perform a task. This can be difficult, especially when the person is moving, because the robot can't see everything and the layout of the environment limits visibility. In this paper, we introduce a new method that calculates how likely it is to see the user from different locations using Monte Carlo simulations. Since the robot takes time to get to these locations, we consider that time and visibility limits when deciding where to search next. This way, the robot can select the location with the best chance of seeing the user. Our tests in various simulated settings show that this method reduces search time significantly compared to a simple approach that uses background information.",
        "reference": "An autonomous service robot often first has to search for a user to execute a task. This is a challenging problem, especially when this person moves around because the robotâs field of view is limited. The environment also poses visibility limitations that influence the perception of the user. In this paper, we propose a method that estimate the userâs observability in the environment. When estimating effective search locations, we take into account the time for the robot to reach the search location and the visibility limitations. In this way, the robot can choose the next search location that has the maximum expected observability of the user. Our experiments demonstrate that our approach leads to a significantly shorter search time compared to other approach."
      },
      {
        "source": "Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments. Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions. For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information. Considering dynamic obstacles introduces another level of complexity, since they can lead to necessary replanning or collisions at later stages. In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be efficiently planned in real time at low CPU cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.",
        "prediction": "Mobile robots need to understand their surroundings to move safely in changing environments. Most robots, like humanoids and smaller wheeled ones, use flat areas for navigation. However, humanoids require more than just a 2D map because they can step over and onto objects, meaning they need information about height as well. Dealing with moving obstacles adds more complexity since it may require changing plans to avoid collisions later. In this paper, we introduce a system that first identifies flat areas in height maps and detects moving obstacles. Our system then creates prediction maps to help plan paths quickly and efficiently in real time. We demonstrate through simulations and real-world tests that our system can process information in under 10 milliseconds for each cycle, enabling advanced real-time 3D footstep planning.",
        "reference": "Perception of the environment is necessary for mobile robots to navigate safely in dynamic environments. Most robots (humanoids and wheeled robots) rely on planar regions. For humanoids (robots with human form or characteristics), a 2D map is not sufficient because they can step over and onto objects, so they need height information. Dynamic obstacles bring another level of complexity, because it can lead to necessary replanning or collisions. In this paper, we present a framework that extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be planned in real time at low processor cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms and allows for real-time 3D footstep planning."
      },
      {
        "source": "In this paper, a lab automation drone notional concept is introduced. Here, a robotic limb is attached to a robotic rotorcraft. The limb's gripper allows the unmanned aerial vehicle to dexterously manipulate objects such as micro-arrays and test tubes often used in high throughput systems (HTS). The resulting drone could augment existing HTS operations. The 6 degree-of-freedom (DOF) arm and gripper design are presented. Test-and-evaluation approach and results are also given.",
        "prediction": "This paper introduces a concept for a lab automation drone. The drone has a robotic arm attached to a flying device. The arm's gripper lets the drone handle small objects like micro-arrays and test tubes used in high throughput systems. This drone could improve current high throughput operations. The design of the arm and gripper is explained, along with the testing methods and results.",
        "reference": "In this paper, a concept of lab automation drone is introduced. Here, a robotic arm is attached to a drone. The armâs gripper allows the drone to manipulate objects such as chips and test tubes often used in scientific experimentations like high throughput systems. The drone could augment existing high throughput systems operations. The 6 degree-of-freedom arm and gripper design are presented. Results of evaluations and tests are also given."
      },
      {
        "source": "Robot companionship has become more popular in past years. However, humanoid gait might be somewhat unstable for these applications. Even with miniature humanoids, falls occur frequently. Thus, wheel attachments have been added onto a miniature humanoid, so it can move faster and with more stability than walking. In addition, with such attachments a robot can switch from walking to rolling when necessary. DARwIn-OP is a humanoid robot that has been used as an experimentation and performance evaluation platform. This paper discusses preliminary work regarding robot companionship applications by using a miniature humanoid capable of fetching different toys based on voice command.",
        "prediction": "Robot companionship has gained popularity recently. However, humanoid robots can be unstable when walking, leading to frequent falls even with small models. To help with this, wheels have been added to a miniature humanoid robot, allowing it to move faster and more steadily. This robot can also switch between walking and rolling as needed. DARwIn-OP is one such humanoid robot used for testing and performance evaluation. This paper looks at early work on robot companionship using a small humanoid that can fetch toys based on voice commands.",
        "reference": "Robot companionship has become more popular in past years. However, humanoid (robots with human form or characteristics) walking might be unstable. Even with miniature humanoids, falls occur frequently. Wheels have been added onto a miniature humanoid, so it can move faster and with more stability than walking. With wheels, a robot can switch from walking to rolling when necessary. DARwIn-OP is a humanoid robot that has been used for experimentation and evaluation. This paper discusses preliminary work for robot companionship applications by using a miniature humanoid capable of fetching different toys based on voice command."
      },
      {
        "source": "In the modern era of automation and robotics, autonomous vehicles are currently the focus of academic and industrial research. The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6m/sec. We present the same results in this research and compare them with other state-of-the-art methods of vision and learning based navigation. With the ever increasing number of unmanned aerial vehicles getting involved in activities in the civilian and commercial domain, there is an increased need for autonomy in these systems too. Due to guidelines set by the governments regarding the operation ceiling of civil drones, road-tracking based navigation is garnering interest. In an attempt to achieve the above mentioned tasks, we propose an imitation learning based, data-driven solution to UAV autonomy for navigating through city streets by learning to fly by imitating an expert pilot. Derived from the classic image classification algorithms, our classifier has been constructed in the form of a fast 39-layered Inception model, that evaluates the presence of roads using the tomographic reconstructions of the input frames. Based on the Inception-v3 architecture, our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning. The data used for training the system has been captured from the drone, by flying it in and around urban and semi-urban streets, by experts having at least 6-8 years of flying experience. Permissions were taken from required authorities who made sure that minimal risk (to pedestrians) is involved in the data collection process. With the extensive amount of drone data that we collected, we have been able to navigate successfully through roads without crashing or overshooting, with an accuracy of 98.44%.",
        "prediction": "Autonomous vehicles, including drones, are a major focus in research today. The MAVNet system allows drones to fly quickly, up to 6 meters per second. In this study, we compare our findings with other advanced navigation methods that rely on vision and learning. As the number of drones used for civilian and commercial purposes increases, the need for more autonomous systems grows. Since governments have set rules for how high civil drones can fly, navigation based on road tracking has become more appealing. To address these needs, we suggest a method that uses imitation learning, which helps drones navigate city streets by learning from expert pilots. Our classifier is based on a fast 39-layered Inception model, designed to identify roads using images taken by the drone. This system, based on Inception-v3 architecture, is more efficient and accurate than many other imitation learning models. We trained the system using data collected from expert pilots with 6 to 8 years of flying experience, and we got the necessary permissions to ensure safety during data collection. With the large amount of drone data we collected, we successfully navigated roads with an accuracy of 98.44%, avoiding crashes or overshooting.",
        "reference": "Current academic and industrial research is interested in autonomous vehicles. MAVNet computational efficiency enables the drone to fly up to 6m/sec. The solution is compared with other recent methods. Drones are increasingly used in the civilian and commercial domain and need to be autonomous. Governments set guidelines on the operation ceiling of civil drones. So, road-tracking based navigation is attracting interest. Researchers propose data-driven solutions allowing drones to autonomously navigate city streets, learning to fly by imitating an expert pilot. The algorithm, based on the Inception model, detects roads using tomographic reconstructions. The Inception model is an extension of classic image classification algorithms. The Inception-v3 architecture has better accuracy than many existing models of imitation learning. The data used for training the system was captured from the drone over urban streets, navigated by an expert pilot. Data collection requires special permission to ensure pedestrian security. The drone can navigate successfully through roads without crashing or overshooting; its accuracy is 98.44%."
      },
      {
        "source": "Advances in electronics and sensor technology have widened the scopes of networked drones to include applications as diverse as surveillance, video recording, operations, entertainment/advertising, signal emission, transportation, and delivery. These applications and services require video recording for their operations. Large drones are used singly in missions while small ones are used in formations or swarms. The small drones are proving to be useful in civilian applications. Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones. To develop group display applications, a real-time drone formation control for group display is proposed. Simulation shows that drone formation can display messages effectively.",
        "prediction": "Recent improvements in electronics and sensors have expanded the uses of networked drones to include various activities like surveillance, video recording, entertainment, and delivery. These tasks often require video recording. Larger drones are typically used for single missions, while smaller drones work together in groups or swarms, proving useful for civilian purposes. The idea of using small drones for group flights and entertainment has led to the development of networked drones. A new approach for controlling drone formations in real-time has been suggested to create group displays. Simulations indicate that these formations can successfully show messages.",
        "reference": "Advances in technology allowed drones to be used for surveillance, video recording, operations, entertainment/advertising, signal emission, transportation, and delivery. These applications and services require video recording. Large drones are used individually while small ones are used in groups. The small drones are proving to be useful in civilian applications. Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones. To develop group display applications, a real-time drone formation control for group display is proposed. Simulation shows that drone formation can display messages effectively."
      },
      {
        "source": "This study focuses on the digital marketing capabilities of tourism SMEs. The study addresses the question of how the use of ICT-based tools benefit the organisational capabilities of a company. By adopting marketing as a set-of-skills approach, the study provides new insights into the existing tourism literature on e-marketing. Initial findings indicate that the digital marketing capabilities of companies are transformed through ICT-based uptake. Four major capabilities were identified, each of which evolves as a result of using the tools. A key finding of the study is that the use of ICT-based tools transforms digital marketing capabilities from a set of abilities that enables tourism SMEs not only to float in a web-marketing stream, but also to lead such a stream.",
        "prediction": "This study looks at how small and medium-sized tourism businesses use digital marketing tools. It explores how these tools improve a company's abilities. By viewing marketing as a skill set, the study offers new insights into tourism e-marketing. The initial results show that companies change their digital marketing skills by using these tools. Four main skills were identified, which develop because of the tools used. A key finding is that these tools help tourism businesses not just to participate in the online marketing space, but also to take a leading role in it.",
        "reference": "This study focuses on the digital marketing capabilities of tourism small and medium-sized enterprises (SMEs). The study questions on how information and communication technology (ICT) tools can help the organisational capabilities of a company. The study provides new insights from tourism studies on digital marketing. Findings show that digital marketing capabilities of companies are transformed by ICT tools. Four major capabilities were identified, each of which evolves as a result of using the tools. A key finding of the study is that ICT tools transform these capabilities in a set of abilities for SMEs in web-marketing."
      },
      {
        "source": "The prevalence and rapid development of the Internet and mobile technology in recent decades has revamped our living styles and daily habits. To ride on the digital trend, more business activities have been engaged in the digital world. Marketing and advertising is one of typical business areas that is transformed digitally. The rise of Key Opinion Leaders (KOLs), social media platforms, and Omni-channel retailing have attracted countless business entities to consider the adoption of digital marketing tools for promoting and advertising their brands and products. However, with the increasing diversity of the types of digital marketing tools, they must be carefully selected based on a multiple number of criterion. In this paper, a fuzzy-AHP method is proposed and developed for assisting industry practitioners in systematically and effectively evaluate and select proper digital marketing tool(s) for adoption. The developed method not only streamlines the internal business process of digital marketing tool selection, but it also increases the practitioner's effectiveness of achieving the pre-defined strategic marketing objectives.",
        "prediction": "The growth of the Internet and mobile technology has changed how we live and work. Businesses are increasingly moving their activities online, with marketing and advertising being key areas undergoing this digital transformation. The emergence of Key Opinion Leaders, social media, and multi-channel retailing has encouraged many businesses to use digital marketing tools to promote their brands and products. However, due to the variety of available digital marketing tools, businesses need to choose carefully based on several factors. This paper presents a fuzzy-AHP method that helps business professionals evaluate and select suitable digital marketing tools effectively. This method not only simplifies the selection process but also helps professionals better achieve their marketing goals.",
        "reference": "The development of the Internet and mobile technology in recent decades has modified our living styles and daily habits. More business activities have been engaged in the digital world. Marketing and advertising is one of typical business areas that is transformed digitally. Many businesses consider the adoption of digital marketing tools for their promotion and advertisement, due to the rise of Key Opinion Leaders (person with expert status and influence), social media platforms, and Omni-channel retailing (multiple channels but a uniform experience for the customer). However, with the increasing diversity of digital marketing tools, they must be carefully selected. In this paper, a method to organize and analyze complex decisions is proposed and developed for assisting businesses to evaluate and select appropriate digital marketing tools. The developed method rationalizes and simplifies the process of digital marketing tool selection. It also increases effectiveness of achieving strategic marketing objectives."
      },
      {
        "source": "In this paper we revisit a topic originally discussed in 1955, namely the lack of direct evidence that muscle hypertrophy from exercise plays an important role in increasing strength. To this day, long-term adaptations in strength are thought to be primarily contingent on changes in muscle size. Given this assumption, there has been considerable attention placed on programs designed to allow for maximization of both muscle size and strength. However, the conclusion that a change in muscle size affects a change in strength is surprisingly based on little evidence. We suggest that these changes may be completely separate phenomena based on: (1) the weak correlation between the change in muscle size and the change in muscle strength after training; (2) the loss of muscle mass with detraining, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load resistance training, yet divergent results in strength.",
        "prediction": "In this paper, we discuss a topic first brought up in 1955 about the unclear link between muscle growth from exercise and increased strength. People still believe that getting stronger is mainly connected to changes in muscle size. Because of this belief, many training programs focus on increasing both muscle size and strength. However, the idea that growing muscle size leads to increased strength has very little supporting evidence. We propose that these changes might actually be unrelated for several reasons: first, there is a weak relationship between muscle size changes and strength changes after training; second, muscle mass can decrease when people stop training, but strength often stays the same; and third, muscle growth can be similar whether using light or heavy weights, yet strength results can differ.",
        "reference": "In this paper we revisit a topic originally discussed in 1955, namely the lack of evidence that muscle growth plays an important role in increasing strength. To this day, long-term adaptations in strength are thought to be related to changes in muscle size. Given this assumption, training programs made for increasing both muscle size and strength were popular. However, the conclusion that a change in muscle size has an influence on strength is surprisingly based on little evidence. We suggest that these changes may be based on: (1) the weak correlation between the change in muscle size and the change in muscle strength after training; (2) the loss of muscle mass with the interruption of training, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load strength training, yet different results in strength."
      },
      {
        "source": "Low-intensity occlusion (50-100 mm hg) training provides a unique beneficial training mode for promoting muscle hypertrophy. Training at intensities as low as 20% 1 repetition maximum with moderate vascular occlusion results in muscle hypertrophy in as little as 3 weeks. A typical exercise prescription calls for 3 to 5 sets to volitional fatigue with short rest periods. The metabolic buildup causes positive physiologic reactions, specifically a rise in growth hormone that is higher than levels found with higher intensities. Occlusion training is applicable for those who are unable to sustain high loads due to joint pain, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts.",
        "prediction": "Low-intensity occlusion training, which involves applying pressure to the muscles at a level of 50-100 mm hg, is an effective way to increase muscle size. This training can be done with weights as light as 20% of a personâs maximum strength and can show results in about 3 weeks. A common workout routine includes doing 3 to 5 sets until tired, with short breaks in between. This method creates metabolic stress that leads to beneficial changes in the body, including a significant increase in growth hormone, which is actually more than what happens with heavier weights. Occlusion training is useful for people who cannot lift heavy weights due to joint pain, recovery after surgery, heart rehab, athletes reducing their load, and astronauts.",
        "reference": "Low-intensity occlusion training, which is a training method with blood flow restriction, provides a unique beneficial training mode for muscle growth. Training at intensities as low as 20% of maximum strength with moderate occlusion results in muscle growth in 3 weeks. A typical exercise consists of 3 to 5 sets to muscle failure with short rest periods. The metabolic accumulation causes positive physiologic reactions, specifically a rise in growth hormone, which is one of the main hormone responsible of muscle growth, that is higher than levels found with higher intensities. Occlusion training is applicable for those who are unable to sustain high loads due to joint pain, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts."
      },
      {
        "source": "Current dogma suggests aerobic exercise training has minimal effect on skeletal muscle size. We and others have demonstrated that aerobic exercise acutely and chronically alters protein metabolism and induces skeletal muscle hypertrophy. These findings promote an antithesis to the status quo by providing novel perspective on skeletal muscle mass regulation and insight into exercise-countermeasures for populations prone to muscle loss.",
        "prediction": "Recent beliefs say that aerobic exercise does not significantly change the size of skeletal muscles. However, our research and others show that aerobic exercise both temporarily and long-term affects how proteins are processed and can lead to increased muscle size. These results challenge the usual view, offering new ideas on how muscle mass is controlled and providing solutions for people at risk of losing muscle.",
        "reference": "Current belief suggests cardio exercise training has minimal effect on muscle size. We and others have demonstrated that cardio exercise alters protein metabolism (responsible for protein synthesis and muscle growth) and induces muscle growth. These findings against the current belief provide a novel perspective on muscle mass regulation and insight into exercise to prevent muscle loss."
      },
      {
        "source": "Stretch training is widely used in a variety of fitness-related capacities such as increasing joint range of motion, preventing contractures and alleviating injuries. Moreover, some researches indicate that stretch training may induce muscle hypertrophy; however, studies on the topic have been primarily relegated to animal and in vitro models. The purpose of this brief review was to evaluate whether stretch training is a viable strategy to induce muscle hypertrophy in humans. Of the 10 studies identified, 3 observed some significantly positive effects of stretch training on muscle structure. Intriguingly, in these studies, the stretching was carried out with an apparatus that aided in its performance, or with an external overload. Of the 5 available studies that integrated stretching into a resistance training programme, 2 applied the stretching in the interset rest period and were the ones that showed enhanced muscle growth. In conclusion, passive, low-intensity stretch does not appear to confer beneficial changes in muscle size and architecture; alternatively, albeit limited evidence suggests that when stretching is done with a certain degree of tensile strain (particularly when loaded, or added between active muscle contractions) may elicit muscle hypertrophy.",
        "prediction": "Stretch training is commonly used to improve flexibility, prevent injuries, and support recovery. Some studies suggest that it might help muscles grow, but most research has been done on animals or in labs. This review looked at whether stretch training could help humans build muscle. Out of 10 studies, 3 found positive effects on muscle structure with stretching. These studies used special equipment or added weight during stretching. Among 5 studies that included stretching in resistance training, 2 showed that stretching between sets led to more muscle growth. Overall, gentle and passive stretching doesn't seem to increase muscle size, but stretching with some tension or added weight might promote muscle growth.",
        "reference": "Stretch training is used in a variety of fitness capacities such as increasing flexibility, preventing contractures (shortening of muscle) and reduce injuries. Moreover, some researches indicate that stretch training may induce muscle growth. The purpose of this review was to evaluate if stretch training is a viable strategy to induce muscle growth in humans. Of the 10 studies identified, 3 observed positive effects of stretch training on muscles. In these studies, the stretching was performed with external help like equipment or load. Of the 5 available studies that integrated stretching into strength training, 2 applied the stretching in the rest period between the sets and were the ones that showed enhanced muscle growth. In conclusion, passive, low-intensity stretch does not appear to produce beneficial changes in muscles but evidence suggests that when stretching is done with a certain intensity (particularly when loaded, or added between active muscle contractions), it may induce muscle growth."
      },
      {
        "source": "Cycle training is widely performed as a major part of any exercise program seeking to improve aerobic capacity and cardiovascular health. However, the effect of cycle training on muscle size and strength gain still requires further insight, even though it is known that professional cyclists display larger muscle size compared to controls. Therefore, the purpose of this review is to discuss the effects of cycle training on muscle size and strength of the lower extremity and the possible mechanisms for increasing muscle size with cycle training. It is plausible that cycle training requires a longer period to significantly increase muscle size compared to typical resistance training due to a much slower hypertrophy rate. Cycle training induces muscle hypertrophy similarly between young and older age groups, while strength gain seems to favor older adults, which suggests that the probability for improving in muscle quality appears to be higher in older adults compared to young adults. For young adults, higher-intensity intermittent cycling may be required to achieve strength gains. It also appears that muscle hypertrophy induced by cycle training results from the positive changes in muscle protein net balance.",
        "prediction": "Cycle training is commonly used in exercise programs to improve aerobic fitness and heart health. However, we still need to understand how it affects muscle size and strength. While professional cyclists have larger muscles than non-cyclists, this review looks at how cycle training impacts muscle size and strength in the legs and the possible reasons for these changes. It seems that cycle training takes longer to noticeably increase muscle size compared to regular weight training, as it leads to muscle growth more slowly. Cycle training appears to help both young and older individuals grow muscle size, but older adults seem to gain strength more effectively. This suggests that older people might improve their muscle quality better than younger people. For young adults, more intense interval cycling may be needed to build strength. Additionally, the muscle growth from cycle training is linked to positive changes in the balance of muscle proteins.",
        "reference": "Cycling training is performed as a major part of any training program which objective is to improve cardiovascular capacities and health. However, the effect of cycling training on muscle size and strength still requires a better comprehension. Therefore, the purpose of this review is to discuss the effects of cycling training on muscle size and strength of the legs and the possible mechanisms for increasing muscle size with cycling training. It is plausible that cycling training requires a longer period to significantly increase muscle size compared to strength training due to a much slower muscle growth rate. Cycling training induces muscle growth similarly between young and older people, while strength gain seems to favor older adults. For young adults, series of high-intensity cycling may be required to achieve strength gains. It also appears that muscle growth induced by cycling training results from the positive changes in protein balance, which is the balance between protein intake which leads to muscle growth and protein loss which leads to muscle loss)."
      },
      {
        "source": "Resistance training is the most effective method to increase muscle mass. It has also been shown to promote many health benefits. Although it is deemed safe and of clinical relevance for treating and preventing a vast number of diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies. Similarly, an inverted U-shaped relationship between training dose/volume and physiological response has been hypothesized to exist. However, the majority of available evidence supports a clear dose-response relationship between resistance training volume and physiological responses, such as muscle hypertrophy and health outcomes. Additionally, there is a paucity of data to support the inverted U-shaped response. The overarching principle argued herein is that volume is the most easily modifiable variable that has the most evidenced-based response with important repercussions, be these muscle hypertrophy or health-related outcomes.",
        "prediction": "Resistance training is the best way to build muscle mass and has many health benefits. It is considered safe and important for treating and preventing many diseases. Researchers have focused on finding the least amount of exercise that is still effective. There is a theory that suggests a U-shaped curve, meaning too little or too much training might not be effective. However, most evidence shows a clear connection between the amount of resistance training and health results like muscle growth. There is not much data to support the U-shaped idea. The main point is that the volume of training is the easiest factor to change and has the strongest evidence linking it to results, whether in muscle growth or health benefits.",
        "reference": "Strength training is the most effective method to increase muscle mass. It has also been shown to promote many health benefits. Although it is helpful for treating and preventing diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies. Similarly, an inverted U-shaped relationship (which means that the efficiency increases until a point, and then starts decreasing) between training volume and physiological response has been hypothesized to exist. However, evidence supports a clear correlation between resistance training volume (number of exercises, sets, etc.) and physiological responses, such as muscle growth and health outcomes. Additionally, there is a lack of data to support the inverted U-shaped response. The principle suggested is that volume is the most easily modifiable variable that has the most important response, for muscle growth or health outcomes."
      },
      {
        "source": "Although the effects of short versus long inter-set rest intervals in resistance training on measures of muscle hypertrophy have been investigated in several studies, the findings are equivocal and the practical implications remain unclear. Current evidence indicates that both short and long inter-set rest intervals may be useful when training for achieving gains in muscle hypertrophy. Novel findings involving trained participants using measures sensitive to detect changes in muscle hypertrophy suggest a possible advantage for the use of long rest intervals to elicit hypertrophic effects. However, due to the paucity of studies with similar designs, further research is needed to provide a clear differentiation between these two approaches.",
        "prediction": "Research has looked at how short and long rest periods between sets in weight training affect muscle growth, but the results are mixed and the practical advice is unclear. Current studies suggest that both short and long rest periods can help grow muscles. New findings with trained individuals show that longer rest periods might be better for muscle growth. However, since there are not many studies with the same methods, more research is needed to clearly compare these two strategies.",
        "reference": "The effects of short versus long rest intervals between sets in strength training on muscle growth have been investigated in several studies but the findings and the practical implications are unclear. Current evidence indicates that both short and long rest intervals may be useful for muscle growth. Novel findings suggest for trained people a possible advantage for the use of long rest intervals to induce muscle growth. However, due to the lack of studies with similar methodologies, further research is needed to provide a clear differentiation between these two approaches."
      },
      {
        "source": "Memory is a process in which information is encoded, stored, and retrieved. For vertebrates, the modern view has been that it occurs only in the brain. This review describes a cellular memory in skeletal muscle in which hypertrophy is 'remembered' such that a fibre that has previously been large, but subsequently lost its mass, can regain mass faster than naive fibres. A new cell biological model based on the literature, with the most reliable methods for identifying myonuclei, can explain this phenomenon. According to this model, previously untrained fibres recruit myonuclei from activated satellite cells before hypertrophic growth. Even if subsequently subjected to grave atrophy, the higher number of myonuclei is retained, and the myonuclei seem to be protected against the elevated apoptotic activity observed in atrophying muscle tissue. Fibres that have acquired a higher number of myonuclei grow faster when subjected to overload exercise, thus the nuclei represent a functionally important 'memory' of previous strength. This memory might be very long lasting in humans, as myonuclei are stable for at least 15 years and might even be permanent. However, myonuclei are harder to recruit in the elderly, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice.",
        "prediction": "Memory involves encoding, storing, and retrieving information. In vertebrates, it was thought to happen only in the brain. This review discusses a form of memory in skeletal muscle where muscles remember their previous size. A muscle fiber that used to be larger but lost size can regain mass more quickly than fibers that have never been large. A new model explains this by showing that untrained fibers can take in myonuclei from activated satellite cells before they grow larger. Even if these fibers go through significant muscle loss, they keep more myonuclei, which seem to be protected from the cell death that often happens in shrinking muscle. Fibers that have more myonuclei grow faster during intense exercise, indicating that these nuclei serve as a type of memory for strength. This memory could last a long time in humans, as myonuclei can last for at least 15 years and might even be permanent. However, recruiting myonuclei becomes more difficult as people get older. If this long-lasting muscle memory exists, early strength training could be recommended as a health measure",
        "reference": "Memory is a process in which information is encoded, stored, and retrieved. For vertebrates, it has been said that it occurs only in the brain. This review describes a cellular memory in muscles in which muscle growth is 'remembered' such that a fibre that has lost its mass, can regain it faster than untrained fibres. A new model, with the most reliable methods for identifying myonuclei (nuclei in muscle fiber), can explain this phenomenon. According to this model, previously untrained fibres recruit myonuclei from activated satellite cells (quiescent cells acting as a reserve population of cells for regeneration of muscle) before muscle growth. Even after grave muscle loss, the higher number of myonuclei is retained, and the myonuclei seem to be protected against programmed cell death observed during muscle loss. Fibres that have acquired a higher number of myonuclei grow faster during strength exercise, thus the nuclei represent a functionally important 'memory' of previous strength. This memory might be very long lasting in humans, as myonuclei are stable for at least 15 years and might even be permanent. However, myonuclei are harder to recruit for old people, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice."
      },
      {
        "source": "It has been hypothesized that eating small, frequent meals enhances fat loss and helps to achieve better weight maintenance. Several observational studies lend support to this hypothesis, with an inverse relationship noted between the frequency of eating and adiposity. The purpose of this narrative review is to present and discuss a meta-analysis with regression that evaluated experimental research on meal frequency with respect to changes in fat mass and lean mass. Feeding frequency was positively associated with reductions in fat mass and body fat percentage as well as an increase in fat-free mass. However, sensitivity analysis of the data showed that the positive findings were the product of a single study, casting doubt as to whether more frequent meals confer beneficial effects on body composition. In conclusion, although the initial results of this meta-analysis suggest a potential benefit of increased feeding frequencies for enhancing body composition, these findings need to be interpreted with circumspection.",
        "prediction": "Some researchers think that eating small meals more often can help lose fat and maintain weight better. Some studies show that people who eat more frequently tend to have less body fat. This review looks at a study that analyzed research on how often people eat and its effects on body fat and muscle mass. Eating more often was linked to lower fat mass and a higher amount of muscle. However, further analysis showed that these positive results came mainly from one study, raising doubts about the benefits of frequent meals for body composition. Overall, while the initial results suggest that eating more often could help improve body composition, these conclusions should be taken carefully.",
        "reference": "It has been hypothesized that eating small, frequent meals enhances fat loss and helps for better weight maintenance. Several studies support this hypothesis, with a link between the frequency of eating and being overweight. This review aims to present and discuss a research on meal frequency with respect to changes in body mass. Eating frequency was positively associated with reductions in fat mass and increasing in fat-free mass. However, the positive findings were the product of a single study, leaving a doubt about the beneficial effect of frequent meals on body composition. In conclusion, although the initial results suggest a potential benefit of increased eating frequencies for enhancing body composition, these findings need to be carefully interpreted."
      },
      {
        "source": "Inactive adults experience a 3% to 8% loss of muscle mass per decade, accompanied by resting metabolic rate reduction and fat accumulation. Ten weeks of resistance training may increase lean weight by 1.4 kg, increase resting metabolic rate by 7%, and reduce fat weight by 1.8 kg. Benefits of resistance training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem. Resistance training may assist prevention and management of type 2 diabetes by decreasing visceral fat, reducing HbA1c, increasing the density of glucose transporter type 4, and improving insulin sensitivity. Resistance training may enhance cardiovascular health, by reducing resting blood pressure, decreasing low-density lipoprotein cholesterol and triglycerides, and increasing high-density lipoprotein cholesterol. Resistance training may promote bone development, with studies showing 1% to 3% increase in bone mineral density. Resistance training may be effective for reducing low back pain and easing discomfort associated with arthritis and fibromyalgia and has been shown to reverse specific aging factors in skeletal muscle.",
        "prediction": "Inactive adults lose about 3% to 8% of muscle mass every decade, which also leads to a lower resting metabolic rate and more body fat. After 10 weeks of resistance training, people can gain about 1.4 kg of lean mass, boost their resting metabolic rate by 7%, and reduce body fat by 1.8 kg. The benefits of resistance training include better physical performance, improved movement control, faster walking speed, more independence in daily activities, enhanced mental abilities, and higher self-esteem. It can help prevent and manage type 2 diabetes by lowering visceral fat, reducing HbA1c levels, increasing the amount of glucose transporter type 4, and improving how the body responds to insulin. Resistance training can also improve heart health by lowering resting blood pressure, decreasing harmful cholesterol and triglycerides, and increasing good cholesterol. Additionally, it can support bone health, with studies showing a 1% to 3% increase in bone density. It may help reduce low back pain and relieve discomfort from arthritis and fibromyalgia, and it has been shown to counteract some aging effects in skeletal muscle.",
        "reference": "Per decade, inactive adults experience a muscle loss of 3% to 8%, a reduction of resting metabolic rate (energy consumed by the body at rest) and fat accumulation. Ten weeks of strength training may increase fat-free mass by 1.4 kg, resting metabolic rate by 7%, and reduce fat weight by 1.8 kg. Benefits of strength training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem. Strength training may assist prevention and management of type 2 diabetes by decreasing abdominal fat, reducing HbA1c which is a form of hemoglobin linked to a sugar, increasing the density of glucose transporter type 4, and improving insulin sensitivity. Strength training may enhance cardiovascular health, by reducing resting blood pressure, decreasing 'bad' cholesterol and triglycerides (main constituents of body fat), and increasing 'good' cholesterol. Strength training may promote bone development, with studies showing 1% to 3% increase in bone mineral density. Strength training may be effective for reducing low back pain, joint and muscle pain, and reverse specific aging factors in muscles."
      },
      {
        "source": "We hypothesized that compared to post-exercise protein intake, co-ingestion of alcohol would down-regulate translation initiation signaling and decrease rates of MPS.",
        "prediction": "We thought that drinking alcohol along with protein after exercise would reduce the signaling that starts protein synthesis and lower the rate of muscle protein synthesis.",
        "reference": "We assumed that consumption of protein and alcohol (compared to protein only) would reduce protein synthesis."
      },
      {
        "source": "Eight healthy physically active male subjects (age 21.4Â±4.8 yr, body mass (BM) 79.3Â±11.9 kg, peak oxygen uptake (VO2peak) 48.1Â±4.8 mLÂ·kgâ1Â·minâ1, leg extension one repetition maximum (1RM) 104Â±20 kg; values are mean Â± SD) who had been participating in regular exercise (3 times wkâ1 for >6 months) volunteered for this study.",
        "prediction": "Eight healthy active male participants aged about 21 years and with an average body weight of 79 kg took part in this study. They had been exercising regularly, about three times a week for over six months.",
        "reference": "Eight healthy physically active men (3 trainings per week for at least 6 months) volunteered for this study."
      },
      {
        "source": "The study employed a randomized counter-balanced, cross-over design in which each subject completed bouts of consecutive resistance, continuous and intermittent high-intensity exercise with either post-exercise ingestion of alcohol-carbohydrate (ALC-CHO), alcohol-protein (ALC-PRO) or protein only (PRO) beverages on three separate occasions.",
        "prediction": "The study used a method where participants did different types of intense exercise followed by drinking one of three beverages: alcohol with carbohydrates, alcohol with protein, or just protein. Each participant experienced all three types of drinks on different days.",
        "reference": "Subjects did high intensity exercise and just after consumed an alcohol-carbohydrate, an alcohol-protein or a protein drink in three separate occasions."
      },
      {
        "source": "Resistance exercise consisted of eight sets of five repetitions at â¼80% of 1RM.",
        "prediction": "Resistance exercise involved doing eight sets of five repetitions at about 80% of the maximum weight a person could lift once.",
        "reference": "Training consisted of eight sets of five repetitions of leg extension at 80% of their maximum strength."
      },
      {
        "source": "After completion of the final set, subjects rested for 5 min before commencing 30 min of continuous cycling at â¼63% PPO (â¼70% VO2peak).",
        "prediction": "After finishing the last set, participants rested for 5 minutes before starting 30 minutes of continuous cycling at about 63% of their peak power output.",
        "reference": "After 5 minutes rest, subjects cycled for 30 minutes at medium intensity,"
      },
      {
        "source": "Upon completion, subjects rested on the bike for 2 min before undertaking 10Ã30 s high intensity intervals at â¼110% of PPO, with 30 s active recovery (â¼50% PPO) between each work bout.",
        "prediction": "After finishing, participants rested on the bike for 2 minutes before doing 10 intervals of 30 seconds at about 110% of their peak performance output, with 30 seconds of lower intensity recovery between each interval",
        "reference": "then 5 minutes at high intensity."
      },
      {
        "source": "Immediately following exercise and after 4 h recovery, subjects ingested a 500 mL solution of either protein (PRO, 25 g whey protein powder; ISO8, Musashi, Melbourne, VIC Australia) or an energy-match in the form of CHO (25 g maltodextrin, International Health Investments, Helensvale, QLD Australia).",
        "prediction": "After exercising and resting for 4 hours, participants drank 500 mL of either a protein solution with 25 g of whey protein or a carbohydrate solution with 25 g of maltodextrin.",
        "reference": "Immediately following exercise and after 4 h recovery, subjects consumed a 500mL drink of protein or carbohydrates."
      },
      {
        "source": "Furthermore, a CHO-based meal (1.5 gÂ·kgâ1 BM) was consumed â¼2 h post-exercise, immediately after the muscle biopsy, according to recommendations for post-exercise glycogen recovery [24].",
        "prediction": "A CHO-based meal (1.5 g per kg of body mass) was eaten about 2 hours after exercise, right after the muscle biopsy, to help with glycogen recovery as recommended.",
        "reference": "A carbohydrate meal was consumed 2 h after exercise, according to recommendation for glycogen recovery."
      },
      {
        "source": "The 8 h time frame represents an important phase of post-exercise recovery [1] as well as the period during which blood alcohol concentrations are likely to be elevated by a post-event drinking binge [14].",
        "prediction": "The 8-hour time frame is important for recovering after exercise and is also when blood alcohol levels may rise due to drinking after an event",
        "reference": "The 8 h period after exercise is an important phase for recovery but also the period during which blood alcohol level may be the highest after excessive consumption of alcohol."
      },
      {
        "source": "The alcohol ingestion protocol (1.5 gÂ·kgâ1 BM; 12Â±2 standard drinks) began 1 h post-exercise and was consumed in 6 equal volumes of 1 part vodka (â¼60 mL) to four parts orange juice (â¼240 mL, 1.8 g CHOÂ·kgâ1 BM) during a 3 h period.",
        "prediction": "The alcohol intake plan involved drinking 1.5 grams of alcohol per kilogram of body mass, which is about 12 standard drinks. This started 1 hour after exercising and was spread out over 3 hours in 6 equal parts. Each part consisted of 1 part vodka (about 60 mL) mixed with 4 parts orange juice (about 240 mL), providing additional carbohydrates.",
        "reference": "The alcohol consumption started 1 h after exercise with 6 drinks (60mL of vodka and 240mL of orange juice) and during 3 h."
      },
      {
        "source": "The focus of the early post-exercise period (i.e., 1â8 h) is to enhance physiological processes that are critical for reversing the exercise-induced disturbances to homeostasis and physiological function and for promoting adaptations to training [1].",
        "prediction": "The early post-exercise period, which lasts from 1 to 8 hours, aims to improve important body processes that help restore balance and function affected by exercise, as well as support training adaptations",
        "reference": "The period after exercise (1-8h) enhances the body's processes that reverse the effects of the exercise and promotes adaptation to the training."
      },
      {
        "source": "For the PRO condition, orange juice was consumed with a matched volume of water in place of the alcohol.",
        "prediction": "In the PRO condition, people drank orange juice along with an equal amount of water instead of alcohol.",
        "reference": "For the protein drink, orange juice was consumed with water instead of alcohol."
      },
      {
        "source": "Subjects ingested the beverages within 5 min every 30 min.",
        "prediction": "Participants drank the beverages in 5 minutes every half hour",
        "reference": "Subjects consumed the drinks in 5 minutes every 30 minutes."
      },
      {
        "source": "Blood, cell signaling and mRNA data were analyzed by two-way ANOVA (two factor: time Ã treatment) with repeated measures and myofibrillar protein synthesis was analyzed by one-way ANOVA with repeated measures.",
        "prediction": "Blood, cell signaling, and mRNA data were examined using two-way ANOVA, looking at the effects of time and treatment with repeated measures. Myofibrillar protein synthesis was examined using one-way ANOVA with repeated measures.",
        "reference": "Data (blood, protein synthesis, responses, etc.) were analyzed several times for the 3 different consumptions of drinks."
      },
      {
        "source": "The first novel finding of this study was that mTOR signaling and rates of myofibrillar protein synthesis (MPS) following concurrent resistance, continuous and intermittent high-intensity exercise, designed to mimic the metabolic profile of many team sports, were impaired during the early (8 h) recovery phase by the ingestion of large amounts (1.5 gâ¢kgâ1 BM) of alcohol.",
        "prediction": "This study found that drinking a lot of alcohol (1.5 g per kg of body weight) after doing intense exercises (like resistance training and high-intensity workouts) could reduce the activity of mTOR signaling and the production of myofibrillar protein synthesis during the early recovery phase (8 hours)",
        "reference": "The first finding of this study was that the mTOR enzyme (responsible for muscle growth) and protein synthesis (after exercise) were reduced by an excessive alcohol consumption during the 8 h period of recovery."
      },
      {
        "source": "These outcomes were most evident (37% reduction in rates of MPS) when alcohol was consumed in the absence of post-exercise protein intake, as is likely to occur when intoxication reduces the athlete's compliance to sound recovery practices.",
        "prediction": "The results showed a 37% decrease in MPS rates when alcohol was consumed without having protein right after exercise. This likely happens when being drunk prevents athletes from following good recovery habits.",
        "reference": "Consequences were most evident when alcohol was consumed without protein (37 % reduction of protein synthesis)."
      },
      {
        "source": "However, a second finding was that even when protein was consumed in amounts shown to be optimally effective to stimulate MPS [8] during post-exercise recovery, the intake of alcohol reduced MPS by â¼24%, representing only a partial ârescueâ of the anabolic response compared with protein alone.",
        "prediction": "A second finding showed that when protein was consumed at effective levels to promote muscle protein synthesis after exercise, drinking alcohol reduced muscle protein synthesis by about 24%, which is only a partial improvement compared to having protein alone.",
        "reference": "A second finding was that even with protein consumption, alcohol reduced protein synthesis by around 24%."
      },
      {
        "source": "The mechanistic target of rapamycin complex 1 (mTORC1) is a central node for integrating nutrient (i.e. amino acid) and exercise/contraction signal transduction [31], [32].",
        "prediction": "mTORC1 is an important complex that helps the body respond to nutrients like amino acids and signals from exercise or muscle contraction",
        "reference": "mTOR is important in absorption of nutrients (like amino acids) and in sending signals to the body to produce an effort."
      },
      {
        "source": "In conclusion, the current data provide the novel observation that alcohol impairs the response of MPS in exercise recovery in human skeletal muscle despite optimal nutrient provision.",
        "prediction": "In conclusion, the current data show for the first time that alcohol weakens the muscle protein synthesis response during recovery after exercise in human skeletal muscle, even when nutrients are provided properly",
        "reference": "The data from this study show that alcohol reduce the protein synthesis after exercise even with an optimal consumption of nutrients."
      },
      {
        "source": "The quantity of alcohol consumed in the current study was based on amounts reported during binge drinking by athletes.",
        "prediction": "The amount of alcohol considered in this study was based on what athletes said they drank during binge drinking sessions.",
        "reference": "The quantity of alcohol consumed in this study was based on consumption by athletes during binge drinking."
      },
      {
        "source": "However, published reports suggest intakes of some individuals can be significantly greater [9], [50], which is of concern for many reasons related to health and safety [13].",
        "prediction": "Some reports indicate that certain individuals may consume much larger amounts, which raises concerns about health and safety.",
        "reference": "However, reports show that some individuals can consume higher quantities, which is a concern for health and safety issues."
      },
      {
        "source": "Recommended nutritional strategies to maximize recovery in skeletal muscle include protein for enhancing rates of protein synthesis and carbohydrate for replenishing glycogen stores [2],[3].",
        "prediction": "To help muscles recover better, it's important to consume protein to boost protein building in the body and carbohydrates to restore energy stores called glycogen",
        "reference": "Nutritional strategies to optimize muscle recovery include proteins which are recommended to allow protein synthesis (production of new proteins which improve, for example, muscle mass) and carbohydrates to recharge glycogen stores (energy storage)."
      },
      {
        "source": "Regrettably, there has been difficulty in finding an educational message with alcohol consumption related to sports performance that has resonance with athletes.",
        "prediction": "It has been challenging to communicate a clear message about how alcohol affects sports performance in a way that athletes connect with.",
        "reference": "Regrettably, it is difficult to find an educational message about alcohol consumption and sport performances that speaks to athletes."
      },
      {
        "source": "Given the need to promote protein synthesis that underpins adaptation, repair and regeneration of skeletal muscle the results of the current study provide clear evidence of impaired recovery when alcohol is consumed after concurrent (resistance, continuous and intermittent high-intensity) exercise even in the presence of optimal nutritional conditions.",
        "prediction": "This study shows that drinking alcohol after different types of exercise can slow down the recovery of skeletal muscle, even when nutrition is adequate.",
        "reference": "Considering the importance of protein synthesis (adaptation, repair and regeneration of muscles), the results of this study provide evidence of reduced recovery when alcohol is consumed after exercise, even with an optimal consumption of nutrients."
      },
      {
        "source": "We propose our data is of paramount interest to athletes and coaches.",
        "prediction": "Our data is very important for athletes and coaches",
        "reference": "We consider our data crucial for athletes and coaches."
      },
      {
        "source": "Our findings provide an evidence-base for a message of moderation in alcohol intake to promote recovery after exercise with the potential to alter current sports culture and athlete practices.",
        "prediction": "Our results support the idea that consuming alcohol in moderation can help with recovery after exercise. This could change how athletes approach drinking and overall sports culture.",
        "reference": "Our findings provide evidence for a message of moderation in alcohol consumption to promote recovery after exercise, with the potential to change sport cultures and athlete practices."
      },
      {
        "source": "Muscle contraction and the intake of leucine-rich protein sources activate independent but complimentary signaling responses that converge at the mechanistic target of rapamycin (mTOR) to stimulate protein translation enhancing rates of muscle protein synthesis [4]â[6].",
        "prediction": "When muscles contract and when we consume protein sources high in leucine, they trigger separate but related signaling pathways that come together at a key protein called mTOR. This process encourages the translation of proteins, which boosts the rate of muscle protein synthesis",
        "reference": "Muscle contraction and consumption of leucine-rich protein (essential amino acid composing proteins) induce reactions which increase the protein synthesis."
      },
      {
        "source": "The ingestion of â¼20â25 g of high quality protein soon after exercise [7], repeated every 4 h [8] has been shown to maximise the anabolic response in skeletal muscle.",
        "prediction": "Eating about 20 to 25 grams of high-quality protein soon after exercise and then every 4 hours can help maximize muscle growth",
        "reference": "Consumption of 20-25 g of high quality protein after exercise and repeated every 4 h showed an optimal anabolic response (increasing muscle mass) of the muscles."
      },
      {
        "source": "The cultural environment surrounding some sports often involves the intake of large amounts of alcohol after training and competition, with athletes in several team sports being particularly at risk of âbinge drinkingâ practices [9]â[11].",
        "prediction": "In some sports, the culture includes drinking a lot of alcohol after training and competitions. Athletes in team sports are especially prone to binge drinking.",
        "reference": "Several studies showed that athletes are more likely to drink alcohol to excess (50-65% drink above dangerous level)."
      },
      {
        "source": "The outcomes of binge drinking after exercise are likely to include the direct effect of alcohol on physiological processes as well as the indirect effect on the athlete's recovery due to not eating or resting adequately as a result of intoxication.",
        "prediction": "Binge drinking after exercise can directly affect the body's processes and can also hurt an athlete's recovery because they may not eat or rest enough due to being drunk",
        "reference": "Consequences of an excessive consumption after exercise are direct effect on the body but also indirect effect on the recovery due to an inappropriate eating and rest."
      },
      {
        "source": "Although the concurrent consumption of carbohydrate can partially offset the deleterious effects of alcohol intake on post-exercise glycogen resynthesis [14], the effect of alcohol consumption on muscle protein synthesis is unknown.",
        "prediction": "Drinking carbohydrates while consuming alcohol can help reduce some negative effects on glycogen recovery after exercise, but it is unclear how alcohol affects muscle protein building.",
        "reference": "Consumption of carbohydrates can partially counter balance the effects of alcohol on the recharge of glycogen stores but the effect on muscle protein synthesis are unknown."
      },
      {
        "source": "The aim of the current study was to determine the effect of alcohol intake on anabolic cell signaling and rates of myofibrillar protein synthesis (MPS) in humans during recovery from a bout of strenuous exercise approximating stresses an athlete may experience in training and performance for various team sports such as various football and rugby codes, and court sports.",
        "prediction": "This study aimed to find out how drinking alcohol affects cell signaling and the production of muscle proteins in people recovering from intense exercise similar to what athletes face in team sports like football, rugby, and court sports.",
        "reference": "The aim of this study was to determine the effect of alcohol on anabolism and protein synthesis in humans during recovery following an effort an athlete could do (in rugby or football for example)."
      },
      {
        "source": "Human aging results in a variety of changes to skeletal muscle. Sarcopenia is the age-associated loss of muscle mass and is one of the main contributors to musculoskeletal impairments in the elderly. Previous research has demonstrated that resistance training can attenuate skeletal muscle function deficits in older adults, however few articles have focused on the effects of resistance training on functional mobility. The purpose of this systematic review was to 1) present the current state of literature regarding the effects of resistance training on functional mobility outcomes for older adults with skeletal muscle function deficits and 2) provide clinicians with practical guidelines that can be used with seniors during resistance training, or to encourage exercise. We set forth evidence that resistance training can attenuate age-related changes in functional mobility, including improvements in gait speed, static and dynamic balance, and fall risk reduction. Older adults should be encouraged to participate in progressive resistance training activities, and should be admonished to move along a continuum of exercise from immobility, toward the recommended daily amounts of activity.",
        "prediction": "As people age, their skeletal muscles undergo various changes. Sarcopenia is the loss of muscle mass associated with aging and it significantly affects the physical abilities of older individuals. While previous studies have shown that resistance training can help improve muscle function in older adults, not many have looked specifically at how it impacts mobility. This review aims to summarize what is known about the effects of resistance training on mobility outcomes in older adults who have muscle function issues and to give practical advice for clinicians working with seniors in training or exercise. The evidence shows that resistance training can help improve mobility as people age, leading to better walking speed, balance, and a reduced risk of falls. Older adults should be encouraged to engage in progressive resistance training activities and should gradually increase their activity levels from being inactive to meeting recommended daily activity goals.",
        "reference": "Human aging results in a variety of changes to muscles. Sarcopenia is the age-associated muscle loss and is one of the main contributors to muscle disorders in older adults. Previous research has demonstrated that strength training can attenuate muscle function deficits in older adults, however few articles have focused on the effects of strength training on mobility. The purpose of this review was to present the effects of strength training on mobility for older adults with muscle function deficits and to provide guidelines that can be used with seniors during strength training. We present evidence that strength training can attenuate age-related changes in mobility, including improvements in walking speed, static and dynamic balance, and fall risk reduction. Older adults should be encouraged to participate in strength training activities, and should avoid immobility."
      },
      {
        "source": "Maximizing the hypertrophic response to resistance training (RT) is thought to be best achieved by proper manipulation of exercise program variables including exercise selection, exercise order, length of rest intervals, intensity of maximal load, and training volume. An often overlooked variable that also may impact muscle growth is repetition duration. Duration amounts to the sum total of the concentric, eccentric, and isometric components of a repetition, and is predicated on the tempo at which the repetition is performed. We conducted a systematic review and meta-analysis to determine whether alterations in repetition duration can amplify the hypertrophic response to RT. Results indicate that hypertrophic outcomes are similar when training with repetition durations ranging from 0.5 to 8 s. From a practical standpoint it would seem that a fairly wide range of repetition durations can be employed if the primary goal is to maximize muscle growth. Findings suggest that training at volitionally very slow durations (>10s per repetition) is inferior from a hypertrophy standpoint, although a lack of controlled studies on the topic makes it difficult to draw definitive conclusions.",
        "prediction": "To get the most muscle growth from resistance training, itâs important to choose the right exercise variables like what exercises to do, the order of exercises, how long to rest, the intensity, and the overall volume of training. One factor that is often overlooked is how long each repetition lasts. This duration includes the time spent on lifting the weight, lowering it, and holding it still, and it depends on the speed of the exercise. We did a review and analysis to see if changing the duration of repetitions could improve muscle growth. Our results show that muscle growth is similar when using repetition durations between 0.5 and 8 seconds. Practically, this means a wide range of repetition durations can be used for muscle growth. However, very slow repetitions that take more than 10 seconds are not as effective for muscle growth, although there arenât many controlled studies to confirm this fully.",
        "reference": "Maximizing the muscle growth following strength training can be done by manipulating variables like exercise selection, exercise order, rest intervals, intensity of maximal load, and training volume (number of exercises, sets, etc.). A neglected variable that also may impact muscle growth is repetition duration. Total duration of a repetition is the sum of the contraction, the lengthening and isometric (static contraction) and is based on the tempo. We conducted a review and analysis of multiple studies to determine if modification of repetition duration can amplify the muscle growth. Results indicate that muscle growth is similar when training with repetition durations from 0.5 to 8 s. Using a wide range of repetition durations can be employed if the primary goal is to maximize muscle growth. Findings suggest that training at very slow durations (>10s per repetition) is less efficient for muscle growth, although a lack of studies on the topic makes it difficult to draw definitive conclusions."
      },
      {
        "source": "Recovery from exercise refers to the time period between the end of a bout of exercise and the subsequent return to a resting or recovered state. It also refers to specific physiological processes or states occurring after exercise that are distinct from the physiology of either the exercising or the resting states. In this context, recovery of the cardiovascular system after exercise occurs across a period of minutes to hours, during which many characteristics of the system, even how it is controlled, change over time. Some of these changes may be necessary for long-term adaptation to exercise training, yet some can lead to cardiovascular instability during recovery. Furthermore, some of these changes may provide insight into when the cardiovascular system has recovered from prior training and is physiologically ready for additional training stress. This review focuses on the most consistently observed hemodynamic adjustments and the underlying causes that drive cardiovascular recovery and will highlight how they differ following resistance and aerobic exercise. Primary emphasis will be placed on the hypotensive effect of aerobic and resistance exercise and associated mechanisms that have clinical relevance, but if left unchecked, can progress to symptomatic hypotension and syncope. Finally, we focus on the practical application of this information to strategies to maximize the benefits of cardiovascular recovery, or minimize the vulnerabilities of this state. We will explore appropriate field measures, and discuss to what extent these can guide an athlete's training.",
        "prediction": "Recovery from exercise is the time it takes to return to a resting state after physical activity. It includes certain changes in the body that happen after exercising, which are different from the physical states during or after exercise. For the heart and blood vessels, recovery takes minutes to hours, and during this time, the way they operate may change. Some changes are important for getting better at exercising, while others might cause problems in heart stability during recovery. Understanding these changes can help determine when the heart is ready for more exercise. This review looks at common changes in blood flow during recovery and the reasons behind them, highlighting how they differ between strength training and aerobic exercises. It will specifically focus on how aerobic and resistance exercises can lower blood pressure and the important mechanisms involved. If not managed well, this can lead to low blood pressure and fainting. Lastly, we will discuss how this information can help improve recovery strategies for athletes and talk about practical measures that can assist in their training.",
        "reference": "Recovery from exercise refers to the time period between the end of exercise and the return to a resting or recovered state. It also refers to specific physiological processes occurring after exercise. Recovery of the cardiovascular system occurs across a period of minutes to hours, during which many characteristics of the system change over time. Some of these changes may be necessary for long-term adaptation to exercise training, yet some can lead to cardiovascular instability during recovery. These changes may provide insight into when the cardiovascular system has recovered and is physiologically ready for additional training. This review focuses on the most consistently observed blood flow adjustments and the causes that drive cardiovascular recovery and how they differ following strength and cardio exercise. First we focus on the effect leading to low blood pressure of cardio and strength exercise and associated mechanisms, which can progress to symptomatic hypotension (low blood pressure) and fainting. Finally, we focus on the practical application to maximize the benefits of cardiovascular recovery, or minimize the vulnerabilities. We will explore measures, and discuss how these can guide an athlete's training."
      },
      {
        "source": "Exercise and physical activity are increasingly becoming key tools in the treatment and prevention of several medical conditions including arthritis and diabetes; this notion has been termed \"exercise as medicine\". Exercise has favorable effects on reducing cardiovascular risk, inflammation, cachexia, and hypertension, in addition to increasing physical functioning, strength, and cardio-respiratory capacity. Chronic kidney disease, a condition that affects around 10% of the population, is often overlooked as a target for exercise-based therapy. Despite the vast range of severity in kidney disease (e.g., pre-dialysis, dialysis, transplant), exercise has a potential role in all patients suffering from the condition. In this review, we summarise the important role exercise may have in the clinical management of kidney disease and how this form of 'medicine' should be best administered and 'prescribed'.",
        "prediction": "Exercise and physical activity are becoming important in treating and preventing various health problems like arthritis and diabetes, which is known as \"exercise as medicine\". Exercise helps reduce risks for heart disease, inflammation, weight loss, and high blood pressure, while also improving physical ability, strength, and breathing capacity. Chronic kidney disease affects about 10% of people and is often ignored as a condition that could benefit from exercise therapy. Regardless of how severe the kidney disease is, exercise can help all affected patients. This review discusses the significant role that exercise can play in managing kidney disease and how it should be prescribed to patients.",
        "reference": "Exercise and physical activity are key tools in the treatment and prevention of several medical conditions including joint disorders and diabetes. Exercise can reduce cardiovascular risk, inflammation, illness causing muscle loss, and hypertension, in addition to increasing physical functioning, strength, and cardio-respiratory capacity. Chronic kidney disease, a condition that affects around 10% of the population, is often neglected as a target for exercise-based therapy. Despite the vast range of severity in kidney disease, exercise has a potential role in all patients suffering from the condition. In this review, we summarise the potential important role of exercise in the management of kidney disease and how this form of 'medicine' should be used."
      },
      {
        "source": "Blood flow restriction (BFR) is an effective clinical intervention used to increase strength in healthy individuals. However, its effects on pain and function in individuals with knee pain are unknown. Objective: To determine the effectiveness of adding BFR to resistance exercise for pain relief and improvement of function in patients with knee pain. Methods: Systematic review with meta-analysis of randomized clinical trials. Randomized clinical trials that compared resistance exercise with or without BFR to treat knee pain and function in individuals older than 18 years of age with knee pain were included. The pooled standardized mean difference (SMD) estimate showed that resistance exercises with BFR was not more effective than resistance exercises for reducing pain (SMD: -0.37cm, 95% CI=-0.93, 0.19) and improving knee function (SMD=-0.23 points, 95% CI=-0.71, 0.26) in patients with knee pain.",
        "prediction": "Blood flow restriction (BFR) is a method used in clinics to help healthy people get stronger. However, we do not know how it affects pain and function in people with knee pain. The goal of this study was to see if adding BFR to strength training helps with pain relief and better function for people with knee pain. We looked at many clinical trials where some people did strength exercises with BFR, while others did the same exercises without BFR. These trials focused on adults over 18 years who have knee pain. The results showed that doing strength exercises with BFR did not reduce pain or improve knee function more than just doing strength exercises alone.",
        "reference": "Exercise with blood flow restriction (BFR) is used to increase strength in healthy individuals. However, its effects on individuals with knee pain are unknown. The objective is to determine the effectiveness of adding BFR to strength exercise for pain relief and improvement of function in patients with knee pain. We conducted a review and analysis of multiple studies. Studies that compared strength exercise with or without BFR to treat knee pain and function. The results showed that resistance exercises with BFR was not more effective than strength exercises for reducing pain and improving knee function in patients with knee pain."
      },
      {
        "source": "In Japan, there were an estimated 43 million patients with hypertension in 2010. The management of this condition is given the highest priority in disease control, and the importance of lifestyle changes for the prevention and treatment of hypertension has been recognized in Japan. In particular, emphasis has been placed on increasing the levels of activities of daily living and physical exercise (sports). In this literature review, we examined appropriate exercise prescriptions (e.g., type, intensity, duration per session, and frequency) for the prevention and treatment of hypertension as described in Japanese and foreign articles. This review recommends safe and effective whole-body aerobic exercise at moderate intensity (i.e., 50-65% of maximum oxygen intake, 30-60 min per session, 3-4 times a week) that primarily focuses on the major muscle groups for the prevention and treatment of hypertension. Resistance exercise should be performed at low-intensity without breath-holding and should be used as supplementary exercise, but resistance exercise is contraindicated in patients with hypertension who have chest symptoms such as chest pain.",
        "prediction": "In Japan, about 43 million people had high blood pressure in 2010. Managing this condition is very important, and lifestyle changes for preventing and treating high blood pressure are recognized as crucial. There is a focus on increasing everyday activities and physical exercise. This review looks at exercise guidelines (such as type, intensity, duration, and frequency) for preventing and treating high blood pressure from both Japanese and foreign studies. It recommends safe and effective whole-body aerobic exercise at a moderate intensity (50-65% of maximum oxygen intake, 30-60 minutes per session, 3-4 times a week) that targets major muscle groups. Resistance training should be done at low intensity without holding breath and can be a supplementary exercise, but it is not recommended for patients with high blood pressure who experience chest symptoms like pain.",
        "reference": "In Japan, 43 million patients had high blood pressure in 2010. The management of this condition and the importance of lifestyle changes for the prevention and treatment of high blood pressure has been recognized in Japan. In particular, increasing the levels of activities of daily living and physical exercise. In this review, we examined appropriate exercise prescriptions (e.g., type, intensity, duration per session, and frequency) for the prevention and treatment of high blood pressure. This review recommends full body cardio exercise at moderate intensity (i.e., 50-65% of maximum intensity, 30-60 min per session, 3-4 times a week) that focuses on the major muscle groups. Strength exercise should be performed at low-intensity without breath-holding and should be used as supplementary exercise, but it is contraindicated in patients with high blood pressure who have chest symptoms such as chest pain."
      },
      {
        "source": "Physical activity has proved to be an effective means of preventing several diseases and improving general health. Common sense advices call for late inception of intense, strength training-related activities, like weight lifting and plyometrics, which are usually postponed at the end of the growth age, even among sport practitioners. However, such advices seem to have a mainly anecdotal nature. Current literature does not seem to have any particular aversion against the practice of strength training by children and adolescents, provided that some safety rules are followed, like medical clearance, proper instruction from a qualified professional and progressive overload. At the same time, several studies provide consistent findings supporting the benefits of repeated, intense physical efforts in young subjects. Improved motor skills and body composition, in terms of increased fat free mass, reduced fat mass and enhanced bone health, have been extensively documented, especially if sport practice began early, when the subjects were pubescent. It can be therefore concluded that strength training is a relatively safe and healthy practice for children and adolescents.",
        "prediction": "Physical activity is effective for preventing diseases and improving health. Common advice suggests delaying intense strength training activities like weight lifting until after growth is complete. However, this advice is mostly based on personal experience rather than scientific evidence. Research does not generally oppose strength training for children and teens if safety measures are in place, such as medical checks, qualified instruction, and gradual increase in intensity. Many studies show that regular intense exercise benefits young people by improving motor skills and body composition, including more muscle, less fat, and better bone health, especially if they start sports early during puberty. Thus, strength training is generally safe and healthy for children and adolescents.",
        "reference": "Physical activity has many benefits like preventing diseases and improving general health. In popular opinion, it is recommended to start intense physical activities like weight lifting and plyometrics (exercises like sprint and jumps) after adolescence. But this advice does not seem to be based on facts. We did not find any recommendation against strength training at a young age if it is well supervised with safety rules, medical clearance, proper instruction from a professional and progressive overload (gradual increase of stress on muscle and nervous system). Several studies showed many benefits of repeated, intense physical efforts in young people. Improved motor skills and body composition (muscle mass increased, fat mass decreased, healthier bone) were found in studies, especially if sport practice began during puberty. We can conclude that strength training is a safe and healthy practice for children and adolescents."
      },
      {
        "source": "recently, there has been a renewed public interest in IFast. Given the importance of nutrition in optimizing athletic performance, there is a concern about the effects of IFast on athletics. Looking at high-intensity, endurance, and resistance exercises, studies have been varied but are uniform in showing that there is no benefit to athletic performance while fasting.",
        "prediction": "There has been new public interest in intermittent fasting (IFast). Nutrition plays a key role in enhancing athletic performance, which raises concerns about how IFast affects athletes. Research on high-intensity, endurance, and resistance exercises shows mixed results, but overall, it suggests that fasting does not improve athletic performance.",
        "reference": "Nowadays, people are interested in intermittent fasting (an eating pattern where you cycle between periods of eating and fasting) Nutrition is important for the optimization of sport performance so there is a concern about the effects of intermittent fasting on performance. Studies showed that there are no benefit in high-intensity, endurance or strength training while fasting."
      },
      {
        "source": "Nearly every physically active person encounters periods in which the time available for exercise is limited (e.g., personal, family, or business conflicts). During such periods, the goal of physical training may be to simply maintain (rather than improve) physical performance. Similarly, certain special populations may desire to maintain performance for prolonged periods, namely athletes (during the competitive season and off-season) and military personnel (during deployment). In general populations, endurance performance can be maintained for up to 15 weeks when training frequency is reduced to as little as 2 sessions per week or when exercise volume is reduced by 33â66% (as low as 13â26 minutes per session), as long as exercise intensity (exercising heart rate) is maintained. Strength and muscle size (at least in younger populations) can be maintained for up to 32 weeks with as little as 1 session of strength training per week and 1 set per exercise, as long as exercise intensity (relative load) is maintained; whereas, in older populations, maintaining muscle size may require up to 2 sessions per week and 2â3 sets per exercise, while maintaining exercise intensity. Our primary conclusion is that exercise intensity seems to be the key variable for maintaining physical performance over time, despite relatively large reductions in exercise frequency and volume.",
        "prediction": "Most active people face times when they have less time to exercise due to personal, family, or work commitments. During these times, the main goal of training is to keep their physical performance stable rather than improve it. This is also true for certain groups like athletes during competition and off-season, and military personnel while deployed. Research shows that regular people can maintain their endurance performance for up to 15 weeks if they cut back to just 2 workouts a week or reduce their exercise volume by 33-66%, as long as they keep the exercise intensity high. For younger individuals, strength and muscle size can be kept for about 32 weeks with just 1 strength training session per week and 1 set for each exercise, provided they maintain the intensity. Older individuals might need 2 sessions each week and 2-3 sets per exercise to keep muscle size while also keeping up the intensity. Overall, exercise intensity is the most important factor for maintaining physical performance, even with significant reductions in how often and how much one exercises.",
        "reference": "Physically active people encounter periods with limited time available for exercise. During such periods, the goal of training may be to simply maintain physical performance. Some people may also desire to maintain performance for prolonged periods, like athletes during competitive season or militaries during deployment. Endurance performance can be maintained for up to 15 weeks with 2 trainings per week, or with a reduction of 13â26 minutes per training, as long as exercise intensity (exercising heart rate) is maintained. Strength and muscle size can be maintained for up to 32 weeks with 1 strength training per week and 1 set per exercise, as long as exercise intensity (load) is maintained. In older populations, maintaining muscle size may require up to 2 trainings per week and 2â3 sets per exercise, while maintaining exercise intensity. Exercise intensity seems to be the key variable for maintaining physical performance, even with reduction of frequency and volume (number of exercises, sets, etc.)"
      },
      {
        "source": "Nutrient timing is a popular nutritional strategy that involves the consumption of combinations of nutrients--primarily protein and carbohydrate--in and around an exercise session. Some have claimed that this approach can produce dramatic improvements in body composition. It has even been postulated that the timing of nutritional consumption may be more important than the absolute daily intake of nutrients. The post-exercise period is widely considered the most critical part of nutrient timing. Theoretically, consuming the proper ratio of nutrients during this time not only initiates the rebuilding of damaged muscle tissue and restoration of energy reserves, but it does so in a supercompensated fashion that enhances both body composition and exercise performance. Several researchers have made reference to an anabolic âwindow of opportunityâ whereby a limited time exists after training to optimize training-related muscular adaptations. However, the importance - and even the existence - of a post-exercise âwindowâ can vary according to a number of factors. Not only is nutrient timing research open to question in terms of applicability, but recent evidence has directly challenged the classical view of the relevance of post-exercise nutritional intake with respect to anabolism.",
        "prediction": "Nutrient timing is a method where people eat specific combinations of nutrients, mainly protein and carbohydrates, around their exercise times. Some people believe that this can greatly improve body composition. It is suggested that the timing of meals could be more crucial than just how much nutrients are consumed in a day. The time right after exercising is often seen as the most important for nutrient timing. The idea is that eating the right mix of nutrients then helps rebuild muscle and restock energy supplies in a way that improves body composition and workout performance. Researchers talk about an anabolic \"window of opportunity\" meaning there is a limited time after training to maximize muscle gains. However, the significance and even the existence of this post-exercise \"window\" can depend on various factors. The research on nutrient timing raises questions about its applicability, and recent studies have challenged the traditional belief about the importance of post-exercise nutrition for muscle growth.",
        "reference": "Nutrient timing is a popular nutritional strategy that involves the consumption of combinations of nutrients around an exercise session. Some people say that this approach can produce dramatic improvements in body composition. It has even been hypothesized that the timing may be more important than the total daily intake of nutrients. The post-exercise period is considered the most important part of nutrient timing. In theory, consuming the proper ratio of nutrients during this time allows the rebuilding of damaged muscle tissue and restoration of energy reserves, but also enhances both body composition and exercise performance. Researchers have made reference to an anabolic âwindow of opportunityâ (a limited time after training to optimize muscular adaptations). However, the importance - and even the existence - of a post-exercise âwindowâ can vary according to a number of factors. Research is uncertain about the applicability of nutrient timing. Besides, the relevance of post-exercise nutritional intake concerning anabolism (increasing muscle mass) has been challenged by recent evidence."
      },
      {
        "source": "Lack of time is among the more commonly reported barriers for abstention from exercise programs. The aim of this review was to determine how strength training can be most effectively carried out in a time-efficient manner by critically evaluating research on acute training variables, advanced training techniques, and the need for warm-up and stretching. When programming strength training for optimum time-efficiency we recommend prioritizing bilateral, multi-joint exercises that include full dynamic movements (i.e. both eccentric and concentric muscle actions), and to perform a minimum of one leg pressing exercise (e.g. squats), one upper-body pulling exercise (e.g. pull-up) and one upper-body pushing exercise (e.g. bench press). Exercises can be performed with machines and/or free weights based on training goals, availability, and personal preferences. Weekly training volume is more important than training frequency and we recommend performing a minimum of 4 weekly sets per muscle group using a 6â15 RM loading range (15â40 repetitions can be used if training is performed to volitional failure). Advanced training techniques, such as supersets, drop sets and rest-pause training roughly halves training time compared to traditional training, while maintaining training volume. However, these methods are probably better at inducing hypertrophy than muscular strength, and more research is needed on longitudinal training effects. Finally, we advise restricting the warm-up to exercise-specific warm-ups, and only prioritize stretching if the goal of training is to increase flexibility.",
        "prediction": "Many people say they don't have enough time to exercise. This review looks at how to do strength training effectively while saving time. We suggest focusing on exercises that use both sides of the body and involve multiple joints with full movements. Key exercises should include at least one leg exercise like squats, one upper-body pulling exercise like pull-ups, and one upper-body pushing exercise like bench presses. You can use machines or free weights depending on your goals and what you prefer. It's more important to do enough volume each week rather than how often you train. We recommend at least four sets per muscle group each week using a weight that you can lift for 6 to 15 repetitions. Techniques like supersets and drop sets can significantly reduce training time while keeping the volume the same. These methods may help build muscle size more than strength, and more studies are needed to understand their long-term effects. Lastly, warm-ups should be specific to the exercises you're doing, and stretching should be focused on only if you're aiming to improve flexibility.",
        "reference": "Lack of time is one of the most common reason for not exercising. The aim of this review was to determine how strength training can be time-efficient by evaluating research on training variables, advanced training techniques, and the need for warm-up and stretching. We recommend choosing bilateral (with the two arms or legs), multi-joint (multiple joints involved) exercises that include full dynamic movements and to perform a minimum of one leg pressing exercise (e.g. squats), one pulling exercise (e.g. pull-up) and one pushing exercise (e.g. bench press). Exercises can be performed with machines and/or free weights. Weekly training volume (number of exercises, sets, etc.) is more important than training frequency and we recommend a minimum of 4 weekly sets per muscle group using a load that permits to do 6 to 15 repetitions. Advanced training techniques like combining exercises with no rest or shortening the rest time while using lighter weights can cuts the training time in half, while maintaining training volume. However, these methods are probably better to increase muscle mass than strength. Finally, we advise exercise-specific warm-ups, and stretching only if the goal of training is to increase flexibility."
      },
      {
        "source": "Training frequency is considered an important variable in the hypertrophic response to regimented resistance exercise. The purpose of this paper was to conduct a systematic review and meta-analysis of experimental studies designed to investigate the effects of weekly training frequency on hypertrophic adaptations. Results showed no significant difference between higher and lower frequency on a volume-equated basis. Meta-regression analysis of non-volume-equated studies showed a significant effect favoring higher frequencies, although the overall difference in magnitude of effect between frequencies of 1 and 3+ days per week was modest. In conclusion, there is strong evidence that resistance training frequency does not significantly or meaningfully impact muscle hypertrophy when volume is equated. Thus, for a given training volume, individuals can choose a weekly frequency per muscle groups based on personal preference.",
        "prediction": "Training frequency is an important factor in how muscles grow with resistance exercise. This paper reviews studies that looked at how often people train each week affects muscle growth. The results showed that there was no significant difference in muscle growth between higher and lower training frequencies when the total training volume was the same. When looking at studies that did not match the training volume, there was a noticeable benefit for training more often, but the difference between training once a week and three or more times was not very large. In summary, there is strong evidence that how often someone trains does not greatly affect muscle growth if the total volume of training is the same. Therefore, individuals can select their training frequency for each muscle group based on what they prefer.",
        "reference": "Training frequency is an important variable for hypertrophy (increasing muscle mass) in strength training. The purpose of this paper was to conduct a review and analysis of multiple studies investigating the effects of weekly training frequency on hypertrophy. Results showed no significant difference between higher and lower frequency with the same training volume (number of exercises, sets, etc.). Analysis of studies with different training volumes showed better results for higher frequencies, although the difference between frequencies of 1 and 3+ days per week was small. In conclusion, there is strong evidence that resistance training frequency does not significantly impact muscle hypertrophy when training volume is the same. Thus, for a given training volume, individuals can choose a weekly frequency per muscle groups based on personal preference."
      },
      {
        "source": "A variety of specialized training techniques have been advocated as a means to heighten muscle growth. Forced repetitions/drop sets, supersets, and heavy negatives, in particular, have been purported to enhance the hypertrophic response to resistance exercise. This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to resistance training programs.",
        "prediction": "Different training methods have been recommended to increase muscle growth. Techniques like forced repetitions, drop sets, supersets, and heavy negatives are said to improve muscle development from resistance exercise. This article will look at how these methods can help muscle growth and their possible use in resistance training programs",
        "reference": "A variety of training techniques have been suggested to support muscle growth. Forced repetitions/drop sets (use lighter weight or receiving help to continue the set), supersets (combining exercises with no rest), and heavy negatives (lowering phase of the lift), are pretended to enhance hypertrophy (increasing muscle mass). This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to strength training."
      },
      {
        "source": "The quest to increase lean body mass is widely pursued by those who lift weights. Research is lacking, however, as to the best approach for maximizing exercise-induced muscle growth. Bodybuilders generally train with moderate loads and fairly short rest intervals that induce high amounts of metabolic stress. Powerlifters, on the other hand, routinely train with high-intensity loads and lengthy rest periods between sets. Although both groups are known to display impressive muscularity, it is not clear which method is superior for hypertrophic gains. It has been shown that many factors mediate the hypertrophic process and that mechanical tension, muscle damage, and metabolic stress all can play a role in exercise-induced muscle growth. Therefore, the purpose of this paper is twofold: (a) to extensively review the literature as to the mechanisms of muscle hypertrophy and their application to exercise training and (b) to draw conclusions from the research as to the optimal protocol for maximizing muscle growth.",
        "prediction": "Many people who lift weights want to increase their muscle mass, but research on the best way to do this is limited. Bodybuilders usually lift moderate weights with short breaks, creating a lot of metabolic stress. In contrast, powerlifters lift heavy weights with longer breaks. Both groups have impressive muscles, but it is unclear which training style leads to better muscle growth. Several factors, including mechanical tension, muscle damage, and metabolic stress, affect muscle growth during exercise. This paper aims to review existing research on how muscles grow and to determine the best training methods for maximizing muscle gain.",
        "reference": "Increasing muscle mass is the goal of many people who lift weights. Research is lacking, however, as to the optimal way to induce muscle growth. Bodybuilders train with moderate loads and short rest intervals. Powerlifters, on the other hand, train with high-intensity loads and lengthy rest periods. Although both groups are known to display impressive muscularity, it is not clear which method is superior for increasing muscle mass. It has been shown that many factors mediate the process of muscle growth and that mechanical tension, muscle damage, and metabolic stress all can play a role in muscle growth. Therefore, the purpose of this paper is to review the literature as to the mechanisms of muscle hypertrophy and their application to exercise training and to draw conclusions from the research as to the optimal way to induce muscle growth."
      }
    ]
  ],
  "aiir_mistral_prompt": [
    {
      "SARI": 42.095513428502095,
      "BLEU": 0.2307744683082961,
      "FKGL": 15.697142857142858
    },
    [
      {
        "source": "Abstract   Novel technological advances in mobile devices and applications can be exploited in wildfire confrontation, enabling end-users to easily conduct several everyday tasks, such as access to data and information, sharing of intelligence and coordination of personnel and vehicles. This work describes an innovative mobile application for wildfire information management that operates on Windows Phone devices and acts as a complementary tool to the web-based version of the AEGIS platform for wildfire prevention and management. Several tasks can be accomplished from the AEGIS App, such as routing, spatial search for closest facilities and firefighting support infrastructures, access to weather data and visualization of fire management data (water sources, gas refill stations, evacuation sites etc.). An innovative feature of AEGIS App is the support of these tasks by a digital assistant for artificial intelligence named Cortana (developed by Microsoft for Windows Phone devices), that allows information utilization through voice commands. The application is to be used by firefighting personnel in Greece and is potentially expected to contribute towards a more sophisticated transferring of information and knowledge between wildfire confrontation operation centers and firefighting units in the field.",
        "prediction": "Abstract Novel technological advances in mobile devices and applications can be used to help fight wildfires. They allow users to easily perform everyday tasks like accessing information, sharing intelligence, and coordinating personnel and vehicles. This work describes a new mobile application for managing wildfire information that works on Windows Phone devices. It complements the web-based version of the AEGIS platform, which is designed for wildfire prevention and management. Users can accomplish various tasks with the AEGIS App, such as finding routes, searching for nearby facilities, accessing firefighting support resources, checking weather data, and visualizing fire management information like water sources, gas refill stations, and evacuation sites. A key feature of the AEGIS App is the support of a digital assistant powered by artificial intelligence named Cortana, which was developed by Microsoft for Windows Phone devices. This assistant allows users to access information using voice commands. The application is intended for use by firefighting personnel in Greece and is expected to improve the exchange of information and knowledge between wildfire operation centers and firefighting teams in the field.",
        "reference": "Novel mobile devices and applications can be used in wildfire confrontation by helping users to access data and information and coordinate personnel and vehicles. This paper describes a new Windows Phone application for wildfire information management which is complementary to the web version of the AEGIS platform for wildfire prevention and management. The AEGIS App can be used for searching for the closest firefighting infrastructures, as well as access to weather data, and visualization of water sources, gas refill stations, evacuation sites, etc. The AEGIS App supports these tasks through voice commands with Microsoft Cortana (AI digital assistant for Windows Phone).Â  The application is designed for firefighters in Greece but it can help communication between wildfire coordination and local firefighting units."
      },
      {
        "source": "In recent years, mobile technologies have developed and applied in education fields, and some mobile emerging carriers with mobile technologies include a personal digital assistant (PDA), smart phone, and e-book. Some of the mobile carriers combines context-aware technologies or involve into wireless network environments to make effective use through the combination of learning scenarios and technologies, and then provide students new learning experiences differed from the past learning. In view of the application of mobile technology in education, some previous studies have addressed that mobile learning is a meaningful learning that can improve the interaction between students and the situations and reach the purposes of learning. In the main stream of mobile learning, using mobile carriers with suitable learning methods or strategies in mobile learning activities for different students to enhance learning have gradually become a important and concern issue. The purpose of this study is to investigate the learning achievement and learning attitude of elementary school students on a campus plant learning activity when they use mobile carriers and competitive learning strategies. The experimental results show that the competitive learning group of students have better learning performance than non-competitive learning group of students. After completing the learning activity, the two groups of students presented high positive attitudes towards learning.",
        "prediction": "In recent years, mobile technologies have been developed and used in education. Some examples of mobile devices with these technologies include a personal digital assistant (PDA), smartphone, and e-book. These mobile devices can work with context-aware technologies, which means they can adapt based on the user's environment, and they can connect to wireless networks. This combination allows for effective learning experiences that are different from traditional education methods. Previous studies have shown that mobile learning can improve interaction between students and their learning situations, helping them achieve their educational goals. In the area of mobile learning, choosing the right mobile devices along with appropriate learning methods or strategies for different students has become an important topic of discussion. This study aims to explore the learning achievements and attitudes of elementary school students participating in a campus plant learning activity using mobile devices and competitive learning strategies. The experimental results indicate that students in the competitive learning group performed better than those in the non-competitive learning group. After the learning activity, both groups of students showed a positive attitude toward learning.",
        "reference": "Mobile technologies, such as personal digital assistants (PDA), smartphones, and e-books, are increasingly used in the educational field. Some mobile carriers combine learning scenarios and context-aware technologies or wireless network environments providing students with new learning experiences. Mobile learning is effective as it can improve the interaction between students and situations. An important question in the mobile learning field is how to enhance learning through the use of mobile carriers with suitable learning methods in student activities. This study investigates learning achievement and attitude of elementary school students when they use mobile carriers and competitive learning strategies during campus plant learning activities. The competitive learning group of students has better learning performance than the non-competitive one. After the activity, both groups of students were positive about learning."
      },
      {
        "source": "This paper proposes an electrophysiological wireless patient monitoring system which integrates a Wireless ECG signal transmitter, GPS device and a mobile phone to acquire physiological signals and transmit them to a local server via Bluetooth wireless technology. Four kinds of monitor units were specially designed for a wireless communication, including a control center , a local monitor unit, mobile devices (personal digital assistant; PDA), and a Web page (for both patient and doctor). The use of various monitor units is created to fulfill different medical personnel requirements and wishes. This application was developed to promote the mobility and flexibility for the patients and also for the medical personnel, which further will improve both the quality of health care and lifestyle of the patient.",
        "prediction": "This paper proposes a wireless system for monitoring patients' body functions. It includes a device that transmits ECG signals, which measure the electrical activity of the heart, a GPS device that tracks location, and a mobile phone to collect body signals and send them to a local server using Bluetooth, a technology for short-range wireless communication. Four types of monitoring units were specially designed for wireless communication. These include a control center to manage the system, a local monitor unit for nearby observation, mobile devices like personal digital assistants (PDAs) to allow remote access, and a web page for both patients and doctors to view information. These various monitoring units are created to meet the different needs and preferences of medical staff. This system was developed to enhance freedom and flexibility for patients and healthcare providers, which will ultimately improve the quality of healthcare and patients' lifestyles.",
        "reference": "This paper suggests a system to monitor patients wirelessly using a device that transmits ECG signals, a GPS device, and a mobile phone. The signals are sent to a local server via Bluetooth technology. Four types of monitor units were created for wireless communication: a control center, a local monitor unit, mobile devices such as personal digital assistants (PDA), and a web page accessible to both patients and doctors. Various monitor units are used to satisfy different medical personnel needs. This application was developed to boost the quality of healthcare and patient lifestyle by increasing mobility and flexibility for both patients and medical personnel."
      },
      {
        "source": "As various kinds of output devices emerged, such as highresolution printers or a display of PDA(Personal Digital Assistant), the importance of high-quality resolution conversion has been increasing. This paper proposes a new method for enlarging image with high quality. One of the largest problems on image enlargement is the exaggeration of the jaggy edges. To remedy this problem, we propose a new interpolation method, which uses artificial neural network to determine the optimal values of interpolated pixels. The experimental results are shown and evaluated. The effectiveness of our methods is discussed by comparing with the conventional methods.",
        "prediction": "As various output devices appeared, such as high-resolution printers and displays for Personal Digital Assistants (PDAs), the need for high-quality image resolution conversion has grown. This paper presents a new method for enhancing images with high quality. One major issue with image enlargement is the increase in jagged edges. To address this problem, we introduce a new method of interpolation, which uses artificial neural networks to find the best values for the pixels that are being added. The results from our experiments are shown and evaluated. We discuss the effectiveness of our methods by comparing them to traditional methods.",
        "reference": "The rise of output devices like high-resolution printers and PDA displays has increased the need for high-quality resolution conversion. The paper proposes a new method to make images bigger while maintaining high quality. The main issue with enlarging images is that jagged edges can become exaggerated. To solve this problem, we suggest a new method that helps us to estimate the value of the newly generated pixels using a neural network. The experiment's results are presented and analyzed. We evaluate the effectiveness of our methods by comparing them to traditional approaches."
      },
      {
        "source": "A significative percentage of the human population suffer from impairments in their capacity to distinguish or even see colours. For them, everyday tasks like navigating through a train or metro network map becomes demanding. We present a novel technique for extracting colour information from everyday natural stimuli and presenting it to visually impaired users as pleasant, non-invasive sound. This technique was implemented inside a Personal Digital Assistant (PDA) portable device. In this implementation, colour information is extracted from the input image and categorised according to how human observers segment the colour space. This information is subsequently converted into sound and sent to the user via speakers or headphones. In the original implementation, it is possible for the user to send its feedback to reconfigure the system, however several features such as these were not implemented because the current technology is limited.We are confident that the full implementation will be possible in the near future as PDA technology improves.",
        "prediction": "A significant number of people have difficulty in seeing or distinguishing colors. For these individuals, daily tasks like using a train or metro map can be challenging. We introduce a new method for obtaining color information from everyday visuals and conveying it to visually impaired users through enjoyable and non-intrusive sounds. This method has been applied in a Personal Digital Assistant (PDA), which is a small, portable electronic device. In this method, color information is taken from an image and categorized based on how humans perceive colors. This information is then turned into sound and delivered to the user through speakers or headphones. In the initial version, users could provide feedback to adjust the system, but some features like these were not implemented due to current technological limitations. We believe that a complete version will be feasible soon as PDA technology advances.",
        "reference": "A significant percentage of people have trouble differentiating or seeing colors. Simple tasks like using a train or subway map can be difficult for them. We introduce a new method to help visually impaired users perceive color information using non-invasive, pleasant sounds generated from everyday stimuli. We put this technique into a portable device called a Personal Digital Assistant (PDA). In this implementation, we extract color information from the input image and organize it based on how people perceive color. Then, the information is changed into sound and sent to the user through speakers or headphones. In the first version, the user could give feedback to change the system, but we couldn't add all the features due to technology limitations. We believe that we can add all the features soon as PDA technology advances."
      },
      {
        "source": "Inappropriate use of medicines increases the risk of hospital admissions for the elderly. Not only does this lead to unnecessary suffering for the patients but also incurs a great financial cost to the society. A medicine decision support system in a Personal Digital Assistant (PDA), with a barcode reader, can provide an overview of the patientsu0027 complete medicine use, and detect unsuitable drugs and drug combinations. Focusing on the elderly, our aim was to evaluate if a mobile medicine decision support system with a barcode reader is useful and user-friendly for nurses in home care. The participants received a comprehensive overview from the patientsu0027 medicine use and noted drug-drug interactions, therapeutic duplications and warnings for drugs unsuitable for elderly people. The nurses regarded that the decision support system increased prevention and safety, was useful and user-friendly. Our findings suggest that most of the content and functions were regarded as important. Therefore, this decision support system might be a useful tool for district nurses.",
        "prediction": "Inappropriate use of medicines increases the risk of hospital admissions for elderly people. This not only causes unnecessary suffering for patients but also leads to significant financial costs for society. A medicine decision support system in a Personal Digital Assistant (PDA), which is a handheld device for managing information, with a barcode reader can give an overview of patients' complete medicine use and identify unsuitable drugs and combinations of drugs. We focused on the elderly to evaluate whether a mobile medicine decision support system with a barcode reader is useful and easy to use for nurses in home care. The nurses received a comprehensive overview of patients' medicine use and noted interactions between drugs, unnecessary duplications of therapy, and alerts for drugs that are not suitable for elderly people. The nurses believed that the decision support system increased prevention and safety, and found it useful and easy to use. Our findings suggest that most of the content and functions were considered important. Therefore, this decision support system could be a helpful tool for district nurses.",
        "reference": "Misusing medicines can make older people more likely to end up in the hospital. This causes patient suffering and financial cost to society. A support system for medicine decision, with a bar code reader, in a PDA can help identify inappropriate medication use and combinations by providing a complete overview of the patient's medication The goal was to evaluate if a mobile medicine decision support system with a barcode reader is helpful and easy to use for home care nurses working specially with older patients. The participants were provided with a complete overview of the patient's medication usage, and identified any drug interactions, duplicated medications, and any warnings about drugs that are not suitable for elderly patients. The nurses found the decision support system to be helpful, and easy to use, and improving the prevention and safety measures. Our results indicate that the majority of the content and features were considered significant. So, this system could be helpful for district nurses."
      },
      {
        "source": " :[0],\"access to patient appointment schedules can help clinicians manage time and problems better. Many large health care organizations manage clinical appointment scheduling via enterprise resource scheduling systems which are poorly accessible by clinicians. Also, staff other than the clinicianu0027s personal assistant(s) may manage scheduling, making it difficult for clinicians to stay informed of changes. Many a clinician today uses a personal digital assistant (PDA) containing basic calendaring functionality. Our âPalmOversiteâ project demonstrates the feasibility of integrating enterprise appointment schedule information into a PDA calendar, making schedule information much more readily available to the clinician.",
        "prediction": "Access to patient appointment schedules can help clinicians manage their time and problems better. Many large health care organizations use enterprise resource scheduling systems to manage clinical appointment scheduling, but these systems are often not easily accessible to clinicians. In addition, staff members who are not personal assistants may handle scheduling, which can make it hard for clinicians to keep track of changes. Many clinicians today use a personal digital assistant (PDA), which is a handheld device that includes basic calendar features. Our \"PalmOversite\" project shows that it is possible to integrate information from enterprise appointment schedules into a PDA calendar, making schedule information much easier for clinicians to access.",
        "reference": "Knowing patients' appointment schedules can help clinicians manage time and problems more effectively. Healthcare organizations often use enterprise resource scheduling systems for clinical appointment scheduling, but these systems may not be easily accessible by clinicians. Moreover, scheduling may not only be handled by the clinician's assistant(s), creating challenges for clinicians to stay updated on any changes. Many clinicians today use a personal digital assistant (PDA) with a basic calendar. Our project called 'PalmOversite' shows the practicability of integrating enterprise appointment schedule information into a PDA calendar. This makes it easier for clinicians to access their schedule information."
      },
      {
        "source": "Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of multidrug-resistant tuberculosis (MDR-TB) patients in Peru, in conjunction with the Peruvian National TB Program (NTP). Monthly bacteriology tests, which must be collected from health establishments located across this major city, are an integral part of this treatment. Currently, a SES employee visits each health establishment to collect this information by hand, process it and type it into an electronic medical record system  this :[81],\"paper, we describe the development and implementation of a personal digital assistant (PDA)-based electronic system to collect, verify and upload monthly bacteriology data into the PIH-EMR. After an initial implementation period, we performed a pilot study to test the use of this system. We completed a baseline assessment in two health districts and then implemented the electronic system in one of the districts while the control site continued to use the paper-based system during the same period. The PDA-based system had a processing time of 6.2 days, significantly lower than measurements for both the baseline [54.8] and control sites [64.4] (both pu003c0.0001). It was also able to reduce the frequency of discrepancy from 10.1% to 2.8% (pu003c0.0001) and receive positive feedback from the users. Finally, the systemâs cost would be recuperated in three months from time savings due to increased work efficiency. This system will be the subject of a larger study to determine its impact on delays, errors and costs.",
        "prediction": "Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat most patients with multidrug-resistant tuberculosis (MDR-TB) in Peru, alongside the Peruvian National TB Program (NTP). Monthly bacteriology tests, which are important laboratory tests used to diagnose and monitor the treatment of tuberculosis, must be collected from health facilities in this large city. Currently, a SES employee goes to each health facility to gather this information by hand, process it, and enter it into an electronic medical record system. In this report, we describe the development and implementation of a personal digital assistant (PDA)-based electronic system to collect, verify, and upload monthly bacteriology data into the PIH Electronic Medical Record (PIH-EMR). After an initial period of putting the system into use, we conducted a pilot study to evaluate the effectiveness of this system. We did a baseline assessment in two health districts and then put the electronic system into use in one of the districts while the other site continued to use the paper-based system during the same time. The PDA-based system processed information in 6.2 days, which is significantly quicker than the times for both the baseline (54.8 days) and control sites (64.4 days). It also reduced the frequency of errors from 10.1% to 2.8% and received positive feedback from users. Finally, the system's costs would be recovered in three months due to time savings from increased work efficiency. This system will be part of a larger study to understand its effects on delays, errors, and costs.",
        "reference": "PIH (Partners In Health) and SES (Socios En Salud) provide treatment for most of the MDR-TB (multidrug-resistant tuberculosis) patients in Peru along with the Peruvian NTP (National TB Program). Monthly bacteriology tests are necessary for this treatment and must be collected from various health establishments located throughout the city. An employee from SES is currently going to each health establishment and collecting monthly bacteriology test results by hand, processing them, and typing them into an electronic medical record system. In this paper, we explain how we made a digital system using a personal digital assistant (PDA) to gather, check, and upload monthly bacteriology data into the PIH-EMR (Partners In Health Electronic Medical Record).  After an initial period of putting the system into action, we conducted a test study to evaluate the effectiveness of using this system. We first evaluated the current system in two health districts, then introduced the electronic system in one district while the other continued using the paper-based system during the same time. The PDA-based system took only 6.2 days to process, which was significantly lower than both the baseline (54.8) and control sites (64.4) (both less than 0.0001). The PDA-based system reduced differences from 10.1% to 2.8% and received positive feedback from users. The system would pay for itself in three months due to increased efficiency and time savings. A larger study will be conducted to assess the impact of this system on delays, errors, and costs."
      },
      {
        "source": "In order to facilitate knowledge transfer between specialists and generalists and between experts and novices, and to promote interdisciplinary communication, there is a need to provide methods and tools for doing so. This interdisciplinary research team developed and evaluated a decision support tool (DST) on a personal digital assistant (PDA) for cardiac tele-triage/tele-consultation when the presenting problem was chest pain. The combined human factors methods of cognitive work analysis during the requirements-gathering phase and ecological interface design during the design phase were used to develop the DST. A pilot clinical trial was conducted at a quaternary cardiac care hospital over a 3-month period. During this time, the DST was used by the nine nursing coordinators who provide tele-triage/tele-consultation 24/7. This clinical trial validated the design and demonstrated its usefulness to advanced cardiac care nurses, its potential for use by nurses less experienced in cardiac care, and for its potential use in an interdisciplinary team environment.",
        "prediction": "To help share knowledge between specialists and generalists and between experts and novices, and to improve communication across different fields, it is important to provide methods and tools for this purpose. A team of researchers created and tested a decision support tool (DST) on a personal digital assistant (PDA) for remote evaluation and consultation when someone reports chest pain. They used two main approaches: cognitive work analysis, which studies how people think and work together, during the requirements-gathering phase, and ecological interface design, which focuses on how to efficiently present information, during the design phase. A small clinical trial took place at a specialized cardiac care hospital over three months. During this time, nine nursing coordinators who offer remote evaluation and consultations used the DST around the clock. This clinical trial confirmed that the design works well and showed that it is useful for experienced cardiac care nurses and could also benefit less experienced nurses and interdisciplinary teams.",
        "reference": "To improve communication between specialists, generalists, experts, and novices and encourage interdisciplinary collaboration, we need to develop methods and tools. An interdisciplinary research team created and tested a decision support tool (DST) on a personal digital assistant (PDA) to aid cardiac tele-triage/tele-consultation for patients with chest pain. To create the DST (Decision Support Tool), we used both cognitive work analysis and ecological interface design methods during the requirements-gathering and design phases. A trial was done for 3 months at a quaternary cardiac care hospital During the trial, nine nursing coordinators used DST for 24/7 tele-triage/tele-consultation. This clinical trial confirmed that the design is useful for advanced cardiac care nurses, as well as for less experienced nurses and interdisciplinary teams."
      },
      {
        "source": "This paper presents M-CALL, a mobile computer-assisted language learning courseware for Korean language learners. Since conventional computer-assisted language learning is often boring, it exploits a cyber pet game to increase the learnerâs interest. M-CALL runs on a personal digital assistant with public wireless LAN for mobile learning. It grows a cyber pet by solving problems of Korean language learning. Korean Proficiency Test (KPT), a nationally certified Korean language test, was used as problem sets. It consists of cyber pet game, mobile learning courseware, mobile learning system, and mobile tutoring. It provides various functions for Korean language learning. Currently, the prototype M-CALL was designed and partly implemented between mobile PDA and personal computer.",
        "prediction": "This paper presents M-CALL, a mobile computer-assisted language learning courseware for Korean language learners. Since traditional computer-assisted language learning can often be uninteresting, it uses a game involving a virtual pet to enhance the learnerâs engagement. M-CALL operates on a personal digital assistant, commonly known as a PDA, connected to a public wireless local area network, abbreviated as LAN, for mobile learning. The game involves caring for a virtual pet by solving problems related to learning the Korean language. The Korean Proficiency Test, referred to as KPT, is a nationally recognized test for assessing proficiency in the Korean language and is used to create the problem sets. M-CALL includes a virtual pet game, mobile learning courseware, a mobile learning system, and mobile tutoring. It offers various functions tailored for learning the Korean language. Currently, the prototype of M-CALL has been designed and partially implemented to work between a mobile PDA and a personal computer.",
        "reference": "M-CALL is a mobile courseware for Korean language learners. It incorporates a cyber pet game to make it more engaging for learners than traditional computer-assisted language learning methods. M-CALL is a mobile learning system that uses a personal digital assistant with public wireless LAN (Computer network in small geographic areas). A cyber pet is raised while solving problems related to Korean language learning. The KPT, a nationally recognized exam for Korean language proficiency, served as the source material for the problem sets. It includes a virtual pet game, a mobile course for learning, a mobile learning platform, and mobile tutoring. It offers multiple features for learning Korean. Right now, a preliminary version of M-CALL has been developed and partially implemented for use on both mobile PDAs and personal computers."
      },
      {
        "source": "This study compared text entry performance of two stylus-driven soft keyboards for use in hand-held computing devices: the QWERTY and the T9. Participants transcribed text presented on a computer screen into a personal digital assistant (PDA) using a stylus and one of these two keyboards. We introduced a new psychophysical technique for measuring transcription rate that provides a composite measure of speed and accuracy. Using this technique, we calculated the maximum transcription rate for each keyboard. The results show that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9 keyboardâs apparent superior physical characteristics. An ancillary experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in visual scanning time due to perceptual grouping of the letters on the keys. Together these findings imply that the QWERTY keyboard layout remains the most effective of the currently available designs for stylus tapping on soft keyboards.",
        "prediction": "This study compared text entry performance of two stylus-driven soft keyboards for use in hand-held computing devices: the QWERTY and the T9. Participants copied text shown on a computer screen into a personal digital assistant, which is a type of mobile device, using a stylus, which is a pen-like tool. We introduced a new method for measuring how fast and accurately people can type. Using this method, we calculated the maximum transcription rate, which is the highest speed at which text can be entered, for each keyboard. The results show that people typed faster using the QWERTY keyboard than the T9, even though the T9 keyboard seemed to have better physical features. An additional experiment showed that the lower performance of the T9 layout might have been due to longer visual scanning time, which is the duration spent looking for letters, because of how the letters were arranged on the keys. Overall, these findings suggest that the QWERTY keyboard layout is still the most effective design for stylus tapping on soft keyboards.",
        "reference": "This study compared two onscreen keyboards, the QWERTY and the T9, for text entry performance on hand-held computing devices. Participants used a stylus to input text on a PDA using either a QWERTY or T9 keyboard in this study. We created a new way to measure transcription rate that considers both speed and accuracy together. We used this method to determine the fastest possible typing speed for each keyboard. The study found that the QWERTY keyboard had a higher transcription rate than the T9 keyboard, even though the T9 keyboard was physically better. Another test showed that the T9 keyboard's lower performance might be because the grouped letters on its keys require more visual scanning time. Overall, these results suggest that, among the current options, the QWERTY keyboard layout is still the most efficient for typing on touch screens with a stylus."
      },
      {
        "source": "The proliferation of mobile devices such as smart phones and Personal Digital Assistant (PDA) opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system). In Mcommerce systems, we still see many common components that we have in standard E-commerce applications, such as web servers and database servers. However, these new applications raise some unique challenges. For example, the limitations of mobile devices (e.g., small screen size and reduced CPU performance) implies that software development is partly different from desktop applications. Questions which are posed when designing M-commerce system include: âWhat kind of information do the users want to access via mobile devices?â, âHow can we provide useful applications with limited user input facility?â, âHow can we test a distributed M-commerce system?â In this paper, we discuss about some software development issues for mobile commerce systems from our experiences while developing an M-commerce system for tourists. Our prototype, easyHotel, is an useful software that allows booking hotel rooms via mobile phones.",
        "prediction": "The growth of mobile devices like smartphones and Personal Digital Assistants (PDAs) creates new opportunities for mobile E-commerce systems, commonly known as Mobile-commerce or M-commerce systems. In M-commerce systems, we still see many of the same components found in standard E-commerce applications, such as web servers and database servers. However, these new applications present some unique challenges. For example, the limitations of mobile devices, such as small screen sizes and lower CPU (Central Processing Unit) performance, mean that software development differs from desktop applications. Some questions that arise when designing an M-commerce system include: âWhat kind of information do users want to access via mobile devices?â âHow can we provide useful applications with limited user input options?â âHow can we test a distributed M-commerce system?â In this paper, we discuss software development issues for mobile commerce systems based on our experiences while developing an M-commerce system for tourists. Our prototype, easyHotel, is useful software that allows users to book hotel rooms via mobile phones.",
        "reference": "The increasing use of mobile devices like smartphones and PDAs provides opportunities for the development of new mobile e-commerce systems, also known as M-commerce (Mobile-commerce) systems. M-commerce systems share several components with traditional E-commerce applications, such as web servers and database servers. However, these new applications present some distinct challenges. For example, due to mobile devices' limitations, such as smaller screens and weaker processors (also called CPUs), software development for mobile applications is partially different from desktop applications. Designing an M-commerce system involves asking questions such as: \"What information do users want on mobile devices?\", \"How can we create useful apps with limited user input?\", and \"How do we test a distributed M-commerce system?\" In this paper, we share our experiences developing an M-commerce system for tourists and discuss software development issues for such systems. Our software prototype, easyHotel, is a helpful application enabling users to book hotel rooms through their mobile phones."
      },
      {
        "source": "It is widely acknowledged that information such as web content should be adapted for mobile platforms to account for restrictions in mobile environments. As emerging mobile platforms such as different kinds of Personal Digital Assistant (PDA) tend to vary largely in their capabilities, we suggest that adaptation should be platform-specific. Common approaches for content adaptation are automated conversion and explicit specification of adapted content, with a trade-off between quality and development/maintenance effort. As alternative avoiding this trade-off, we propose a simple object-oriented framework for content adaptation. To facilitate the use of this framework in the Web, we base our approach on the object-oriented WebComposition model and its XML-based implementation WCML. We apply our object-oriented approach to an example application to demonstrate how object-oriented specification of platform-adapted content reduces development/maintenance effort.",
        "prediction": "It is widely accepted that information like web content needs to be adjusted for mobile devices due to the limitations these platforms have. New mobile devices, such as different types of Personal Digital Assistants (PDAs), vary greatly in what they can do, so we recommend that adjustments be made specifically for each platform. Common methods for adapting content include automated conversion, which means changing content using software, and explicitly defining the adapted content, which involves manually making changes. These methods involve a trade-off between the quality of the content and the effort needed for development and maintenance. As an alternative to this trade-off, we suggest a simple framework based on object-oriented programming, which is a way of organizing software design. To make this framework usable on the web, we base our method on the object-oriented WebComposition model, which is a system for combining web content, and its XML-based implementation known as WCML. We demonstrate our object-oriented approach through a sample application to show that our method can lower the effort required for developing and maintaining platform-specific content.",
        "reference": "It is widely recognized that information, such as web content, should be adjusted for mobile platforms to accommodate the limitations of mobile environments. As new mobile platforms, such as various types of PDAs, differ significantly in their capabilities, we propose that adaptation should be tailored to each platform. Common methods for content adaptation involve automated conversion or explicitly specifying adapted content, balancing the trade-off between quality and the effort required for development and maintenance. Instead of making this trade-off, we suggest using a straightforward object-oriented framework for content adaptation. To make this framework more accessible for use on the web, we build our approach on the object-oriented WebComposition model and its implementation, WCML, which is an application of XML. We use our object-oriented framework in an example application to show how specifying platform-adapted content using an object-oriented approach can lower development and maintenance costs."
      },
      {
        "source": "In monitoring a patientu0027s real-time vital signs through Body Area Networks (BAN), rich data sources are communicated to medical practitioners. It is essential that data is delivered in timely-context aware manner. In this paper a system is designed for patients with cardiac disorders, with an emphasis on the design of the sensing device and communication scheme chosen. Several existing wearable physiological devices (Patient Sensing Device â PSD) used in the Healthcare systems are bulky in design and are not flexible and comfortable for the elderly patients. Presented is a unique flexible, as well as detachable PSD for the comfort of patients. Also discussed is a model for transmission, storage and processing of patient related data, which ensures periodic logging of patient data without saturating communication networks. A proof of concept prototype has been developed and implemented to enable transmission of Electrocardiogram (ECG) signal and body temperature of a patient, which can be expanded to include other vital signs. Communication between a mobile smart-phone and the ECG and temperature acquisition apparatus is implemented Bluetooth. The presented Data Management System â Periodic Model (DMS â PM) is designed to manage wireless interface of sensor units with the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a Smart phone making use of the existing GSM network.",
        "prediction": "In monitoring a patient's real-time vital signs through Body Area Networks (BAN), rich data sources are communicated to medical practitioners. It is essential that data is delivered in a timely and context-aware manner. In this paper, a system is designed for patients with cardiac disorders, focusing on the design of the sensing device and the chosen communication scheme. Several existing wearable physiological devices, referred to as Patient Sensing Devices (PSD), used in healthcare systems are bulky, inflexible, and uncomfortable for elderly patients. Presented is a unique flexible and detachable PSD for the comfort of patients. Also discussed is a model for the transmission, storage, and processing of patient-related data, which ensures periodic logging of patient data without overwhelming communication networks. A proof of concept prototype has been developed and implemented to enable the transmission of Electrocardiogram (ECG) signals and body temperature of a patient, with the potential to include other vital signs. Communication between a mobile smartphone and the ECG and temperature acquisition apparatus is implemented using Bluetooth, which is a wireless technology for exchanging data between devices over short distances. The presented Data Management System â Periodic Model (DMS â PM) is designed to manage the wireless interface of sensor units with the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or smartphone, utilizing the existing Global System for Mobile Communications (GSM) network.",
        "reference": "Medical practitioners can access a wealth of data sources by using Body Area Networks (BAN) to monitor a patient's real-time vital signs. A BAN refers to a network of wearable or implantable devices worn on or attached to the human body for various purposes. Timely and context-aware delivery of data is crucial. This paper presents a system specifically designed for patients with cardiac disorders, focusing on the design of the sensing device and communication scheme selected. Many of the current wearable physiological devices used in healthcare systems, known as Patient Sensing Devices (PSD), are bulky and uncomfortable for elderly patients due to their inflexible design. We introduce a unique Patient Sensing Device (PSD) that is both flexible and detachable, designed for patient comfort. We also propose a model for transmitting, storing, and processing patient-related data that ensures regular logging of data without overwhelming communication networks. We have developed and implemented a proof-of-concept prototype that can transmit a patient's Electrocardiogram (ECG) signal and body temperature, potentially expanding to other vital signs. Communication between a mobile smartphone and the ECG and temperature acquisition apparatus is achieved via Bluetooth. The Data Management System - Periodic Model (DMS - PM) introduced here is created to facilitate the wireless connection between sensor units and the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a smartphone, utilizing the existing GSM network."
      },
      {
        "source": "Advancement of wireless and mobile technology has enabled additional platforms to support learning in a single learning space. Current trend integrates usage of mobile terminals such as smart PDA (personal digital assistant) in a learning system. Such devices can communicate with wireless mobile terminal and realize the intelligence exchange with its surroundings [1]. A LOCH (Language Learning Outside the Classroom) system named One Day Trip is developed to assist overseas students to learn Japanese in real life situations with the help of a PDA. This paper proposes the implementation with Knowledge Management (KM) concepts in the system to aid the teacher and learners in the learning environment.",
        "prediction": "The advancement of wireless and mobile technology has created new platforms to support learning in one space. The current trend involves using mobile devices such as smart PDAs (personal digital assistants) in a learning system. These devices can communicate with wireless mobile technology and share information with their surroundings. A LOCH (Language Learning Outside the Classroom) system called One Day Trip has been developed to help international students learn Japanese in real-life situations using a PDA. This paper suggests implementing Knowledge Management (KM) concepts in the system to support teachers and learners in the learning environment.",
        "reference": "Wireless and mobile technology progress has allowed more platforms to facilitate learning within a unified space. The current trend is to use mobile devices, such as smart PDAs, in learning systems. These devices can communicate wirelessly with mobile terminals and exchange information with the surrounding environment One Day Trip is a language learning system called LOCH (Language Learning Outside the Classroom), designed to help foreign students learn Japanese in real-life situations using a PDA. This paper suggests incorporating Knowledge Management (KM) concepts in the One Day Trip system to support both the teacher and learners in the learning environment."
      },
      {
        "source": "In recent years, we have developed applications for teaching both wired and wireless networking. These applications have been written for the Cybiko personal digital assistant, an inexpensive alternative to other hardware. Unfortunately, the Cybiko PDA was recently discontinued. As a result, these applications had to be ported to other platforms to remain useful. Instead of porting each application to individual platforms, which would prove to be extremely time consuming because of other APIu0027s and networking protocols, we created the Vassar College Messaging Layer. This layer abstracts the Cybiko networking structure and interface, allowing Cybiko applications to be ported to other platforms with minimal code alteration.",
        "prediction": "In recent years, we have developed applications for teaching both wired and wireless networking. These applications were created for the Cybiko personal digital assistant, which is a low-cost alternative to other hardware. Unfortunately, the Cybiko PDA has been discontinued. As a result, these applications needed to be adapted for other platforms to remain useful. Instead of adapting each application to different platforms, which would be very time-consuming due to different application programming interfaces (APIs) and networking protocols, we created the Vassar College Messaging Layer. This layer simplifies the Cybiko networking structure and interface, allowing Cybiko applications to be adapted to other platforms with very little changes to the code.",
        "reference": "In recent years, we have created applications for teaching both wired and wireless networking. These applications are designed for the Cybiko personal digital assistant, which offers a cost-effective alternative to other hardware options. The Cybiko PDA was discontinued recently. Consequently, these applications needed to be adapted to other platforms to maintain their usefulness. To avoid the time-consuming task of porting each application to various platforms due to different APIs and networking protocols, we developed the Vassar College Messaging Layer. This layer simplifies the Cybiko networking structure and interface, making it easier to adapt Cybiko applications to different platforms without needing to make significant changes to the code."
      },
      {
        "source": "Unlike many other classes of hardware, smartcards do not have the ability to communicate securely with the user. Deprived of means to keep the owner informed, the positive properties of smartcards are difficult to utilize. We explore the area at the border between smartcards and other, more powerful (and thus more useful), machines. On the other side of this border we find the Personal Digital Assistant  :[66],\"our view, to be useful as an extension of the usersu0027 private sphere, a machine must at least have enough functionality and resources to create trustworthy digital signatures (to speak for the user, as it were). A less resourceful machine can merely act as a memory prothesis, helping the owner remembering addresses and phone  are :[121],\"designed to be tamper resistant, and as such they seem ideal as a minimal machine. However, trustworthy digital signatures can not be created by smartcards alone, simply because the user does not know what is given to the card for  :[163],\"order to be trusted--that is, being able to make trustworthy digital signatures--a smartcard must be supported by some infrastructure outside the card proper. We explore what must be included in such an infrastructure, and demonstrate that trustworthy digital signatures can in fact be made using a standard  :[211],\"argue that based on this fact, nontrivial distributed systems can be constructed by utilizing smartcards; a nontrivial system is one where holders of smartcards are \"first class citizens\". Asserting that a smartcard can act as a trusted machine gives new opportunities for designers of user-centric  that smartcards are :[257],\"here to stay, finding ways to apply them in constructive manners is prudent.",
        "prediction": "Unlike many other types of hardware, smartcards cannot communicate securely with the user. Without a way to keep the owner informed, it is difficult to use the positive features of smartcards effectively. We examine the area where smartcards meet other more powerful machines. On the other side, we find the Personal Digital Assistant (PDA). In our view, to be useful as an extension of the user's private life, a machine must have enough capability and resources to create trustworthy digital signatures, which means it can act on behalf of the user. A less capable machine can only help the owner remember addresses and phone numbers. Smartcards are designed to resist tampering, making them seem ideal as simple machines. However, they cannot create trustworthy digital signatures by themselves because the user does not know what is being sent to the card to be trusted. In order for a smartcard to be trusted and make reliable digital signatures, it must be supported by some kind of infrastructure outside the smartcard itself. We explore what should be included in this infrastructure and show that trustworthy digital signatures can indeed be created using a standard system. We argue that, based on this fact, complex distributed systems can be created using smartcards; a complex system is one where smartcard users are treated as equal participants. Claiming that a smartcard can function as a trusted machine opens up new opportunities for designers focused on user needs. Since smartcards are likely to remain relevant, it is wise to find ways to use them effectively.",
        "reference": "Smartcards lack the capability to communicate with the user in a secure manner, unlike other hardware classes. (Smart cards are small, portable devices that have a special chip inside. They can store and process information securely.) Without a way to keep the owner updated, it becomes challenging to take advantage of the useful features of smart cards. We look at how smart cards and powerful machines can be combined to make even better devices. We believe that Personal Digital Assistants (PDAs) are more useful than smartcards because they can extend the user's private sphere. PDAs have enough functionality and resources to create trustworthy digital signatures, which can speak for the user. A less resourceful machine can serve as a memory aid, assisting the owner in remembering addresses and phone numbers, such as [121]. These machines are designed to be tamper-resistant, making them suitable for a minimalistic purpose. To create trustworthy digital signatures, a smartcard needs support from infrastructure outside the card itself. This is because the user is not aware of what information is given to the card, making it impossible for the card to be trusted solely on its own. We investigate the necessary components of this infrastructure and show that reliable digital signatures can indeed be created using a standard method [211]. We propose that smartcards can be utilized to build nontrivial distributed systems, where smartcard holders are considered important participants or \"first class citizens\". Claiming that smartcards can function as trusted machines opens up fresh possibilities for designers focused on user-centric approaches. It is evident that smartcards are here to stay, so it is wise for designers to explore and implement them in meaningful ways."
      },
      {
        "source": "In this paper we present the main features of a system that we have developed and that provides a new kind of tele-assistance service to elderly people.apart from the functionalities offered by the current tele-assistance services, also provides a high quality, anywhere and at any time assistance. We rate the assistance as high quality because allows the monitoring of vital signs and a local detection of anomalous situations by the device that the person carries in real time. Therefore, it sends alarms autonomously when  this paper we :[84],\"explain the three main functionalities offered by AINGERU: universal assistance anywhere and at any time, monitoring of vital signs irrespective of location or time and remote monitoring by allowing authorized external persons to consult data about monitored persons using the Internet. Moreover we show how those functionalities are achieved by making use of PDAs (Personal Digital Assistant), wireless communication, Semantic Web, Web services and agent technologies.",
        "prediction": "In this paper we present the main features of a system that we have developed which provides a new kind of tele-assistance service to elderly people. Apart from the functionalities offered by current tele-assistance services, it also provides high quality assistance that is available anywhere and at any time. We rate the assistance as high quality because it allows the monitoring of vital signs and local detection of abnormal situations by the device that the person carries in real time. Therefore, it autonomously sends alarms when needed. In this paper we explain the three main functionalities offered by AINGERU: universal assistance anywhere and at any time, monitoring of vital signs regardless of location or time, and remote monitoring allowing authorized external persons to consult data about monitored individuals using the Internet. Moreover, we show how those functionalities are achieved by using PDAs (Personal Digital Assistants), wireless communication, Semantic Web (a web of data that enables machines to understand and respond to complex human requests), Web services (a method of communication between two electronic devices over a network), and agent technologies (software that acts on behalf of an individual or organization).",
        "reference": "This paper introduces a new tele-assistance service for elderly people that goes beyond existing services by offering high-quality assistance anywhere and anytime. Our system provides high-quality assistance because it allows real-time monitoring of vital signs and local detection of anomalous situations through the device carried by the person. We explain the three main functions of AINGERU in this paper: universal assistance anywhere and at any time, monitoring vital signs regardless of location or time, and remote monitoring that allows authorized external individuals to access data about monitored persons via the internet. We use PDAs, wireless communication, Semantic Web (aims to enhance the World Wide Web by adding meaning to the information available online), Web services, and agent technologies to achieve the aforementioned functionalities."
      },
      {
        "source": "Objective: To evaluate the effectiveness of a personal digital assistant (PDA)âbased clinical decision support system (CDSS) on nonsteroidal anti-inflammatory drug (NSAID) prescribing safety in the outpatient  :[26],\"The design was a randomized, controlled trial conducted in a university-based resident clinic. Internal medicine residents received a PDA-based CDSS suite. For intervention residents, the CDSS included a prediction rule for NSAID-related gastrointestinal risk assessment and treatment recommendations. Unannounced standardized patients (SPs) trained to portray musculoskeletal symptoms presented to study physicians. Safety outcomes were assessed from the prescriptions given to the SPs. Each prescription was reviewed by a committee of clinicians blinded to participant, intervention group assignment, and baseline or follow-up  :[108],\"Prescriptions were judged as safe or unsafe. :[26],\"The main outcome measure was the differential change in unsafe prescribing of NSAIDs for the intervention versus the control  :[135],\"At baseline, the mean proportion of cases per physician with unsafe prescriptions for the two groups was similar (0.27 vs. 0.29, p u003e 0.05). Controlling for baseline performance, intervention participants prescribed more safely than controls after receiving the CDSS (0.23 vs. 0.45 [F = 4.24, p u003c 0.05]). With the CDSS, intervention participants documented more complete assessment of patient gastrointestinal risk from  :[198],\"Participants provided with a PDA-based CDSS for NSAID prescribing made fewer unsafe treatment decisions than participants without the CDSS.",
        "prediction": "Objective To evaluate the effectiveness of a personal digital assistant PDA based clinical decision support system CDSS on nonsteroidal anti inflammatory drug NSAID prescribing safety in the outpatient The design was a randomized controlled trial conducted in a university based resident clinic Internal medicine residents received a PDA based CDSS suite For intervention residents the CDSS included a prediction rule for NSAID related gastrointestinal risk assessment and treatment recommendations Unannounced standardized patients SPs trained to portray musculoskeletal symptoms presented to study physicians Safety outcomes were assessed from the prescriptions given to the SPs Each prescription was reviewed by a committee of clinicians blinded to participant intervention group assignment and baseline or follow up Prescriptions were judged as safe or unsafe The main outcome measure was the differential change in unsafe prescribing of NSAIDs for the intervention versus the control At baseline the mean proportion of cases per physician with unsafe prescriptions for the two groups was similar 0.27 vs 0.29 p greater than 0.05 Controlling for baseline performance intervention participants prescribed more safely than controls after receiving the CDSS 0.23 vs 0.45 F equals 4.24 p less than 0.05 With the CDSS intervention participants documented more complete assessment of patient gastrointestinal risk from Participants provided with a PDA based CDSS for NSAID prescribing made fewer unsafe treatment decisions than participants without the CDSS",
        "reference": "We did a study to test if a clinical decision support system (CDSS) on a personal digital assistant (PDA) could improve the safety of prescribing nonsteroidal anti-inflammatory drugs (NSAIDs) in outpatient clinics. We conducted a randomized, controlled trial in a university-based resident clinic. Residents in internal medicine were given a CDSS suite based on PDA. Intervention residents were provided with a CDSS that had a prediction rule for assessing gastrointestinal risk related to NSAIDs and recommendations for treatment. Trained individuals, known as standardized patients (SPs), who were equipped with musculoskeletal symptoms, interacted with the physicians participating in the study without prior notification. The study evaluated the safety outcomes of prescriptions given to standardized patients portraying musculoskeletal symptoms. A committee of clinicians who didn't know about the participant, intervention group assignment, or the baseline or follow-up data reviewed each prescription. They determined whether a prescription was safe or unsafe. The study aimed to see if the PDA-based CDSS would result in a reduction of unsafe prescribing of NSAIDs. The main outcome measured the difference in unsafe prescribing between the intervention and control groups. At the beginning of the study, both groups had a similar proportion of unsafe prescriptions. (0.27 vs 0.29) After controlling for the baseline performance, it was found that those who received the CDSS suite prescribed nonsteroidal anti-inflammatory drugs more safely than those who didn't (0.23 vs 0.45, with statistical significance). Participants who had access to the CDSS through a PDA documented a more comprehensive assessment of gastrointestinal risk in patients. Moreover, the presence of the CDSS resulted in fewer unsafe treatment decisions compared to participants who did not have access to the CDSS."
      },
      {
        "source": "Recently pedestrian navigation has been studied by many researchers, which provides pedestrians with a similar function of car navigation. On the other hand, a 3dimensional (3D) map, which is one of major themes in machine vision research, has been utilized as a simulation tool in city and landscape planning, and other engineering fields. The 3D maps will give more intuitive information compared to conventional 2-dimensional (2D) ones. In this paper we first propose pedestrian navigation based on 3D maps, and describe technologies required and its use situations. Secondly we compare effectiveness of 2D and 3D maps for navigation by object search experiments under conditions: 3D maps with and without texture; display sizes corresponding to a mobile phone and PDA (Personal Digital Assistant). The experimental results show that 3D maps with texture on mobile phone display size, and 3D maps without texture on PDA display size are superior to 2D maps in search time and error rate. From these results, we can say the effectiveness of 3D maps in pedestrian navigation.",
        "prediction": "Recently, many researchers have studied pedestrian navigation, which helps people find their way in a manner similar to how car navigation systems work. At the same time, a three-dimensional (3D) map has become a major focus in machine vision research and is used as a simulation tool in city and landscape planning, as well as in other engineering fields. 3D maps provide more intuitive information compared to traditional two-dimensional (2D) maps. In this paper, we first propose pedestrian navigation using 3D maps and explain the necessary technologies and their applications. Next, we compare the effectiveness of 2D and 3D maps for navigation through object search experiments. The conditions for these experiments include 3D maps with and without texture, and display sizes related to a mobile phone and a Personal Digital Assistant (PDA). The experimental results indicate that 3D maps with texture on a mobile phone display and 3D maps without texture on a PDA display are better than 2D maps in terms of search time and error rate. From these results, we can confirm the effectiveness of 3D maps in pedestrian navigation.",
        "reference": "Recently many researchers have studied pedestrian navigation, which is similar to car navigation but designed for pedestrians. A 3D map is widely used in machine vision research and various engineering fields, such as city and landscape planning, as a simulation tool. 3D maps are more intuitive than 2D maps. In this paper, we suggest using 3D maps for pedestrian navigation and explain the necessary technology and possible scenarios for its application. We will conduct object search experiments to compare the effectiveness of 2D and 3D maps for navigation. The experiments will consider the following conditions: 3D maps with and without texture, and display sizes equivalent to a mobile phone and a Personal Digital Assistant (PDA). The results of the experiment suggest that 3D maps with texture on a mobile phone display and 3D maps without texture on a PDA display are better than 2D maps in terms of search time and error rate. Based on these results, we can conclude that 3D maps are effective for pedestrian navigation."
      },
      {
        "source": "Mobile agents are a competitive concept of client-server computing and are especially suitable in mobile environments, that are characterized by low bandwidth communication facilities and ad hoc connection/disconnection to stationary systems. They can be used for information retrieval and information filtering, in which case they evaluate replies and return only the relevant data. Mobile agents as a metaphor of active objects are created on a mobile device such as a Personal Digital Assistant (PDA), will be launched into the information galaxy and are fulfilling the mobile user âs task on the services available on networked stationary systems. One transmission channel for these itinerant agents is email. This paper introduces Active M 3 as an example of an active mail framework, which can be regarded as a first approach in authoring mobile agents in a graphical interactive manner. Active M 3 integrates two known concepts: active mail and multimedia mail.",
        "prediction": "Mobile agents are an advanced idea in client-server computing and work well in mobile settings. These settings often have low internet connection speeds and devices that connect and disconnect frequently from fixed systems. Mobile agents help with finding and filtering information. They assess responses they receive and bring back only the important data. Mobile agents are like active objects created on mobile devices, such as Personal Digital Assistants (PDAs). They are sent out into the vast world of information to perform tasks for mobile users using services available on connected stationary systems. Email is one way to transmit these traveling agents. This paper introduces Active M 3, an example of an active mail framework. This framework represents an initial effort in creating mobile agents in a user-friendly graphical way. Active M 3 combines two familiar ideas: active mail and multimedia mail.",
        "reference": "Mobile agents are a competitive concept in client-server computing, particularly well-suited for mobile environments. These environments are characterized by limited bandwidth communication and the frequent connection and disconnection to stationary systems. They can be utilized for information retrieval and filtering, where they assess responses and provide only the pertinent data. Mobile agents act like active objects that can be created on a mobile device like a PDA. They are sent out to perform tasks on the networked stationary systems and fulfill the user's needs. Email serves as a transmission channel for these mobile agents. This paper presents Active M 3, which is an active mail framework that allows users to create mobile agents using a graphical interface. Active M3 is a framework that combines two concepts: active mail and multimedia mail."
      },
      {
        "source": "Digital Video Broadcasting â Handheld (DVB-H) is a technology developed as an extension of Digital Video Broadcasting â Terrestrial (DVB-T) with additional features that make it suitable for delivery to mobile devices such as phones and Personal Digital Assistant (PDAs). This paper deals with the conditions of receiving digital video broadcast type services in mobile handheld devices. The DVB-H standard is introduced and the key technology elements on data link layer and physical layer are discussed in some details. Finally the DVB-H terminal and network design is described.",
        "prediction": "Digital Video Broadcasting â Handheld (DVB-H) is a technology built on Digital Video Broadcasting â Terrestrial (DVB-T) with extra features for mobile devices like phones and Personal Digital Assistants (PDAs). This paper examines how to receive digital video broadcasts on mobile handheld devices. The DVB-H standard is explained, and important technical aspects of the data link layer and physical layer are discussed in detail. Lastly, the design of DVB-H terminals and networks is described.",
        "reference": "DVB-H is a technology based on DVB-T that is designed for delivering content to mobile devices like phones and PDAs. This paper discusses how digital video broadcast services can be received on mobile handheld devices. The introduction of the DVB-H standard includes a discussion of key technology elements on the data link layer and physical layer, providing some detailed information. This paper also covers the design of DVB-H terminals and networks."
      },
      {
        "source": "Summary form only given, as follows. We present a design for a low cost but powerful and high speed communications device powered by IDTu0027s RV4640 as its processing engine. The device can achieve very high speed, thanks to the PCI bus compatible IDT ATM NIC. The device could be used as a two way pager, a set-top box, an Internet terminal, a personal digital assistant or as a video phone. The RV4640 is a very affordable 64 bit RISC processor that executes 175 dhrystone MIPS at 133 MHz. The RV4640 can be connected to a System Interface Chip which will provide I/O and memory control. The IDT77903 ATM card is a full duplexed 25 Mbps NIC with a PCI bus interface and it costs less than $100 (US). Integrating this card into our device as a network interface will make highspeed videoconferencing and multimedia applications easily implementable.",
        "prediction": "We present a design for a low-cost but powerful and high-speed communications device powered by IDT's RV4640 as its processing engine. The device can achieve very high speed due to the PCI bus compatible IDT ATM Network Interface Card (NIC). The device could be used as a two-way pager, a set-top box, an Internet terminal, a personal digital assistant, or as a video phone. The RV4640 is an affordable 64-bit Reduced Instruction Set Computer (RISC) processor that executes 175 Dhrystone MIPS at 133 MHz. The RV4640 can be connected to a System Interface Chip which will provide input/output (I/O) and memory control. The IDT77903 ATM card is a full duplexed 25 Megabits per second (Mbps) NIC with a Peripheral Component Interconnect (PCI) bus interface and it costs less than $100 (US). Integrating this card into our device as a network interface will make high-speed videoconferencing and multimedia applications easily implementable.",
        "reference": "Summary provided in the following. We propose a low-cost and high-speed communication device that uses IDT's RV4640 as the processing engine. This device is designed with IDT's RV4640 as the processing engine and can achieve high speed due to the PCI bus (a type of computer bus that simplifies the communication between computer components by providing a standardized interface) compatible IDT ATM NIC. This device can serve multiple purposes such as a two-way pager, set-top box, Internet terminal, personal digital assistant, or video phone. The RV4640 is a low-cost 64-bit RISC processor that runs at 133 MHz and can execute 175 dhrystone MIPS. The RV4640 can connect to a System Interface Chip for I/O (a specialized integrated circuit designed to facilitate communication between a computer system and its external devices) and memory control. The IDT77903 ATM card, which costs less than $100 (US), is a NIC with a PCI bus interface that is capable of full duplexing at 25 Mbps. Using the IDT77903 ATM card as a network interface in our device will make it easy to implement high-speed videoconferencing and multimedia applications."
      },
      {
        "source": "Dr. Who is a Microsoft research project aiming at creating a speech-centric multimodal interaction framework, which serves as the foundation for the NET natural user interface. The paper discusses MiPadu0027s design, implementation work in progress, and preliminary user study in comparison to the existing pen-based PDA interface. MiPad is the application prototype that demonstrates compelling user advantages for wireless personal digital assistant (PDA) devices, MiPad fully integrates continuous speech recognition (CSR) and spoken language understanding (SLU) to enable users to accomplish many common tasks using a multimodal interface and wireless technologies. It tries to solve the problem of pecking with tiny styluses or typing on minuscule keyboards in todayu0027s PDAs. Unlike a cellular phone, MiPad avoids speech-only interaction. It incorporates a built-in microphone that activates whenever a field is selected. As a user taps the screen or uses a built in roller to navigate, the tapping action narrows the number of possible instructions for spoken word understanding. MiPad currently runs on a Windows CE Pocket PC with a Windows 2000 machine where speech recognition is performed. The Dr Who CSR engine uses a unified CFG and n-gram language model. The Dr Who SLU engine is based on a robust chart parser and a plan-based dialog manager.",
        "prediction": "Dr Who is a Microsoft research project aiming to create a speech-centered system that allows users to interact using different methods. This system provides the basis for the NET natural user interface. The paper discusses the design of MiPad, the ongoing implementation work, and an early study comparing it to the existing pen-based personal digital assistant (PDA) interface. MiPad is a prototype application that shows clear advantages for wireless PDAs. It fully integrates continuous speech recognition (CSR), which allows devices to understand spoken language in real-time, and spoken language understanding (SLU), enabling users to complete various tasks using a combination of methods and wireless technology. MiPad seeks to address the inconvenience of using small styluses or tiny keyboards with current PDAs. Unlike a cellular phone, MiPad does not rely solely on speech interaction. It has a built-in microphone that activates when a user selects a field. As a user taps the screen or uses a built-in roller to navigate, the tapping action helps to narrow down the possible commands for understanding speech. MiPad currently operates on a Windows CE Pocket PC alongside a Windows 2000 machine where speech recognition takes place. The Dr Who CSR engine uses a unified context-free grammar (CFG) and an n-gram language model, while the Dr Who SLU engine relies on a detailed chart parser and a plan-based dialog manager.",
        "reference": "Dr. Who is a Microsoft research project that aims to create a speech-focused system for interacting with technology. This system will serve as the foundation for a natural user interface called NET. The paper discusses MiPad's design and implementation, which are still in progress, as well as a preliminary user study comparing it to existing pen-based PDA interfaces. MiPad is a prototype application that shows how wireless personal digital assistants (PDAs) can benefit from integrating continuous speech recognition (CSR) and spoken language understanding (SLU) technologies. This allows users to perform common tasks using a multimodal interface and wireless technology. It aims to solve the issue of having to use small styluses or type on tiny keyboards on modern PDAs. MiPad does not rely solely on speech interaction, unlike a cellular phone. MiPad has a built-in microphone that turns on when a field is selected. When a user taps the screen or utilizes a built-in roller for navigation, this action reduces the range of potential instructions for spoken word comprehension. MiPad is currently operating on a Windows CE Pocket PC, with speech recognition being carried out on a Windows 2000 machine. The Windows CE Pocket PC is a PDA that runs the Windows Embedded Compact operating system. The Dr Who CSR engine combines a CFG and an n-gram language model. The Dr Who SLU engine uses a chart parser and a plan-based dialog manager."
      },
      {
        "source": "Little is known about how viable new mobile applications emerge in complex commercial environments. Research in the sociology of technology suggests that the evolution of new applications is a process of social interaction between multiple constituencies, aiming to create a common definition of mobile technology problems and solutions that is obvious only in retrospect. This theory is illustrated by the early evolution of the personal digital assistant (PDA). According to this view, established technological communities attempt to impose their own definitions of key problems and solutions on new mobile technology, thereby forcing newer players to provide a \"total system\" that completely redefines a new application area.",
        "prediction": "Little is known about how new mobile applications become successful in complicated business environments. Research in the sociology of technology, which is the study of the social aspects of technology, indicates that the development of new applications involves social interaction among various groups. These groups work to establish a shared understanding of the problems and solutions related to mobile technology, which often becomes clear only after the fact. This idea is exemplified by the early development of the personal digital assistant, or PDA, which is a portable device that manages information. According to this perspective, established technological communities, which are groups with experience and knowledge in technology, try to enforce their own views on important issues and solutions for new mobile technologies. This pressure can compel new entrants to create a \"total system,\" which means a comprehensive solution that fundamentally changes the way a new application niche is understood.",
        "reference": "We don't know much about how new mobile apps succeed in complicated business environments. Research in the sociology of technology indicates that the development of new applications involves social interaction among different groups. These groups work together to establish a shared understanding of mobile technology challenges and solutions, which often becomes clear only in hindsight. The PDA's early evolution exemplifies this theory. This idea suggests that existing technology groups try to define the problems and solutions for new mobile tech, which puts pressure on new players to create a total system that redefines the application area."
      },
      {
        "source": "In the ubiquitous environment, mobile terminals like personal digital assistant or cellular phone are used to access the Web. We implemented the procedures in a ubiquitous/universal passive viewer (u-PaV) system that transforms Web content into passive viewing content that is especially useful for mobile terminals. Extracting images and text from Web content, u-PaV generates a Macromedia Flash file, which is a popular multimedia format. Although the presentation of Web content depends on the terminal type, the Web interface of mobile terminals is designed almost the same as that of personal computers. However, comparing mobile and desktop terminals, some difference in device characteristics, such as screen resolution or sound faithfulness, affect the presentation on the terminal. Moreover, when changing the access style between interactive and passive, the presentation should be adjusted for the terminal type because the lacking information is usually not perceived after transformation. To adjust the play style of Web content to the terminal type, we developed a method for visual presentation. First, using keyword analysis, we represent the emotional aspect of a Web page by adjusting the background color of the screen. Second, we emphasize the subject of the content by the logotype of the keyword. Third, we segment the picture of the content into pieces and present one after another using visual effects. These procedures can be applied to any type of terminal.",
        "prediction": "In the everywhere environment, mobile devices like personal digital assistants or cell phones are used to access the internet. We created processes in a universal passive viewer (u-PaV) system that changes internet content into passive viewing content that is especially helpful for mobile devices. By extracting images and text from internet content, u-PaV produces a Macromedia Flash file, which is a widely used multimedia format. Although how internet content is displayed depends on the device type, the internet interface of mobile devices is designed almost the same as that of personal computers. However, when comparing mobile and desktop devices, certain differences in device features, such as screen resolution or sound quality, influence how content is presented on the device. Additionally, when switching from interactive to passive access, the presentation should be modified for the device type because missing information is often not noticed after transformation. To adjust the display of internet content to the device type, we created a method for visual presentation. First, using keyword analysis, we show the emotional tone of a webpage by changing the background color of the screen. Second, we highlight the main topic of the content by using the logotype of the keyword. Third, we break the image of the content into parts and display them one after another using visual effects. These processes can be applied to any type of device.",
        "reference": "In the ubiquitous environment, devices like personal digital assistants or cell phones are used to access the Internet. We created a system called ubiquitous/universal passive viewer (u-PaV) that converts Web content into a format suitable for easy viewing on mobile devices. u-PaV takes text and images from the Web and creates a multimedia file in Macromedia Flash format, a widely used multimedia format. Mobile devices and personal computers have similar Web interfaces, although they may look different depending on the device. Mobile and desktop terminals have some differences in device characteristics, such as screen resolution and sound quality, which can affect how content is presented on the device. When switching between interactive and passive access styles, the presentation needs to be adjusted for the device type because some information may be lost during transformation and not noticed by the user. We developed a visual presentation method to customize how Web content is displayed based on the device type. First, we analyze keywords to capture the emotional tone of a web page and adjust the screen's background color accordingly. Then, we use the keyword's logo to highlight the main subject of the content. Finally, we divide the content's image into sections and present them one by one using visual effects. These steps can be used on any type of device."
      },
      {
        "source": "We have developed two-way location aware system, named as âThe Beijing Explorerâ, which exchanged positioning information and usersâ situation to one another using a PDA (Personal Digital Assistant) with built-in wireless LAN and a GPS (Global Positioning System) receiver in real time. Users can see their position and their chats on the screen of a PDA using the system real-timely. The system was used for the guidance of the Palace Museum (Forbidden City) in Beijing, China. We carried on experiments two times using the system. The results of experiments show that the service using positioning data and sharing contents were valuable and interesting. The correct positioning information is important for the guidance system.",
        "prediction": "We have developed a two-way location aware system named âThe Beijing Explorerâ which exchanged positioning information and user situations with each other using a PDA or Personal Digital Assistant. A PDA is a handheld device that combines computing and mobile phone features and includes built-in wireless LAN, which stands for Local Area Network, and a GPS or Global Positioning System receiver in real time. Users can see their position and their chats on the screen of a PDA using the system in real time. The system was used for guiding visitors in the Palace Museum, also known as the Forbidden City, in Beijing, China. We conducted experiments two times using the system. The results of the experiments show that the service using positioning data and sharing content was valuable and interesting. Correct positioning information is important for the guidance system.",
        "reference": "We created a location-aware system called \"The Beijing Explorer\" that uses a PDA with wireless LAN and GPS to exchange positioning and user information in real-time. Users can view their position and chats in real-time on the PDA screen when using the system. The system was used to guide visitors at the Palace Museum (Forbidden City) in Beijing, China. We conducted two experiments using the system. The experiment results indicate that the service was useful and engaging because it shared positioning data and content. Accurate positioning information is crucial for the guidance system."
      },
      {
        "source": "A truly personal machine, called a private machine and implemented as a Personal Digital Assistant (PDA), is fundamentally different from traditional machines. It is personal and private in an unprecedented manner, and its modus operandi is such that network and power failures will not be rare. Designing distributed systems where PDAs are treated as \"first class citizens\" is a  private :[59],\"assets (electronic money, keys for authentication and opening doors) will be stored in PDAs. Ownership and control of these :[59],\"assets and the media that store and communicate them should remain with the user. This must be reflected in the design of systems for private  :[105],\"introduce the \"open-ended argument\" to describe the design strategy we used for designing a system that is designed to reveal information to the user (as opposed to hide it). We argue and show that when systems are designed this way, the user (a human) is better able to control the system and his personal data, as he can make better decisions than the system itself based on qualitative assessment of the provided information. The system we have designed and implemented under this design guidelines is presented and discussed.",
        "prediction": "A truly personal machine called a private machine and implemented as a Personal Digital Assistant PDA is fundamentally different from traditional machines It is personal and private in a way that has not been seen before and its way of working is such that network and power failures will not be uncommon Designing distributed systems where PDAs are treated as first class citizens is essential Assets such as electronic money and keys for authentication and opening doors will be stored in PDAs Ownership and control of these assets and the media that store and communicate them should remain with the user This must be reflected in the design of systems for private applications We introduce the open-ended argument to describe the design strategy we used for creating a system that is meant to reveal information to the user rather than hide it We argue and show that when systems are designed this way the user a human is better able to control the system and their personal data as they can make better decisions than the system itself based on qualitative assessment of the provided information The system we have designed and implemented under these design guidelines is presented and discussed",
        "reference": "A Personal Digital Assistant (PDA) used as a private machine, is fundamentally distinct from traditional machines because it is a personalized device. It offers an unprecedented level of personal and private experience, and its operation is designed to handle network and power failures, which are expected to occur frequently. In designing distributed systems, PDAs are given high importance and treated as \"first class citizens\". This means that important assets like electronic money and authentication keys will be stored in PDAs. The user should retain ownership and control of these assets and the media that stores and communicates them. This principle should be incorporated into the design of private systems. We introduced the concept of the \"open-ended argument\" to describe our design strategy, which focuses on creating systems that are intended to provide information to the user rather than hiding it. We argue and demonstrate that when systems are designed in this manner, the user (a human) gains improved control over both the system and their personal data. By enabling users to make decisions based on qualitative assessment of the information provided, they are better equipped to make informed choices compared to relying solely on the system's automated decisions. We have created a system based on the design guidelines and we will explain it."
      },
      {
        "source": "Depression is under recognized in a variety of pediatric settings. The purpose of this paper is to describe the development and initial evaluation of a personal digital assistant (PDA)-based decision support system (DSS) for pediatric depression screening in ages 8 to 18 years of age by pediatric advanced practice nurse (APN) students. Three aspects are described: selection of depression screening instrument; integration of the instrument into the PDA; and quantitative (usage) and qualitative (focus group) evaluation. Only one third of eligible patients were screened. Twenty percent of those screened were identified as at risk for mood disorder. The barriers to screening identified through focus groups included a lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor motivation and comfort, as well as perceived or real cultural barriers. Suggestions for educational, research, and interventions to integrate clinical based PDA-based screening are discussed.",
        "prediction": "Depression is often not recognized in various pediatric environments. This paper aims to explain the creation and initial assessment of a personal digital assistant (PDA)-based decision support system (DSS) designed for screening depression in children and teenagers aged 8 to 18. Three main areas are discussed: choosing a tool to screen for depression; incorporating this tool into the PDA; and evaluating its use through quantitative (numeric data on how often it was used) and qualitative (feedback from focus groups) methods. Only one-third of the patients who could be screened were actually screened. Among those screened, 20% were found to be at risk for mood disorders, which are mental health issues that affect emotions. The focus groups revealed several barriers to screening, including not having enough time, not knowing enough about depression, lacking a guideline for intervention, not having referral resources, issues with how user-friendly the PDA was, and the motivation and comfort level of supervisors, as well as perceived or actual cultural obstacles. The paper discusses suggestions for education, research, and methods to better incorporate PDA-based screening into clinical practice.",
        "reference": "Depression often goes unnoticed in many pediatric settings. This paper aims to explain the creation and early assessment of a decision support system (DSS) that uses personal digital assistants (PDAs) for screening pediatric depression among children aged 8 to 18 years, carried out by pediatric advanced practice nurse (APN) students. Three aspects are discussed: choosing a depression screening tool, incorporating the tool into the PDA, and evaluating it through quantitative (usage) and qualitative (focus group) assessments. Only one third of eligible patients were screened. 20% of the screened patients were found to be at risk for a mood disorder. Barriers to screening were identified through focus groups, including lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor motivation and comfort, and cultural barriers. The paper discusses suggestions for integrating PDA-based screening into clinical practice through education, research, and interventions."
      },
      {
        "source": "This study explored the potential of the application of wireless and mobile computing technologies to be used in improving the efficiency of patient care and education and future developments in information and communication technologies to support healthcare professionals and medical students in healthcare research, medical education and training. The design used for this study was a systematic review of published materials obtained from EMBASE and MEDLINE online databases, and the Cochrane Library database, including personal observations. Today, more than 50% of healthcare professionals and medical students are using Personal Digital Assistant with expected growth of more than 75% by year-end 2007. In addition, wireless and mobile computing technologies allows Personal Digital Assistant to connect directly to networks or the Internet. Studies relating to processes of patient care and should evaluate mobile computing technologies as a potential timesaving tool. Wireless and mobile computing technologies is only beginning to take its first step in improving patient care and education. They have shown a positive impact on patient safety, health care efficiency, and ultimately patient satisfaction.",
        "prediction": "This study explored how wireless and mobile computing technologies can improve patient care, education, and future healthcare research for healthcare professionals and medical students. The study design was a systematic review, which means it looked at previously published materials from online databases like EMBASE and MEDLINE, as well as the Cochrane Library database, and included personal observations. Currently, more than 50% of healthcare professionals and medical students use Personal Digital Assistants (PDAs), with expected growth to over 75% by the end of 2007. Additionally, wireless and mobile computing technologies enable PDAs to connect directly to networks or the Internet. Research on patient care processes should assess mobile computing technologies as potentially saving time. Wireless and mobile computing technologies are just starting to improve patient care and education. They have shown positive effects on patient safety, healthcare efficiency, and overall patient satisfaction.",
        "reference": "This study examined how wireless and mobile computing technologies can enhance patient care and education. It also explored how advancements in information and communication technologies can support healthcare professionals and medical students in research, education, and training. We conducted a systematic review for this study, analyzing published materials from databases such as EMBASE, MEDLINE, and the Cochrane Library, as well as personal observations. Over 50% of healthcare professionals and medical students currently use Personal Digital Assistants, and this number is expected to grow by more than 75% by the end of 2007. Wireless and mobile computing technologies enable Personal Digital Assistants to connect directly to networks or the Internet. Studies should examine whether mobile computing technologies can save time in patient care processes. Wireless and mobile computing technologies are still in the early stages of improving patient care and education. These technologies have positively impacted patient safety, healthcare efficiency, and patient satisfaction."
      },
      {
        "source": "Nursing students can learn many things through practical training by experiencing actual medical practice and by coming in contact with patients. Therefore practical training is an effective learning opportunity for developing the practical nursing care ability of nursing students. Moreover, at hospitals, which are important training facilities, with regard to medical safety, the use of learning tools that produce electrical waves is not possible. So, we created a learning support environment that facilitates the imagination of nursing techniques, and enables effective preparation, review, and learning at anytime and anywhere using a portable digital assistant (PDA) device for practical training. As described in this paper, we report on the outline of the educational materials named \"digital nursing dictionary\" that we developed and the evaluation of the practices using it.",
        "prediction": "Nursing students can learn many things through practical training by experiencing real medical situations and interacting with patients. Therefore practical training is an effective way to develop the skills needed for nursing care. Additionally, hospitals are key facilities for training, but due to medical safety concerns, using learning tools that create electrical waves is not allowed. To address this, we created a supportive learning environment that encourages creativity in nursing techniques and allows for effective preparation, review, and learning anytime and anywhere using a portable digital assistant (PDA) device for practical training. In this paper, we describe the educational materials called \"digital nursing dictionary\" that we developed and evaluate the practices that used it.",
        "reference": "Nursing students can learn through practical training and by interacting with patients in real medical settings. Practical training is effective for developing the practical nursing care ability of nursing students. Moreover, hospitals, which are important training facilities, do not allow the use of learning tools that produce electrical waves due to medical safety concerns. We developed a learning support environment that helps nursing students visualize and practice techniques. It allows for convenient preparation, review, and learning using a portable digital assistant (PDA) device, enabling anytime and anywhere practical training. We developed an educational tool called the 'digital nursing dictionary' and evaluated its effectiveness, as outlined in this paper."
      },
      {
        "source": "Limitation in display size and resolution on mobile devices is one of the main obstacles for wide-spread use of web applications in a wireless environment. Web pages are often too large for a PDA (Personal Digital Assistant) screen to present. The same problem exists for devices with low resolution such as WebTV. Manual reconstruction of web pages for these devices would ease the problem; however, the large variation of display capabilities will greatly increase the burden of web page designers since they have to customize a web page for each possible display device. In this paper, we propose a document segmentation and presentation system. The system automatically divides a web document into a number of logical segments based on the screen size and the structure and content of the document. Additional information such as overviews and summaries is also extracted to facilitate navigation. The system presents the segments and structural information of a web document to make full use of the screen for information finding.",
        "prediction": "The limitation in display size and resolution on mobile devices is one of the main obstacles for the widespread use of web applications in a wireless environment. Web pages are often too large for a Personal Digital Assistant (PDA) screen to show. The same problem occurs for devices with low resolution, such as WebTV, which is a web-enabled television. Manually changing web pages for these devices would help the situation; however, the large differences in display capabilities would greatly increase the workload for web page designers since they would have to customize a web page for each possible display device. In this paper, we propose a document segmentation and presentation system. This system automatically divides a web document into several logical segments based on the screen size and the structure and content of the document. Additional information such as overviews and summaries is also extracted to help with navigation. The system displays the segments and structural information of a web document to make full use of the screen for finding information.",
        "reference": "Small screens and low resolutions on mobile devices are a major obstacle for the widespread adoption of web applications in a wireless environment. PDA screens are often too small to display entire web pages. Low-resolution devices like WebTV face the same problem. Manually reconstructing web pages for these devices would help, but the wide range of display capabilities would make it challenging for web page designers as they would have to customize each web page for every possible display device, increasing their workload. This paper suggests a system for segmenting and presenting documents. The system divides a web document into logical segments automatically, using information about the screen size, document structure, and content. The system also extracts summaries and overviews to make navigation easier. The system optimizes the use of the screen for information finding by showing the segments and structure of a web document."
      },
      {
        "source": "Take 8-bit microcontroller (C8051F005) as the nucleus and study a kind of voltage harmonic monitor device that satisfies the long-range monitor. The harmonic analysis algorithm adopts Fast Fourier Transform (FFT). This device has two work modes: ânativeâ and âremoteâ. It also can communicate with monitor center through telephone line, serial port, IC card, PDA (Personal Digital Assistant), etc.",
        "prediction": "Take an 8-bit microcontroller called C8051F005 as the central part and study a type of voltage harmonic monitor device designed for long-range monitoring. The device uses a method for analyzing harmonics called Fast Fourier Transform (FFT). This device has two modes of operation: \"native\" and \"remote\". It can also communicate with a monitoring center through various methods such as a telephone line, a serial port, an IC card, and a personal digital assistant (PDA).",
        "reference": "Study a voltage harmonic monitor device for long-range monitoring using the 8-bit microcontroller C8051F005 as the core. The harmonic analysis uses FFT. The device has two modes: \"native\" and \"remote\". It can communicate with a monitoring center via different methods such as telephone line, serial port, IC card, and PDA (Personal Digital Assistant)."
      },
      {
        "source": "With network and small screen device improvements, such as wireless abilities, increased memory and CPU speeds, users are no longer limited by location when accessing on-line information. We are interested in studying the effect of users switching from a large screen device, such as a desktop or laptop to use the same web page on a small device, in this case a PDA (Personal Digital Assistant). We discuss three common transformation approaches for display of web pages on the small screen: Direct Migration, Linear and Overview. We introduce a new Overview method, called the Gateway, for use on the small screen that exploits a userâs familiarity of a web page. The users in an initial study prefer using the Gateway and Direct Migration approach for web pages previously used on the large screen, despite the common Linear approach used by many web sites.",
        "prediction": "With improvements in networks and small screen devices like wireless capabilities, more memory, and faster CPU speeds, users can now access online information from anywhere. We want to study how users change from using a large screen device, such as a desktop computer or laptop, to accessing the same web page on a small device, specifically a PDA, which stands for Personal Digital Assistant. We will discuss three common methods for displaying web pages on small screens: Direct Migration, Linear, and Overview. We also introduce a new Overview method called the Gateway, which is designed for small screens and takes advantage of users' familiarity with a web page. In an initial study, users preferred the Gateway and Direct Migration methods for web pages they had previously used on large screens, even though many websites typically use the common Linear method.",
        "reference": "Improvements in network and small-screen devices, such as wireless capabilities, faster CPU speeds, and increased memory, have eliminated location restrictions for accessing online information. We want to study the impact of users switching from a desktop or laptop to a PDA (Personal Digital Assistant) when accessing the same web page. We are looking at three common ways to display web pages on small screens: Direct Migration, Linear, and Overview. Gateway is our new Overview method for small screens that use the user's familiarity with a web page. Many websites use the Linear method, but an initial study showed that users prefer using the Gateway and the Direct Migration method for web pages."
      },
      {
        "source": "The limitations and constraints of mobile systems need to be adequately addressed in software development. We have been developing a taxonomy of risks based on SEIu0027s risk questionnaire and applied it during the development of a negotiation support system for a Personal Digital Assistant (PDA). In our planned research, we will explore how we can better integrate existing risk management strategies and Agile Methods (AM).",
        "prediction": "The limitations and constraints of mobile systems need to be properly addressed in software development. We have been creating a classification of risks based on the Software Engineering Institute's (SEI) risk questionnaire and used it during the development of a negotiation support system for a Personal Digital Assistant (PDA). In our planned research, we will investigate how we can better combine existing risk management strategies and Agile Methods (AM).",
        "reference": "During software development, restrictions due to mobile systems need to be addressed. Based on SEI's risk questionnaire, we developed a classification of risks and applied it while developing a negotiation support system for a PDA. Risk management strategies and Agile Methods and how we can integrate them better will be studied in our future research."
      },
      {
        "source": "Expansions of mobile services and private data have required increased level of protection. Speaker recognition, one of the biometric technologies, arises lots of research interests for its simple, cheap and convenient characteristics. In this paper, a robust speaker recognition system which facilitates reliable authentication with multi-channel voices is presented. A large multi-channel corpus, including mobile phone, personal digital assistant (PDA), telephone and microphone, is collected to evaluate the system performance.",
        "prediction": "Expansions of mobile services and private data have required a higher level of protection. Speaker recognition, which is one of the biometric technologies that use physical characteristics for identification, has gained a lot of research interest because it is simple, inexpensive, and convenient. In this paper, a strong speaker recognition system that allows for reliable authentication using multiple voice sources is presented. A large collection of diverse voice recordings, including those from mobile phones, personal digital assistants (PDAs), telephones, and microphones, is gathered to assess the system's performance.",
        "reference": "The growth of mobile services and private data necessitates higher levels of protection. Speaker recognition, a technology using the voice of users to identify them, leads to a lot of research interest because of its simple, cheap, and convenient characteristics. This work presents a powerful speaker recognition system that makes the authentification with multi-channel voices easier. Data are collected on mobile phones, PDAs, telephones, and microphones to evaluate the system's performance."
      },
      {
        "source": "This paper presents a method to generate unique and nevertheless highly random pseudonyms in a distributed environment. More precisely, each user can now generate his pseudonym locally in his personal security environment, e.g. in his smart card or his personal digital assistant. There is no need for any information interchange between issuing parties or global data (especially keys), except unique identifiers for each user and each device of the system. Additionally the holder can prove, that he generated a specific pseudonym without revealing his identity and he can reveal his identity by disclosing the pseudonym. Whereas the verifier of a disclosed pseudonym can be sure, that the presenter of the pseudonym is the holder of the pseudonym (i.e. the person which originally generated it). The identifier of the user and the identifier of the useru0027s device will be used to generate unique pseudonyms, but to ensure pseudonymity, both components will be stored in the pseudonym in encrypted form.",
        "prediction": "This paper presents a method to create unique and highly random pseudonyms in a distributed environment. More precisely, each user can now generate their pseudonym locally in their personal security environment, such as in their smart card or personal digital assistant. There is no need for any information exchange between issuing parties or global data (especially keys), except for unique identifiers for each user and each device in the system. Additionally, the holder can prove that they created a specific pseudonym without revealing their identity, and they can disclose their identity by revealing the pseudonym. The verifier of a disclosed pseudonym can be sure that the person presenting the pseudonym is the holder of that pseudonym, meaning the person who originally generated it. The identifier of the user and the identifier of the user's device will be used to generate unique pseudonyms, but to ensure pseudonymity, both components will be stored in the pseudonym in encrypted form.",
        "reference": "This work presents a method to generate unique and random pseudonyms in a distributed system. Every user can now create his pseudonym locally in their own personal security environment, e.g. in his chip card or PDA. No information exchange is required between issuing parties or global data, except for unique identifiers for each user and device in the system. The holder can also prove that he generated a distinct pseudonym without revealing his identity; by divulging it, he can reveal his identity. In that case, the verifier of a divulgated pseudonym can be sure that the one who presents the pseudonym is holding it. (i.e. the person that originally created it) The user identifier and device's identifier will be used to create unique pseudonyms but to ensure anonymity with pseudonyms, both identifiers will be stored within the pseudonym in encrypted form."
      },
      {
        "source": "In todayu0027s mobile information society, location-based services play an increasingly important role. These services are to be accessed by users with a mobile end device for the use of city maps, route planning, navigation, or traffic information. Mobile end devices, however, do not have computing power or storage capacity comparable to that of a personal computer or laptop. These deficits can be bypassed by employing special methods in development of the respective applications. This paper outlines the experience gained in the development of a prototype for route computation in public transport networks to be used on a personal digital assistant. Subdivision of the route computation process into various steps for minimizing the computation expenditure on the mobile end device plays a significant role.",
        "prediction": "In today's mobile information society, location-based services are becoming very important. These services can be used by people with a mobile device for city maps, route planning, navigation, or traffic information. However, mobile devices do not have the same computing power or storage capacity as personal computers or laptops. These limitations can be addressed by using special methods in the development of the applications. This paper describes the experiences gained in creating a prototype for calculating routes in public transport networks to be used on a personal digital assistant, which is a type of handheld device. Dividing the route calculation process into different steps to reduce the computing load on the mobile device is very important.",
        "reference": "Location-based service's role in today's mobile information society is increasing . Users can access city maps, route planning, navigation, or traffic information with their mobile devices. Compared to laptops or personal computers, mobile devices do not have the same computing power or storage capacity. This shortage can be overcome by using specific methods during the development of the respective application. This paper shows the gained experience from developing a prototype designed for a PDA that calculates routes in public transport networks. Dividing the route computation process into multiple steps to reduce the computational load on the mobile device is crucial."
      },
      {
        "source": "DIANE is a digital assistant system that aims to fasten the doctor access to various informations at the hospital such as health care facility, medical records, and also human resource data. The fasten access could be achieved by implementing face recognition and live streaming as part of the digital assistant system.",
        "prediction": "DIANE is a digital assistant system that aims to speed up doctors' access to various information at the hospital, such as healthcare facility details, medical records, and human resource data. The quicker access could be achieved by using face recognition, which is a technology that identifies individuals by their facial features, and live streaming, which means broadcasting real-time video, as part of the digital assistant system.",
        "reference": "DIANE is a digital assistant system that allows the doctor a faster access patient and hospital information. This could be done with face recognition and live streaming."
      },
      {
        "source": "Digital assistants are emerging to become more prevalent in our daily lives. In interacting with these assistants, users may engage in multiple tasks within a short period of time.",
        "prediction": "Digital assistants are becoming more common in our everyday lives. When using these assistants, users can complete several tasks in a brief amount of time.",
        "reference": "Digital assistants are becoming popular in our daily lives. It will allow users to do multiple tasks in a faster way."
      },
      {
        "source": "As extensive experimental research has shown individuals suffer from diverse biases in decision-making. In our paper we analyze the effects of decision-making biases of managers in collaborative decision processes on organizational performance. In the simulations, managerial decisions which are based on different levels of organizational complexity and different incentive systems suffer from biases known from descriptive decision theory. The results illustrate how biases in combination with each other and in different organizational contexts affect organizational performance. We find that, contrary to intuition, some combinations of biases significantly improve organizational performance while these biases negatively affect organizational performance when they occur separately. This might evoke considerations whether decision-making should be as rational as possible.",
        "prediction": "Extensive research has shown that individuals experience various biases when making decisions. In our paper, we examine how these decision-making biases affect managers during group decision processes and how this impacts the performance of organizations. In our simulations, we observe that managerial decisions, influenced by different levels of complexity within the organization and various incentive systems, exhibit biases identified in a field called descriptive decision theory. The results demonstrate how these biases, both when combined and in different organizational settings, influence the overall performance of organizations. Surprisingly, we found that certain combinations of biases can actually enhance organizational performance, while these same biases can harm performance when they occur alone. This raises questions about whether decision-making should strive to be as rational as possible.",
        "reference": "Research showed that people suffer from diverse biases (disproportionate weight in favor of or against an idea) in decision-making. We analyzed the effects of decision-making biases of managers on organizational performance. In the simulations, managers decisions which are based on organizational skills and rules, suffer from several known biases. The results illustrate how combined biases in different contexts affect organizational performance. Contrary to expectations, some combinations of biases improve organizational performance. However, when they occur separately, they decrease performance. This raises questions about the importance of rationality in decision-making."
      },
      {
        "source": "Big data, the enhanced ability to collect, store and analyze previously unimaginable quantities of data in tremendous speed and with negligible costs, delivers immense benefits in marketing efficiency, healthcare, environmental protection, national security and more. The central tenets of the current privacy framework, the principles of data minimization and purpose limitation, are severely strained by the big data technological and business reality. As we increasingly interact with these artificial agents in unsupervised settings, with no human mediators, their seeming autonomy and increasingly sophisticated functionality and behavior, raises legal and philosophical questions. The focus on the machine is a distraction from the debate surrounding data driven ethical dilemmas, such as privacy, fairness and discrimination. The machine may exacerbate, enable, or simply draw attention to the ethical challenges, but it is humans who must be held accountable. Policymakers should seek to devise agreed-upon guidelines for ethical data analysis and profiling. Such guidelines would address the use of legal and technical mechanisms to obfuscate data; criteria for calling out unethical, if not illegal, behavior; categories of privacy and non-privacy harms; and strategies for empowering individuals through access to data in intelligible form.",
        "prediction": "Big data refers to the improved ability to gather, keep, and examine extremely large amounts of information quickly and at low costs. It provides significant advantages in areas such as marketing efficiency, healthcare, environmental protection, national security, and more. The key ideas in today's privacy laws, known as data minimization and purpose limitation, are being challenged by the realities of big data technology and business practices. As we increasingly interact with artificial agentsâcomputer systems that operate without human oversightâtheir apparent independence and increasingly advanced functions raise important legal and philosophical questions. Focusing too much on the machines distracts from important discussions about ethical dilemmas linked to data, such as privacy, fairness, and discrimination. While machines might worsen or highlight these ethical issues, it is humans who should be held responsible. Policymakers should create agreed-upon rules for ethical data analysis and profiling. These rules would include the use of legal and technical methods to conceal data, standards for identifying unethical or illegal actions, classifications of privacy and non-privacy harms, and ways to empower people by giving them access to their data in a clear format.",
        "reference": "Big data (the ability to collect, store and analyze huge quantities of data in a really fast and cheap way) offers immense benefits in marketing, healthcare, environment, national security and more. The principles of privacy, limitation of data collection and use are stretched by the business and technological reality of big data. Our increasing interactions with these technologies without human supervision, and their growing autonomy, functionality and behavior raises legal and philosophical questions. The focus on the machine is a distraction from the debate on ethical dilemmas about data like privacy, fairness and discrimination. The machine may influence the ethical challenges, but the humans must remain responsible. Responsible people should find guidelines for ethical data analysis and collection. These guidelines would deal with mechanisms to protect data, criteria about unethical or illegal behavior, privacy harms, and strategies to give people access to data."
      },
      {
        "source": "Amazon's Echo, and Apple's Siri have drawn attention from different user groups; however, these existing commercial VUIs support limited language options for users including native English speakers and non-native English speakers. we conducted a usability study of the Google Home Smart Speaker with 20 participants including native English and non-native English speakers to understand their differences in using the Google Home Smart Speaker. The findings show that compared with their counterparts, the native English speakers had better and more positive user experiences in interacting with the device. It also shows that users' English language proficiency plays an important role in interacting with VUIs. The findings from this study can create insights for VUI designers and developers for implementing multiple language options and better voice recognition algorithms in VUIs for different user groups across the world.",
        "prediction": "Amazon's Echo and Apple's Siri have attracted attention from different groups of users. However, these existing commercial Voice User Interfaces (VUIs) support limited language options for users, including both native English speakers and non-native English speakers. We conducted a usability study of the Google Home Smart Speaker with 20 participants, including both native and non-native English speakers, to understand their differences in using the device. The findings show that, compared to their counterparts, the native English speakers had better and more positive experiences when interacting with the device. It also shows that a user's proficiency in the English language plays an important role in how they interact with VUIs. The findings from this study can provide insights for VUI designers and developers to implement multiple language options and improve voice recognition algorithms in VUIs for various user groups around the world.",
        "reference": "The VUIs (voice user interface) like Amazonâs Echo or Appleâs Siri are popular nowadays. However, they have limited language options for users. We studied the usability of the Google Home Smart Speaker with native and non-native English speakers to understand their differences in using this device. The results show that the native English speakers had a better experience with the device than the non-native. It also shows that language skills play an important role. The results of this study can help VUI developers for improving language options and voice recognition in the devices."
      },
      {
        "source": "the smart speakers cannot distinguish human voice from machine voice. a method to identify which of human or machine is sending voice commands to a smart speaker is desired. to prevent such machine-voice based attacks to a smart speaker in absence of residents, we propose a system consisting of a speaker and a microphone array to detect the existence of a human nearby, supposing it can be incorporated in a smart speaker in the future.",
        "prediction": "Smart speakers are unable to tell the difference between a human voice and a machine-generated voice. There is a need for a method to identify whether a human or machine is giving voice commands to a smart speaker. To prevent attacks using machine voices when residents are not present, we propose a system that includes a speaker and a microphone array. This system would detect if a human is nearby and could potentially be integrated into a smart speaker in the future.",
        "reference": "The smart speakers cannot differentiate between human voice and machine voice. A method to identify if the voice command is from a human or a machine is required. We propose a system composed of a speaker and microphones to detect the presence of humans. It could help to prevent attacks on a smart speaker with a machine voice in absence of residents"
      },
      {
        "source": "As smart speakers with voice interaction capability permeate continuously in the world, more and more people will gradually get used to the new interaction mediumâvoice. Although speech recognition, natural language processing (NLP) have been greatly improved over the past few years, users still may encounter errors from time to time like âcannot understandâ, âno requested audio resource (such as music)â, which can frustrate users. Therefore, when an error message is reported, it is vital that the smart speaker gives an effective and proper response. However, currently the response strategies adopted by leading smart speaker brands in China differed mainly on two dimensions: âapology or notâ and âhumor or neutralâ. We explored userâs preference of response strategies under two error scenariosâââcannot understandâ and âno requested audio resourceâ. Two dependent variables (satisfaction and perceived sincerity of response) were measured. The results showed that participants were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios. In the âno requested audio resourceâ scenario, humor had no significant impact on the perception of satisfaction and sincerity. But in the âcannot understandâ scenario, humorous expression decreased perceived sincerity.",
        "prediction": "As smart speakers that can interact using voice become more common around the world, more people will start to use this new way of interactingâvoice. Even though technologies like speech recognition, which is the ability of a program to recognize and understand spoken words, and natural language processing (NLP), which helps computers understand and respond to human language, have greatly improved in recent years, users may still experience errors sometimes, such as âcannot understandâ or âno requested audio resourceâ (like music), which can be frustrating. Therefore, when an error message appears, it is important for the smart speaker to provide a helpful and appropriate response. However, the response strategies used by the leading smart speaker brands in China mainly differ in two ways: whether or not they include an apology and whether they use humor or a neutral tone. We looked at user preferences for response strategies in two error situations: âcannot understandâ and âno requested audio resource.â We measured two dependent variables: satisfaction, which refers to how pleased users are, and perceived sincerity of the response, which means how genuine the response seems to users. The results showed that participants were more satisfied and felt a higher level of sincerity when the smart speaker apologized in both error situations. In the âno requested audio resourceâ situation, using humor did not significantly affect users' feelings of satisfaction and sincerity. However, in the âcannot understandâ situation, a humorous response reduced how sincere the users perceived the response to be.",
        "reference": "Smart speakers are becoming popular around the world and people will get used to this new way of interacting with the voice. Even with the progress of speech recognition and natural language processing (interactions between computers and human language), users may still get errors like âcannot understandâ or âno requested audio resourceâ which can frustrate users. So, it is important that the smart speaker gives an effective and proper response during an error message. The responses of the most popular brand of smart speakers are based on 2 elements, apology and humor. We studied userâs preference in two error scenarios : âcannot understandâ and âno requested resourceâ Satisfaction of the user and perceived sincerity of the response were measured. The results showed that users were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios. In the âno requested audio resourceâ scenario, humor had no impact on the satisfaction or sincerity. But in the âcannot understandâ scenario, humor decreased perceived sincerity."
      },
      {
        "source": "A pharmacophore analysis approach was used to investigate and compare different classes of compounds relevant to the drug discovery process (specifically, drug molecules, compounds in high throughput screening libraries, combinatorial chemistry building blocks and nondrug molecules). Significant differences were observed between the pharmacophore profiles obtained for the drug molecules and those obtained for the high-throughput screening compounds, which appear to be closely related to the nondrug pharmacophore distribution. It is suggested that the analysis of pharmacophore profiles could be used as an additional tool for the property-based optimization of compound selection and library design processes, thus improving the odds of success in lead discovery projects.",
        "prediction": "A pharmacophore analysis approach was used to study and compare different types of chemical compounds important in drug discovery. This includes drug molecules, compounds used in high throughput screening libraries, building blocks from combinatorial chemistry, and compounds that are not drugs. Significant differences were found between the pharmacophore profiles of drug molecules and those of high-throughput screening compounds, which seem to be closely linked to the distribution of nondrug pharmacophores. It is suggested that analyzing pharmacophore profiles could serve as an extra tool for optimizing the selection of compounds and designing libraries, thus increasing the chances of success in finding lead compounds for drug development.",
        "reference": "A pharmacophore analysis investigated and compared different compounds of the drug discovery process. Significant differences were observed between the pharmacophore profiles of the drug molecules and the high-throughput screening compounds, which appear to be related to the nondrug pharmacophore distribution. It is suggested that the analysis could be used as an additional tool for the optimization of compound selection and library design processes.."
      },
      {
        "source": "Annotation of bioassay protocols using semantic web vocabulary is a way to make experiment descriptions machine-readable. Protocols are communicated using concise scientific English, which precludes most kinds of analysis by software algorithms. Given the availability of a sufficiently expressive ontology, some or all of the pertinent information can be captured by asserting a series of facts, expressed as semantic web triples (subject, predicate, object). With appropriate annotation, assays can be searched, clustered, tagged and evaluated in a multitude of ways, analogous to other segments of drug discovery informatics. The BioAssay Ontology (BAO) has been previously designed for this express purpose, and provides a layered hierarchy of meaningful terms which can be linked to.",
        "prediction": "Annotation of bioassay protocols using semantic web vocabulary is a method that makes descriptions of experiments understandable by machines. Bioassay protocols are described in clear scientific English, which limits the ability of software programs to analyze them. When there is a detailed structure, known as ontology, information can be captured by stating facts in the form of semantic web triples, which consist of three parts: subject, predicate, and object. With the right annotations, assays can be searched, grouped, labeled, and assessed in many ways, similar to other areas of drug discovery informatics. The BioAssay Ontology (BAO), which is a structured set of terms related to bioassays, was specifically created for this purpose and offers a multi-layered organization of meaningful terms that can be connected to.",
        "reference": "Annotation of bioassay protocols with web vocabulary can make experiment descriptions machine-readable. Protocols use concise scientific English which prevents most of analysis by software algorithms. There is a sufficient ontology, so the pertinent information can be written using semantic web triples (subject, predicate, object). With appropriate annotation, assays can be searched, clustered, tagged and evaluated. The BioAssay Ontology (BAO) has been designed for this purpose, and provides many meaningful terms."
      },
      {
        "source": "Next generation sequencing (NGS) produces massive datasets consisting of billions of reads and up to thousands of samples. Subsequent bioinformatic analysis is typically done with the help of open source tools, where each application performs a single step towards the final result. This situation leaves the bioinformaticians with the tasks to combine the tools, manage the data files and meta-information, document the analysis, and ensure reproducibility.",
        "prediction": "Next generation sequencing, or NGS, is a technology that can analyze DNA and produces large amounts of data consisting of billions of sequences and many samples. After this data is generated, bioinformatic analysis is usually carried out using open source tools. These are software applications that are freely available for anyone to use, where each tool is designed to carry out a specific step in the analysis process. This means that bioinformaticians, who are specialists in handling biological data, must combine these different tools, manage the data files and additional information about the data, write down the steps of their analysis, and make sure their results can be repeated by others.",
        "reference": "Next generation sequencing (NGS) produces datasets of billions of reads and thousands of samples. The analysis is typically done with open source tools, performing a single step towards the final result. The bioinformaticians have to combine the tools, manage the files and information, document the analysis, and ensure reproducibility."
      },
      {
        "source": "SPSS Clementinel2.0 statistical software was used to mine the association rules between Etiology and traditional Chinese medicine (TCM), Syndromes and TCM, Symptoms and TCM. The classic Apriori algorithm is useful to mine cases of influenza treated by contemporary famous old Chinese medicine.",
        "prediction": "SPSS Clementine 2.0 is a type of statistical software used to discover the relationships between Etiology, which is the study of the causes of diseases, and traditional Chinese medicine (TCM). It also examines the relationships between Syndromes, which are a group of symptoms that consistently occur together, and TCM, as well as between Symptoms, which are signs of a condition or disease, and TCM. The classic Apriori algorithm is a method used in data mining that helps to find common patterns in data. This algorithm is particularly useful in studying cases of influenza that are treated with methods from well-known traditional Chinese medicine practitioners.",
        "reference": "SPSS Clementinel2.0 statistical software was used to extract data and find relations between traditional Chinese medicine and other medicine. The classic Apriori algorithm is useful to find cases of influenza treated by old Chinese medicine."
      },
      {
        "source": "Identifying antimicrobial resistant (AMR) bacteria in metagenomics samples is essential for public health and food safety. Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and constructing the correlations between genotype and phenotype in humans and other species. a Bayesian framework for genotype estimation for mixtures of multiple bacteria, named as Genetic Polymorphisms Assignments (GPA) has reduced the false discovery rate (FDR) and mean absolute error (MAE) in single nucleotide variant (SNV) identification.",
        "prediction": "Identifying antimicrobial resistant (AMR) bacteria in metagenomics samples is essential for public health and food safety. Next-generation sequencing (NGS) technology has provided a powerful tool for identifying genetic variation and constructing the connections between genetic makeup (genotype) and observable traits (phenotype) in humans and other species. A Bayesian framework for estimating genetics in mixtures of multiple bacteria, named Genetic Polymorphisms Assignments (GPA), has reduced the false discovery rate (FDR) and mean absolute error (MAE) in identifying single nucleotide variants (SNV).",
        "reference": "Identifying bacterias that are resistant to antimicrobial in samples of genetic material collected from the environment is essential for public health and food safety. Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and constructing the correlations between genotype (genetic code of an individual) and phenotype (physical characteristics of an indvidual) in humans and other species. The Genetic Polymorphism Assignements (GPA) is a framework which determines the genetic constitution of multiple bacteria while reducing the number of false positive results and improving the accuracy of calculations when identifying the variation of a single nucleotide."
      },
      {
        "source": "The CRISPR/Cas9 system was recently developed as a powerful and flexible technology for targeted genome engineering, including genome editing (altering the genetic sequence) and gene regulation (without altering the genetic sequence). These applications require the design of single guide RNAs (sgRNAs) that are efficient and specific. However, this remains challenging, as it requires the consideration of many criteria.",
        "prediction": "The CRISPR/Cas9 system was recently developed as a powerful and flexible technology for targeted genome engineering. Genome engineering includes genome editing, which is the process of altering the genetic sequence, and gene regulation, which is managing gene activity without changing the genetic sequence. These applications require the design of single guide RNAs, known as sgRNAs, that are efficient and specific. However, this task remains challenging because it involves considering many criteria.",
        "reference": "The CRISPR/Cas9 system is a powerful technology for gene editing and gene regulation. These applications require the design of single guide RNAs (which are enzymes that can delete, insert or alter DNA) that are efficient and specific. However, this remains challenging, as it requires the consideration of many criteria."
      },
      {
        "source": "The hidden connection between these reports is that gene editing could be used to solve issues related to health care allocation. Improving the health of future generations might coincide with public health goals; it might improve the health of individuals and communities, and, if successful, might be seen as a public good. However, enhancing future generations will require In Vitro Fertilisation and Pre-implantation Genetic Diagnosis. Remarkably, the necessary involvement of women in an enhancing scenario has not been discussed by its proponents. The present discourse on moral obligations of future generations, although not referring to women, seems to imply that women might be required, morally, if not legally, to reproduce with IVF. Enhancing future generations will be gendered, unless the artificial womb is developed. These are challenging issues that require a wider perspective, of both women and men. Despite the lack of a unified feminist conclusion in the discussions about the merits and risks of human genome modification, there is an urgent need to clarify the role of women in this scenario.",
        "prediction": "The hidden connection between these reports is that gene editing could be used to solve issues related to health care allocation. Gene editing refers to the process of making changes to the DNA of an organism, which can help correct genetic disorders or enhance certain traits. Improving the health of future generations might coincide with public health goals; it might improve the health of individuals and communities, and, if successful, might be seen as a public good. However, enhancing future generations will require In Vitro Fertilisation, which is a medical procedure where an egg is fertilized by sperm outside the body, and Pre-implantation Genetic Diagnosis, which involves testing embryos for genetic disorders before implantation. Remarkably, the necessary involvement of women in an enhancing scenario has not been discussed by its proponents. The present discourse on moral obligations of future generations, although not referring to women, seems to imply that women might be required, morally, if not legally, to reproduce with IVF. Enhancing future generations will be gendered, meaning it will involve specific roles for different genders, unless the artificial womb is developed. An artificial womb is a device that can support the growth of a fetus outside a biological motherâs body. These are challenging issues that require a wider perspective, of both women and men. Despite the lack of a unified feminist conclusion in the discussions about the merits and risks of human genome modification, there is an urgent need to clarify the role of women in this scenario.",
        "reference": "Gene editing could be used to solve issues related to health care allocation. Improving the health of future generations might coincide with public health goals. However, enhancing future generations will require In Vitro Fertilisation (IVF) and Pre-implantation Genetic Diagnosis. The necessary involvement of women in an enhancing scenario has not been discussed. The discourse on moral obligations of future generations seems to imply that women might be required to reproduce with IVF. Enhancing future generations will be gendered, unless the artificial womb is developed. These are challenging issues that require a wider perspective, of both women and men. There are no unified feminist conclusion about the merits and risks of human genome modification. There is also an urgent need to clarify the role of women in this scenario."
      },
      {
        "source": "CRISPR-Cas is a tool that is widely used for gene editing. However, unexpected off-target effects may occur as a result of long-term nuclease activity. Anti-CRISPR proteins, which are powerful molecules that inhibit the CRISPR-Cas system, may have the potential to promote better utilization of the CRISPR-Cas system in gene editing, especially for gene therapy. Additionally, more in-depth research on these proteins would help researchers to better understand the co-evolution of bacteria and phages. Therefore, it is necessary to collect and integrate data on various types of anti-CRISPRs.",
        "prediction": "CRISPR-Cas is a tool that is widely used for gene editing. However, unexpected off-target effects may occur as a result of long-term nuclease activity. Nucleases are enzymes that cut DNA. Anti-CRISPR proteins are powerful molecules that inhibit, or stop, the CRISPR-Cas system. They may have the potential to promote better utilization of the CRISPR-Cas system in gene editing, especially for gene therapy, which is a treatment that involves altering genes to prevent or treat diseases. Additionally, more in-depth research on these proteins would help researchers to better understand the co-evolution of bacteria and phages. Phages are viruses that infect bacteria. Therefore, it is necessary to collect and integrate data on various types of anti-CRISPRs.",
        "reference": "CRISPR-Cas is a tool used for gene editing. However, unintended genetic modifications may occur. Anti-CRISPR proteins (molecules that inhibit the CRISPR-Cas system) may improve utilization of the CRISPR-Cas system in gene editing, especially for gene therapy. More research on these proteins would help to understand the co-evolution of bacteria and bacteriophages (virus that infects and replicates within bacteria). It is necessary to collect and integrate data on various types of anti-CRISPRs."
      },
      {
        "source": "CRISPR has become a hot research area ever since its advent for its efficiency and specificity in editing almost every section of DNA sequences. Based on its function of gene perturbation, a variety of gene editing techniques have been developed to achieve different aims. The target locations of a DNA strain can be precisely broken and repaired, during which the genes can be removed, repaired, silenced, or activated. The high efficiency of CRISPR/Cas9 reagents preparation and the easiness of experiment conduction make it now a powerful tool of high-content screen.",
        "prediction": "CRISPR is now a popular area of research because it is very efficient and specific in editing nearly any part of DNA sequences. Gene editing techniques based on gene perturbation, which means altering genes, have been developed for different purposes. The target locations of a DNA strand can be accurately broken and repaired, allowing genes to be removed, repaired, silenced, or activated. The high efficiency of preparing CRISPR/Cas9 reagents and the ease of conducting experiments make it a powerful tool for high-content screening, which is a way to quickly test many samples or conditions.",
        "reference": "CRISPR is a popular research area known for its efficiency and specificity in editing DNA sequences. A variety of gene editing techniques have been developed for different aims. The target locations of a DNA strain can be precisely broken and repaired, during which the genes can be removed, repaired, silenced, or activated. The high efficiency of CRISPR/Cas9 reagents preparation and the easiness of experiment conduction make it a powerful tool."
      },
      {
        "source": "The CRISPR-Cpf1 system has been successfully applied in genome editing. However, target efficiency of the CRISPR-Cpf1 system varies among different gRNA sequences. Using machine learning technology, a SVM model was created to predict target efficiency for any given gRNAs. the first web service application, CRISPR-DT (CRISPR DNA Targeting), to help users design optimal gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and specificity is available.",
        "prediction": "The CRISPR-Cpf1 system is a tool used to edit DNA in living organisms. However, the effectiveness of the CRISPR-Cpf1 system can differ depending on the specific gRNA sequences used. To address this, a model using machine learning technology called a Support Vector Machine (SVM) was developed to predict how effective different gRNAs will be. The first online service application, called CRISPR-DT (CRISPR DNA Targeting), is now available to assist users in designing ideal gRNAs for the CRISPR-Cpf1 system by taking into account both how effective they are and how specific they can be.",
        "reference": "The CRISPR-Cpf1 system (a DNA-editing technology) has been successfully applied in gene editing. However target efficiency of the CRISPR-Cpf1 system varies among different gRNA (piece of RNA that serves as a guide to DNA-targeting enzymes) sequences. Using machine learning technology, a support-vector machine model (algorithm used for data classification) was created to predict the target efficiency for any given gRNAs. CRISPR-DT (CRISPR DNA Targeting) is available. It is the first web service application to help users design optimal gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and target specificity (recognition mecanism)."
      },
      {
        "source": "Emerging self-driving vehicles are vulnerable to different attacks due to the principle and the type of communication systems that are used in these vehicles. These vehicles are increasingly relying on external communication via vehicular ad hoc networks (VANETs). VANETs add new threats to self-driving vehicles that contribute to substantial challenges in autonomous systems. These communication systems render self-driving vehicles vulnerable to many types of malicious attacks, such as Sybil attacks, Denial of Service (DoS), black hole, grey hole and wormhole attacks. In this paper, we propose an intelligent security system designed to secure external communications for self-driving and semi self-driving cars. The hybrid detection system relies on the Back Propagation neural networks (BP), to detect a common type of attack in VANETs: Denial-of-Service (DoS). The experimental results show that the proposed BP-IDS is capable of identifying malicious vehicles in self-driving and semi self-driving vehicles.",
        "prediction": "Emerging self-driving vehicles are at risk from various attacks because of how they communicate and the systems they use. These vehicles rely more and more on external communication through a type of network called vehicular ad hoc networks, or VANETs for short. VANETs introduce new dangers for self-driving vehicles and create significant challenges for systems that operate autonomously. These communication systems make self-driving vehicles susceptible to several types of harmful attacks, including Sybil attacks, Denial of Service (DoS), black hole, grey hole, and wormhole attacks. In this paper, we present a smart security system aimed at protecting external communications for both self-driving and semi self-driving cars. The hybrid detection system uses Back Propagation neural networks, known as BP, to identify a common type of attack in VANETs called Denial of Service (DoS). Our experimental results indicate that the proposed BP Intrusion Detection System, or BP-IDS, can successfully detect malicious vehicles within self-driving and semi self-driving vehicles.",
        "reference": "Self-driving vehicles are vulnerable to different attacks because of their communication systems. These vehicles use external communication via a network. This network add new threats to self-driving vehicles that contribute to the challenges in autonomous systems. With these communication systems, self-driving vehicles are vulnerable to many types of malicious attacks on the network. In this paper, we propose an intelligent security system to secure external communications for self-driving cars. The system will detect a common type of attack in the network: Denial-of-Service (attack trying to make network resource unavailable). The results show that the intrusion detection system is capable of identifying malicious vehicles in self-driving vehicles."
      },
      {
        "source": "Self-driving vehicle technologies are progressing rapidly and are expected to play a significant role in the future of transportation. One of the main challenges for self-driving vehicles on public roads is the safe cooperation and collaboration among multiple vehicles using sensor-based perception and inter-vehicle communications. When self-driving vehicles try to occupy the same spatial area simultaneously, they might collide with one another, might become deadlocked, or might slam on the brakes making it uncomfortable or unsafe for passengers in a self-driving vehicle. In this paper, we study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet. We present a safe protocol for merge points named Autonomous Vehicle Protocol for Merge Points, where self-driving vehicles use both vehicular communications and their own perception systems for cooperating with other self-driving and/or human-driven vehicles. Our simulation results show that our traffic protocol has higher traffic throughput, compared to simple traffic protocols, while ensuring safety.",
        "prediction": "Self-driving vehicle technologies are advancing quickly and are expected to significantly impact the future of transportation. A major challenge for self-driving vehicles on public roads is ensuring safe cooperation and collaboration among multiple vehicles. This involves using sensors to gather information about the surroundings and communication systems between vehicles. When self-driving vehicles attempt to occupy the same space at the same time, they may collide, become stuck, or suddenly stop, which can make the ride uncomfortable or unsafe for passengers. In this paper, we explore how a self-driving vehicle can safely navigate merge points, where two lanes with different traffic priorities meet. We introduce a safe system for these merge points called the Autonomous Vehicle Protocol for Merge Points. This protocol allows self-driving vehicles to use both vehicle-to-vehicle communication and their own sensors to work together with other self-driving and human-driven vehicles. Our simulation results demonstrate that our traffic protocol allows for greater traffic flow compared to simpler protocols, while still ensuring safety.",
        "reference": "Self-driving vehicle technologies are progressing and are expected to play a significant role in the future of transportation. A main challenge for self-driving vehicles on public roads is the safe cooperation, collaboration and communication with other vehicles. When self-driving vehicles are in the same area, they might collide, become blocked, or suddenly brake and make uncomfortable or unsafe the passengers. We study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet. We present a safe protocol where self-driving vehicles use both vehicular communications and their own perception systems for cooperating with other vehicles (self-driving or human-driven). Our simulation results show that our traffic protocol leads to a better traffic flow, while ensuring safety."
      },
      {
        "source": "This paper provides a holistic study of how stock prices vary in their response to financial disclosures across different topics. Thereby, we specifically shed light into the extensive amount of filings for which no a priori categorization of their content exists. For this purpose, we utilize an approach from data mining - namely, latent Dirichlet allocation - as a means of topic modeling. This technique facilitates our task of automatically categorizing, ex ante, the content of more than 70,000 regulatory 8-K filings from U.S. companies. We then evaluate the subsequent stock market reaction. Our empirical evidence suggests a considerable discrepancy among various types of news stories in terms of their relevance and impact on financial markets. For instance, we find a statistically significant abnormal return in response to earnings results and credit rating, but also for disclosures regarding business strategy, the health sector, as well as mergers and acquisitions. Our results yield findings that benefit managers, investors and policy-makers by indicating how regulatory filings should be structured and the topics most likely to precede changes in stock valuations.",
        "prediction": "This paper provides a complete study of how stock prices change in response to financial disclosures on different subjects. We specifically focus on the large number of filings for which there is no prior classification of their content. To achieve this, we use a method from data mining called latent Dirichlet allocation, which is a way of identifying topics. This method helps us automatically categorize the content of more than 70,000 regulatory 8-K filings from U.S. companies before analyzing them. We then assess how the stock market responds afterward. Our findings show that there is a significant difference among various types of news stories regarding their importance and effect on financial markets. For example, we observe a significant abnormal return when there are earnings results and credit rating changes, as well as for disclosures about business strategy, the health sector, and mergers and acquisitions. Our results offer valuable insights for managers, investors, and policy-makers by showing how regulatory filings should be organized and which topics are most likely to lead to changes in stock prices.",
        "reference": "This paper studies how stock prices vary with financial disclosures. We particularly study the many uncategorized filings. We use latent Dirichlet allocation for topic modeling. This helps automatically predict the categories based on the content of 70,000 regulatory 8-K filings from U.S. companies, which announce significant events relevant to shareholders. We then evaluate the stock market reaction. Evidence suggests a large difference among types of news stories in relevance and impact on financial markets. For example, we find unusual returns in response to disclosures about earnings results, credit rating, business strategy, the health sector, mergers and acquisitions. Our results are useful for managers, investors and policy-makers. They show how to structure regulatory filings and which topics influence stock valuations."
      },
      {
        "source": "A significant problem of using deep learning techniques is the limited amount of data available for training. There are some datasets available for the popular problems like item recognition and classification for self-driving cars, however, it is very limited for the industrial robotics field. In previous work, we have trained a multi-objective Convolutional Neural Network (CNN) to identify the robot body in the image and estimate 3D positions of the joints by using just a 2D image, but it was limited to a range of robots produced by Universal Robots (UR). In this work, we extend our method to work with a new robot arm - Kuka LBR iiwa, which has a significantly different appearance and an additional joint. However, instead of collecting large datasets once again, we collect a number of smaller datasets containing a few hundred frames each and use transfer learning techniques on the CNN trained on UR robots to adapt it to a new robot having different shapes and visual features. We have proven that transfer learning is not only applicable in this field, but it requires smaller well-prepared training datasets, trains significantly faster and reaches similar accuracy compared to the original method, even improving it on some aspects.",
        "prediction": "A significant problem of using deep learning techniques is the limited amount of data available for training. There are some datasets available for popular problems like item recognition and classification for self-driving cars; however, it is very limited for the industrial robotics field. In previous work, we trained a multi-objective Convolutional Neural Network (CNN) to identify the robot body in images and estimate 3D positions of the joints using just a 2D image, but it was limited to a range of robots produced by Universal Robots (UR). In this work, we extend our method to work with a new robot arm called Kuka LBR iiwa, which has a significantly different appearance and an additional joint. Instead of collecting large datasets again, we collect several smaller datasets containing a few hundred frames each and use transfer learning techniques on the CNN trained on UR robots to adapt it to a new robot with different shapes and visual features. We have proven that transfer learning is not only applicable in this field but requires smaller well-prepared training datasets, trains significantly faster, and reaches similar accuracy compared to the original method, even improving it in some aspects.",
        "reference": "Limited data available for training affects the use of deep learning techniques. Datasets are available for problems such as item recognition and classification for self-driving cars, but very limited for industrial robotics. A multi-objective Convolutional Neural Network (CNN) was first trained to identify the robot in the image and find 3D positions of the joints using just a 2D image. But this only used robots made by Universal Robots (UR). Here we work with a new robot arm - Kuka LBR iiwa which looks very different and has an additional joint. We collect a number of smaller datasets and use transfer learning techniques on the CNN trained on UR robots to adapt it to a robot that looks different. Transfer learning requires smaller training datasets, learns faster and reaches similar or even better accuracy."
      },
      {
        "source": "We introduce Ignition: an end-to-end neural network architecture for training unconstrained self-driving vehicles in simulated environments. The model is a ResNet-18 variant, which is fed in images from the front of a simulated F1 car, and outputs optimal labels for steering, throttle, braking. Importantly, we never explicitly train the model to detect road features like the outline of a track or distance to other cars; instead, we illustrate that these latent features can be automatically encapsulated by the network.",
        "prediction": "We introduce Ignition, which is a complete system using a type of artificial intelligence called a neural network to train self-driving cars in virtual settings. The model is a variation of ResNet-18, which is a specific architecture of neural networks known for image processing. It takes images from the front of a simulated Formula 1 car and produces the best commands for steering, acceleration (throttle), and stopping (braking). Importantly, we do not specifically train the model to recognize road features like the edges of a racetrack or the distance to other cars. Instead, we show that these hidden features can be automatically learned by the network.",
        "reference": "Ignition is a neural network for training unconstrained self-driving vehicles in simulated environments. This ResNet-18 variant model receives images from the front of a simulated car and uses them to steer, throttle, or brake appropriately. The model is not explicitly trained to detect road features such as track outline or distance to other cars, as these features can automatically be calculated by the network."
      },
      {
        "source": "As for the humanoid robots, the internal noise, which is generated by motors, fans and mechanical components when the robot is moving or shaking its body, severely degrades the performance of the speech recognition accuracy. In this paper, a novel speech recognition system robust to ego-noise for humanoid robots is proposed, in which on/off state of the motor is employed as auxiliary information for finding the relevant input features. For this, we consider the bottleneck features, which have been successfully applied to deep neural network (DNN) based automatic speech recognition (ASR) system. When learning the bottleneck features to catch, we first exploit the motor on/off state data as supplementary information in addition to the acoustic features as the input of the first deep neural network (DNN) for preliminary acoustic modeling. Then, the second DNN for primary acoustic modeling employs both the bottleneck features tossed from the first DNN and the acoustics features. When the proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, the experimental results show that achieve obvious improvement (11% relative) is achieved by our algorithm over the conventional systems.",
        "prediction": "Humanoid robots produce internal noise from their motors, fans, and mechanical parts when they move or shake. This noise negatively affects how accurately they can recognize speech. In this paper, we propose a new speech recognition system designed to withstand this type of noise, referred to as ego-noise. The system uses the on/off state of the motor as extra information to help identify the relevant input features. To do this, we look at bottleneck features, which are useful for a type of speech recognition system that relies on deep neural networks (DNNs). \n\nIn our approach, we first use the motor's on/off state as additional data along with sound features as input for the first deep neural network, which is focused on basic sound modeling. Next, a second deep neural network performs primary sound modeling by using both the bottleneck features from the first network and the sound features. We tested our method on the TIMIT database and found that it resulted in a significant improvement in recognizing speech, achieving an 11% relative reduction in phoneme error rate compared to traditional systems.",
        "reference": "Internal noise generated by motors, fans and mechanical components severely decreases speech recognition accuracy, when the humanoid robot is moving or shaking its body. This paper presents a novel speech recognition system robust to ego-noise for humanoid robots. On/off state of the motor is used to find relevant input features. Bottleneck features have been successfully applied to automatic speech recognition (ASR) systems based on deep neural networks (DNN). The motor on/off state data and acoustic features are used as the input of the first deep neural network (DNN) for preliminary acoustic modeling. The second DNN for primary acoustic modeling uses both bottleneck features from the first DNN and acoustic ones. The proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, experimental results show that improvement (11% relative) is achieved by our algorithm over the conventional systems."
      },
      {
        "source": "Recognizing Traffic Signs using intelligent systems can drastically reduce the number of accidents happening world-wide. With the arrival of Self-driving cars it has become a staple challenge to solve the automatic recognition of Traffic and Hand-held signs in the major streets. Various machine learning techniques like Random Forest, SVM as well as deep learning models has been proposed for classifying traffic signs. Though they reach state-of-the-art performance on a particular data-set, but fall short of tackling multiple Traffic Sign Recognition benchmarks. In this paper, we propose a novel and one-for-all architecture that aces multiple benchmarks with better overall score than the state-of-the-art architectures. Our model is made of residual convolutional blocks with hierarchical dilated skip connections joined in steps. With this we score 99.33% Accuracy in German sign recognition benchmark and 99.17% Accuracy in Belgian traffic sign classification benchmark. Moreover, we propose a newly devised dilated residual learning representation technique which is very low in both memory and computational complexity.",
        "prediction": "Recognizing Traffic Signs using intelligent systems can significantly reduce the number of accidents occurring globally. With the introduction of Self-driving cars, it has become a key challenge to achieve automatic recognition of Traffic and Hand-held signs on main roads. Various machine learning techniques, such as Random Forest and SVM (Support Vector Machine), as well as deep learning models, have been proposed to classify traffic signs. While these techniques achieve excellent performance on specific data sets, they struggle to meet the requirements of multiple Traffic Sign Recognition benchmarks. In this paper, we introduce a new architecture that excels in multiple benchmarks with a better overall score than current leading models. Our model is composed of residual convolutional blocks, which are layers designed to improve learning by allowing the model to skip certain connections, combined with hierarchical dilated skip connections arranged in steps. With this approach, we achieve 99.33% accuracy in the German sign recognition benchmark and 99.17% accuracy in the Belgian traffic sign classification benchmark. Additionally, we present a newly developed dilated residual learning representation technique that requires very little memory and has low computational complexity.",
        "reference": "If intelligent systems recognize traffic signs, it can reduce car accidents. For self-driving cars, we need automatic recognition of traffic and hand signs. Machine learning techniques  could be used to classify traffic signs. They perform well on a particular dataset, but fail on multiple traffic sign recognition test datasets. We proposed a new and better method. This model is based on enhanced convolutional neural networks (a deep-learning approach often used for image recognition). This model was more than 99% correct on German and Belgian sign recognition datasets. This new model is very low in both memory and computational complexity."
      },
      {
        "source": "In this paper, we present a transfer learning method for the end-to-end control of self-driving cars, which enables a convolutional neural network (CNN) trained on a source domain to be utilized for the same task in a different target domain. A conventional CNN for the end-to-end control is designed to map a single front-facing camera image to a steering command. To enable the transfer learning, we let the CNN produce not only a steering command but also a lane departure level (LDL) by adding a new task module, which takes the output of the last convolutional layer as input. The CNN trained on the source domain, called source network, is then utilized to train another task module called target network, which also takes the output of the last convolutional layer of the source network and is trained to produce a steering command for the target domain. The steering commands from the source and target network are finally merged according to the LDL and the merged command is utilized for controlling a car in the target domain. To demonstrate the effectiveness of the proposed method, we utilized two simulators, TORCS and GTAV, for the source and the target domains, respectively. Experimental results show that the proposed method outperforms other baseline methods in terms of stable and safe control of cars.",
        "prediction": "In this paper, we present a method called transfer learning for controlling self-driving cars. This method allows a convolutional neural network, or CNN, which is a type of artificial intelligence model, trained in one area, known as the source domain, to be used for the same task in a different area, called the target domain. A typical CNN for controlling a self-driving car is created to convert a single image from the front-facing camera into a steering command. To enable transfer learning, we modify the CNN so that it generates not just a steering command but also information about how far the car is from its lane, known as lane departure level or LDL. We do this by adding a new task module that takes the final output from the last layer of the CNN as input. The CNN trained in the source domain, referred to as the source network, is then used to train another module called the target network. The target network also takes the output from the last layer of the source network and learns to generate a steering command for the target domain. The steering commands from both the source and target networks are combined based on the lane departure level, and the merged command is used to control the car in the target domain. To show how effective this method is, we used two simulators, TORCS and GTAV, representing the source and target domains. The results of our experiments indicate that this method performs better than other standard methods in providing steady and safe control of cars.",
        "reference": "A transfer learning method to control self-driving cars is proposed, in which a convolutional neural network (CNN) is trained on one domain then used for the same task in a different domain. A conventional CNN is designed to map a single front-facing camera image to control a car. CNN produces a steering command and a lane departure level (LDL, mechanism designed to warn the driver when the vehicle begins to move out of its lane). To enable the transfer learning, a new task module takes the output of the last convolutional layer as input. The CNN trained on the source domain is then used to train the target network. It takes the output of the last convolutional layer of the source network and is trained to produce a steering command for the target domain. The steering commands from the source and target network are merged and used for car control in the target domain. Two simulators were used to evaluate the proposed method. The proposed method is more stable and safer for car control."
      },
      {
        "source": "This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE), a novel minimal simulation of a centralised financial market, based on a Limit Order Book (LOB) such as is common in major stock exchanges. Construction of BSE was motivated by the fact that most of the worldâs major financial markets have automated, with trading activity that previously was the responsibility of human traders now being performed by high-speed autonomous automated trading systems. Research aimed at understanding the dynamics of this new style of financial market is hampered by the fact that no operational real-world exchange is ever likely to allow experimental probing of that market while it is open and running live, forcing researchers to work primarily from time-series of past trading data. Similarly, university-level education of the engineers who can create next-generation automated trading systems requires that they have hands-on learning experience in a sufficiently realistic teaching environment. BSE as described here addresses both those needs: it has been successfully used for teaching and research in a leading UK university since 2012, and the BSE program code is freely available as open-source on GitHuB.",
        "prediction": "This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE) which is a new and simple model of a centralized financial market based on a Limit Order Book (LOB). A Limit Order Book is a system commonly used in major stock exchanges to keep track of buy and sell orders. The creation of BSE was inspired by the fact that most of the world's major financial markets have automated their operations. This means that the trading activities that were once done by human traders are now performed by high-speed automated trading systems that operate without human intervention. Research on understanding how this new type of market functions is difficult because real-world exchanges do not allow experiments while they are active. This situation forces researchers to rely mainly on historical trading data. Additionally, engineering students who will develop future automated trading systems need practical experience in a realistic learning environment. BSE meets these requirements as it has been effectively used for teaching and research at a well-known university in the UK since 2012. The program code for BSE is available for free to the public as open-source on GitHub.",
        "reference": "This paper describes the Bristol Stock Exchange (BSE), a minimal simulation of a centralised financial market based on a Limit Order Book (LOB), a type of order to buy or sell a security at a specific price or better. BSE was built because most of the financial markets became automated. Research tries to understand the dynamics of this automated financial markets but Trainee engineers also need a realistic learning experience to build automated trading systems. BSE has been successfully used for both teaching and research since 2012. BSE code is freely available on GitHuB."
      },
      {
        "source": "Once self-driving car becomes a reality and passengers are no longer worry about it, they will need to find new ways of entertainment. The simulation results show that the accuracy of our prediction for the contents need to be cached in the areas of the self-driving car is achieved at 98.04% and our approach can minimize delay. However, retrieving entertainment contents at the Data Center (DC) can hinder content delivery service due to high delay of car-to-DC communication. To address these challenges, we propose a deep learning based caching for self-driving car, by using Deep Learning approaches deployed on the Multi-access Edge Computing (MEC) structure. First, at DC, Multi-Layer Perceptron (MLP) is used to predict the probabilities of contents to be requested in specific areas. To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units. Second, in order to cache entertainment contents stylized for car passengersâ features such as age and gender, Convolutional Neural Network (CNN) is used to predict age and gender of passengers. Through this, the self-driving car can identify the contents need to be downloaded from the MEC server and cached. Finally, we formulate deep learning based caching in the self-driving car that enhances entertainment services as an optimization problem whose goal is to minimize content downloading delay. To solve the formulated problem, a Block Successive Majorization-Minimization (BS-MM) technique is applied.",
        "prediction": "Once self-driving cars become a reality and passengers no longer worry about driving, they will need new ways of entertainment. The simulation results show that our accuracy in predicting the content to be stored for the self-driving cars is 98.04% and our method can minimize delay. However, retrieving entertainment content from the Data Center, which is a central location that stores data, can slow down the delivery service due to the high delay in communication between the car and the Data Center. To tackle these challenges, we propose a method using deep learning for caching in self-driving cars, utilizing a Multi-access Edge Computing structure. First, at the Data Center, a Multi-Layer Perceptron, which is a type of artificial neural network, is used to predict the likelihood of specific content being requested in certain areas. To reduce the delay in communication from the car to the Data Center, the predictions made by the Multi-Layer Perceptron are stored in Multi-access Edge Computing servers located near the road. Second, to store entertainment content designed for the characteristics of car passengers, such as age and gender, a Convolutional Neural Network, another type of artificial neural network, is used to predict the age and gender of the passengers. This allows the self-driving car to determine which content needs to be downloaded from the Multi-access Edge Computing server and stored. Finally, we define deep learning based caching for self-driving cars designed to improve entertainment services as an optimization problem aimed at minimizing content download delays. To solve this problem, we use a technique called Block Successive Majorization-Minimization.",
        "reference": "Once self-driving cars become reality and passengers no longer worry about it, they will need to find other forms of entertainment. Prediction accuracy was 98.04% for contents to be cached for self-driving cars. Such an approach can minimize delay. However, high communication delay can slow retrieval of entertainment content from Data Centers (DC). Self-driving cars can use deep learning caching to address these challenges. It is deployed on the Multi-access Edge Computing (MEC) structure that moves services from a centralized cloud to the network edges and closer to the customer. Multi-Layer Perceptron (MLP), a type of artificial neural network, is used to predict the content requested in specific areas. To reduce delay, MLP outputs are sent to MEC servers for roadside units. A Convolutional Neural Network (CNN) is used to predict passengersâ age and gender to cache adapted entertainment content. The self-driving car can therefore identify the contents to be downloaded and cached. Deep learning caching is formulated for the self-driving car to enhance entertainment services and minimize content downloading delay. A Block Successive Majorization-Minimization (BS-MM) technique solves the problem."
      },
      {
        "source": "Moral responsibility is a major concern in automated decision-making, with applications ranging from self-driving cars to kidney exchanges.",
        "prediction": "Moral responsibility is an important issue in automated decision-making. This includes systems like self-driving cars, which are vehicles that can operate without human intervention, and kidney exchanges, which are programs that allow people to donate kidneys to others in need through a network of transactions.",
        "reference": "Moral responsibility is a major concern in automated decision-making, from self-driving cars to kidney transplants."
      },
      {
        "source": "A key problem for autonomous car navigation is the understanding, at an object level, of the current driving situation. Addressing this issue requires the extraction of meaningful information from on-board stereo imagery by classifying the fundamental elements of urban scenes into semantic categories that can more easily be interpreted and be reflected upon (streets, buildings, pedestrians, vehicles, signs, etc.). A probabilistic method is proposed to fuse a coarse prior 3D map data with stereo imagery classification. A novel fusion architecture based on the Stixel framework is presented for combining semantic pixel-wise segmentation from a convolutional neural network (CNN) with depth information obtained from stereo imagery while integrating coarse prior depth and label information. The proposed approach was tested on a manually labeled data set in urban environments. The results show that the classification accuracy of the fundamental elements composing the urban scene was significantly enhanced by this method compared to what is obtained from the semantic pixel-wise segmentation of a CNN alone.",
        "prediction": "A key problem for self-driving car navigation is understanding the current driving situation at an object level. To tackle this issue, it is necessary to extract meaningful information from the car's on-board stereo images by classifying the basic elements of urban scenes into categories that are easier to interpret and analyze such as streets, buildings, pedestrians, vehicles, and signs. A method that uses probabilities is proposed to combine rough three-dimensional (3D) map data with classifications from stereo images. A new way to merge this information is presented based on the Stixel framework, which combines semantic pixel-wise segmentation from a convolutional neural network (CNN) with depth information acquired from stereo images while also integrating rough prior depth and label information. This approach was tested on a manually labeled data set in urban areas. The results demonstrate that the accuracy of classifying the basic elements of urban scenes was significantly improved by this method compared to relying solely on the semantic pixel-wise segmentation of a CNN.",
        "reference": "A key problem for autonomous car navigation is the understanding of the environment while driving. It needs to extract information from the sensors and cameras and classify the elements into categories so it can be easily analysed (streets, buildings, pedestrians, vehicles, signs, etc.). A method is to fuse 3D map data with classification of the sensors and cameras. This system combine image segmentation (simplify the representation of an image to facilitate its analysis) and information obtained from sensors and cameras while integrating prior information. This approach was tested on manually entered data in urban environments. The results show that the classification of elements is more accurate with this method than the image segmentation alone."
      },
      {
        "source": "This paper proposes a MATLAB/Simulink benchmark suite for an open-source self-driving system based on Robot Operating System (ROS). One approach to the development of self-driving systems is the utilization of ROS which is an open-source middleware framework used in the development of robot applications. On the other hand, the popular approach in the automotive industry is the utilization of MATLAB/Simulink which is software for modeling, simulating, and analyzing. MATLAB/Simulink provides an interface between ROS and MATLAB/Simulink that enables to create functionalities of ROS-based robots in MATLAB/Simulink. However, it is not been fully utilized in the development of self-driving systems yet because there are not enough samples for self-driving, and it is difficult for developers to adopt co-development. Therefore, we provide a MATLAB/Simulink benchmark suite for a ROS-based self-driving system called Autoware. Autoware is popular open-source software that provides a complete set of self-driving modules. The provided benchmark contains MATLAB/Simulink samples available in Autoware. They help to design ROS-based self-driving systems using MATLAB/Simulink.",
        "prediction": "This paper proposes a MATLAB/Simulink benchmark suite for an open-source self-driving system based on Robot Operating System (ROS). One approach to the development of self-driving systems is the utilization of ROS, which is an open-source middleware framework used in the development of robot applications. On the other hand, the popular approach in the automotive industry is the utilization of MATLAB/Simulink, which is software for modeling, simulating, and analyzing. MATLAB/Simulink provides an interface between ROS and MATLAB/Simulink that enables the creation of functionalities of ROS-based robots in MATLAB/Simulink. However, it has not been fully utilized in the development of self-driving systems yet because there are not enough samples for self-driving, and it is difficult for developers to adopt co-development. Therefore, we provide a MATLAB/Simulink benchmark suite for a ROS-based self-driving system called Autoware. Autoware is popular open-source software that provides a complete set of self-driving modules. The provided benchmark contains MATLAB/Simulink samples available in Autoware. They help to design ROS-based self-driving systems using MATLAB/Simulink.",
        "reference": "This paper proposes MATLAB/Simulink tests for an open-source self-driving system based on Robot Operating System. One approach to the development of self-driving systems is the utilization of Robot Operating System (open-source software framework used in the development of robot applications). But the popular approach in the automotive industry is the utilization of MATLAB/Simulink (software for modeling, simulating, and analyzing). MATLAB/Simulink provides an interface that enables to create functionalities of robots (based on robot operating system). However, it is not fully utilized in the development of self-driving systems yet because there are not enough samples, and it is difficult for developers to adopt co-development. We provide MATLAB/Simulink tests for a self-driving system (based on robot operating system) called Autoware. Autoware is a popular open-source software that provides a complete set of self-driving modules. The provided tests contain MATLAB/Simulink samples available in Autoware. They help to design self-driving systems (based on robot operating system) using MATLAB/Simulink."
      },
      {
        "source": "The management of self-driving systems is becoming more complex as the development of self-driving technology progresses. One approach to the development of self-driving systems is the use of ROS; however, the system used in the automotive industry is typically designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving. These models are incompatible with ROS-based systems. To allow the two to be used in tandem, it is necessary to rewrite the C++ code and incorporate them into the ROS-based system, which makes development inefficient. Therefore, the proposed framework allows models created using MATLAB/Simulink to be used in a ROS-based self-driving system, thereby improving development efficiency. Furthermore, our evaluations of the proposed framework demonstrated its practical potential.",
        "prediction": "The management of self-driving systems is becoming more complex as self-driving technology develops. One way to develop self-driving systems is by using ROS, which stands for Robot Operating System. However, the automotive industry typically designs systems using MATLAB/Simulink. MATLAB is a programming platform used for numerical computing, while Simulink is a graphical programming environment for modeling, simulating, and analyzing dynamic systems. The models created with MATLAB/Simulink cannot be used directly with ROS-based systems. To enable both to work together, the C++ programming code must be rewritten and integrated into the ROS-based system, leading to less efficient development. The proposed framework allows models created with MATLAB/Simulink to be used in a ROS-based self-driving system, improving development efficiency. Our evaluations of this proposed framework showed that it has practical potential.",
        "reference": "The management of self-driving systems is becoming more complex as the development of self-driving technology progresses. Self-driving systems use Robot Operating System (open-source software framework used in the development of robot applications). However, in the automotive industry, the system is designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving. These models are incompatible with systems based on Robot Operating System. To use both, it is necessary to incorporate new code into the system based on Robot Operating System, which makes development inefficient. Therefore, the proposed framework allows models created using MATLAB/Simulink to be used in a self-driving system, which improve development efficiency. Furthermore, our evaluations of the proposed framework demonstrated its practical potential."
      },
      {
        "source": "Ensuring the safety of self-driving cars is important, but neither industry nor authorities have settled on a standard way to test them. Deploying self-driving cars for testing in regular traffic is a common, but costly and risky method, which has already caused fatalities. As a safer alternative, virtual tests, in which self-driving car software is tested in computer simulations, have been proposed. One cannot hope to sufficiently cover the huge number of possible driving situations self-driving cars must be tested for by manually creating such tests. Therefore, we developed AsFault, a tool for automatically generating virtual tests for systematically testing self-driving car software. We demonstrate AsFault by testing the lane keeping feature of an artificial intelligence-based self-driving car software, for which AsFault generates scenarios that cause it to drive off the road. A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw",
        "prediction": "Ensuring the safety of self-driving cars is important, but neither the car industry nor government authorities have agreed on a standard way to test them. Using self-driving cars in real traffic for testing is common, but it is also expensive and dangerous, and it has already led to deaths. A safer option is to conduct virtual tests, where the software that runs self-driving cars is evaluated using computer simulations. It is impossible to cover the vast number of driving situations that self-driving cars must be tested for by creating these tests manually. Consequently, we developed AsFault, a tool for automatically generating virtual tests to systematically evaluate self-driving car software. We demonstrate AsFault by testing the lane keeping feature of software that uses artificial intelligence, for which AsFault creates scenarios that make the car drive off the road. A video showing AsFault in action can be viewed at: https://youtu.be/lJ1sa42VLDw",
        "reference": "Ensuring the safety of self-driving cars is important, but there is no standard way to test them. Testing self-driving cars in regular traffic is costly and risky, and has already caused fatalities. As a safer alternative, virtual tests (self-driving car software tested in computer simulations) have been proposed. To cover the huge number of possible driving situations, self-driving cars must be tested in manually created tests. We developed AsFault, a tool for automatically generating virtual tests for testing self-driving car software. We demonstrate AsFault by testing the lane keeping feature of a self-driving car software with scenarios going off the road. A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw"
      },
      {
        "source": "With the developing of the technology on self-driving, more and more L3 driverless vehicles are launched in market, people get opportunities to experience the self-driving cars in their daily life. As a result, there is a growing demand for the autopilot experience. Natural and efficient human-computer interaction can not only improve the driving experience, but also accelerate the process of self-driving commercialization. This paper discusses eye-movement interaction, voice interaction and gesture interaction in self-driving car, and analyzes the technology, advantages and disadvantages of the existing interaction modes, and prospect the future development trend of self-driving human-computer interaction.",
        "prediction": "With the development of self-driving technology, more L3 driverless vehicles are being launched in the market, giving people the chance to experience self-driving cars in their daily lives. This has led to an increasing demand for the autopilot experience. Natural and efficient human-computer interaction can enhance the driving experience and speed up the commercialization of self-driving cars. This paper discusses eye movement interaction, voice interaction, and gesture interaction in self-driving cars. It also analyzes the technology, advantages, and disadvantages of these existing interaction methods, and looks at future development trends in self-driving human-computer interaction.",
        "reference": "Self-driving technology is developing, more and more driverless vehicles are launched in market and accessible for people in their daily life. So there is a growing demand for the autopilot experience. Natural and efficient human-computer interaction can improve the driving experience and accelerate the process of self-driving commercialization. This paper discusses interactions with the eye, voice and gesture in self-driving car, analyzes the technology, the interaction modes, and considers the future of self-driving human-computer interaction."
      },
      {
        "source": "In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems. Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on highfidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle. It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios. The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1]. In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using vision-based imitation learning we obtain safer self-driving behavior.",
        "prediction": "In recent years self-driving vehicles have become more common on public roads promising increased safety and efficiency in transportation systems. To improve the reliability of these vehicles on the road extensive software tests are needed ideally using high-fidelity simulators where multiple vehicles and pedestrians interact with the self-driving vehicle. It is crucial to ensure that self-driving software is evaluated against a wide variety of difficult simulated driving scenarios. The best current methods for generating driving scenarios still require human involvement. In this paper we suggest automating this process by using Bayesian optimization which is a statistical method used to find the maximum or minimum of a function to create challenging self-driving scenarios that reveal weaknesses in poorly designed or poorly trained self-driving systems and increase the risk of accidents with simulated pedestrians and vehicles. We demonstrate that by including these generated scenarios in the training data for the self-driving system and refining the system using vision-based imitation learning which is a method where a model learns by observing a human's actions we can achieve safer self-driving behavior.",
        "reference": "Self-driving vehicles have become common on public roads, with the promise of a safe and efficient mode of transport. To be reliable, these vehicles need many software tests on simulators with interactions of multiple vehicles and pedestrians. It is essential that self-driving software is evaluated with many different challenging driving scenarios. The driving scenario generation still needs human contribution. We propose to automate the process and generate conflicting self-driving that expose weaknesses of self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. By incorporating the generated scenarios into the parameters of the self-driving policy, and by adjusting the policy with the imitation learning, we obtain safer self-driving behavior."
      },
      {
        "source": "At the brink of the introduction of self-driving vehicles, only little is known about how potential users perceive them. This is especially true for self-driving vehicles deployed in public transport services. In this study, the relative preferences for a trip with a self-driving bus is assessed compared to a trip with a regular bus, based on a stated preference experiment. Based on the responses of 282 respondents from the Netherlands and Germany, a discrete choice model is estimated as a Mixed Logit model including attitudes towards trust in self-driving vehicles and interest in technology. The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips. This is due to the finding that the value of travel time is about twice as high for the self-driving bus as for the regular bus for a short commuting trip. Findings from this study further suggest that the popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes. People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others. Preferences towards automated public transport services are expected to evolve along with the transition from demonstration pilots to their deployment in regular operations.",
        "prediction": "At the brink of the introduction of self-driving vehicles only a little is known about how potential users perceive them This is especially true for self-driving vehicles used in public transport services In this study the relative preferences for a trip with a self-driving bus are assessed compared to a trip with a regular bus based on a stated preference experiment Based on the responses of 282 respondents from the Netherlands and Germany a discrete choice model is estimated as a Mixed Logit model including attitudes towards trust in self-driving vehicles and interest in technology The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips This is due to the finding that the value of travel time is about twice as high for the self-driving bus as for the regular bus for a short commuting trip Findings from this study further suggest that the popularity of self-driving buses decreases with the presence of a human steward on-board or if they are operated as a demand-responsive service with fixed routes People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving buses better than others Preferences towards automated public transport services are expected to evolve along with the transition from demonstration pilots to their deployment in regular operations",
        "reference": "Little is known about how potential users perceive self-driving vehicles. This is especially true for self-driving vehicles in public transport services. In this study, the preferences between a trip in a self-driving bus and a regular bus were compared. The results of 282 participants were studied, including trust in self-driving vehicles and interest in technology. The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips. The preference is about twice as high for the self-driving bus as for the regular bus for a short commuting trip. The popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes. People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others. Preferences for automated public transport services are expected to evolve with their deployment in regular operations."
      },
      {
        "source": "In the wake of the on-going digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions. While the benefits of this transformation can be massive, there are also tremendous risks to our society. After the automation of many production processes and the creation of self-driving vehicles, the automation of society is next. This is moving us to a tipping point and to a crossroads: we must decide between a society in which the actions are determined in a top-down way and then implemented by coercion or manipulative technologies (such as personalized ads and nudging) or a society, in which decisions are taken in a free and participatory way and mutually coordinated. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. The fundaments of human dignity, autonomous decision-making, and democracies are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies, but also the basis of greater efficiency and success.",
        "prediction": "In the wake of the ongoing digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions. While the benefits of this transformation can be massive, there are also significant risks to our society. After the automation of many production processes and the creation of self-driving vehicles, the automation of society is next. This is moving us to a tipping point and to a crossroads: we must decide between a society in which actions are determined in a top-down way and then implemented by coercion or manipulative technologies such as personalized ads and nudging, or a society in which decisions are made in a free and participatory way and mutually coordinated. Modern information and communication systems, abbreviated as ICT, enable both options, but the latter has economic and strategic benefits. The foundations of human dignity, autonomous decision-making, and democracies are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies but also the basis of greater efficiency and success.",
        "reference": "The on-going digital revolution will dramatically transform our economy and societal institutions. But this also presents risks for our society. Automation of society is coming. We must choose either between a society in which the actions are determined top-down by coercion or manipulative technologies (such as personalized ads) or in which decisions are taken freely and cooperatively. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. Foundations of human dignity, autonomous decision-making, and democracies are weakening. These core principles of society and the basis of greater efficiency and success need to be defended."
      },
      {
        "source": "This paper addresses the financial markets problem space with particular emphasis on trading systems seen in banking today. With the advent of modern computing, cross-regional trading transactions can now be executed within milliseconds, a reality that is impossible without the advancements of software systems technology. We then move on and discuss the anatomy of a trading system and how it fits in with the banks ecosystem of vital inter-working components.",
        "prediction": "This paper addresses the financial markets problem space with a focus on trading systems used in banks today. With the development of modern computing technology, trading transactions that occur across different regions can now be completed in milliseconds. This speed is only possible because of advancements in software systems. We will then discuss the structure of a trading system and how it operates within the essential components that make up the bank's ecosystem.",
        "reference": "This paper addresses problems of trading systems in banking. Modern computing allows cross-regional trading transactions within milliseconds. We then discuss how a trading system fits in with the bank ecosystem."
      },
      {
        "source": "In this paper we present queueing-theoretical methods for the modeling, analysis, and control of autonomous mobility-on-demand MOD systems wherein robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure acceptable quality of service throughout the network. We first cast an autonomous MOD system within a closed Jackson network model with passenger loss. The theoretical insights are used to design a robust, real-time rebalancing algorithm, which is applied to a case study of New York City and implemented on an eight-vehicle mobile robot testbed. The case study of New York shows that the current taxi demand in Manhattan can be met with about 8,000 robotic vehicles roughly 70% of the size of the current taxi fleet operating in Manhattan. Finally, we extend our queueing-theoretical setup to include congestion effects, and study the impact of autonomously rebalancing vehicles on overall congestion. Collectively, this paper provides a rigorous approach to the problem of system-wide coordination of autonomously driving vehicles, and provides one of the first characterizations of the sustainability benefits of robotic transportation networks.",
        "prediction": "In this paper we discuss methods from queueing theory for modeling, analyzing, and controlling transportation systems where robotic, self-driving vehicles transport customers in urban areas and reposition themselves to maintain good service quality throughout the network. We start by representing an autonomous mobility-on-demand (MOD) system using a closed Jackson network model that accounts for the loss of passengers. The theoretical findings help us create a strong, real-time rebalancing algorithm, which we apply in a case study of New York City and test on a mobile robot setup with eight vehicles. The New York case study indicates that the current taxi demand in Manhattan can be satisfied with about 8,000 robotic vehicles, which is roughly 70% of the number of taxis currently operating in Manhattan. Finally, we expand our queueing-theoretic approach to consider congestion effects and investigate how autonomously repositioning vehicles influence overall congestion. In summary, this paper offers a thorough method for managing the coordinated operation of self-driving vehicles and presents one of the first assessments of the sustainability advantages of robotic transportation networks.",
        "reference": "Queueing models are used for autonomous mobility-on-demand MOD systems. A queueing model is constructed so that queue lengths and waiting time can be predicted. In MOD systems,  robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure quality of service. We first cast an autonomous MOD system within a closed Jackson network model,a class of queueing network, with passenger loss. A real-time rebalancing algorithm is applied to a case study of New York City. It is implemented on an eight-vehicle mobile robot testbed. The current taxi demand in Manhattan can be met with about 8,000 robotic vehicles. It represents roughly 70% of the size of the current taxi fleet in Manhattan. Congestion effects are also included to study the impact of autonomously rebalancing vehicles on overall traffic jams. This paper describes the sustainability benefits of robotic transportation networks."
      },
      {
        "source": "Many model based techniques have been proposed in the literature for applying domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation. However sensor based robot control overcomes many of the difficulties of uncertain models and unknown environments which limit the domain of application of the previous methods. Furthermore, for service and manipulation tasks, it is more suitable to study the interaction between the robot and its environment at the contact point using the sensor based control, rather than specifying the joint positions and velocities required to achieve them.",
        "prediction": "Many techniques that rely on models have been suggested for using humanoid robots in domestic service tasks. These include teleoperation, which is remote control of robots, and learning from demonstration and imitation, where robots learn by watching humans. However, controlling robots using sensors solves many problems that arise from unreliable models and unfamiliar environments, which limits how the earlier methods can be applied. Additionally, for tasks involving service and manipulation, it is more effective to examine how the robot interacts with its surroundings at the point of contact using sensor-based control. This approach is preferred over specifying the positions and speeds of the robot's joints needed to perform those tasks.",
        "reference": "Model based techniques exist to apply domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation. Sensor based robot control overcomes difficulties of uncertain models and unknown environments. Interaction between the robot and its environment using the sensor based control is important."
      },
      {
        "source": "Inaccurate information, in the field of library and information science, is often regarded as a problem that needs to be corrected or simply understood as either misinformation or disinformation without further consideration. Misinformation and disinformation, however, may cause significant problems for users in online environments, where they are constantly exposed to an abundance of inaccurate and/or misleading information. This paper aims to establish conceptual groundwork for future empirical research by examining the relationships among information, misinformation, and disinformation. Our analysis extends to a discussion of cues to deception, as means for detecting misinformation and disinformation. We argue that misinformation and disinformation are related yet distinct sub-categories of information. Misinformation is a multifaceted concept, more complex than simply being inaccurate or incomplete, and disinformation does not always entail misinformation.",
        "prediction": "Inaccurate information in library and information science is often viewed as a problem that needs correction or is understood as either misinformation or disinformation without much thought. Misinformation and disinformation, however, can create serious issues for users in online settings, where they are frequently exposed to a large amount of inaccurate or misleading information. This paper seeks to lay the foundational concepts for future research by looking at the connections between information, misinformation, and disinformation. Our study includes a discussion on cues to deception, which are methods for identifying misinformation and disinformation. We argue that misinformation and disinformation are related but different categories of information. Misinformation is a complex idea that goes beyond just being incorrect or incomplete, and disinformation does not always include misinformation.",
        "reference": "Inaccurate information is often regarded as a problem that needs to be corrected or simply understood as misinformation or disinformation without further consideration. Misinformation and disinformation may cause problems online because users are constantly exposed to inaccurate and/or false information. This paper aims to establish preliminary work for future research by examining the relationships among information, misinformation, and disinformation. Our analysis extends to a discussion of means for detecting misinformation and disinformation. We argue that misinformation and disinformation are related but distinct sub-categories of information. Misinformation is more complex than simply being inaccurate or incomplete, and disinformation does not always involve misinformation."
      },
      {
        "source": "The growth of social media provides a convenient communication scheme for people, but at the same time it becomes a hotbed of misinformation. The wide spread of misinformation over social media is injurious to public interest. We design a framework, which integrates collective intelligence and machine intelligence, to help identify misinformation. The basic idea is: (1) automatically index the expertise of users according to their microblog contents; and (2) match the experts with given suspected misinformation. By sending the suspected misinformation to appropriate experts, we can collect the assessments of experts to judge the credibility of information, and help refute misinformation. In this paper, we focus on expert finding for misinformation identification. We propose a tag-based method to index the expertise of microblog users with social tags. Experiments on a real world dataset demonstrate the effectiveness of our method for expert finding with respect to misinformation identification in microblogs.",
        "prediction": "The growth of social media provides a convenient way for people to communicate, but it also leads to a lot of false information. This spread of false information on social media is harmful to the public. We have created a system that combines the intelligence of many people with the intelligence of machines to help find false information. The main idea is: (1) automatically organize the expertise of users based on what they post on their microblogs, which are short online posts; and (2) connect these experts with suspected false information. By sending the suspected false information to the right experts, we can gather their opinions to evaluate the trustworthiness of the information and help correct the falsehoods. In this paper, we focus on finding experts to identify misinformation. We suggest a method that uses tags, which are keywords or labels, to organize the expertise of microblog users. Tests on a real-world dataset show that our method is effective for locating experts in relation to identifying misinformation in microblogs.",
        "reference": "The growth of social media leads to better communication between people, but also propagation of misinformation. The wide spread of misinformation over social media have bad consequences for public interest. We design a framework to help identify misinformation. The idea is to index the expertise of users and to match the experts with given suspected misinformation. By sending the suspected misinformation to appropriate experts, they can judge the credibility of information, and help refute misinformation. In this paper, we focus on finding appropriate experts for misinformation identification. We propose a method to index the expertise of users with tags. Experiments on a real world dataset demonstrate the effectiveness of our method for expert finding for misinformation identification."
      },
      {
        "source": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the scarcity of misinformation in support of such research. This paper aims to address the aforementioned challenges by conceptualizing misinformation and enabling the interoperability of misinformation. In particular, a representation and a model of misinformation are proposed through surveying, synthesizing, and explicating existing work in the field. The ontology-supported misinformation model can not only guide future misinformation research but also lay the foundation for building a digital misinformation library by advancing our knowledge on misinformation and by improving its sharing, management, and reuse. In addition, we present a formal methodology for managing misinformation in a digital library, and suggest future research directions related to the misinformation model.",
        "prediction": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the scarcity of misinformation to support such research. This paper aims to address these challenges by defining what misinformation is and enabling different types of misinformation to work together. In particular, a representation and a model of misinformation are proposed by looking at existing work in the field. The model, supported by an organized system of knowledge, can not only guide future research on misinformation but also help create a digital library of misinformation. This library would enhance our understanding of misinformation and improve how it is shared, managed, and reused. In addition, we present a formal method for managing misinformation in a digital library and suggest future research directions related to the misinformation model.",
        "reference": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the rare misinformation data. This paper aims to address these challenges by conceptualizing misinformation and being able to completely understand and work on misinformation. A representation and a model of misinformation are proposed through existing work in the field. The model can guide future misinformation research and help building a digital misinformation library by advancing our knowledge on misinformation and by improving its sharing, management, and reuse. In addition, we present a methodology for managing misinformation in a digital library, and suggest future research directions."
      },
      {
        "source": "Online Social Networks OSNs have become increasingly popular means of information sharing among users. The spread of news regarding emergency events is common in OSNs and so is the spread of misinformation related to the event. We define as misinformation any false or inaccurate information that is spread either intentionally or unintentionally. In this paper we study the problem of misinformation identification in OSNs, and we focus in particular on the Twitter social network. Based on user and tweets characteristics, we build a misinformation detection model that identifies suspicious behavioral patterns and exploits supervised learning techniques to detect misinformation. Our extensive experimental results on 80294 unique tweets and 59660 users illustrate that our approach effectively identifies misinformation during emergencies. Furthermore, our model manages to timely identify misinformation, a feature that can be used to limit the spread of the misinformation.",
        "prediction": "Online Social Networks (OSNs) have become a popular way for users to share information. News about emergency events often spreads quickly on OSNs, but so does misinformation related to those events. Misinformation is defined as any false or inaccurate information that is spread either on purpose or by mistake. In this paper, we examine how to identify misinformation in OSNs, focusing specifically on the Twitter social network. We create a misinformation detection model based on the characteristics of users and tweets, which identifies suspicious behaviors and uses supervised learning techniques to detect misinformation. Our detailed experiments involved 80,294 unique tweets and 59,660 users, showing that our method effectively identifies misinformation during emergencies. Additionally, our model can quickly recognize misinformation, which can help reduce its spread.",
        "reference": "Social media have become popular means of information sharing. The spread of news regarding emergency events is common in social media but so is the spread of misinformation. Misinformation is any false or inaccurate information that is spread intentionally or not. In this paper we study the problem of misinformation identification in social media, and we focus in particular on Twitter. We build a misinformation detection model that identifies suspicious behavioral patterns and detect misinformation. We found 80294 unique tweets and 59660 users. It illustrates that our approach identifies misinformation during emergencies. Our model manages to timely identify misinformation, it can be used to limit the spread of the misinformation."
      },
      {
        "source": "The advent of WWW changed the way we can produce and access information. Recent studies showed that users tend to select information that is consistent with their system of beliefs, forming polarized groups of like-minded people around shared narratives where dissenting information is ignored. In this environment, users cooperate to frame and reinforce their shared narrative making any attempt at debunking inefficient. Such a configuration occurs even in the consumption of news online, and considering that 63% of users access news directly form social media, one hypothesis is that more polarization allows for further spreading of misinformation. Along this path, we focus on the polarization of users around news outlets on Facebook in different European countries (Italy, France, Spain and Germany). First, we compare the page posting behavior and the users interacting patterns across countries and observe different posting, liking and commenting rates. Second, we explore the tendency of users to interact with different pages (i.e., selective exposure) and the emergence of polarized communities generated around specific pages.",
        "prediction": "The advent of the World Wide Web (WWW) changed the way we produce and access information. Recent studies showed that users tend to select information that matches their beliefs, forming polarized groups of like-minded people around shared stories while ignoring opposing information. In this environment, users work together to support and strengthen their shared story, making any attempts to disprove it ineffective. This situation occurs even when consuming news online, and considering that 63% of users access news directly from social media, one hypothesis is that more polarization leads to further spread of misinformation. Along this path, we focus on the polarization of users around news outlets on Facebook in different European countries: Italy, France, Spain, and Germany. First, we compare the behavior of posting on pages and how users interact across countries, observing different rates for posting, liking, and commenting. Second, we explore the tendency of users to interact with different pages, known as selective exposure, and the formation of polarized communities generated around specific pages.",
        "reference": "The WWW changed the ways we can produce and access information. Users tend to select information that agrees with their beliefs. They form polarized groups of like-minded people sharing narratives that ignore contradicting information. Here, users reinforce their shared narratives and can resist debunking This is the case with online news. Because 63% of users access news from social media, polarization could increase misinfomation spread. We focus on polarisation of Facebook news consumers in different European countries. Posting, liking and commenting rates differ across countries. We look at how users interact with different pages and polarized communities form around specific pages."
      },
      {
        "source": "We find that Italy is the most polarized country, followed by France, Germany and lastly Spain. Finally, we present a variation of the Bounded Confidence Model to simulate the emergence of these communities by considering the usersu0027 engagement and trust on the news. Our findings suggest that trust in information broadcaster plays a pivotal role against polarization of users online.",
        "prediction": "We find that Italy is the most polarized country, followed by France, Germany and lastly Spain. Finally, we present a variation of the Bounded Confidence Model to simulate the emergence of these communities by considering the users' engagement and trust in the news. Our findings suggest that trust in information broadcasters plays a pivotal role against the polarization of users online.",
        "reference": "Italy is the most polarized country, then France, Germany and Spain. A variant of the Bounded Confidence Model simulates the emergence of these communities by considering user engagement and trust in the news. Trust in an information source plays a major role against polarization of users online."
      },
      {
        "source": "Online social media provide users with unprecedented opportunities to engage with diverse opinions. We discuss the policy implications of our model, highlighting the downside of debunking strategies and suggesting alternative strategies to contrast misinformation. Simultaneously, they allow the spread of misinformation by empowering individuals to self-select the narratives they want to be exposed to, both through active (confirmation bias) and passive (personalized news algorithms) self-reinforcing mechanisms. A precise theoretical understanding of such trade-offs is still largely missing. We introduce a stylized social learning model where most participants in a network update their beliefs unbiasedly based on the arrival of new information, while a fraction of participants display confirmation bias, enabling them to reject news that are incongruent with their pre-existing beliefs. We show that this simple confirmation bias mechanism can generate permanent opinion polarisation. Furthermore, the model results in states where unbiased agents behave \"as if\" they were biased, due to their biased neighbours effectively functioning as gatekeepers, restricting their access to free and diverse information. We derive analytic results for the distribution of individual agentsâ beliefs, explicitly demonstrating the aforementioned trade-off between confirmation bias and social connectivity, which we further validate against US county-level data on the impact of Internet access on the formation of beliefs about global warming. Our findings indicate that confirmation bias in small doses may actually result in improved accuracy across individuals by preserving information diversity in a social network. However, results also indicate that when confirmation bias grows past an optimal value, accuracy declines as biased agents restrict information flow to subgroups.",
        "prediction": "Online social media give users unique chances to hear various opinions. We talk about the effects of our model on policy, pointing out the downsides of ways to counter false information and suggesting other methods to contrast misinformation. At the same time, social media allow false information to spread by enabling people to choose the stories they want to see, either actively through a tendency to favor information that confirms existing beliefs (confirmation bias) or passively through personalized news algorithms that curate content for individuals. A clear theoretical understanding of these trade-offs is still largely lacking. We introduce a simplified social learning model where most participants in a network update their beliefs fairly based on new information, while a small percentage of participants show confirmation bias, making them reject news that does not fit their existing beliefs. We demonstrate that this simple confirmation bias can lead to lasting divisions in opinions. Moreover, the model leads to situations where unbiased agents act like they are biased, as their biased neighbors act like gatekeepers, limiting their access to a variety of information. We present analytical results on the range of individual beliefs, clearly showing the trade-off between confirmation bias and social connections, and we further confirm this with data from US counties on how Internet access affects beliefs about global warming. Our findings suggest that a small amount of confirmation bias may actually improve accuracy among individuals by maintaining a variety of information in a social network. However, the results also show that when confirmation bias exceeds a certain level, accuracy decreases as biased individuals limit the flow of information to smaller groups.",
        "reference": "Social media give users opportunities to interact with different opinions. We discuss the meaning of our model for policy and the downsides of myth-busting We suggest alternatives to fight misinformation. But misinformation is spread via social media because individuals can search for information that confirms their beliefs and personalized news algorithms may supply it. Theoretical understanding of the balance between opportunities and misinformation is incomplete. We introduce a stylized social learning model. In this model, most participants in a network update their beliefs based on new information, while others show confirmation bias and can reject news that differs from their beliefs. This simple confirmation bias mechanism can create lasting opinion polarisation. Besides, in the model, unbiased people behave âas ifâ biased because biased neighbours limit their access to diverse information. With our model, we show the trade-off between confirmation bias and social connectivity. We validated the model using the data on how internet access influences beliefs on global warming. Small confirmation bias may even improve accuracy across individuals by keeping information diversity in a social network. But large confirmation bias lowers accuracy as biased individuals limit information flow to others."
      },
      {
        "source": "Superintelligence is a potential type of future artificial intelligence (AI) that is significantly more intelligent than humans in all major respects. If built, superintelligence could be a transformative event, with potential consequences that are massively beneficial or catastrophic. Meanwhile, the prospect of superintelligence is the subject of major ongoing debate, which includes a significant amount of misinformation. Superintelligence misinformation is potentially dangerous, ultimately leading bad decisions by the would-be developers of superintelligence and those who influence them. This paper surveys strategies to counter superintelligence misinformation. Two types of strategies are examined: strategies to prevent the spread of superintelligence misinformation and strategies to correct it after it has spread. In general, misinformation can be difficult to correct, suggesting a high value of strategies to prevent it. The strategies proposed can be applied to lay public attention to superintelligence, AI education programs, and efforts to build expert consensus.",
        "prediction": "Superintelligence is a possible future form of artificial intelligence or AI that would be much smarter than humans in all important ways. If superintelligence is created, it could change the world, leading to extremely positive or very negative outcomes. The idea of superintelligence is currently being heavily discussed, and there is a lot of false information about it. This false information, known as misinformation, can be harmful. It can cause poor decisions by those who want to create superintelligence and by people who influence those developers. This paper looks at ways to combat misinformation about superintelligence. Two categories of strategies are discussed: ways to stop misinformation from spreading and ways to fix it after it has already spread. In general, it is often hard to correct misinformation, which makes preventing it very important. The suggested strategies can be used to inform the general public about superintelligence, in educational programs about AI, and in efforts to reach agreement among experts.",
        "reference": "Superintelligence is a potential future artificial intelligence (AI) significantly more intelligent than humans. Superintelligence could be a major event, with potential consequences that are beneficial or catastrophic. The prospect of superintelligence is the subject of major debate, which includes a lot of misinformation. Superintelligence misinformation could be dangerous, and lead to bad decisions by the people that could work on the project. This paper searches for strategies to counter superintelligence misinformation. Two strategies are examined: to prevent the spread of misinformation and to correct it after it has spread. Misinformation can be difficult to correct, so preventing it seems to be the best strategy. The strategies proposed can be used to bring public attention to superintelligence, AI education programs, and efforts to build expert consensus."
      },
      {
        "source": "The widespread online misinformation could cause public panic and serious economic damages. The misinformation containment problem aims at limiting the spread of misinformation in online social networks by launching competing campaigns. Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem for the case when an arbitrary number of cascades are allowed. First, we provide a formal model for multi-cascade diffusion and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of $\\\\Omega(2^{\\\\log^{1-\\\\epsilon}n^4})$ in polynomial time unless $NP \\\\subseteq DTIME(n^{\\\\polylog{n}})$. Third, we introduce several types of cascade priority that are frequently seen in real social networks. Finally, we design novel algorithms for solving the misinformation containment problem. The effectiveness of the proposed algorithm is supported by encouraging experimental results.",
        "prediction": "The widespread online misinformation can lead to public panic and serious economic damage. The misinformation containment problem focuses on limiting the spread of misinformation in online social networks by creating competing campaigns. We present the first analysis of this problem allowing for multiple \"cascades,\" which are instances of how information spreads among users. First, we offer a formal model for multi-cascade diffusion and introduce an important concept called \"cascade priority,\" which refers to the order or importance assigned to different cascades. Second, we demonstrate that the misinformation containment problem cannot be approximated within a specific factor in polynomial time unless a certain condition in computational complexity theory holds, relating to classes of problems known as NP (nondeterministic polynomial time) and DTIME, which refers to the time complexity class of decision problems. Third, we outline several types of cascade priority that are often seen in actual social networks. Finally, we develop new algorithms to address the misinformation containment problem. The effectiveness of these proposed algorithms is supported by promising experimental results.",
        "reference": "The online misinformation could cause public panic and serious economic damages. The goal of misinformation containment is to limit the spread of misinformation in online social networks by launching campaigns to counter misinformation. We present the first analysis of the misinformation containment problem with a random number of cascades (people observe the actions of others and then make the same choice) allowed. First, we provide a diffusion model and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of Î©(2log1âÏµn4) in polynomial time unless $NP \\subseteq DTIME(n^{\\polylog{n}})$ Third, we introduce several types of cascade priority that are frequently seen in social networks. Finally, we design algorithms for solving the misinformation containment problem. The proposed algorithm is effective and shows encouraging results."
      },
      {
        "source": "Yet contemporary work in Philosophy argues provisional belief in conspiracy theories isâat the veryâleast understandable (because conspiracies occur) and if we take an evidential approachâjudging individual conspiracy theories on their particular meritsâbelief in such theories turns out to be warranted in a range of cases. Drawing on this work, I examine the kinds of evidence typically associated with conspiracy theories, showing that the evidential problems typically associated with conspiracy theories are not unique to such theories. As such, if there is a problem with the conspiracy theoristâs use of evidence, it is one of principle: is the principle which guides their use of evidence somehow in error? I argue that whatever we might think about conspiracy theories generally, there is no prima facie case for a scepticism of conspiracy theories based purely on their use of evidence.",
        "prediction": "Contemporary work in Philosophy suggests that having a temporary belief in conspiracy theories is at least understandable because conspiracies do happen. If we look at each conspiracy theory based on its specific evidence, we can find that believing in some of these theories is justified in various situations. I will explore the types of evidence commonly linked to conspiracy theories, demonstrating that the evidence issues usually found with these theories are not only applicable to them. Therefore, if there is a problem with how conspiracy theorists use evidence, it is a fundamental issue: is the guiding principle behind their use of evidence incorrect? I argue that regardless of our overall views on conspiracy theories, there is no strong reason to be skeptical of them just because of how they use evidence.",
        "reference": "To believe in conspiracy theories is understandable as conspiracies occur and if we take an evidential approach, belief in such theories turns out to be warranted in a range of cases. Drawing on this work, I examine evidence associated with conspiracy theories, showing that the evidential problems are not unique to conspiracy theories. The problem with the use of evidence of conspiracy theorist could be the principle which guides their use of it. I argue that there is no ground to be suspicious of conspiracy theories as a whole, because those are based on evidence."
      },
      {
        "source": "Conspiracy theories have gained much academic and media attention recently, due to their large impact on public events. However, little is known about how conspiracy theories are produced and developed on social media. We present a qualitative study of conspiracy theorizing on Reddit during a public health crisis--the Zika virus outbreak. Using a mixed-methods approach including content analysis and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the Zika crisis, the conditions under which Zika conspiracy theories emerge, and the particular discursive strategies through which Zika conspiracy theories developed in online forums. Our analysis shows that conspiracy talk emerged as people attempted to make sense of a public health crisis, reflecting their emergent information needs and their pervasive distrust in formal sources of Zika information. Practical implications for social computing researchers, health practitioners, and policymakers are discussed.",
        "prediction": "Conspiracy theories have received a lot of attention from researchers and the media recently because they significantly influence public events. However, we know very little about how conspiracy theories are created and spread on social media. This study examines conspiracy theories on Reddit during a public health crisis known as the Zika virus outbreak. We used a mixed-methods approach, which combines different research methods like content analysis (a way to analyze communication in texts) and discourse analysis (a study of how language is used in written or spoken communication). We identified types of conspiracy theories that were shared on Reddit as a response to the Zika crisis, the situations that led to the creation of these theories, and the specific ways in which these theories were discussed in online forums. Our findings indicate that discussions about conspiracy theories arose as people tried to understand a public health crisis, showing their need for information and their general distrust of official sources of information regarding the Zika virus. We also discuss the practical implications of our study for researchers in social computing, health professionals, and policymakers.",
        "reference": "Conspiracy theories have gained much attention recently, due to their large impact on public events. Little is known about how conspiracy theories are produced and developed on social media. We present a study of conspiracy theory creation on Reddit during a public health crisis. Using content and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the crisis, the conditions of their creation, and the strategies of their development in online forums. Our analysis shows that conspiracy talk come from people trying to make sense of a public health crisis, which reflect their information needs and their lack of confidence in formal sources of information. Implications for social computing researchers, health practitioners, and policymakers are discussed."
      },
      {
        "source": "Conspiracy theories are omnipresent in online discussions---whether to explain a late-breaking event that still lacks official report or to give voice to political dissent. Conspiracy theories evolve, multiply, and interconnect, further complicating efforts to understand them and to limit their propagation. It is therefore crucial to develop scalable methods to examine the nature of conspiratorial discussions in online communities. What do users talk about when they discuss conspiracy theories online? What are the recurring elements in their discussions? What do these elements tell us about the way users think? This work answers these questions by analyzing over ten years of discussions in r/conspiracy---an online community on Reddit dedicated to conspiratorial discussions. We focus on the key elements of a conspiracy theory: the conspiratorial agents, the actions they perform, and their targets. For example, a narrative-motif such as \\\"governmental agency-controls-communications\\\" represents the various ways in which multiple conspiratorial statements denote how governmental agencies control information. Thus, narrative-motifs expose commonalities between multiple conspiracy theories even when they refer to different events or circumstances. In the process, these representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about. Our approach enables a population-scale study of conspiracy theories in alternative news and social media with implications for understanding their adoption and combating their spread.",
        "prediction": "Conspiracy theories are everywhere in online discussions. They can be used to explain sudden events that have not been officially reported or to express political disagreement. Conspiracy theories evolve, increase, and connect with each other, making it harder to understand and control them. Therefore, it is important to create methods that can be used on a large scale to study these discussions in online communities. What do users talk about when discussing conspiracy theories online? What are the common themes in their discussions? What do these themes reveal about users' thought processes? This work answers these questions by analyzing over ten years of conversations in r/conspiracy, which is an online community on Reddit focused on conspiracy theories. We examine the main aspects of a conspiracy theory, including the people or groups involved, the actions they take, and their targets. For instance, a narrative-motif like \"governmental agency-controls-communications\" shows how different conspiracy statements suggest that government agencies manipulate information. Therefore, narrative-motifs reveal similarities between various conspiracy theories, even if they relate to different events or situations. This analysis helps us understand the way users discuss conspiracy theories and provides a way to interpret their conversations. Our method allows for a large-scale study of conspiracy theories in alternative news and social media, which is important for understanding how they are accepted and for fighting against their spread.",
        "reference": "Conspiracy theories are omnipresent in online discussions. Conspiracy theories evolve, multiply, and interconnect, complicating how to understand them and to limit their propagation. It is crucial to develop methods to examine the nature of these conspiratorial discussions. What do users talk about? What are the recurring elements in their discussions? What do these elements tell us about the way users think? This work answers these questions by analyzing over ten years of discussions in an online community on the social media Reddit dedicated to conspiratorial discussions. We focus on the key elements of a conspiracy theory: the conspiratorial agents, the actions they perform, and their targets. For example, a narrative-motif (an idea) such as \"governmental agency-controls-communications\" represents the various ways in which multiple conspiratorial statements suggest how governmental agencies control information. Narrative-motifs expose similarities between multiple conspiracy theories even when they refer to different events or circumstances. These representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about. Our approach enables a population-scale study of conspiracy theories in alternative news and social media and ways to understand them and limit their propagation."
      },
      {
        "source": "Blockchain technology is the underlying enabling technology developed for Bitcoin, the most common cryptocurrency. Blockchain technologies have become increasingly popular with the potential to become a powerful disruptive force. Individuals and organizations may benefit from blockchain with its ability to increase secure data exchange and to make that transaction simpler and easier between entities. We investigate factors that influence an individualu0027s intention to use a blockchain cryptocurrency. We develop a model of cryptocurrency adoption grounded in the theory of planned behavior (TPB) to: identify the determinants for the acceptance of cryptocurrency and explore the relative importance of each construct. We offer empirical evidence for a better theoretical understanding of cryptocurrency adoption with practical implications in an e-government context.",
        "prediction": "Blockchain technology is the foundational technology created for Bitcoin which is the most widely used type of digital currency known as cryptocurrency. Blockchain technologies are increasingly popular because they have the potential to fundamentally change various industries. Both individuals and organizations can benefit from blockchain due to its ability to enhance secure data sharing and to simplify and ease transactions between different parties. We examine the factors that affect a personâs intention to use a blockchain-based cryptocurrency. We create a model for cryptocurrency adoption based on the theory of planned behavior which is a psychological theory that helps understand how individual intentions are formed. This model aims to identify the factors that influence the acceptance of cryptocurrency and to evaluate the significance of each of these factors. We provide evidence to improve the theoretical understanding of cryptocurrency adoption and its practical implications in the context of e-government which is the use of digital technology by government agencies to provide services to citizens.",
        "reference": "Blockchain technology is a technology developed for Bitcoin, the most common cryptocurrency. Blockchain technologies have become popular with the potential to become a powerful disruptive force. People and organizations may use it to increase secure data exchange and make transactions simpler and easier. We investigate what influence people to use a blockchain cryptocurrency. We develop a model of cryptocurrency adoption to identify how cryptocurrency is accepted. Our evidence allow a better understanding of cryptocurrency adoption."
      },
      {
        "source": "With the introduction of memory-bound cryptocurrencies, such as Monero, the implementation of mining code in browser-based JavaScript has become a worthwhile alternative to dedicated mining rigs. Based on this technology, a new form of parasitic computing, widely called cryptojacking or drive-by mining, has gained momentum in the web. A cryptojacking site abuses the computing resources of its visitors to covertly mine for cryptocurrencies. In this paper, we systematically explore this phenomenon. For this, we propose a 3-phase analysis approach, which enables us to identify mining scripts and conduct a large-scale study on the prevalence of cryptojacking in the Alexa 1 million websites. We find that cryptojacking is common, with currently 1 out of 500 sites hosting a mining script. Moreover, we perform several secondary analyses to gain insight into the cryptojacking landscape, including a measurement of code characteristics, an estimate of expected mining revenue, and an evaluation of current blacklist-based countermeasures.",
        "prediction": "With the introduction of memory-bound cryptocurrencies such as Monero the implementation of mining code in browser-based JavaScript has become a worthwhile alternative to dedicated mining rigs Memory-bound cryptocurrencies are digital currencies that rely heavily on a user's computer memory for mining rather than processing power Based on this technology a new form of parasitic computing widely called cryptojacking or drive-by mining has gained momentum on the web Cryptojacking is when a website takes advantage of the computing resources of its visitors to secretly mine for cryptocurrencies In this paper we systematically explore this phenomenon For this we propose a three-phase analysis approach which helps us identify mining scripts and conduct a large-scale study on how common cryptojacking is in the Alexa 1 million websites Alexa is a service that ranks websites based on traffic We find that cryptojacking is common with currently 1 out of 500 sites hosting a mining script Moreover we perform several secondary analyses to gain insight into the cryptojacking landscape These analyses include examining code characteristics estimating expected mining revenue and evaluating current blacklist-based countermeasures Blacklist-based countermeasures are methods used to block harmful websites from being accessed",
        "reference": "Memory-bound cryptocurrencies like Monero can be mined  from a browser with JavaScript, better than with a dedicated rig. However, this technology enables cryptojacking, whereby a site covertly mines for cryptocurrencies on its visitorsâ computers. We propose a new approach to identify mining scripts. The approach was evaluated on Alexa 1 websites. Cryptojacking is common, as 1 in 500 sites host a mining script. We also measured code characteristics, estimated mining revenue, and evaluated blacklist-based countermeasures."
      },
      {
        "source": "The rise of modern blockchains has facilitated the emergence of smart contracts: autonomous programs that live and run on the blockchain. Smart contracts have seen a rapid climb to prominence, with applications predicted in law, business, commerce, and governance.  contracts :[39],\"are commonly written in a high-level language such as Ethereumu0027s Solidity, and translated to compact low-level bytecode for deployment on the blockchain. Once deployed, the bytecode is autonomously executed, usually by a %Turing-complete virtual machine. As with all programs, smart contracts can be highly vulnerable to malicious attacks due to deficient programming methodologies, languages, and toolchains, including buggy compilers. At the same time, smart contracts :[39],\"are also high-value targets, often commanding large amounts of cryptocurrency. Hence, developers and auditors need security frameworks capable of analysing low-level bytecode to detect potential security vulnerabilities. In this paper, we present Vandal: a security analysis framework for Ethereum smart contracts. Vandal consists of an analysis pipeline that converts low-level Ethereum Virtual Machine (EVM) bytecode to semantic logic relations. Users of the framework can express security analyses in a declarative fashion: a security analysis is expressed in a logic specification written in the \\souffle language.",
        "prediction": "The rise of modern blockchains has facilitated the emergence of smart contracts autonomous programs that live and run on the blockchain Smart contracts have seen a rapid climb to prominence with applications predicted in law business commerce and governance Smart contracts are commonly written in a high-level language such as Ethereum's Solidity and translated to compact low-level bytecode for deployment on the blockchain Once deployed the bytecode is autonomously executed usually by a Turing-complete virtual machine A Turing-complete virtual machine is a system that can execute any computation that can be done by a traditional computer As with all programs smart contracts can be highly vulnerable to malicious attacks due to deficient programming methodologies languages and toolchains including buggy compilers At the same time smart contracts are also high-value targets often commanding large amounts of cryptocurrency Hence developers and auditors need security frameworks capable of analyzing low-level bytecode to detect potential security vulnerabilities In this paper we present Vandal a security analysis framework for Ethereum smart contracts Vandal consists of an analysis pipeline that converts low-level Ethereum Virtual Machine EVM bytecode to semantic logic relations Users of the framework can express security analyses in a declarative fashion a security analysis is expressed in a logic specification written in the Souffle language",
        "reference": "Smart contracts have appeared thanks to blockchain technology. These autonomous programs are used in law, business, commerce, and governance. Smart contracts are written in a high-level language such as Ethereumâs Solidity and translated to bytecode. that live and run on the blockchain are predicted in Once deployed on the blockchain, the bytecode is autonomous. Smart contracts are vulnerable to malicious attacks due to poor programming, languages and toolchains Smart contracts can command large amounts of cryptocurrency. Developers and auditors need frameworks to detect security vulnerabilities. Vandal is a security analysis framework for Ethereum smart contracts. Vandal converts Ethereum Virtual Machine bytecode to semantic logic relations. Users can express security analyses in the SoufflÃ© language."
      },
      {
        "source": "Vandal is both fast and robust, successfully analysing over 95\\% of all 141k unique contracts with an average runtime of 4.15 seconds; outperforming the current state of the art tools---Oyente, EthIR, Mythril, and Rattle---under equivalent conditions.",
        "prediction": "Vandal is both fast and strong, successfully analyzing over 95% of all 141,000 unique contracts with an average runtime of 4.15 seconds. It performs better than the current best tools, which are Oyente, EthIR, Mythril, and Rattle, under similar conditions.",
        "reference": "Vandal is both efficient (95% accuracy), fast (141k in 4.15 s) and robust. It outperforms the state of the art tools like Oyente, EthIR, Mythril, and Rattle"
      },
      {
        "source": "As Bitcoinu0027s popularity has grown over the decade since its creation, it has become an increasingly attractive target for adversaries of all kinds.",
        "prediction": "As Bitcoin's popularity has grown over the decade since its creation, it has become an increasingly attractive target for adversaries of all kinds",
        "reference": "One of the most powerful potential adversaries is the country of China, which has expressed adversarial positions regarding the cryptocurrency and demonstrated powerful capabilities to influence it."
      },
      {
        "source": "For decentralised P2P networks, it is very important to have a mechanism in place that allows the nodes to control resource usage and prevent flooding and denial-of-service attacks with spam. In this paper, we discuss and compare the different approaches to fully decentralised resource control that are used by projects in the cryptocurrency space. The introduced methods are then applied to design a decentralised exchange for Namecoin names (or more generally, crypto assets) as an example.",
        "prediction": "For decentralized peer-to-peer (P2P) networks, it is very important to have a system that allows the nodes, which are the active participants in the network, to manage how resources are used. This system helps prevent flooding and denial-of-service attacks, which are attempts to make a network unavailable by overwhelming it with spam or excessive requests. In this paper, we discuss and compare different methods of fully decentralized resource management that are used by various projects in the cryptocurrency space. The methods we introduce are then applied to create a decentralized exchange for Namecoin names, which are a type of digital asset, or more generally, for crypto assets.",
        "reference": "In decentralised P2P networks nodes need a way  to control resource usage and prevent flooding and denial-of-service attacks. We compared different approaches to decentralised resource control in cryptocurrency projects. We designed a decentralised exchange for crypto assets, for  example Namecoin names, with these methods."
      },
      {
        "source": "Cryptocurrency is a rapid developing financial technology innovation which has attracted a large number of people around the world. The high-speed evolution, radical price fluctuations of cryptocurrency, and the inconsistent attitudes of monetary authorities in different countries have triggered panic and chain reactions towards the application and adoption of cryptocurrency and have caused public security related events. In this paper, we analyze the dynamics and systemic risk of the cryptocurrency market based on the public available price history. Furthermore, consistent with public perception, our quantitative analysis reveals that the cryptocurrency market is relatively fragile and unstable.",
        "prediction": "Cryptocurrency is a rapidly developing financial technology that has attracted many people around the world. The fast changes in cryptocurrency, extreme price fluctuations, and different attitudes of monetary authorities, which are government bodies in charge of managing a country's money supply and interest rates, have caused fear and reactions towards using and accepting cryptocurrency. This has also led to events related to public safety. In this paper, we analyze the dynamics, which refer to the forces that cause changes, and systemic risk, which is the risk of a breakdown in an entire system, of the cryptocurrency market based on publicly available price history. Additionally, in line with what the public thinks, our quantitative analysis, which uses numerical data for analysis, shows that the cryptocurrency market is relatively fragile and unstable.",
        "reference": "Cryptocurrency is a financial technology innovation which has attracted many people around the world. The high-speed evolution, radical price fluctuations of cryptocurrency, and the inconsistent attitudes of monetary authorities in different countries have caused panic. In this paper, we analyze the dynamics and risks of the cryptocurrency market. Consistent with public perception, our analysis reveals that the cryptocurrency market is fragile and unstable."
      },
      {
        "source": "Cryptocurrency was built initially as a possible implementation of digital currency, then various derivatives were created in a variety of fields such as financial transactions, capital management, and even nonmonetary applications. This paper aims to offer analytical insights to help understand cryptocurrency by treating it as a financial asset. We position cryptocurrency by comparing its dynamic characteristics with two traditional and massively adopted financial assets: foreign exchange and stock. Our investigation suggests that the dynamics of cryptocurrency are more similar to stock. As to the robustness and clustering structure, our analysis shows cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market.",
        "prediction": "Cryptocurrency was initially created as a type of digital currency, and over time, various versions have been developed for different uses like financial transactions, managing investments, and even nonmonetary purposes. This paper aims to provide insights for understanding cryptocurrency by examining it as a financial asset. We compare cryptocurrency's features with two widely used financial assets: foreign exchange, which involves trading currencies, and stocks, which represent shares in companies. Our research indicates that the behavior of cryptocurrency is more akin to that of stocks. However, when looking at stability and how investments group together, our analysis reveals that the cryptocurrency market is more unstable than the stock market, making it currently a high-risk financial market.",
        "reference": "Cryptocurrency was initially an implementation of digital currency, then derivatives were created in various fields. This paper aims to help understand cryptocurrency. We compared cryptocurrency with foreign exchange and stock. Our investigation suggests that cryptocurrency is similar to stock. Our analysis shows that cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market."
      },
      {
        "source": "The smart device owning rate such as smart phone and smart watch is higher than ever before and mobile payment has become one of the major payment methods in many different areas. At the same time, blockchain-based cryptocurrency is becoming a nonnegligible type of currency and the total value of all types of cryptocurrency has reached USD 200 billion. Therefore, it is a natural demand to support cryptocurrency payment on mobile devices. Considering the poor infrastructure and low penetration of financial service in developing countries, this combination is especially attractive. The high storage cost and payment processing latency are the two main obstacles for mobile payment using cryptocurrency. We propose two different schemes for cryptocurrency mobile payment, one involves a centralized bank and the other one does not require any centralized party. We also provide a solution for the bank to meet KYC (know your customer)/AML (antimoney laundering) compliance requirements when it is involved in cryptocurrency mobile payment processing.",
        "prediction": "The rate of ownership for smart devices like smartphones and smartwatches is higher than ever before, and mobile payment has become one of the main methods of payment in many areas. At the same time, cryptocurrency based on blockchain technology is becoming an important type of currency, with the total value of all cryptocurrencies reaching 200 billion US dollars. As a result, there is a clear demand for supporting cryptocurrency payments on mobile devices. This is particularly appealing in developing countries, where financial services are not widespread and infrastructure is weak. However, high storage costs and delays in payment processing are major challenges for using cryptocurrency in mobile payments. We propose two different plans for cryptocurrency mobile payments, one that involves a centralized bank and another that does not rely on any central authority. Additionally, we provide a solution for the bank to comply with KYC, which stands for \"know your customer,\" and AML, which stands for \"anti-money laundering\" regulations when it participates in processing cryptocurrency mobile payments.",
        "reference": "The owning rate of smart devices is higher than ever before and mobile payment has become a major payment method. Cryptocurrency is becoming an important type of currency and the total value of cryptocurrencies has reached USD 200 billion. Therefore, support of cryptocurrency payment on mobile devices is a natural demand. Considering the poor infrastructure and the low usage of financial service in developing countries, this combination is especially attractive. The high storage cost and payment processing latency are two obstacles for cryptocurrency mobile payment. We propose two solutions, one with a centralized bank and the other one without any centralized party. We also provide a solution for the bank to meet KYC (know your customer)/AML (antimoney laundering) expectations about cryptocurrency mobile payment."
      },
      {
        "source": "Motivated by recent financial crises significant research efforts have been put into studying contagion effects and herding behaviour in financial markets. Much less has been said about influence of financial news on financial markets. We propose a novel measure of collective behaviour in financial news on the Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic risk indicator. We evaluate the NCI on financial documents from large Web news sources on a daily basis from October 2011 to July 2013 and analyse the interplay between financial markets and financially related news. We hypothesized that strong cohesion in financial news reflects movements in the financial markets. Cohesiveness is more general and robust measure of systemic risk expressed in news, than measures based on simple occurrences of specific terms. Our results indicate that cohesiveness in the financial news is highly correlated with and driven by volatility on the financial markets.",
        "prediction": "Motivated by recent financial crises, significant research efforts have focused on studying contagion effects and herding behavior in financial markets. Contagion effects refer to the spread of market shocks from one sector to others, while herding behavior is when investors follow othersâ actions rather than relying on their own analysis. Much less attention has been given to how financial news influences these markets. We propose a new measure of collective behavior in financial news called the News Cohesiveness Index (NCI), which can serve as an indicator of systemic risk. Systemic risk refers to the potential for widespread financial instability. We evaluate the NCI using financial documents from large web news sources daily from October 2011 to July 2013, analyzing the relationship between financial markets and related news. We hypothesized that strong cohesiveness in financial news indicates movements in the financial markets. Cohesiveness is a more general and reliable measure of systemic risk as expressed in news, compared to measures that only count specific terms. Our findings show that cohesiveness in financial news is highly correlated with and influenced by volatility in the financial markets.",
        "reference": "Motivated by recent financial crises, research efforts have been put into studying contagion effects (spread of market disturbances) and herding behaviour (individuals acting collectively without centralized direction) in financial markets. Much less has been said about influence of financial news on financial markets. We propose a measure of collective behaviour in financial news on the Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic risk indicator, which signals probability of financial system crises. We evaluate the NCI on financial documents from Web news sources and analyse the relation between financial markets and financial news. We hypothesized that strong cohesion in financial news reflects variations in the financial markets. Cohesiveness is a better measure of systemic risk expressed in news, than measures based on simple occurrences of specific terms. Our results show that cohesiveness in the financial news is highly correlated with variations in the financial markets."
      },
      {
        "source": "In this paper, I propose a methodology to study the comovement between the entropy of different financial markets. The entropy is derived using singular value decomposition of the components of stock market indices in financial markets from selected developed economies, i.e., France, Germany, the United Kingdom, and the United States. I study how a shock in the entropy in the United States affects the entropy in the other financial markets. I also model the entropy using a dynamic factor model and derive a common factor behind the entropy movements in these four markets.",
        "prediction": "In this paper, I propose a way to study how the measure of disorder, known as entropy, behaves in different financial markets. Entropy is calculated using a mathematical technique called singular value decomposition, which helps to analyze stock market indices from selected developed countries, specifically France, Germany, the United Kingdom, and the United States. I investigate how a sudden change in entropy in the United States impacts the entropy in the other financial markets. Additionally, I use a dynamic factor model, which is a statistical method for analyzing data that changes over time, to understand the common influences behind the changes in entropy in these four markets.",
        "reference": "In this paper, I propose a methodology to study the comovement (correlation on profits on investment) between the entropy (randomness and uncertainty) of different financial markets. The entropy is based on the components measuring the stock market in financial markets from selected developed economies (France, Germany, the United Kingdom, and the United States). I study how a shock in the entropy in the United States affects the entropy in the other financial markets. I also model the entropy using different time variables and obtain a common factor behind the entropy movements in these four markets."
      },
      {
        "source": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones, and fraudsters have evolved with them. Smartphones are packed with functionality that can easily be used for data theft or inappropriate contact with other parties - none of which passes through company-owned systems, and is to all intents and purposes 'off the grid'. Employers need to be aware of these risks when devices are issued, along with ensuring that processes are in place when suspicions are raised, explains Philip Ridley of CCL-Forensics. Detecting 'tech-savvy' corporate fraudsters is a constant game of catch-up. It's not only about playing catch-up with the intellect, motives and awareness of the e-fraudster, but also the technologies that can be misused. What's more, the methods through which the technology can be manipulated to secrete, disguise and protect fraudulent activities - all while staying away from corporate networks where they can readily be monitored and detected - are constantly evolving. This means a company's intellectual property and sensitive data is at risk of sabotage or just good old-fashioned theft.",
        "prediction": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones, and fraudsters have evolved with them. Smartphones are advanced mobile devices that come with many features which can be used for stealing data or making inappropriate contacts with others. These actions often happen outside of company systems and are considered to be 'off the grid'. Employers need to understand these risks when they give out devices and must have procedures in place when there are suspicions about misuse, explains Philip Ridley of CCL-Forensics. Detecting skilled corporate fraudsters is an ongoing challenge. It's not just about keeping up with the cleverness, motives, and knowledge of the e-fraudster, but also the technologies that can be exploited. Furthermore, the ways in which technology can be used to hide, disguise, and protect fraudulent actionsâwhile avoiding corporate networks where they can be easily monitored and detectedâare always changing. This means that a company's intellectual property, which includes ideas and inventions, and sensitive data are at risk of being sabotaged or simply stolen.",
        "reference": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones, and fraudsters have evolved with them. Smartphones have functionalities that can be used for data theft or inappropriate contact with other parties. They are out of the systems of the company and are not monitored or controlled. Employers need to be aware of these risks when devices are delivered and have processes when suspicions are raised. Detecting fraudsters with computer skills is a constant game of catch-up. It's not only about playing catch-up with the cyberfraudster, but also the technologies that can be misused. Moreover, the methods assisting fraudulent activities (still out of reach of company systems) are constantly evolving. This means a company's intellectual property and sensitive data is at risk of sabotage or theft."
      },
      {
        "source": "Phishers continue to alter the source code of the web pages used in their attacks to mimic changes to legitimate websites of spoofed organizations and to avoid detection by phishing countermeasures. Manipulations can be as subtle as source code changes or as apparent as adding or removing significant content. To appropriately respond to these changes to phishing campaigns, a cadre of file matching algorithms is implemented to detect phishing websites based on their content, employing a custom data set consisting of 17,992 phishing attacks targeting 159 different brands. The results of the experiments using a variety of different content-based approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate.",
        "prediction": "Phishers change the source code of web pages used in their attacks to make them look like real websites of impersonated organizations and to avoid being detected by methods designed to stop phishing. These changes can be as simple as minor modifications to the source code or as obvious as adding or removing important information. To effectively respond to these changes in phishing campaigns, a group of file matching algorithms is used to find phishing websites based on their content. This process uses a special data set that includes 17,992 phishing attacks against 159 different brands. The results from tests using various content-based methods show that some of them can detect more than 90% of phishing incidents while keeping the false positive rate low.",
        "reference": "Phishers, people who attempt to trick people over the internet to steal their money, continue to modify the web pages used in their attacks to imitate websites of spoofed organizations and to avoid detection by phishing countermeasures. Manipulations can be as subtle as changing the source code, which is the programming instructions, or as apparent as adding or removing significant content. To respond to these changes to phishing campaigns, algorithms are used to detect phishing websites based on their content, employing a data set consisting of 17,992 phishing attacks targeting 159 different brands. The results of the experiments using different approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate."
      },
      {
        "source": "Mobile devices are very common in everyoneâs day-to- day life. Nowadays such devices come with many features of desktop or laptop. Hence people can use these devices for diverse applications. As the acceptability and usability of such devices are very high, there are chances that these devices can be used for illegal activities. The percentage of mobile phones or smart phones involved in cyber crimes is in hike. So it becomes necessary to digitally analyze such devices requiring cyber forensics tools. This paper discusses different types of digital evidence present in Microsoftâs Windows Mobile smart phones and an agent based approach for logically acquiring such devices. Also it describes a tool developed for forensically acquiring and analyzing Windows Mobile devices and WinCE PDAs.",
        "prediction": "Mobile devices are very common in everyoneâs daily life. Nowadays, these devices have many features similar to those of desktop or laptop computers. As a result, people can use these devices for various applications. Because mobile devices are widely accepted and used, there is a risk that they can also be used for illegal activities. The percentage of mobile phones or smartphones involved in cyber crimes is increasing. Therefore, it is necessary to digitally analyze these devices, which requires cyber forensics tools. This paper discusses different types of digital evidence present in Microsoftâs Windows Mobile smartphones and an agent-based approach for logically acquiring such devices. It also describes a tool developed for forensically acquiring and analyzing Windows Mobile devices and Windows CE (WinCE) Personal Digital Assistants (PDAs).",
        "reference": "Mobile devices are very common in everyoneâs day-to-day life. Nowadays such devices come with many features of computers. People can use these devices for diverse applications. There are chances that these devices can be used for illegal activities. The percentage of mobile phones or smart phones involved in cyber crimes is increasing. So it becomes necessary to digitally analyze such devices with cyber forensics tools. This paper discusses different types of digital evidence present in Microsoftâs Windows Mobile smart phones and how to acquire such devices. Also it describes a forensic tool for acquiring and analyzing Windows Mobile devices and personal digital assistants."
      },
      {
        "source": "Detection of different types of image editing operations carried out on an image is an important problem in image forensics. It gives the information about the processing history of an image, and also can expose forgeries present in an image. There have been a few methods proposed to detect different types of image editing operations in a single framework. However, all the operations have to be known a priori in the training phase. But, in real-forensics scenarios it may not be possible to know about the editing operations carried out on an image. To solve this problem, we propose a novel deep learning-based method which can differentiate between different types of image editing operations. The proposed method classifies image patches in a pair-wise fashion as either similarly or differently processed using a deep siamese neural network. Once the network learns feature that can discriminate between different image editing operations, it can differentiate between different image editing operations not present in the training stage. The experimental results show the efficacy of the proposed method in detecting/discriminating different image editing operations.",
        "prediction": "Detecting various types of image editing actions performed on an image is a significant issue in image forensics. Image forensics is the field that deals with the investigation of images to determine their authenticity and the methods used to manipulate them. This detection provides information about the history of how an image was processed and can reveal any alterations or forgeries. Some methods have been introduced to identify different types of image editing actions within a single system. However, these methods require prior knowledge of all editing actions during the training phase. In real forensic situations, it may not always be possible to know the editing actions done on an image. To address this challenge, we present a new method based on deep learning that can identify various image editing actions. Our method classifies sections of an image in pairs as either similarly edited or differently edited using a deep Siamese neural network. A Siamese neural network is a type of neural network architecture that learns to differentiate between two inputs. Once this network learns the features that help distinguish between various image editing actions, it can identify editing actions that were not included during training. The results from our experiments demonstrate the effectiveness of our proposed method in detecting and differentiating different image editing actions.",
        "reference": "Detection of image editing is an important task in image forensics. The edit history of an image can expose forgeries in the image. Various methods have been proposed to detect image editing operations. However all of the possible types of image manipulation must be known in advance. But, in the real world, manipulations on images are sometimes unknowable. A novel deep learning-based method can distinguish between different types of image editing operations. This method uses a deep siamese neural network to compare images two by two. Using deep learning, the computer can learn to see features of edited images as compared to unedited and learn to differentiate between different image editing operations. This method works to find out what editing an image has undergone."
      },
      {
        "source": "The increasing prevalence of Internet of Things (IoT) devices has made it inevitable that their pertinence to digital forensic investigations will increase into the foreseeable future. These devices produced by various vendors often posses limited standard interfaces for communication, such as USB ports or WiFi/Bluetooth wireless interfaces. Meanwhile, with an increasing mainstream focus on the security and privacy of user data, built-in encryption is becoming commonplace in consumer-level computing devices, and IoT devices are no exception. Under these circumstances, a significant challenge is presented to digital forensic investigations where data from IoT devices needs to be analysed. This work explores the electromagnetic (EM) side-channel analysis literature for the purpose of assisting digital forensic investigations on IoT devices. EM side-channel analysis is a technique where unintentional electromagnetic emissions are used for eavesdropping on the operations and data handling of computing devices. The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require, and must result in, no modification to the target device. The literature on various EM side-channel analysis attack techniques are discussed â selected on the basis of their applicability in IoT device investigation scenarios. The insight gained from the background study is used to identify promising future applications of the technique for digital forensic analysis on IoT devices â potentially progressing a wide variety of currently hindered digital investigations.",
        "prediction": "The increasing use of Internet of Things (IoT) devices means that their role in digital forensic investigations will grow in the coming years. IoT devices, made by different manufacturers, often have limited standard ways to communicate, such as Universal Serial Bus (USB) ports or wireless connections like WiFi and Bluetooth. At the same time, as there is more focus on protecting user data, built-in encryption is becoming common in consumer devices, including IoT devices. This creates a major challenge for digital forensics, which involves analyzing data from IoT devices. This work looks into electromagnetic (EM) side-channel analysis to help with digital forensic investigations on IoT devices. EM side-channel analysis is a method that uses unintentional electromagnetic emissions to secretly observe the operations and data management of devices. Since EM side-channel methods do not interfere with the target device, they are a suitable option for digital forensics, as these methods do not change anything on the device being studied. The literature discusses various EM side-channel attack techniques chosen for their relevance to investigating IoT devices. The knowledge gained from this background research is used to discover promising future uses of this technique for digital forensic analysis on IoT devices, which could help improve many digital investigations currently facing challenges.",
        "reference": "Internet of Things (IoT) devices (devices connected to the internet, collecting and sharing data) will be used in digital forensic investigations in the future. These devices have limited interfaces for communication, such as USB ports or WiFi/Bluetooth wireless interfaces. Meanwhile, with an increasing focus on the security and privacy of user data, built-in encryption (which encode information) is becoming commonplace in devices. This presents a significant challenge to digital forensic investigations, where data from IoT devices needs to be analysed. This work explores the electromagnetic (EM) side-channel analysis literature for the purpose of assisting digital forensic investigations on IoT devices. EM side-channel analysis is a technique where electromagnetic emissions are used for eavesdropping on the operations and data handling of devices. The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require no modification to the target device. The literature on various EM side-channel analysis attack techniques are discussed â selected according to their applicability in IoT device investigations. The data obtained from our survey are used to identify promising future applications of the technique for digital forensic analysis on IoT devices."
      },
      {
        "source": "The malicious alteration of machine time is a big challenge in computer forensics. Performance figures show the feasibility of our proposal. Detecting such changes and reconstructing the actual timeline of events is of paramount importance. However, this can be difficult since the attacker has many opportunities and means to hide such changes. In particular, cloud computing, host and guest machine time can be manipulated in various ways by an attacker. Guest virtual machines are especially vulnerable to attacks coming from their (more privileged) host. As such, it is important to guarantee the timeline integrity of both hosts and guests in a cloud, or at least to ensure that the alteration of such timeline does not go undetected. In this paper we survey the issues related to host and guest machine time integrity in the cloud. Further, we describe a novel architecture for host and guest time alteration detection and correction/resilience with respect to compromised hosts and guests. The proposed framework has been implemented on an especially built simulator.",
        "prediction": "The harmful change of machine time is a big problem in computer investigation. Performance data show that our idea is workable. Finding these changes and rebuilding the real sequence of events is extremely important. However, this can be hard because attackers have many ways to hide these changes. Specifically, in cloud computing, the time of both the host (the main system) and guest machines (virtual machines running on the host) can be changed by an attacker in different ways. Guest virtual machines are particularly at risk from attacks from their host, which has more privileges. Therefore, it is important to ensure the timeline integrity, or the accuracy of the timeline, of both hosts and guests in a cloud setting, or at least to make sure that any changes to this timeline are noticed. In this paper, we examine the problems related to the time integrity of hosts and guests in the cloud. Additionally, we present a new system for detecting and correcting time changes or improving resilience against compromised hosts and guests. The proposed structure has been tested on a specially designed simulator.",
        "reference": "Machine timestamp falsification can be used in cyber attacks. The algorithm detects manipulations effectively. That is why it is important to detect such changes and to reconstruct the actual timeline of events. However, the hacker can try to hide their tracks. In cloud computing, hackers can manipulate host and guest machine time. Guest virtual machines use computing resources provided by a physical machine called a host. Guest virtual machines are especially vulnerable to attacks coming from their host. That is why the timeline integrity of both hosts and guests in a cloud is important. Any manipulation of such a timeline should be detected. In this paper we survey the issues related to host and guest machine time integrity in the cloud. A new algorithm is proposed to detect host and guest time manipulations and to correct or reject them. A simulator has been built for this purpose."
      },
      {
        "source": "Image tampering, being readily facilitated and proliferated by todayâs digital techniques, is increasingly causing problems regarding the authenticity of images. As the most popular multimedia data, JPEG images can be easily tampered without leaving any clues; therefore, JPEG-based forensics , including the detection of double compression, interpolation, rotation, etc., has become an active research topic in multimedia forensics. Nevertheless, the interesting issue of detecting image tampering and its related operations by using the same quantization matrix has not been fully investigated. Aiming to detect such forgery manipulations under the same quantization matrix, we propose a detection method by using shift-recompression -based reshuffle characteristic features. The learning classifiers are applied for classification. Our experimental results indicate that the approach is indeed highly effective in detecting image tampering and relevant manipulations with the same quantization matrix.",
        "prediction": "Image tampering is becoming a bigger issue due to modern digital techniques that make it easy to alter images, raising concerns about their authenticity. JPEG images, a common type of image format, can be easily changed without leaving noticeable signs, making JPEG-based forensic methods important. Forensics refers to the application of scientific methods to investigate crime. In this context, it includes detecting signs of manipulation, such as double compression, interpolation (the process of estimating values between two known values), and rotation. However, the ability to identify image tampering that uses the same quantization matrix needs more research. A quantization matrix is a component used in compressing images to reduce file size while maintaining quality. To address this, we suggest a detection method that uses characteristics from shift-recompression, which is a technique for altering an image without significant changes. We apply learning classifiers, which are algorithms that can learn from data to make predictions or categorizations. Our test results show that this method is very effective in detecting image tampering and related modifications that occur using the same quantization matrix.",
        "reference": "Image tampering has become a serious problem with the advancement of digital techniques. JPEG images can be easily manipulated without leaving any clues. This is why researchers are trying to develop methods for JPEG image manipulation detection. However, methods based on image compression techniques, like quantization, are rarely applied. To detect such manipulations, we propose a detection method to identify inconsistencies in the quantization matrix caused by the manipulation. Then machine learning algorithms are applied to detect image manipulation. Experimental results show that the approach is highly effective in detecting image tampering."
      },
      {
        "source": "In this paper, we present a novel approach to accurately calibrate the kinematic model of a humanoid based on observations of its monocular camera. Our technique estimates the parameters of the complete model, consisting of the joint angle offsets of the whole body including the legs, as well as the camera extrinsic and intrinsic parameters. Furthermore, we developed an approach to automatically select a subset of configurations for the calibration process that yields a good trade-off between the number of observations and accuracy. Further, our approach to configuration selection yields substantially better optimization results compared to randomly chosen viable configurations. Hence, our system only requires a reduced number of configurations to achieve accurate results. Our optimization is general and the implementation, which is available online, can easily be applied to different humanoids.",
        "prediction": "In this paper, we present a new method to accurately adjust the movement model of a humanoid robot using data from its single camera. Our technique estimates the settings of the entire model, which includes the angles of all joints in the body, such as the legs, as well as the cameraâs external and internal settings. Additionally, we created a method to automatically choose a selection of positions for the calibration that provides a good balance between the number of observations and accuracy. Furthermore, our method for selecting positions leads to significantly better results in optimization compared to configurations chosen randomly. Therefore, our system only needs fewer positions to achieve precise results. Our optimization technique is universal, and the implementation, which can be found online, is easily applicable to different humanoid robots.",
        "reference": "In this paper, we present a novel approach to accurately calibrate a humanoid and its motions (robot with human form or characteristics) based on observations of its camera. Our technique estimates the parameters of the complete model, consisting of the joint angle offsets and the camera parameters. We developed an approach to automatically select configurations for the calibration process that produces a good compromise between the number of observations and accuracy. Our approach to configuration selection generates better optimization results compared to randomly chosen viable configurations. Thus, our system only requires a reduced number of configurations to achieve accurate results. Our optimization is general and the implementation, which is available online, can easily be applied to different humanoids."
      },
      {
        "source": "In this paper, we present an integrated navigation system that allows humanoid robots to autonomously navigate in unknown, cluttered environments. From the data of an onboard consumer-grade depth camera, our system estimates the robot's pose to compensate for drift of odometry and maintains a heightmap representation of the environment. Based on this model, our system iteratively computes sequences of safe actions including footsteps and whole-body motions, leading the robot to target locations. To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles. As we demonstrate in experiments with a Nao humanoid, our system leads to robust navigation in cluttered environments and the robot is able to traverse highly challenging passages.",
        "prediction": "In this paper, we present an integrated navigation system that enables humanoid robots to move independently in unknown and messy environments. Using data from a consumer-grade depth camera, which measures the distance between the robot and objects around it, our system estimates the robot's position to counteract any inaccuracies from its movement tracking. It also keeps a heightmap representation of the environment, which is a 2D depiction showing elevation changes. Based on this model, our system continually calculates sequences of safe actions, such as how to place its feet and how to move its entire body, to guide the robot to specific target locations. To effectively check for possible collisions while planning its movements, we created a new method that considers the shapes of both the robot and the obstacles. In experiments with a Nao humanoid robot, our system demonstrates reliable navigation in cluttered environments, allowing the robot to successfully pass through very difficult spaces.",
        "reference": "In this paper, we present a navigation system that allows humanoid robots (robots with human form or characteristics) to autonomously navigate in unknown, cluttered environments. From the data of a camera which can judge depth and distance, our system estimates the robotâs position and maintains a height representation of the environment. Our system determines safe actions (including footsteps and body motions) leading the robot to target locations. To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles. As we demonstrate in experiments, our system allows the robot to navigate in clustered environments and traverse challenging passages."
      },
      {
        "source": "In this paper, we introduce an approach to efficient robot navigation through cluttered indoor environments. We propose to estimate local obstacle densities based on already detected objects and use them to predict traversal costs corresponding to potential obstacles in regions not yet observable by the robot's sensors. By taking into account the predicted costs for path planning, the robot is then able to navigate in a more foresighted manner and reduces the risk of getting stuck in cluttered regions. As the experimental results demonstrate, our method enables the robot to efficiently navigate through environments containing cluttered regions and achieves significantly shorter completion times compared to a standard approach not using any prediction.",
        "prediction": "In this paper, we introduce a method to help robots move efficiently through messy indoor spaces. We suggest estimating how many obstacles are in the local area based on objects that have already been detected. This information is used to predict the difficulty of moving through areas that the robot's sensors cannot see yet. By considering these predicted difficulties when planning a route, the robot can move more wisely and lessen the chances of getting stuck in crowded areas. The results from our tests show that our approach allows the robot to successfully navigate through cluttered spaces and complete tasks much faster than a typical method that does not use predictions.",
        "reference": "In this paper, we introduce an approach for robot to navigate through cluttered indoor environments. We propose to estimate obstacles based on already detected objects and use them to predict potential obstacles in regions not yet observable by the robot. The robot is then able to navigate in a more anticipated manner and reduces the risk of getting stuck. Our method enables the robot to efficiently navigate through cluttered environments and faster than a standard approach not using any prediction."
      },
      {
        "source": "In many situations, users walk on typical paths between specific destinations at which the service of a mobile robot is needed. Depending on the environment and the paths, step-by-step following of the human might not be the optimal solution since better paths for the robot exist. We propose to perform a prediction about the human's future movements and use this information in a reinforcement learning framework to generate foresighted navigation actions for the robot. Since frequent occlusions of the human will occur due to obstacles and the robot's constrained field of view, the estimate about the humans's position and the prediction of the next destination are affected by uncertainty. Our approach deals with such situations by explicitly considering occlusions in the reward function such that the robot automatically considers to execute actions to get the human in its field of view. We show in simulated and real-world experiments that our technique leads to significantly shorter paths compared to an approach in which the robot always tries to closely follow the user and, additionally, can handle occlusions.",
        "prediction": "In many situations, users typically walk along certain paths to reach specific destinations where a mobile robot is needed. Depending on the environment and the paths, simply following the human step-by-step might not be the best solution because better paths for the robot may exist. We suggest predicting the human's future movements and using this information in a reinforcement learning framework to create smarter navigation actions for the robot. Since the human will often be blocked from the robot's view by obstacles, the robot's estimate of the human's position and prediction of the next destination will have some uncertainty. Our method addresses these situations by taking occlusions into account in the reward function, which helps the robot decide to execute actions that allow it to see the human. We demonstrate through both simulated and real-world experiments that our technique produces significantly shorter paths compared to an approach where the robot always tries to follow the user closely and can also manage occlusions.",
        "reference": "In many situations, users walk on typical paths between specific destinations at which the service of a mobile robot is needed. Depending on the environment and the paths, following the human might not be the optimal solution because better paths for the robot exist. We propose to predict the humanâs future movements and use this information to generate navigation actions for the robot. The estimation of the humanâs position and the prediction of the next destination are uncertain because of the occlusions due to obstacles and the robotâs limited field of view. Our approach deals with considering occlusions so the robot automatically considers to execute actions to get the human in its field of view. We show that our technique leads to significantly shorter paths compared to an approach in which the robot follows the user and, additionally, can handle occlusions."
      },
      {
        "source": "An autonomous service robot often first has to search for a user to carry out a desired task. This is a challenging problem, especially when this person moves around since the robotâs field of view is constrained and the environment structure typically poses further visibility constraints that influence the perception of the user. In this paper, we propose a novel method that computes the likelihood of the userâs observability at each possible location in the environment based on Monte Carlo simulations. As the robot needs time to reach the possible search locations, we take this time as well as the visibility constraints into account when computing effective search locations. In this way, the robot can choose the next search location that has the maximum expected observability of the user. Our experiments in various simulated environments demonstrate that our approach leads to a significantly shorter search time compared to a greedy approach with background information.",
        "prediction": "An autonomous service robot often first has to search for a user to carry out a desired task. This is a challenging problem, especially when this person moves around since the robotâs field of view is limited and the structure of the environment usually creates additional visibility issues that affect the robot's ability to see the user. In this paper, we propose a new method that calculates the probability of being able to see the user at each possible location in the environment using a technique called Monte Carlo simulations. Monte Carlo simulations are methods that rely on repeated random sampling to obtain numerical results. Since the robot needs time to get to the potential search locations, we consider this travel time and the visibility issues when determining the best search locations. This way, the robot can pick the next search location that offers the highest chance of seeing the user. Our experiments in different simulated environments show that our method results in a much shorter search time compared to a greedy approach that uses background information.",
        "reference": "An autonomous service robot often first has to search for a user to execute a task. This is a challenging problem, especially when this person moves around because the robotâs field of view is limited. The environment also poses visibility limitations that influence the perception of the user. In this paper, we propose a method that estimate the userâs observability in the environment. When estimating effective search locations, we take into account the time for the robot to reach the search location and the visibility limitations. In this way, the robot can choose the next search location that has the maximum expected observability of the user. Our experiments demonstrate that our approach leads to a significantly shorter search time compared to other approach."
      },
      {
        "source": "Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments. Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions. For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information. Considering dynamic obstacles introduces another level of complexity, since they can lead to necessary replanning or collisions at later stages. In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be efficiently planned in real time at low CPU cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.",
        "prediction": "Perception of the local environment is necessary for mobile robots to navigate safely in changing surroundings. Most robots, such as humanoids and smaller wheeled robots, work on flat surfaces. For humanoid robots, a simple 2D occupancy map, which shows areas that are occupied or free for navigation, is not enough because they can step over and onto objects, so they also need information about height. When considering moving obstacles, the difficulty increases since these obstacles can require changes to the planned path or cause collisions later on. In this paper, we present a system that first identifies flat areas in height maps and detects moving obstacles. Our system then uses this data to create prediction maps where paths can be quickly planned in real time with low CPU (Central Processing Unit) usage. We demonstrate through simulations and real-world tests that our system can complete each computing cycle in under 10 milliseconds and enables advanced real-time 3D footstep planning.",
        "reference": "Perception of the environment is necessary for mobile robots to navigate safely in dynamic environments. Most robots (humanoids and wheeled robots) rely on planar regions. For humanoids (robots with human form or characteristics), a 2D map is not sufficient because they can step over and onto objects, so they need height information. Dynamic obstacles bring another level of complexity, because it can lead to necessary replanning or collisions. In this paper, we present a framework that extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be planned in real time at low processor cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms and allows for real-time 3D footstep planning."
      },
      {
        "source": "In this paper, a lab automation drone notional concept is introduced. Here, a robotic limb is attached to a robotic rotorcraft. The limb's gripper allows the unmanned aerial vehicle to dexterously manipulate objects such as micro-arrays and test tubes often used in high throughput systems (HTS). The resulting drone could augment existing HTS operations. The 6 degree-of-freedom (DOF) arm and gripper design are presented. Test-and-evaluation approach and results are also given.",
        "prediction": "In this paper, a concept for a lab automation drone is introduced. This drone consists of a robotic arm attached to a flying robotic vehicle known as a rotorcraft. The arm has a gripper that enables the unmanned aerial vehicle, which can fly without a pilot, to skillfully handle small objects like micro-arrays and test tubes that are commonly used in systems designed for processing many tests at once, known as high throughput systems (HTS). This drone could improve current HTS operations. The design of the arm and gripper, which can move in six different ways, called 6 degree-of-freedom (DOF), is presented. A method for testing and evaluating this drone, along with the results, is also provided.",
        "reference": "In this paper, a concept of lab automation drone is introduced. Here, a robotic arm is attached to a drone. The armâs gripper allows the drone to manipulate objects such as chips and test tubes often used in scientific experimentations like high throughput systems. The drone could augment existing high throughput systems operations. The 6 degree-of-freedom arm and gripper design are presented. Results of evaluations and tests are also given."
      },
      {
        "source": "Robot companionship has become more popular in past years. However, humanoid gait might be somewhat unstable for these applications. Even with miniature humanoids, falls occur frequently. Thus, wheel attachments have been added onto a miniature humanoid, so it can move faster and with more stability than walking. In addition, with such attachments a robot can switch from walking to rolling when necessary. DARwIn-OP is a humanoid robot that has been used as an experimentation and performance evaluation platform. This paper discusses preliminary work regarding robot companionship applications by using a miniature humanoid capable of fetching different toys based on voice command.",
        "prediction": "Robot companionship has become more popular in recent years. However, the way humanoid robots walk, known as humanoid gait, might be a bit unstable for these uses. Even small humanoid robots, referred to as miniature humanoids, often fall down. To address this, wheel attachments have been added to a miniature humanoid, allowing it to move faster and more steadily than when walking. Moreover, with these attachments, a robot can change from walking to rolling when needed. DARwIn-OP is a humanoid robot that has been used for experimenting and evaluating performance. This paper discusses early work on robot companionship applications using a miniature humanoid that can fetch different toys based on voice commands.",
        "reference": "Robot companionship has become more popular in past years. However, humanoid (robots with human form or characteristics) walking might be unstable. Even with miniature humanoids, falls occur frequently. Wheels have been added onto a miniature humanoid, so it can move faster and with more stability than walking. With wheels, a robot can switch from walking to rolling when necessary. DARwIn-OP is a humanoid robot that has been used for experimentation and evaluation. This paper discusses preliminary work for robot companionship applications by using a miniature humanoid capable of fetching different toys based on voice command."
      },
      {
        "source": "In the modern era of automation and robotics, autonomous vehicles are currently the focus of academic and industrial research. The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6m/sec. We present the same results in this research and compare them with other state-of-the-art methods of vision and learning based navigation. With the ever increasing number of unmanned aerial vehicles getting involved in activities in the civilian and commercial domain, there is an increased need for autonomy in these systems too. Due to guidelines set by the governments regarding the operation ceiling of civil drones, road-tracking based navigation is garnering interest. In an attempt to achieve the above mentioned tasks, we propose an imitation learning based, data-driven solution to UAV autonomy for navigating through city streets by learning to fly by imitating an expert pilot. Derived from the classic image classification algorithms, our classifier has been constructed in the form of a fast 39-layered Inception model, that evaluates the presence of roads using the tomographic reconstructions of the input frames. Based on the Inception-v3 architecture, our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning. The data used for training the system has been captured from the drone, by flying it in and around urban and semi-urban streets, by experts having at least 6-8 years of flying experience. Permissions were taken from required authorities who made sure that minimal risk (to pedestrians) is involved in the data collection process. With the extensive amount of drone data that we collected, we have been able to navigate successfully through roads without crashing or overshooting, with an accuracy of 98.44%.",
        "prediction": "In the modern era of automation and robotics, autonomous vehicles are currently the focus of academic and industrial research. The computational efficiency of MAVNet allows the drone to fly at high speeds of up to 6 meters per second. We present the same results in this research and compare them with other advanced methods of vision and learning-based navigation. With the ever-increasing number of unmanned aerial vehicles, also known as drones, being used in civilian and commercial activities, there is a greater need for autonomy in these systems. Due to guidelines set by the governments regarding the maximum altitude at which civil drones can operate, road-tracking based navigation is becoming more popular. In order to achieve these goals, we propose a solution based on imitation learning, which means training the system using data from expert pilots, to help unmanned aerial vehicles navigate through city streets. Our system learns to fly by imitating the actions of experienced pilots. Derived from classic image classification algorithms, our classifier is designed as a fast 39-layered Inception model, which checks for the presence of roads by analyzing the detailed images captured from the drone's cameras. Based on the Inception-v3 architecture, our system performs better in terms of processing complexity and accuracy compared to many existing models for imitation learning. The data used to train the system was collected while flying the drone in urban and semi-urban areas by experts with at least 6 to 8 years of flying experience. Permissions were obtained from relevant authorities to ensure minimal risk to pedestrians during the data collection process. With the extensive amount of drone data we collected, we have successfully navigated through roads without crashing or overshooting, achieving an accuracy of 98.44%",
        "reference": "Current academic and industrial research is interested in autonomous vehicles. MAVNet computational efficiency enables the drone to fly up to 6m/sec. The solution is compared with other recent methods. Drones are increasingly used in the civilian and commercial domain and need to be autonomous. Governments set guidelines on the operation ceiling of civil drones. So, road-tracking based navigation is attracting interest. Researchers propose data-driven solutions allowing drones to autonomously navigate city streets, learning to fly by imitating an expert pilot. The algorithm, based on the Inception model, detects roads using tomographic reconstructions. The Inception model is an extension of classic image classification algorithms. The Inception-v3 architecture has better accuracy than many existing models of imitation learning. The data used for training the system was captured from the drone over urban streets, navigated by an expert pilot. Data collection requires special permission to ensure pedestrian security. The drone can navigate successfully through roads without crashing or overshooting; its accuracy is 98.44%."
      },
      {
        "source": "Advances in electronics and sensor technology have widened the scopes of networked drones to include applications as diverse as surveillance, video recording, operations, entertainment/advertising, signal emission, transportation, and delivery. These applications and services require video recording for their operations. Large drones are used singly in missions while small ones are used in formations or swarms. The small drones are proving to be useful in civilian applications. Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones. To develop group display applications, a real-time drone formation control for group display is proposed. Simulation shows that drone formation can display messages effectively.",
        "prediction": "Advances in electronics and sensor technology have expanded the uses of networked drones to include a wide range of activities such as surveillance, video recording, operations, entertainment, advertising, signal emission, transportation, and delivery. These uses require video recording for their functions. Large drones are typically used individually for missions, while small drones are often employed in groups or swarms. Small drones are proving to be valuable for civilian purposes. Considering small drones for uses like group flying, entertainment, and signal emission has led to the deployment of networked drones. To develop applications for group displays, a real-time drone formation control system for group displays has been proposed. Simulations show that drone formations can effectively display messages.",
        "reference": "Advances in technology allowed drones to be used for surveillance, video recording, operations, entertainment/advertising, signal emission, transportation, and delivery. These applications and services require video recording. Large drones are used individually while small ones are used in groups. The small drones are proving to be useful in civilian applications. Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones. To develop group display applications, a real-time drone formation control for group display is proposed. Simulation shows that drone formation can display messages effectively."
      },
      {
        "source": "This study focuses on the digital marketing capabilities of tourism SMEs. The study addresses the question of how the use of ICT-based tools benefit the organisational capabilities of a company. By adopting marketing as a set-of-skills approach, the study provides new insights into the existing tourism literature on e-marketing. Initial findings indicate that the digital marketing capabilities of companies are transformed through ICT-based uptake. Four major capabilities were identified, each of which evolves as a result of using the tools. A key finding of the study is that the use of ICT-based tools transforms digital marketing capabilities from a set of abilities that enables tourism SMEs not only to float in a web-marketing stream, but also to lead such a stream.",
        "prediction": "This study focuses on the digital marketing abilities of small and medium-sized enterprises (SMEs) in tourism. It explores how using information and communication technology (ICT) tools helps improve a company's organizational skills. By viewing marketing as a collection of skills, the study offers new perspectives on existing research about online marketing. The initial results show that the digital marketing abilities of companies change when they adopt ICT tools. Four main capabilities were identified, each developing as a result of using these tools. A key finding is that using ICT tools changes digital marketing skills from just a collection of abilities that allows tourism SMEs to survive in online marketing, to actually leading in that realm.",
        "reference": "This study focuses on the digital marketing capabilities of tourism small and medium-sized enterprises (SMEs). The study questions on how information and communication technology (ICT) tools can help the organisational capabilities of a company. The study provides new insights from tourism studies on digital marketing. Findings show that digital marketing capabilities of companies are transformed by ICT tools. Four major capabilities were identified, each of which evolves as a result of using the tools. A key finding of the study is that ICT tools transform these capabilities in a set of abilities for SMEs in web-marketing."
      },
      {
        "source": "The prevalence and rapid development of the Internet and mobile technology in recent decades has revamped our living styles and daily habits. To ride on the digital trend, more business activities have been engaged in the digital world. Marketing and advertising is one of typical business areas that is transformed digitally. The rise of Key Opinion Leaders (KOLs), social media platforms, and Omni-channel retailing have attracted countless business entities to consider the adoption of digital marketing tools for promoting and advertising their brands and products. However, with the increasing diversity of the types of digital marketing tools, they must be carefully selected based on a multiple number of criterion. In this paper, a fuzzy-AHP method is proposed and developed for assisting industry practitioners in systematically and effectively evaluate and select proper digital marketing tool(s) for adoption. The developed method not only streamlines the internal business process of digital marketing tool selection, but it also increases the practitioner's effectiveness of achieving the pre-defined strategic marketing objectives.",
        "prediction": "The prevalence and rapid development of the Internet and mobile technology in recent decades have changed our living styles and daily habits. To keep up with the digital trend, more businesses have engaged in the digital world. Marketing and advertising are typical business areas that have been transformed digitally. The rise of Key Opinion Leaders (KOLs) which are influential individuals on social media platforms, and Omni-channel retailing which is a method that provides customers with a seamless shopping experience regardless of the channel they use, have attracted many businesses to consider adopting digital marketing tools for promoting and advertising their brands and products. However, with the increasing variety of digital marketing tools, they must be carefully chosen based on several criteria. In this paper, a fuzzy-AHP method is proposed and developed to help industry practitioners systematically and effectively evaluate and select appropriate digital marketing tool(s) for adoption. The developed method not only streamlines the internal business process of selecting digital marketing tools, but it also enhances the practitioner's effectiveness in achieving their predefined strategic marketing objectives.",
        "reference": "The development of the Internet and mobile technology in recent decades has modified our living styles and daily habits. More business activities have been engaged in the digital world. Marketing and advertising is one of typical business areas that is transformed digitally. Many businesses consider the adoption of digital marketing tools for their promotion and advertisement, due to the rise of Key Opinion Leaders (person with expert status and influence), social media platforms, and Omni-channel retailing (multiple channels but a uniform experience for the customer). However, with the increasing diversity of digital marketing tools, they must be carefully selected. In this paper, a method to organize and analyze complex decisions is proposed and developed for assisting businesses to evaluate and select appropriate digital marketing tools. The developed method rationalizes and simplifies the process of digital marketing tool selection. It also increases effectiveness of achieving strategic marketing objectives."
      },
      {
        "source": "In this paper we revisit a topic originally discussed in 1955, namely the lack of direct evidence that muscle hypertrophy from exercise plays an important role in increasing strength. To this day, long-term adaptations in strength are thought to be primarily contingent on changes in muscle size. Given this assumption, there has been considerable attention placed on programs designed to allow for maximization of both muscle size and strength. However, the conclusion that a change in muscle size affects a change in strength is surprisingly based on little evidence. We suggest that these changes may be completely separate phenomena based on: (1) the weak correlation between the change in muscle size and the change in muscle strength after training; (2) the loss of muscle mass with detraining, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load resistance training, yet divergent results in strength.",
        "prediction": "In this paper we revisit a topic originally discussed in 1955, namely the lack of direct evidence that muscle hypertrophy from exercise plays an important role in increasing strength. Muscle hypertrophy refers to the growth in the size of muscle cells. To this day, long-term adaptations in strength are thought to be primarily contingent on changes in muscle size. Given this assumption, there has been considerable attention placed on programs designed to allow for maximization of both muscle size and strength. However, the conclusion that a change in muscle size affects a change in strength is surprisingly based on little evidence. We suggest that these changes may be completely separate phenomena based on: (1) the weak correlation between the change in muscle size and the change in muscle strength after training; (2) the loss of muscle mass with detraining, which is the process of losing the physical fitness gained through exercise, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load resistance training, which is strength training using weights that are either light or heavy, yet divergent results in strength.",
        "reference": "In this paper we revisit a topic originally discussed in 1955, namely the lack of evidence that muscle growth plays an important role in increasing strength. To this day, long-term adaptations in strength are thought to be related to changes in muscle size. Given this assumption, training programs made for increasing both muscle size and strength were popular. However, the conclusion that a change in muscle size has an influence on strength is surprisingly based on little evidence. We suggest that these changes may be based on: (1) the weak correlation between the change in muscle size and the change in muscle strength after training; (2) the loss of muscle mass with the interruption of training, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load strength training, yet different results in strength."
      },
      {
        "source": "Low-intensity occlusion (50-100 mm hg) training provides a unique beneficial training mode for promoting muscle hypertrophy. Training at intensities as low as 20% 1 repetition maximum with moderate vascular occlusion results in muscle hypertrophy in as little as 3 weeks. A typical exercise prescription calls for 3 to 5 sets to volitional fatigue with short rest periods. The metabolic buildup causes positive physiologic reactions, specifically a rise in growth hormone that is higher than levels found with higher intensities. Occlusion training is applicable for those who are unable to sustain high loads due to joint pain, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts.",
        "prediction": "Low-intensity occlusion training uses a pressure of 50 to 100 millimeters of mercury to improve muscle growth. This type of training works effectively with weights as light as 20% of the maximum amount a person can lift once, combined with moderate pressure on the blood vessels. It can lead to muscle growth in just 3 weeks. A typical training plan suggests doing 3 to 5 sets of exercises until the person feels tired, with short rest breaks in between. The buildup of substances in the body during this training leads to beneficial changes, particularly an increase in growth hormone, which can be higher than that seen with heavier weights. Occlusion training is suitable for individuals who cannot lift heavy weights because of joint pain, people recovering from surgery, those in cardiac rehabilitation, athletes who are off training, and astronauts.",
        "reference": "Low-intensity occlusion training, which is a training method with blood flow restriction, provides a unique beneficial training mode for muscle growth. Training at intensities as low as 20% of maximum strength with moderate occlusion results in muscle growth in 3 weeks. A typical exercise consists of 3 to 5 sets to muscle failure with short rest periods. The metabolic accumulation causes positive physiologic reactions, specifically a rise in growth hormone, which is one of the main hormone responsible of muscle growth, that is higher than levels found with higher intensities. Occlusion training is applicable for those who are unable to sustain high loads due to joint pain, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts."
      },
      {
        "source": "Current dogma suggests aerobic exercise training has minimal effect on skeletal muscle size. We and others have demonstrated that aerobic exercise acutely and chronically alters protein metabolism and induces skeletal muscle hypertrophy. These findings promote an antithesis to the status quo by providing novel perspective on skeletal muscle mass regulation and insight into exercise-countermeasures for populations prone to muscle loss.",
        "prediction": "Current belief suggests that aerobic exercise, which is exercise that requires oxygen and includes activities like running and cycling, has little impact on the size of skeletal muscle. However, both our research and that of others shows that aerobic exercise changes how proteins are processed in the body both in the short term and long term. This leads to an increase in skeletal muscle size, known as hypertrophy. These discoveries challenge the traditional view by offering new insights into how skeletal muscle mass is controlled and provide valuable information on how exercise can help those at risk of losing muscle.",
        "reference": "Current belief suggests cardio exercise training has minimal effect on muscle size. We and others have demonstrated that cardio exercise alters protein metabolism (responsible for protein synthesis and muscle growth) and induces muscle growth. These findings against the current belief provide a novel perspective on muscle mass regulation and insight into exercise to prevent muscle loss."
      },
      {
        "source": "Stretch training is widely used in a variety of fitness-related capacities such as increasing joint range of motion, preventing contractures and alleviating injuries. Moreover, some researches indicate that stretch training may induce muscle hypertrophy; however, studies on the topic have been primarily relegated to animal and in vitro models. The purpose of this brief review was to evaluate whether stretch training is a viable strategy to induce muscle hypertrophy in humans. Of the 10 studies identified, 3 observed some significantly positive effects of stretch training on muscle structure. Intriguingly, in these studies, the stretching was carried out with an apparatus that aided in its performance, or with an external overload. Of the 5 available studies that integrated stretching into a resistance training programme, 2 applied the stretching in the interset rest period and were the ones that showed enhanced muscle growth. In conclusion, passive, low-intensity stretch does not appear to confer beneficial changes in muscle size and architecture; alternatively, albeit limited evidence suggests that when stretching is done with a certain degree of tensile strain (particularly when loaded, or added between active muscle contractions) may elicit muscle hypertrophy.",
        "prediction": "Stretch training is commonly used in fitness for various reasons, such as improving the flexibility of joints, preventing tightening of muscles and tendons, and helping to heal injuries. Some research suggests that stretch training may help muscles grow larger; however, most studies have mainly been done on animals and in laboratory settings. This review aimed to see if stretch training can effectively help muscles grow larger in humans. Out of 10 studies looked at, 3 found significant positive effects of stretch training on muscle structure. Interestingly, in these studies, the stretching was done using a machine that assisted the process or with added weight. Among the 5 studies that combined stretching with resistance training, 2 used stretching during the rest periods between sets and showed increases in muscle growth. In conclusion, passive stretching at low intensity does not seem to lead to beneficial changes in muscle size and structure. However, there is limited evidence suggesting that stretching with some level of tension, especially when weights are added or done between muscle contractions, may promote muscle growth.",
        "reference": "Stretch training is used in a variety of fitness capacities such as increasing flexibility, preventing contractures (shortening of muscle) and reduce injuries. Moreover, some researches indicate that stretch training may induce muscle growth. The purpose of this review was to evaluate if stretch training is a viable strategy to induce muscle growth in humans. Of the 10 studies identified, 3 observed positive effects of stretch training on muscles. In these studies, the stretching was performed with external help like equipment or load. Of the 5 available studies that integrated stretching into strength training, 2 applied the stretching in the rest period between the sets and were the ones that showed enhanced muscle growth. In conclusion, passive, low-intensity stretch does not appear to produce beneficial changes in muscles but evidence suggests that when stretching is done with a certain intensity (particularly when loaded, or added between active muscle contractions), it may induce muscle growth."
      },
      {
        "source": "Cycle training is widely performed as a major part of any exercise program seeking to improve aerobic capacity and cardiovascular health. However, the effect of cycle training on muscle size and strength gain still requires further insight, even though it is known that professional cyclists display larger muscle size compared to controls. Therefore, the purpose of this review is to discuss the effects of cycle training on muscle size and strength of the lower extremity and the possible mechanisms for increasing muscle size with cycle training. It is plausible that cycle training requires a longer period to significantly increase muscle size compared to typical resistance training due to a much slower hypertrophy rate. Cycle training induces muscle hypertrophy similarly between young and older age groups, while strength gain seems to favor older adults, which suggests that the probability for improving in muscle quality appears to be higher in older adults compared to young adults. For young adults, higher-intensity intermittent cycling may be required to achieve strength gains. It also appears that muscle hypertrophy induced by cycle training results from the positive changes in muscle protein net balance.",
        "prediction": "Cycle training is commonly used as an important part of exercise programs aimed at enhancing aerobic capacity, which is the body's ability to take in and use oxygen efficiently, and improving cardiovascular health, which refers to the overall health of the heart and blood vessels. However, more understanding is needed about how cycle training affects muscle size and strength gains, even though we know that professional cyclists have larger muscles compared to people who do not cycle. This review aims to explore how cycle training affects muscle size and strength in the lower body and the possible reasons for muscle size increase from cycle training. It is likely that cycle training takes a longer time to cause significant increases in muscle size compared to regular resistance training, which helps prepare and strengthen muscles, because the rate of muscle growth, known as hypertrophy, is much slower with cycling. Cycle training can lead to muscle hypertrophy similarly in both young and older individuals, but strength gains tend to be more pronounced in older adults, suggesting that older adults may have a greater potential for improving muscle quality than younger adults. For younger adults, higher-intensity intermittent cycling, which involves alternating periods of intense effort and rest, might be necessary to achieve strength gains. Additionally, the muscle hypertrophy that results from cycle training seems to be linked to positive changes in the balance of muscle proteins, which are essential for muscle structure and function.",
        "reference": "Cycling training is performed as a major part of any training program which objective is to improve cardiovascular capacities and health. However, the effect of cycling training on muscle size and strength still requires a better comprehension. Therefore, the purpose of this review is to discuss the effects of cycling training on muscle size and strength of the legs and the possible mechanisms for increasing muscle size with cycling training. It is plausible that cycling training requires a longer period to significantly increase muscle size compared to strength training due to a much slower muscle growth rate. Cycling training induces muscle growth similarly between young and older people, while strength gain seems to favor older adults. For young adults, series of high-intensity cycling may be required to achieve strength gains. It also appears that muscle growth induced by cycling training results from the positive changes in protein balance, which is the balance between protein intake which leads to muscle growth and protein loss which leads to muscle loss)."
      },
      {
        "source": "Resistance training is the most effective method to increase muscle mass. It has also been shown to promote many health benefits. Although it is deemed safe and of clinical relevance for treating and preventing a vast number of diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies. Similarly, an inverted U-shaped relationship between training dose/volume and physiological response has been hypothesized to exist. However, the majority of available evidence supports a clear dose-response relationship between resistance training volume and physiological responses, such as muscle hypertrophy and health outcomes. Additionally, there is a paucity of data to support the inverted U-shaped response. The overarching principle argued herein is that volume is the most easily modifiable variable that has the most evidenced-based response with important repercussions, be these muscle hypertrophy or health-related outcomes.",
        "prediction": "Resistance training is the best way to increase muscle size. It has also been proven to offer various health benefits. It is considered safe and important for treating and preventing many diseases. Many research studies have focused on finding a time-efficient and minimal amount of exercise needed. There is a theory that suggests an upside-down U-shaped relationship between the amount of training and the body's response to it. However, most evidence shows a clear connection between the amount of resistance training and physiological responses such as muscle growth and health results. Additionally, there is limited data to support the theory of the U-shaped response. The main point made here is that the amount of training is the most easily changed factor that has the most proven effect on important outcomes, whether they are related to muscle growth or health.",
        "reference": "Strength training is the most effective method to increase muscle mass. It has also been shown to promote many health benefits. Although it is helpful for treating and preventing diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies. Similarly, an inverted U-shaped relationship (which means that the efficiency increases until a point, and then starts decreasing) between training volume and physiological response has been hypothesized to exist. However, evidence supports a clear correlation between resistance training volume (number of exercises, sets, etc.) and physiological responses, such as muscle growth and health outcomes. Additionally, there is a lack of data to support the inverted U-shaped response. The principle suggested is that volume is the most easily modifiable variable that has the most important response, for muscle growth or health outcomes."
      },
      {
        "source": "Although the effects of short versus long inter-set rest intervals in resistance training on measures of muscle hypertrophy have been investigated in several studies, the findings are equivocal and the practical implications remain unclear. Current evidence indicates that both short and long inter-set rest intervals may be useful when training for achieving gains in muscle hypertrophy. Novel findings involving trained participants using measures sensitive to detect changes in muscle hypertrophy suggest a possible advantage for the use of long rest intervals to elicit hypertrophic effects. However, due to the paucity of studies with similar designs, further research is needed to provide a clear differentiation between these two approaches.",
        "prediction": "The effects of short versus long rest periods between sets in resistance training on muscle growth have been studied in several research projects, but the results are mixed and the practical takeaways are still uncertain. Current evidence suggests that both short and long rest periods can be helpful for increasing muscle size. New findings with trained individuals using sensitive measures to detect changes in muscle growth hint that longer rest periods may have an edge in producing muscle growth effects. However, due to the lack of studies with similar methods, more research is necessary to clearly distinguish between these two approaches.",
        "reference": "The effects of short versus long rest intervals between sets in strength training on muscle growth have been investigated in several studies but the findings and the practical implications are unclear. Current evidence indicates that both short and long rest intervals may be useful for muscle growth. Novel findings suggest for trained people a possible advantage for the use of long rest intervals to induce muscle growth. However, due to the lack of studies with similar methodologies, further research is needed to provide a clear differentiation between these two approaches."
      },
      {
        "source": "Memory is a process in which information is encoded, stored, and retrieved. For vertebrates, the modern view has been that it occurs only in the brain. This review describes a cellular memory in skeletal muscle in which hypertrophy is 'remembered' such that a fibre that has previously been large, but subsequently lost its mass, can regain mass faster than naive fibres. A new cell biological model based on the literature, with the most reliable methods for identifying myonuclei, can explain this phenomenon. According to this model, previously untrained fibres recruit myonuclei from activated satellite cells before hypertrophic growth. Even if subsequently subjected to grave atrophy, the higher number of myonuclei is retained, and the myonuclei seem to be protected against the elevated apoptotic activity observed in atrophying muscle tissue. Fibres that have acquired a higher number of myonuclei grow faster when subjected to overload exercise, thus the nuclei represent a functionally important 'memory' of previous strength. This memory might be very long lasting in humans, as myonuclei are stable for at least 15 years and might even be permanent. However, myonuclei are harder to recruit in the elderly, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice.",
        "prediction": "Memory is a process in which information is captured, kept, and recalled. In animals with backbones, it has been commonly believed that this happens only in the brain. This review tells about a kind of memory in skeletal muscle where growth (hypertrophy) is 'remembered' so that a muscle fiber that has grown larger in the past, but later became smaller, can grow back faster than muscles that have never been large before. A new model based on research can explain this idea, using the best ways to identify myonuclei, which are the nuclei or control centers of muscle cells. According to this model, muscle fibers that have never been trained before can attract myonuclei from activated satellite cells (which are special cells that help in muscle repair and growth) before they start to grow larger. Even if these muscles experience significant shrinkage (atrophy) later, they keep a higher number of myonuclei, and these nuclei appear to be shielded against the increased cell death (apoptosis) that happens in shrinking muscle tissue. Muscle fibers that have more myonuclei grow larger more quickly when they are put under extra force (overload exercise), so these nuclei serve as an important 'memory' of previous strength. This muscle memory might last a very long time in humans since myonuclei can remain stable for at least 15 years and may even last permanently. However, it is more difficult to recruit myonuclei in older adults. If this long-lasting muscle memory exists in humans, it suggests that starting strength training early on can be a good health recommendation.",
        "reference": "Memory is a process in which information is encoded, stored, and retrieved. For vertebrates, it has been said that it occurs only in the brain. This review describes a cellular memory in muscles in which muscle growth is 'remembered' such that a fibre that has lost its mass, can regain it faster than untrained fibres. A new model, with the most reliable methods for identifying myonuclei (nuclei in muscle fiber), can explain this phenomenon. According to this model, previously untrained fibres recruit myonuclei from activated satellite cells (quiescent cells acting as a reserve population of cells for regeneration of muscle) before muscle growth. Even after grave muscle loss, the higher number of myonuclei is retained, and the myonuclei seem to be protected against programmed cell death observed during muscle loss. Fibres that have acquired a higher number of myonuclei grow faster during strength exercise, thus the nuclei represent a functionally important 'memory' of previous strength. This memory might be very long lasting in humans, as myonuclei are stable for at least 15 years and might even be permanent. However, myonuclei are harder to recruit for old people, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice."
      },
      {
        "source": "It has been hypothesized that eating small, frequent meals enhances fat loss and helps to achieve better weight maintenance. Several observational studies lend support to this hypothesis, with an inverse relationship noted between the frequency of eating and adiposity. The purpose of this narrative review is to present and discuss a meta-analysis with regression that evaluated experimental research on meal frequency with respect to changes in fat mass and lean mass. Feeding frequency was positively associated with reductions in fat mass and body fat percentage as well as an increase in fat-free mass. However, sensitivity analysis of the data showed that the positive findings were the product of a single study, casting doubt as to whether more frequent meals confer beneficial effects on body composition. In conclusion, although the initial results of this meta-analysis suggest a potential benefit of increased feeding frequencies for enhancing body composition, these findings need to be interpreted with circumspection.",
        "prediction": "It has been proposed that eating smaller, more frequent meals may help with fat loss and better weight management. Several observational studies support this idea, showing a negative relationship between how often people eat and body fat. This review aims to present and discuss a meta-analysis, which is a study that combines results from multiple research studies, that analyzed experiment-based research on meal frequency and its effect on changes in fat mass, which is the amount of fat in the body, and lean mass, which is the amount of muscle and other non-fat tissues. Eating more frequently was linked to decreases in fat mass and body fat percentage, as well as an increase in fat-free mass, which refers to muscle and other non-fat components. However, further analysis of the data indicated that these positive results came from one specific study, raising questions about whether eating more often really benefits body composition. In conclusion, while the initial results of this meta-analysis suggest a possible advantage of eating more frequently for improving body composition, these results should be viewed cautiously.",
        "reference": "It has been hypothesized that eating small, frequent meals enhances fat loss and helps for better weight maintenance. Several studies support this hypothesis, with a link between the frequency of eating and being overweight. This review aims to present and discuss a research on meal frequency with respect to changes in body mass. Eating frequency was positively associated with reductions in fat mass and increasing in fat-free mass. However, the positive findings were the product of a single study, leaving a doubt about the beneficial effect of frequent meals on body composition. In conclusion, although the initial results suggest a potential benefit of increased eating frequencies for enhancing body composition, these findings need to be carefully interpreted."
      },
      {
        "source": "Inactive adults experience a 3% to 8% loss of muscle mass per decade, accompanied by resting metabolic rate reduction and fat accumulation. Ten weeks of resistance training may increase lean weight by 1.4 kg, increase resting metabolic rate by 7%, and reduce fat weight by 1.8 kg. Benefits of resistance training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem. Resistance training may assist prevention and management of type 2 diabetes by decreasing visceral fat, reducing HbA1c, increasing the density of glucose transporter type 4, and improving insulin sensitivity. Resistance training may enhance cardiovascular health, by reducing resting blood pressure, decreasing low-density lipoprotein cholesterol and triglycerides, and increasing high-density lipoprotein cholesterol. Resistance training may promote bone development, with studies showing 1% to 3% increase in bone mineral density. Resistance training may be effective for reducing low back pain and easing discomfort associated with arthritis and fibromyalgia and has been shown to reverse specific aging factors in skeletal muscle.",
        "prediction": "Inactive adults lose muscle mass at a rate of 3% to 8% every decade. This loss is often coupled with a decrease in resting metabolic rate, which is the rate at which the body burns energy while at rest, and an increase in body fat. After ten weeks of resistance training, which involves exercises that increase muscle strength, individuals can gain about 1.4 kg of lean body weight, boost their resting metabolic rate by 7%, and reduce body fat by around 1.8 kg. The benefits of resistance training extend to improved physical performance, better control of movement, increased walking speed, enhanced functional independence, sharper cognitive abilities, and higher self-esteem. Resistance training can help in preventing and managing type 2 diabetes by lowering visceral fat, which is fat stored around internal organs, decreasing levels of HbA1c, a blood test that indicates sugar level control over time, increasing the density of glucose transporter type 4, which helps move glucose into cells, and improving how effectively the body responds to insulin. Moreover, resistance training can boost cardiovascular health by lowering resting blood pressure, reducing low-density lipoprotein (often referred to as \"bad\" cholesterol) and triglycerides (a type of fat found in the blood), and raising high-density lipoprotein (known as \"good\" cholesterol). It may also promote bone health, with research indicating an increase of 1% to 3% in bone mineral density, which is a measure of the amount of minerals in bones. Additionally, resistance training may help reduce lower back pain and alleviate discomfort related to conditions like arthritis and fibromyalgia, a condition characterized by widespread muscle pain and fatigue, and has shown the ability to reverse certain aging effects in skeletal muscle, the muscle used for body movement.",
        "reference": "Per decade, inactive adults experience a muscle loss of 3% to 8%, a reduction of resting metabolic rate (energy consumed by the body at rest) and fat accumulation. Ten weeks of strength training may increase fat-free mass by 1.4 kg, resting metabolic rate by 7%, and reduce fat weight by 1.8 kg. Benefits of strength training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem. Strength training may assist prevention and management of type 2 diabetes by decreasing abdominal fat, reducing HbA1c which is a form of hemoglobin linked to a sugar, increasing the density of glucose transporter type 4, and improving insulin sensitivity. Strength training may enhance cardiovascular health, by reducing resting blood pressure, decreasing 'bad' cholesterol and triglycerides (main constituents of body fat), and increasing 'good' cholesterol. Strength training may promote bone development, with studies showing 1% to 3% increase in bone mineral density. Strength training may be effective for reducing low back pain, joint and muscle pain, and reverse specific aging factors in muscles."
      },
      {
        "source": "We hypothesized that compared to post-exercise protein intake, co-ingestion of alcohol would down-regulate translation initiation signaling and decrease rates of MPS.",
        "prediction": "We proposed that when people consume protein after exercise, drinking alcohol at the same time would reduce the body's signaling process that starts the creation of proteins and lower the rates of muscle protein synthesis.",
        "reference": "We assumed that consumption of protein and alcohol (compared to protein only) would reduce protein synthesis."
      },
      {
        "source": "Eight healthy physically active male subjects (age 21.4Â±4.8 yr, body mass (BM) 79.3Â±11.9 kg, peak oxygen uptake (VO2peak) 48.1Â±4.8 mLÂ·kgâ1Â·minâ1, leg extension one repetition maximum (1RM) 104Â±20 kg; values are mean Â± SD) who had been participating in regular exercise (3 times wkâ1 for >6 months) volunteered for this study.",
        "prediction": "Eight healthy, physically active male subjects, with an average age of 21.4 years, an average body mass of 79.3 kilograms, a peak oxygen uptake of 48.1 milliliters per kilogram per minute, and an average leg extension one repetition maximum of 104 kilograms, volunteered for this study. The values mentioned are averages plus or minus the standard deviation. All subjects had been participating in regular exercise three times a week for more than six months.",
        "reference": "Eight healthy physically active men (3 trainings per week for at least 6 months) volunteered for this study."
      },
      {
        "source": "The study employed a randomized counter-balanced, cross-over design in which each subject completed bouts of consecutive resistance, continuous and intermittent high-intensity exercise with either post-exercise ingestion of alcohol-carbohydrate (ALC-CHO), alcohol-protein (ALC-PRO) or protein only (PRO) beverages on three separate occasions.",
        "prediction": "The study used a method called a randomized counter-balanced, cross-over design. This means that each participant performed a sequence of different types of exercise: they did sets of resistance exercises and both continuous and intermittent high-intensity exercises. After exercising, they ingested different types of beverages on three separate occasions. These beverages were either a mix of alcohol and carbohydrates (ALC-CHO), alcohol and protein (ALC-PRO), or protein only (PRO)",
        "reference": "Subjects did high intensity exercise and just after consumed an alcohol-carbohydrate, an alcohol-protein or a protein drink in three separate occasions."
      },
      {
        "source": "Resistance exercise consisted of eight sets of five repetitions at â¼80% of 1RM.",
        "prediction": "Resistance exercise involved performing eight sets of five repetitions at approximately 80% of one-repetition maximum. One-repetition maximum (1RM) is the maximum amount of weight that a person can lift for a single repetition of an exercise.",
        "reference": "Training consisted of eight sets of five repetitions of leg extension at 80% of their maximum strength."
      },
      {
        "source": "After completion of the final set, subjects rested for 5 min before commencing 30 min of continuous cycling at â¼63% PPO (â¼70% VO2peak).",
        "prediction": "After completing the last set, the participants rested for 5 minutes before starting 30 minutes of uninterrupted cycling at approximately 63% of their Peak Power Output, which is about 70% of their Peak Oxygen Uptake.",
        "reference": "After 5 minutes rest, subjects cycled for 30 minutes at medium intensity,"
      },
      {
        "source": "Upon completion, subjects rested on the bike for 2 min before undertaking 10Ã30 s high intensity intervals at â¼110% of PPO, with 30 s active recovery (â¼50% PPO) between each work bout.",
        "prediction": "After finishing, participants rested on the bike for 2 minutes before doing 10 intervals of high intensity exercise lasting 30 seconds each at about 110 percent of their Peak Power Output (PPO). Between each exercise bout, there was a 30 second period of active recovery at approximately 50 percent of their PPO.",
        "reference": "then 5 minutes at high intensity."
      },
      {
        "source": "Immediately following exercise and after 4 h recovery, subjects ingested a 500 mL solution of either protein (PRO, 25 g whey protein powder; ISO8, Musashi, Melbourne, VIC Australia) or an energy-match in the form of CHO (25 g maltodextrin, International Health Investments, Helensvale, QLD Australia).",
        "prediction": "Immediately after exercise and after 4 hours of recovery, participants drank a 500 mL solution containing either protein (PRO, which is 25 grams of whey protein powder from ISO8, a brand by Musashi located in Melbourne, Victoria, Australia) or an energy-equivalent solution containing carbohydrates (CHO, which is 25 grams of maltodextrin, a type of carbohydrate from International Health Investments based in Helensvale, Queensland, Australia)",
        "reference": "Immediately following exercise and after 4 h recovery, subjects consumed a 500mL drink of protein or carbohydrates."
      },
      {
        "source": "Furthermore, a CHO-based meal (1.5 gÂ·kgâ1 BM) was consumed â¼2 h post-exercise, immediately after the muscle biopsy, according to recommendations for post-exercise glycogen recovery [24].",
        "prediction": "Furthermore, a carbohydrate-based meal (1.5 grams per kilogram of body mass) was consumed approximately 2 hours after exercise, immediately after the muscle tissue sample was taken, according to recommendations for recovery of glycogen after exercise.",
        "reference": "A carbohydrate meal was consumed 2 h after exercise, according to recommendation for glycogen recovery."
      },
      {
        "source": "The 8 h time frame represents an important phase of post-exercise recovery [1] as well as the period during which blood alcohol concentrations are likely to be elevated by a post-event drinking binge [14].",
        "prediction": "The 8-hour time frame represents an important phase of recovery after exercise as well as the period during which the level of alcohol in the blood is likely to be higher due to drinking after an event",
        "reference": "The 8 h period after exercise is an important phase for recovery but also the period during which blood alcohol level may be the highest after excessive consumption of alcohol."
      },
      {
        "source": "The alcohol ingestion protocol (1.5 gÂ·kgâ1 BM; 12Â±2 standard drinks) began 1 h post-exercise and was consumed in 6 equal volumes of 1 part vodka (â¼60 mL) to four parts orange juice (â¼240 mL, 1.8 g CHOÂ·kgâ1 BM) during a 3 h period.",
        "prediction": "The alcohol ingestion protocol involves consuming 1.5 grams of alcohol per kilogram of body mass, which is approximately 12 standard drinks. This protocol starts one hour after exercise and consists of drinking six equal portions, with each portion containing one part vodka, approximately 60 milliliters, mixed with four parts orange juice, approximately 240 milliliters. This mixture provides 1.8 grams of carbohydrates per kilogram of body mass and is consumed over a three-hour period.",
        "reference": "The alcohol consumption started 1 h after exercise with 6 drinks (60mL of vodka and 240mL of orange juice) and during 3 h."
      },
      {
        "source": "The focus of the early post-exercise period (i.e., 1â8 h) is to enhance physiological processes that are critical for reversing the exercise-induced disturbances to homeostasis and physiological function and for promoting adaptations to training [1].",
        "prediction": "The focus of the early post-exercise period, which is the time between 1 to 8 hours after exercising, is to improve the bodily processes that are important for correcting the disruptions caused by exercise to the body's balance and functions and for encouraging changes that result from training.",
        "reference": "The period after exercise (1-8h) enhances the body's processes that reverse the effects of the exercise and promotes adaptation to the training."
      },
      {
        "source": "For the PRO condition, orange juice was consumed with a matched volume of water in place of the alcohol.",
        "prediction": "For the PRO condition, orange juice was consumed with an equal amount of water instead of alcohol.",
        "reference": "For the protein drink, orange juice was consumed with water instead of alcohol."
      },
      {
        "source": "Subjects ingested the beverages within 5 min every 30 min.",
        "prediction": "Subjects drank the beverages within 5 minutes every 30 minutes",
        "reference": "Subjects consumed the drinks in 5 minutes every 30 minutes."
      },
      {
        "source": "Blood, cell signaling and mRNA data were analyzed by two-way ANOVA (two factor: time Ã treatment) with repeated measures and myofibrillar protein synthesis was analyzed by one-way ANOVA with repeated measures.",
        "prediction": "Blood, cell signaling, and mRNA data were analyzed using a statistical method called two-way Analysis of Variance (ANOVA). This method takes into account two factors: time and treatment, and it includes repeated measures, which means that the same subjects were tested multiple times. The analysis of myofibrillar protein synthesis, which refers to the process of forming protein in muscle fibers, was conducted using a different method called one-way ANOVA with repeated measures.",
        "reference": "Data (blood, protein synthesis, responses, etc.) were analyzed several times for the 3 different consumptions of drinks."
      },
      {
        "source": "The first novel finding of this study was that mTOR signaling and rates of myofibrillar protein synthesis (MPS) following concurrent resistance, continuous and intermittent high-intensity exercise, designed to mimic the metabolic profile of many team sports, were impaired during the early (8 h) recovery phase by the ingestion of large amounts (1.5 gâ¢kgâ1 BM) of alcohol.",
        "prediction": "The first novel finding of this study was that mTOR signaling and rates of myofibrillar protein synthesis following concurrent resistance, continuous and intermittent high-intensity exercise, designed to mimic the metabolic profile of many team sports, were impaired during the early 8 hours recovery phase by the ingestion of large amounts 1.5 grams per kilogram of body mass of alcohol",
        "reference": "The first finding of this study was that the mTOR enzyme (responsible for muscle growth) and protein synthesis (after exercise) were reduced by an excessive alcohol consumption during the 8 h period of recovery."
      },
      {
        "source": "These outcomes were most evident (37% reduction in rates of MPS) when alcohol was consumed in the absence of post-exercise protein intake, as is likely to occur when intoxication reduces the athlete's compliance to sound recovery practices.",
        "prediction": "These outcomes were most clear with a 37% reduction in rates of muscle protein synthesis when alcohol was consumed without afterwards taking in protein after exercise, which is likely to happen when being drunk leads the athlete to not follow good recovery practices.",
        "reference": "Consequences were most evident when alcohol was consumed without protein (37 % reduction of protein synthesis)."
      },
      {
        "source": "However, a second finding was that even when protein was consumed in amounts shown to be optimally effective to stimulate MPS [8] during post-exercise recovery, the intake of alcohol reduced MPS by â¼24%, representing only a partial ârescueâ of the anabolic response compared with protein alone.",
        "prediction": "However, a second finding was that even when protein was consumed in amounts shown to be optimally effective to stimulate Muscle Protein Synthesis (MPS) during post-exercise recovery, the intake of alcohol reduced MPS by approximately 24%, representing only a partial ârescueâ of the anabolic response compared with protein alone",
        "reference": "A second finding was that even with protein consumption, alcohol reduced protein synthesis by around 24%."
      },
      {
        "source": "The mechanistic target of rapamycin complex 1 (mTORC1) is a central node for integrating nutrient (i.e. amino acid) and exercise/contraction signal transduction [31], [32].",
        "prediction": "The mechanistic target of rapamycin complex 1, also known as mTORC1, is an important part of the process that combines signals from nutrients, like amino acids, and signals from exercise or muscle contraction.",
        "reference": "mTOR is important in absorption of nutrients (like amino acids) and in sending signals to the body to produce an effort."
      },
      {
        "source": "In conclusion, the current data provide the novel observation that alcohol impairs the response of MPS in exercise recovery in human skeletal muscle despite optimal nutrient provision.",
        "prediction": "In conclusion, the current data provide the new observation that alcohol negatively affects the response of Muscle Protein Synthesis (MPS) during recovery after exercise in human skeletal muscle, even when nutrients are provided in the right amounts.",
        "reference": "The data from this study show that alcohol reduce the protein synthesis after exercise even with an optimal consumption of nutrients."
      },
      {
        "source": "The quantity of alcohol consumed in the current study was based on amounts reported during binge drinking by athletes.",
        "prediction": "The amount of alcohol consumed in this study was based on the amounts reported by athletes during episodes of binge drinking",
        "reference": "The quantity of alcohol consumed in this study was based on consumption by athletes during binge drinking."
      },
      {
        "source": "However, published reports suggest intakes of some individuals can be significantly greater [9], [50], which is of concern for many reasons related to health and safety [13].",
        "prediction": "However, published reports suggest that some individuals consume significantly more than recommended which raises concerns for health and safety",
        "reference": "However, reports show that some individuals can consume higher quantities, which is a concern for health and safety issues."
      },
      {
        "source": "Recommended nutritional strategies to maximize recovery in skeletal muscle include protein for enhancing rates of protein synthesis and carbohydrate for replenishing glycogen stores [2],[3].",
        "prediction": "Recommended nutritional strategies to maximize recovery in skeletal muscle include protein which helps increase the production of proteins in the body and carbohydrates which help refill energy stores called glycogen",
        "reference": "Nutritional strategies to optimize muscle recovery include proteins which are recommended to allow protein synthesis (production of new proteins which improve, for example, muscle mass) and carbohydrates to recharge glycogen stores (energy storage)."
      },
      {
        "source": "Regrettably, there has been difficulty in finding an educational message with alcohol consumption related to sports performance that has resonance with athletes.",
        "prediction": "There has been difficulty in finding an educational message about alcohol consumption and its impact on sports performance that resonates with athletes",
        "reference": "Regrettably, it is difficult to find an educational message about alcohol consumption and sport performances that speaks to athletes."
      },
      {
        "source": "Given the need to promote protein synthesis that underpins adaptation, repair and regeneration of skeletal muscle the results of the current study provide clear evidence of impaired recovery when alcohol is consumed after concurrent (resistance, continuous and intermittent high-intensity) exercise even in the presence of optimal nutritional conditions.",
        "prediction": "The study highlights the importance of protein synthesis, which is the process of creating proteins that are essential for adapting, repairing, and regenerating skeletal muscle. The results show that consuming alcohol after different types of exerciseâsuch as resistance training, continuous exercise, and intermittent high-intensity workoutsâcan significantly hinder recovery. This effect occurs even when nutritional needs are being met optimally.",
        "reference": "Considering the importance of protein synthesis (adaptation, repair and regeneration of muscles), the results of this study provide evidence of reduced recovery when alcohol is consumed after exercise, even with an optimal consumption of nutrients."
      },
      {
        "source": "We propose our data is of paramount interest to athletes and coaches.",
        "prediction": "We suggest that our data is extremely important to athletes and coaches",
        "reference": "We consider our data crucial for athletes and coaches."
      },
      {
        "source": "Our findings provide an evidence-base for a message of moderation in alcohol intake to promote recovery after exercise with the potential to alter current sports culture and athlete practices.",
        "prediction": "Our findings provide support for a message encouraging moderate drinking of alcohol to help recovery after exercise. This could change current sports culture and the behaviors of athletes.",
        "reference": "Our findings provide evidence for a message of moderation in alcohol consumption to promote recovery after exercise, with the potential to change sport cultures and athlete practices."
      },
      {
        "source": "Muscle contraction and the intake of leucine-rich protein sources activate independent but complimentary signaling responses that converge at the mechanistic target of rapamycin (mTOR) to stimulate protein translation enhancing rates of muscle protein synthesis [4]â[6].",
        "prediction": "Muscle contraction and the intake of proteins that are rich in leucine, which is an essential amino acid, activate separate but related processes that come together at a specific molecule known as the mechanistic target of rapamycin, or mTOR. This interaction stimulates the production of proteins, improving the rates at which muscle protein is built.",
        "reference": "Muscle contraction and consumption of leucine-rich protein (essential amino acid composing proteins) induce reactions which increase the protein synthesis."
      },
      {
        "source": "The ingestion of â¼20â25 g of high quality protein soon after exercise [7], repeated every 4 h [8] has been shown to maximise the anabolic response in skeletal muscle.",
        "prediction": "The consumption of about 20 to 25 grams of high-quality protein soon after exercise, repeated every 4 hours, has been shown to maximize the growth and repair response in skeletal muscle.",
        "reference": "Consumption of 20-25 g of high quality protein after exercise and repeated every 4 h showed an optimal anabolic response (increasing muscle mass) of the muscles."
      },
      {
        "source": "The cultural environment surrounding some sports often involves the intake of large amounts of alcohol after training and competition, with athletes in several team sports being particularly at risk of âbinge drinkingâ practices [9]â[11].",
        "prediction": "The cultural environment around some sports often includes consuming large amounts of alcohol after training and competition. Athletes in several team sports are especially at risk of engaging in \"binge drinking,\" which is a practice of drinking a lot of alcohol in a short period.",
        "reference": "Several studies showed that athletes are more likely to drink alcohol to excess (50-65% drink above dangerous level)."
      },
      {
        "source": "The outcomes of binge drinking after exercise are likely to include the direct effect of alcohol on physiological processes as well as the indirect effect on the athlete's recovery due to not eating or resting adequately as a result of intoxication.",
        "prediction": "The results of binge drinking, which means consuming a large amount of alcohol in a short period, after exercising are likely to include both the direct impact of alcohol on the body's functions and the indirect impact on the athlete's recovery. This recovery can be affected by not eating or resting enough due to being intoxicated, which means being under the influence of alcohol.",
        "reference": "Consequences of an excessive consumption after exercise are direct effect on the body but also indirect effect on the recovery due to an inappropriate eating and rest."
      },
      {
        "source": "Although the concurrent consumption of carbohydrate can partially offset the deleterious effects of alcohol intake on post-exercise glycogen resynthesis [14], the effect of alcohol consumption on muscle protein synthesis is unknown.",
        "prediction": "Although taking carbohydrates at the same time can help reduce the harmful effects of drinking alcohol on the rebuilding of glycogen after exercise, the impact of alcohol on the building of muscle protein is not known",
        "reference": "Consumption of carbohydrates can partially counter balance the effects of alcohol on the recharge of glycogen stores but the effect on muscle protein synthesis are unknown."
      },
      {
        "source": "The aim of the current study was to determine the effect of alcohol intake on anabolic cell signaling and rates of myofibrillar protein synthesis (MPS) in humans during recovery from a bout of strenuous exercise approximating stresses an athlete may experience in training and performance for various team sports such as various football and rugby codes, and court sports.",
        "prediction": "The aim of the current study was to determine the effect of alcohol intake on anabolic cell signaling and rates of myofibrillar protein synthesis in humans during recovery from a bout of strenuous exercise. Anabolic cell signaling refers to the biological processes that help cells build up molecules, which is important for muscle growth and recovery. Myofibrillar protein synthesis is the process by which muscle proteins are created and repaired. The study looked at these effects during recovery after intense physical activity, which is similar to the stresses athletes may experience during training and competition in various team sports like football, rugby, and court sports.",
        "reference": "The aim of this study was to determine the effect of alcohol on anabolism and protein synthesis in humans during recovery following an effort an athlete could do (in rugby or football for example)."
      },
      {
        "source": "Human aging results in a variety of changes to skeletal muscle. Sarcopenia is the age-associated loss of muscle mass and is one of the main contributors to musculoskeletal impairments in the elderly. Previous research has demonstrated that resistance training can attenuate skeletal muscle function deficits in older adults, however few articles have focused on the effects of resistance training on functional mobility. The purpose of this systematic review was to 1) present the current state of literature regarding the effects of resistance training on functional mobility outcomes for older adults with skeletal muscle function deficits and 2) provide clinicians with practical guidelines that can be used with seniors during resistance training, or to encourage exercise. We set forth evidence that resistance training can attenuate age-related changes in functional mobility, including improvements in gait speed, static and dynamic balance, and fall risk reduction. Older adults should be encouraged to participate in progressive resistance training activities, and should be admonished to move along a continuum of exercise from immobility, toward the recommended daily amounts of activity.",
        "prediction": "Human aging results in various changes to skeletal muscle. Sarcopenia is the age-related loss of muscle mass and is a significant cause of musculoskeletal problems in older people. Previous research has shown that resistance training, which involves exercises that improve strength and endurance, can help reduce muscle function problems in older adults. However, few studies have looked at how resistance training affects mobility, which is the ability to move freely and easily. The aim of this systematic review was to 1 present the current findings regarding the impact of resistance training on mobility outcomes for older adults with muscle function problems and 2 provide practical guidelines for healthcare providers to use with seniors during resistance training or to encourage exercise. We presented evidence that resistance training can reduce age-related changes in mobility, such as improvements in walking speed, balance in both still and moving positions, and a reduction in the risk of falling. Older adults should be encouraged to engage in progressive resistance training, which means gradually increasing the intensity of the exercises. They should also be advised to move from being inactive towards the recommended daily amount of physical activity.",
        "reference": "Human aging results in a variety of changes to muscles. Sarcopenia is the age-associated muscle loss and is one of the main contributors to muscle disorders in older adults. Previous research has demonstrated that strength training can attenuate muscle function deficits in older adults, however few articles have focused on the effects of strength training on mobility. The purpose of this review was to present the effects of strength training on mobility for older adults with muscle function deficits and to provide guidelines that can be used with seniors during strength training. We present evidence that strength training can attenuate age-related changes in mobility, including improvements in walking speed, static and dynamic balance, and fall risk reduction. Older adults should be encouraged to participate in strength training activities, and should avoid immobility."
      },
      {
        "source": "Maximizing the hypertrophic response to resistance training (RT) is thought to be best achieved by proper manipulation of exercise program variables including exercise selection, exercise order, length of rest intervals, intensity of maximal load, and training volume. An often overlooked variable that also may impact muscle growth is repetition duration. Duration amounts to the sum total of the concentric, eccentric, and isometric components of a repetition, and is predicated on the tempo at which the repetition is performed. We conducted a systematic review and meta-analysis to determine whether alterations in repetition duration can amplify the hypertrophic response to RT. Results indicate that hypertrophic outcomes are similar when training with repetition durations ranging from 0.5 to 8 s. From a practical standpoint it would seem that a fairly wide range of repetition durations can be employed if the primary goal is to maximize muscle growth. Findings suggest that training at volitionally very slow durations (>10s per repetition) is inferior from a hypertrophy standpoint, although a lack of controlled studies on the topic makes it difficult to draw definitive conclusions.",
        "prediction": "Maximizing the hypertrophic response to resistance training is believed to be best achieved by properly adjusting various aspects of an exercise program. These include choosing the right exercises, the order in which they are done, the length of rest periods, how heavy the weights are, and the overall amount of weight lifted over time. An often overlooked aspect that might also affect muscle growth is the duration of each repetition. Duration refers to the total time taken during the concentric, eccentric, and isometric phases of a repetition. The concentric phase is when the muscle is shortening during the lift, the eccentric phase is when the muscle is lengthening while lowering the weight, and the isometric phase occurs when the muscle is contracted but not changing length. The total duration is influenced by the tempo, or speed, at which the repetition is done. We conducted a systematic review and meta-analysis to find out if changing the duration of repetitions could enhance muscle growth in resistance training. Our results show that muscle growth outcomes are similar when using repetition durations of 0.5 to 8 seconds. From a practical perspective, it seems that a wide variety of repetition durations can be utilized if the main goal is to increase muscle size. Our findings suggest that performing repetitions very slowly, taking more than 10 seconds each, is less effective for muscle growth. However, the lack of controlled studies on this topic makes it hard to reach definitive conclusions.",
        "reference": "Maximizing the muscle growth following strength training can be done by manipulating variables like exercise selection, exercise order, rest intervals, intensity of maximal load, and training volume (number of exercises, sets, etc.). A neglected variable that also may impact muscle growth is repetition duration. Total duration of a repetition is the sum of the contraction, the lengthening and isometric (static contraction) and is based on the tempo. We conducted a review and analysis of multiple studies to determine if modification of repetition duration can amplify the muscle growth. Results indicate that muscle growth is similar when training with repetition durations from 0.5 to 8 s. Using a wide range of repetition durations can be employed if the primary goal is to maximize muscle growth. Findings suggest that training at very slow durations (>10s per repetition) is less efficient for muscle growth, although a lack of studies on the topic makes it difficult to draw definitive conclusions."
      },
      {
        "source": "Recovery from exercise refers to the time period between the end of a bout of exercise and the subsequent return to a resting or recovered state. It also refers to specific physiological processes or states occurring after exercise that are distinct from the physiology of either the exercising or the resting states. In this context, recovery of the cardiovascular system after exercise occurs across a period of minutes to hours, during which many characteristics of the system, even how it is controlled, change over time. Some of these changes may be necessary for long-term adaptation to exercise training, yet some can lead to cardiovascular instability during recovery. Furthermore, some of these changes may provide insight into when the cardiovascular system has recovered from prior training and is physiologically ready for additional training stress. This review focuses on the most consistently observed hemodynamic adjustments and the underlying causes that drive cardiovascular recovery and will highlight how they differ following resistance and aerobic exercise. Primary emphasis will be placed on the hypotensive effect of aerobic and resistance exercise and associated mechanisms that have clinical relevance, but if left unchecked, can progress to symptomatic hypotension and syncope. Finally, we focus on the practical application of this information to strategies to maximize the benefits of cardiovascular recovery, or minimize the vulnerabilities of this state. We will explore appropriate field measures, and discuss to what extent these can guide an athlete's training.",
        "prediction": "Recovery from exercise refers to the time between the end of an exercise session and the return to a resting or fully recovered state. It also describes specific physiological (bodily function-related) processes or conditions that occur after exercise, which are different from the state while exercising or resting. In this context, recovery of the cardiovascular system, which includes the heart and blood vessels, happens over minutes to hours, during which many features of the system and how it is controlled change over time. Some of these changes are necessary for long-term adaptation to exercise training, while others can cause instability in the cardiovascular system during recovery. Additionally, some changes can indicate when the cardiovascular system has recovered from previous training and is ready for more stress from exercise. This review focuses on the most commonly seen changes in blood flow and pressure (hemodynamic adjustments) and the underlying reasons that drive cardiovascular recovery, as well as how they differ after resistance training (lifting weights) and aerobic exercise (like running or cycling). The primary focus will be on the lowering of blood pressure (hypotensive effect) that can result from aerobic and resistance exercise, including mechanisms that are clinically important, but if not managed, can lead to serious low blood pressure (symptomatic hypotension) and fainting (syncope). Finally, we will discuss how this information can be practically applied to strategies that maximize the benefits of cardiovascular recovery or minimize the risks during this state. We will explore suitable measures that can be taken in the field and examine how these can help an athlete's training.",
        "reference": "Recovery from exercise refers to the time period between the end of exercise and the return to a resting or recovered state. It also refers to specific physiological processes occurring after exercise. Recovery of the cardiovascular system occurs across a period of minutes to hours, during which many characteristics of the system change over time. Some of these changes may be necessary for long-term adaptation to exercise training, yet some can lead to cardiovascular instability during recovery. These changes may provide insight into when the cardiovascular system has recovered and is physiologically ready for additional training. This review focuses on the most consistently observed blood flow adjustments and the causes that drive cardiovascular recovery and how they differ following strength and cardio exercise. First we focus on the effect leading to low blood pressure of cardio and strength exercise and associated mechanisms, which can progress to symptomatic hypotension (low blood pressure) and fainting. Finally, we focus on the practical application to maximize the benefits of cardiovascular recovery, or minimize the vulnerabilities. We will explore measures, and discuss how these can guide an athlete's training."
      },
      {
        "source": "Exercise and physical activity are increasingly becoming key tools in the treatment and prevention of several medical conditions including arthritis and diabetes; this notion has been termed \"exercise as medicine\". Exercise has favorable effects on reducing cardiovascular risk, inflammation, cachexia, and hypertension, in addition to increasing physical functioning, strength, and cardio-respiratory capacity. Chronic kidney disease, a condition that affects around 10% of the population, is often overlooked as a target for exercise-based therapy. Despite the vast range of severity in kidney disease (e.g., pre-dialysis, dialysis, transplant), exercise has a potential role in all patients suffering from the condition. In this review, we summarise the important role exercise may have in the clinical management of kidney disease and how this form of 'medicine' should be best administered and 'prescribed'.",
        "prediction": "Exercise and physical activity are increasingly important in treating and preventing various medical conditions such as arthritis and diabetes. This idea is referred to as \"exercise as medicine.\" Exercise has beneficial effects by lowering risks for heart problems, inflammation (which is the body's response to injury or infection), weight loss issues known as cachexia, and high blood pressure. It also improves physical ability, strength, and heart and lung fitness. Chronic kidney disease is a condition that affects about 10% of people and is often not recognized as needing exercise-focused treatment. Even though kidney disease can vary greatly in seriousness (for example, some people may not require dialysis, while others may need it, or some may have had a transplant), exercise could be beneficial for all patients with the condition. In this review, we explain the important role exercise may play in managing kidney disease and how this type of 'medicine' should be best used and suggested to patients.",
        "reference": "Exercise and physical activity are key tools in the treatment and prevention of several medical conditions including joint disorders and diabetes. Exercise can reduce cardiovascular risk, inflammation, illness causing muscle loss, and hypertension, in addition to increasing physical functioning, strength, and cardio-respiratory capacity. Chronic kidney disease, a condition that affects around 10% of the population, is often neglected as a target for exercise-based therapy. Despite the vast range of severity in kidney disease, exercise has a potential role in all patients suffering from the condition. In this review, we summarise the potential important role of exercise in the management of kidney disease and how this form of 'medicine' should be used."
      },
      {
        "source": "Blood flow restriction (BFR) is an effective clinical intervention used to increase strength in healthy individuals. However, its effects on pain and function in individuals with knee pain are unknown. Objective: To determine the effectiveness of adding BFR to resistance exercise for pain relief and improvement of function in patients with knee pain. Methods: Systematic review with meta-analysis of randomized clinical trials. Randomized clinical trials that compared resistance exercise with or without BFR to treat knee pain and function in individuals older than 18 years of age with knee pain were included. The pooled standardized mean difference (SMD) estimate showed that resistance exercises with BFR was not more effective than resistance exercises for reducing pain (SMD: -0.37cm, 95% CI=-0.93, 0.19) and improving knee function (SMD=-0.23 points, 95% CI=-0.71, 0.26) in patients with knee pain.",
        "prediction": "Blood flow restriction (BFR) is a treatment method used to help healthy people gain strength. However, it is not clear how it affects pain and function in people with knee pain. The goal of this study was to find out if adding BFR to resistance exercise helps relieve pain and improve function in patients with knee pain. For this study, a systematic review with meta-analysis was conducted, which means researchers analyzed data from multiple randomized clinical trials. These trials tested resistance exercise with and without BFR for treating knee pain in individuals over 18 years old. The combined results showed that resistance exercises with BFR did not significantly reduce pain or improve knee function compared to resistance exercises alone. The pooled standardized mean difference (SMD) for pain reduction was -0.37 cm, with a 95% confidence interval (CI) ranging from -0.93 to 0.19. For knee function improvement, the SMD was -0.23 points, with a 95% CI ranging from -0.71 to 0.26.",
        "reference": "Exercise with blood flow restriction (BFR) is used to increase strength in healthy individuals. However, its effects on individuals with knee pain are unknown. The objective is to determine the effectiveness of adding BFR to strength exercise for pain relief and improvement of function in patients with knee pain. We conducted a review and analysis of multiple studies. Studies that compared strength exercise with or without BFR to treat knee pain and function. The results showed that resistance exercises with BFR was not more effective than strength exercises for reducing pain and improving knee function in patients with knee pain."
      },
      {
        "source": "In Japan, there were an estimated 43 million patients with hypertension in 2010. The management of this condition is given the highest priority in disease control, and the importance of lifestyle changes for the prevention and treatment of hypertension has been recognized in Japan. In particular, emphasis has been placed on increasing the levels of activities of daily living and physical exercise (sports). In this literature review, we examined appropriate exercise prescriptions (e.g., type, intensity, duration per session, and frequency) for the prevention and treatment of hypertension as described in Japanese and foreign articles. This review recommends safe and effective whole-body aerobic exercise at moderate intensity (i.e., 50-65% of maximum oxygen intake, 30-60 min per session, 3-4 times a week) that primarily focuses on the major muscle groups for the prevention and treatment of hypertension. Resistance exercise should be performed at low-intensity without breath-holding and should be used as supplementary exercise, but resistance exercise is contraindicated in patients with hypertension who have chest symptoms such as chest pain.",
        "prediction": "In Japan, there were an estimated 43 million patients with high blood pressure in 2010. Managing this condition is a top priority for disease control, and the importance of lifestyle changes for preventing and treating high blood pressure has been recognized in Japan. Emphasis has been placed on increasing everyday activities and physical exercise, such as sports. In this literature review, we looked at suitable exercise guidelines, including the type, intensity, duration per session, and frequency, for preventing and treating high blood pressure as described in Japanese and foreign articles. This review recommends safe and effective whole-body aerobic exercise at a moderate intensity, which means working at 50-65% of the maximum amount of oxygen the body can use, for 30-60 minutes per session, 3-4 times a week. This exercise should mainly target the major muscle groups to help prevent and treat high blood pressure. Resistance exercise, which helps build strength, should be done at low intensity without holding oneâs breath and should be seen as a supplementary form of exercise. However, resistance exercise is not recommended for patients with high blood pressure who experience chest symptoms like chest pain.",
        "reference": "In Japan, 43 million patients had high blood pressure in 2010. The management of this condition and the importance of lifestyle changes for the prevention and treatment of high blood pressure has been recognized in Japan. In particular, increasing the levels of activities of daily living and physical exercise. In this review, we examined appropriate exercise prescriptions (e.g., type, intensity, duration per session, and frequency) for the prevention and treatment of high blood pressure. This review recommends full body cardio exercise at moderate intensity (i.e., 50-65% of maximum intensity, 30-60 min per session, 3-4 times a week) that focuses on the major muscle groups. Strength exercise should be performed at low-intensity without breath-holding and should be used as supplementary exercise, but it is contraindicated in patients with high blood pressure who have chest symptoms such as chest pain."
      },
      {
        "source": "Physical activity has proved to be an effective means of preventing several diseases and improving general health. Common sense advices call for late inception of intense, strength training-related activities, like weight lifting and plyometrics, which are usually postponed at the end of the growth age, even among sport practitioners. However, such advices seem to have a mainly anecdotal nature. Current literature does not seem to have any particular aversion against the practice of strength training by children and adolescents, provided that some safety rules are followed, like medical clearance, proper instruction from a qualified professional and progressive overload. At the same time, several studies provide consistent findings supporting the benefits of repeated, intense physical efforts in young subjects. Improved motor skills and body composition, in terms of increased fat free mass, reduced fat mass and enhanced bone health, have been extensively documented, especially if sport practice began early, when the subjects were pubescent. It can be therefore concluded that strength training is a relatively safe and healthy practice for children and adolescents.",
        "prediction": "Physical activity has been shown to help prevent various diseases and enhance overall health. Common advice usually suggests delaying intense strength training activities like weight lifting and plyometrics, which are often postponed until after growth has finished, even among athletes. However, this advice mainly comes from personal experiences and stories. Current research does not show strong opposition to children and teenagers engaging in strength training, as long as certain safety guidelines are followed. These guidelines include getting medical approval, receiving proper training from a qualified instructor, and gradually increasing the intensity of workouts. Many studies consistently show the benefits of intense physical activity for young individuals. These benefits include improved motor skills and changes in body composition, such as gaining muscle without adding fat and improving bone health. These effects have been well-documented, especially when sports participation begins early during puberty. Therefore, it can be concluded that strength training is a generally safe and beneficial activity for children and adolescents.",
        "reference": "Physical activity has many benefits like preventing diseases and improving general health. In popular opinion, it is recommended to start intense physical activities like weight lifting and plyometrics (exercises like sprint and jumps) after adolescence. But this advice does not seem to be based on facts. We did not find any recommendation against strength training at a young age if it is well supervised with safety rules, medical clearance, proper instruction from a professional and progressive overload (gradual increase of stress on muscle and nervous system). Several studies showed many benefits of repeated, intense physical efforts in young people. Improved motor skills and body composition (muscle mass increased, fat mass decreased, healthier bone) were found in studies, especially if sport practice began during puberty. We can conclude that strength training is a safe and healthy practice for children and adolescents."
      },
      {
        "source": "recently, there has been a renewed public interest in IFast. Given the importance of nutrition in optimizing athletic performance, there is a concern about the effects of IFast on athletics. Looking at high-intensity, endurance, and resistance exercises, studies have been varied but are uniform in showing that there is no benefit to athletic performance while fasting.",
        "prediction": "Recently, there has been a renewed public interest in IFast. IFast stands for Intermittent Fasting, which is a dietary approach that cycles between periods of eating and fasting. Given the importance of nutrition in optimizing athletic performance, there is a concern about the effects of IFast on athletics. Looking at high-intensity, endurance, and resistance exercises, studies have been varied but are uniform in showing that there is no benefit to athletic performance while fasting.",
        "reference": "Nowadays, people are interested in intermittent fasting (an eating pattern where you cycle between periods of eating and fasting) Nutrition is important for the optimization of sport performance so there is a concern about the effects of intermittent fasting on performance. Studies showed that there are no benefit in high-intensity, endurance or strength training while fasting."
      },
      {
        "source": "Nearly every physically active person encounters periods in which the time available for exercise is limited (e.g., personal, family, or business conflicts). During such periods, the goal of physical training may be to simply maintain (rather than improve) physical performance. Similarly, certain special populations may desire to maintain performance for prolonged periods, namely athletes (during the competitive season and off-season) and military personnel (during deployment). In general populations, endurance performance can be maintained for up to 15 weeks when training frequency is reduced to as little as 2 sessions per week or when exercise volume is reduced by 33â66% (as low as 13â26 minutes per session), as long as exercise intensity (exercising heart rate) is maintained. Strength and muscle size (at least in younger populations) can be maintained for up to 32 weeks with as little as 1 session of strength training per week and 1 set per exercise, as long as exercise intensity (relative load) is maintained; whereas, in older populations, maintaining muscle size may require up to 2 sessions per week and 2â3 sets per exercise, while maintaining exercise intensity. Our primary conclusion is that exercise intensity seems to be the key variable for maintaining physical performance over time, despite relatively large reductions in exercise frequency and volume.",
        "prediction": "Nearly every physically active person experiences times when they have limited time for exercise, such as due to personal, family, or work conflicts. During these times, the goal of physical training may be to maintain physical performance rather than improve it. Certain special groups, like athletes during their competitive season and off-season, and military personnel during deployment, may also want to maintain their performance for longer periods. For the general population, endurance performance can be maintained for up to 15 weeks when training frequency is reduced to as few as 2 sessions per week or when the amount of exercise is cut back by 33 to 66 percent, which means exercising for only 13 to 26 minutes per session, as long as the exercise intensity, or how hard one exercises, is kept up. Strength and muscle size can be maintained for up to 32 weeks in younger populations with just 1 session of strength training per week and 1 set of exercises per session, provided the exercise intensity, or the amount of weight lifted relative to what one can lift, is maintained. In older populations, keeping muscle size may need up to 2 sessions per week and 2 to 3 sets per exercise, while still maintaining exercise intensity. The main conclusion is that exercise intensity appears to be the most important factor for maintaining physical performance over time, even with significant reductions in how often and how much one exercises.",
        "reference": "Physically active people encounter periods with limited time available for exercise. During such periods, the goal of training may be to simply maintain physical performance. Some people may also desire to maintain performance for prolonged periods, like athletes during competitive season or militaries during deployment. Endurance performance can be maintained for up to 15 weeks with 2 trainings per week, or with a reduction of 13â26 minutes per training, as long as exercise intensity (exercising heart rate) is maintained. Strength and muscle size can be maintained for up to 32 weeks with 1 strength training per week and 1 set per exercise, as long as exercise intensity (load) is maintained. In older populations, maintaining muscle size may require up to 2 trainings per week and 2â3 sets per exercise, while maintaining exercise intensity. Exercise intensity seems to be the key variable for maintaining physical performance, even with reduction of frequency and volume (number of exercises, sets, etc.)"
      },
      {
        "source": "Nutrient timing is a popular nutritional strategy that involves the consumption of combinations of nutrients--primarily protein and carbohydrate--in and around an exercise session. Some have claimed that this approach can produce dramatic improvements in body composition. It has even been postulated that the timing of nutritional consumption may be more important than the absolute daily intake of nutrients. The post-exercise period is widely considered the most critical part of nutrient timing. Theoretically, consuming the proper ratio of nutrients during this time not only initiates the rebuilding of damaged muscle tissue and restoration of energy reserves, but it does so in a supercompensated fashion that enhances both body composition and exercise performance. Several researchers have made reference to an anabolic âwindow of opportunityâ whereby a limited time exists after training to optimize training-related muscular adaptations. However, the importance - and even the existence - of a post-exercise âwindowâ can vary according to a number of factors. Not only is nutrient timing research open to question in terms of applicability, but recent evidence has directly challenged the classical view of the relevance of post-exercise nutritional intake with respect to anabolism.",
        "prediction": "Nutrient timing is a popular nutritional strategy that involves eating certain combinations of nutrients, mainly protein and carbohydrates, around exercise sessions. Some people believe this approach can greatly improve body composition, which refers to the makeup of a person's body in terms of fat and muscle. It has even been suggested that the timing of when nutrients are consumed may be more important than how much is eaten throughout the day. The period after exercising is considered the most important time for nutrient timing. Ideally, consuming the right mix of nutrients during this period not only helps repair damaged muscle tissue and restore energy levels but also does so in a way that improves both body composition and exercise performance. Several researchers have mentioned an anabolic \"window of opportunity,\" which refers to a limited time after training to maximize muscle growth and recovery. However, the importance and even the existence of this post-exercise \"window\" can differ based on various factors. Additionally, research on nutrient timing is being questioned regarding its application, and new evidence has directly challenged the traditional belief about how important post-exercise nutrient intake is for muscle growth.",
        "reference": "Nutrient timing is a popular nutritional strategy that involves the consumption of combinations of nutrients around an exercise session. Some people say that this approach can produce dramatic improvements in body composition. It has even been hypothesized that the timing may be more important than the total daily intake of nutrients. The post-exercise period is considered the most important part of nutrient timing. In theory, consuming the proper ratio of nutrients during this time allows the rebuilding of damaged muscle tissue and restoration of energy reserves, but also enhances both body composition and exercise performance. Researchers have made reference to an anabolic âwindow of opportunityâ (a limited time after training to optimize muscular adaptations). However, the importance - and even the existence - of a post-exercise âwindowâ can vary according to a number of factors. Research is uncertain about the applicability of nutrient timing. Besides, the relevance of post-exercise nutritional intake concerning anabolism (increasing muscle mass) has been challenged by recent evidence."
      },
      {
        "source": "Lack of time is among the more commonly reported barriers for abstention from exercise programs. The aim of this review was to determine how strength training can be most effectively carried out in a time-efficient manner by critically evaluating research on acute training variables, advanced training techniques, and the need for warm-up and stretching. When programming strength training for optimum time-efficiency we recommend prioritizing bilateral, multi-joint exercises that include full dynamic movements (i.e. both eccentric and concentric muscle actions), and to perform a minimum of one leg pressing exercise (e.g. squats), one upper-body pulling exercise (e.g. pull-up) and one upper-body pushing exercise (e.g. bench press). Exercises can be performed with machines and/or free weights based on training goals, availability, and personal preferences. Weekly training volume is more important than training frequency and we recommend performing a minimum of 4 weekly sets per muscle group using a 6â15 RM loading range (15â40 repetitions can be used if training is performed to volitional failure). Advanced training techniques, such as supersets, drop sets and rest-pause training roughly halves training time compared to traditional training, while maintaining training volume. However, these methods are probably better at inducing hypertrophy than muscular strength, and more research is needed on longitudinal training effects. Finally, we advise restricting the warm-up to exercise-specific warm-ups, and only prioritize stretching if the goal of training is to increase flexibility.",
        "prediction": "Lack of time is one of the most common reasons people do not participate in exercise programs. This review aimed to find the most effective ways to conduct strength training while saving time by evaluating research on quick training methods advanced training techniques and the importance of warm-up and stretching. To make strength training more time-efficient it is recommended to focus on exercises that work on both sides of the body and involve multiple joints with complete movements that engage both types of muscle actions known as eccentric and concentric. It is suggested to include at least one exercise for pressing down with the legs such as squats one pulling exercise for the upper body like pull-ups and one pushing exercise for the upper body like the bench press. These exercises can be done using exercise machines or free weights depending on the person's goals equipment availability and personal preference. The total amount of training per week is more important than how often training occurs and it is recommended to complete at least 4 sets per week for each muscle group using a loading range known as 6â15 RM which refers to how much weight can be lifted for a given number of repetitions. A higher number of repetitions between 15 to 40 can be done if the training is pushed to failure which means continuing until you cannot perform another repetition. Advanced training techniques such as supersets which involve doing two exercises back to back drop sets where the weight is reduced after each set and rest-pause training can cut training time in half compared to traditional methods while still keeping the same volume of work. However these methods may be more effective for increasing muscle size known as hypertrophy rather than building strength and further research is needed on the long-term effects of these training methods. Lastly it is advised to limit warm-ups to activities specific to the exercises being performed and to only prioritize stretching if the goal of the training is to enhance flexibility.",
        "reference": "Lack of time is one of the most common reason for not exercising. The aim of this review was to determine how strength training can be time-efficient by evaluating research on training variables, advanced training techniques, and the need for warm-up and stretching. We recommend choosing bilateral (with the two arms or legs), multi-joint (multiple joints involved) exercises that include full dynamic movements and to perform a minimum of one leg pressing exercise (e.g. squats), one pulling exercise (e.g. pull-up) and one pushing exercise (e.g. bench press). Exercises can be performed with machines and/or free weights. Weekly training volume (number of exercises, sets, etc.) is more important than training frequency and we recommend a minimum of 4 weekly sets per muscle group using a load that permits to do 6 to 15 repetitions. Advanced training techniques like combining exercises with no rest or shortening the rest time while using lighter weights can cuts the training time in half, while maintaining training volume. However, these methods are probably better to increase muscle mass than strength. Finally, we advise exercise-specific warm-ups, and stretching only if the goal of training is to increase flexibility."
      },
      {
        "source": "Training frequency is considered an important variable in the hypertrophic response to regimented resistance exercise. The purpose of this paper was to conduct a systematic review and meta-analysis of experimental studies designed to investigate the effects of weekly training frequency on hypertrophic adaptations. Results showed no significant difference between higher and lower frequency on a volume-equated basis. Meta-regression analysis of non-volume-equated studies showed a significant effect favoring higher frequencies, although the overall difference in magnitude of effect between frequencies of 1 and 3+ days per week was modest. In conclusion, there is strong evidence that resistance training frequency does not significantly or meaningfully impact muscle hypertrophy when volume is equated. Thus, for a given training volume, individuals can choose a weekly frequency per muscle groups based on personal preference.",
        "prediction": "The frequency of training is an important factor in how muscles grow in response to organized weight training. This paper aimed to systematically review and analyze studies that looked at how often people train each week affects muscle growth. The results indicated that there was no significant difference in muscle growth between higher and lower training frequencies when the total amount of exercise (volume) was kept the same. An analysis of studies that did not control for volume showed a significant advantage for higher training frequencies. However, the overall difference in the level of muscle growth between training once a week and three or more times a week was small. In conclusion, there is strong evidence that how often someone trains does not have a significant or meaningful effect on muscle growth when the total amount of exercise is the same. Therefore, individuals can choose how often to train each week based on their personal preference as long as they maintain the same total volume of training.",
        "reference": "Training frequency is an important variable for hypertrophy (increasing muscle mass) in strength training. The purpose of this paper was to conduct a review and analysis of multiple studies investigating the effects of weekly training frequency on hypertrophy. Results showed no significant difference between higher and lower frequency with the same training volume (number of exercises, sets, etc.). Analysis of studies with different training volumes showed better results for higher frequencies, although the difference between frequencies of 1 and 3+ days per week was small. In conclusion, there is strong evidence that resistance training frequency does not significantly impact muscle hypertrophy when training volume is the same. Thus, for a given training volume, individuals can choose a weekly frequency per muscle groups based on personal preference."
      },
      {
        "source": "A variety of specialized training techniques have been advocated as a means to heighten muscle growth. Forced repetitions/drop sets, supersets, and heavy negatives, in particular, have been purported to enhance the hypertrophic response to resistance exercise. This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to resistance training programs.",
        "prediction": "A variety of specialized training techniques have been recommended to increase muscle growth. Forced repetitions/drop sets, supersets, and heavy negatives are techniques that may enhance muscle hypertrophy, which is the increase in muscle size, in response to resistance exercise. This article will examine how these techniques might help promote muscle hypertrophy and offer insights into how they can be applied in resistance training programs.",
        "reference": "A variety of training techniques have been suggested to support muscle growth. Forced repetitions/drop sets (use lighter weight or receiving help to continue the set), supersets (combining exercises with no rest), and heavy negatives (lowering phase of the lift), are pretended to enhance hypertrophy (increasing muscle mass). This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to strength training."
      },
      {
        "source": "The quest to increase lean body mass is widely pursued by those who lift weights. Research is lacking, however, as to the best approach for maximizing exercise-induced muscle growth. Bodybuilders generally train with moderate loads and fairly short rest intervals that induce high amounts of metabolic stress. Powerlifters, on the other hand, routinely train with high-intensity loads and lengthy rest periods between sets. Although both groups are known to display impressive muscularity, it is not clear which method is superior for hypertrophic gains. It has been shown that many factors mediate the hypertrophic process and that mechanical tension, muscle damage, and metabolic stress all can play a role in exercise-induced muscle growth. Therefore, the purpose of this paper is twofold: (a) to extensively review the literature as to the mechanisms of muscle hypertrophy and their application to exercise training and (b) to draw conclusions from the research as to the optimal protocol for maximizing muscle growth.",
        "prediction": "The quest to increase lean body mass is widely pursued by those who lift weights. Research is lacking, however, as to the best approach for maximizing exercise-induced muscle growth. Bodybuilders generally train with moderate loads, which are weights that are not too heavy, and fairly short rest intervals, meaning they take brief breaks between sets. This method creates a lot of metabolic stress, which is the buildup of byproducts from exercise that can lead to muscle growth. Powerlifters, on the other hand, routinely train with high-intensity loads, meaning they lift heavier weights, and lengthy rest periods between sets, which allows them to recover more fully before lifting again. Although both groups are known for their impressive muscle size, it is not clear which training method is better for gaining muscle. Many factors can influence the process of gaining muscle, and it has been shown that mechanical tension, which is the force applied to muscles when they are stretched; muscle damage, which occurs during exercise and is part of how muscles grow; and metabolic stress all can play a role in exercise-induced muscle growth. Therefore, the purpose of this paper is twofold: to extensively review the literature on the mechanisms of muscle hypertrophy, which is the increase in muscle size, and how they can be applied to exercise training, and to draw conclusions from the research on the best methods for maximizing muscle growth.",
        "reference": "Increasing muscle mass is the goal of many people who lift weights. Research is lacking, however, as to the optimal way to induce muscle growth. Bodybuilders train with moderate loads and short rest intervals. Powerlifters, on the other hand, train with high-intensity loads and lengthy rest periods. Although both groups are known to display impressive muscularity, it is not clear which method is superior for increasing muscle mass. It has been shown that many factors mediate the process of muscle growth and that mechanical tension, muscle damage, and metabolic stress all can play a role in muscle growth. Therefore, the purpose of this paper is to review the literature as to the mechanisms of muscle hypertrophy and their application to exercise training and to draw conclusions from the research as to the optimal way to induce muscle growth."
      }
    ]
  ],
  "aiir_llama_run_1_prompt": [
    {
      "SARI": 38.17997192513837,
      "BLEU": 0.1799105848752066,
      "FKGL": 9.144571428571428
    },
    [
      {
        "source": "Abstract   Novel technological advances in mobile devices and applications can be exploited in wildfire confrontation, enabling end-users to easily conduct several everyday tasks, such as access to data and information, sharing of intelligence and coordination of personnel and vehicles. This work describes an innovative mobile application for wildfire information management that operates on Windows Phone devices and acts as a complementary tool to the web-based version of the AEGIS platform for wildfire prevention and management. Several tasks can be accomplished from the AEGIS App, such as routing, spatial search for closest facilities and firefighting support infrastructures, access to weather data and visualization of fire management data (water sources, gas refill stations, evacuation sites etc.). An innovative feature of AEGIS App is the support of these tasks by a digital assistant for artificial intelligence named Cortana (developed by Microsoft for Windows Phone devices), that allows information utilization through voice commands. The application is to be used by firefighting personnel in Greece and is potentially expected to contribute towards a more sophisticated transferring of information and knowledge between wildfire confrontation operation centers and firefighting units in the field.",
        "prediction": "This passage talks about new mobile technology to help with wildfires. It helps users do tasks like getting information, sharing ideas, and coordinating rescue teams and vehicles. \n\nThe AEGIS App is a new mobile application for managing wildfire information. It works on Windows Phone devices and supports the web version of AEGIS for wildfire prevention. Users can do many tasks with the AEGIS App. They can find routes, search for nearby facilities, and get weather updates. They can also see important fire management data like water sources and evacuation sites.\n\nA unique feature of the AEGIS App is its digital assistant, Cortana. Cortana is an artificial intelligence tool developed by Microsoft. It lets users get information using voice commands. The app is designed for firefighting teams in Greece. It aims to improve the flow of information between wildfire control centers and firefighting units in the field.",
        "reference": "Novel mobile devices and applications can be used in wildfire confrontation by helping users to access data and information and coordinate personnel and vehicles. This paper describes a new Windows Phone application for wildfire information management which is complementary to the web version of the AEGIS platform for wildfire prevention and management. The AEGIS App can be used for searching for the closest firefighting infrastructures, as well as access to weather data, and visualization of water sources, gas refill stations, evacuation sites, etc. The AEGIS App supports these tasks through voice commands with Microsoft Cortana (AI digital assistant for Windows Phone).Â  The application is designed for firefighters in Greece but it can help communication between wildfire coordination and local firefighting units."
      },
      {
        "source": "In recent years, mobile technologies have developed and applied in education fields, and some mobile emerging carriers with mobile technologies include a personal digital assistant (PDA), smart phone, and e-book. Some of the mobile carriers combines context-aware technologies or involve into wireless network environments to make effective use through the combination of learning scenarios and technologies, and then provide students new learning experiences differed from the past learning. In view of the application of mobile technology in education, some previous studies have addressed that mobile learning is a meaningful learning that can improve the interaction between students and the situations and reach the purposes of learning. In the main stream of mobile learning, using mobile carriers with suitable learning methods or strategies in mobile learning activities for different students to enhance learning have gradually become a important and concern issue. The purpose of this study is to investigate the learning achievement and learning attitude of elementary school students on a campus plant learning activity when they use mobile carriers and competitive learning strategies. The experimental results show that the competitive learning group of students have better learning performance than non-competitive learning group of students. After completing the learning activity, the two groups of students presented high positive attitudes towards learning.",
        "prediction": "Recently, mobile technology has grown in education. Examples of mobile tools include personal digital assistants, smartphones, and e-books. Some of these tools use context-aware technology and wireless networks. They create new and effective learning experiences for students. Studies show that mobile learning can improve how students interact with their lessons. For mobile learning to work well, it needs the right tools and teaching methods for different students. This study looks at how mobile tools and competitive learning strategies affect the learning of elementary school students during a plant study on campus. The results showed that students in the competitive learning group performed better than those in the non-competitive group. After the activity, both groups had a positive attitude towards learning.",
        "reference": "Mobile technologies, such as personal digital assistants (PDA), smartphones, and e-books, are increasingly used in the educational field. Some mobile carriers combine learning scenarios and context-aware technologies or wireless network environments providing students with new learning experiences. Mobile learning is effective as it can improve the interaction between students and situations. An important question in the mobile learning field is how to enhance learning through the use of mobile carriers with suitable learning methods in student activities. This study investigates learning achievement and attitude of elementary school students when they use mobile carriers and competitive learning strategies during campus plant learning activities. The competitive learning group of students has better learning performance than the non-competitive one. After the activity, both groups of students were positive about learning."
      },
      {
        "source": "This paper proposes an electrophysiological wireless patient monitoring system which integrates a Wireless ECG signal transmitter, GPS device and a mobile phone to acquire physiological signals and transmit them to a local server via Bluetooth wireless technology. Four kinds of monitor units were specially designed for a wireless communication, including a control center , a local monitor unit, mobile devices (personal digital assistant; PDA), and a Web page (for both patient and doctor). The use of various monitor units is created to fulfill different medical personnel requirements and wishes. This application was developed to promote the mobility and flexibility for the patients and also for the medical personnel, which further will improve both the quality of health care and lifestyle of the patient.",
        "prediction": "This paper presents a wireless patient monitoring system. It uses a Wireless ECG signal transmitter, GPS device, and a mobile phone. These devices gather health signals and send them to a local server using Bluetooth technology. There are four types of monitor units designed for wireless communication. They include a control center, a local monitor unit, personal digital assistants (PDAs), and a web page for both patients and doctors. Each monitor unit meets different needs of medical staff. This system aims to increase flexibility and mobility for patients and healthcare workers. This will help improve the quality of healthcare and the patient's lifestyle.",
        "reference": "This paper suggests a system to monitor patients wirelessly using a device that transmits ECG signals, a GPS device, and a mobile phone. The signals are sent to a local server via Bluetooth technology. Four types of monitor units were created for wireless communication: a control center, a local monitor unit, mobile devices such as personal digital assistants (PDA), and a web page accessible to both patients and doctors. Various monitor units are used to satisfy different medical personnel needs. This application was developed to boost the quality of healthcare and patient lifestyle by increasing mobility and flexibility for both patients and medical personnel."
      },
      {
        "source": "As various kinds of output devices emerged, such as highresolution printers or a display of PDA(Personal Digital Assistant), the importance of high-quality resolution conversion has been increasing. This paper proposes a new method for enlarging image with high quality. One of the largest problems on image enlargement is the exaggeration of the jaggy edges. To remedy this problem, we propose a new interpolation method, which uses artificial neural network to determine the optimal values of interpolated pixels. The experimental results are shown and evaluated. The effectiveness of our methods is discussed by comparing with the conventional methods.",
        "prediction": "As different output devices like high-resolution printers and PDAs became popular, the need for good image resolution conversion grew. This paper presents a new way to enlarge images while keeping high quality. A major issue with enlarging images is that edges can become jagged. To fix this, we suggest a new interpolation method that uses artificial neural networks to find the best values for the new pixels. We show and discuss the results of our experiments. We also compare our method to traditional ones to show its effectiveness.",
        "reference": "The rise of output devices like high-resolution printers and PDA displays has increased the need for high-quality resolution conversion. The paper proposes a new method to make images bigger while maintaining high quality. The main issue with enlarging images is that jagged edges can become exaggerated. To solve this problem, we suggest a new method that helps us to estimate the value of the newly generated pixels using a neural network. The experiment's results are presented and analyzed. We evaluate the effectiveness of our methods by comparing them to traditional approaches."
      },
      {
        "source": "A significative percentage of the human population suffer from impairments in their capacity to distinguish or even see colours. For them, everyday tasks like navigating through a train or metro network map becomes demanding. We present a novel technique for extracting colour information from everyday natural stimuli and presenting it to visually impaired users as pleasant, non-invasive sound. This technique was implemented inside a Personal Digital Assistant (PDA) portable device. In this implementation, colour information is extracted from the input image and categorised according to how human observers segment the colour space. This information is subsequently converted into sound and sent to the user via speakers or headphones. In the original implementation, it is possible for the user to send its feedback to reconfigure the system, however several features such as these were not implemented because the current technology is limited.We are confident that the full implementation will be possible in the near future as PDA technology improves.",
        "prediction": "Many people have trouble seeing or telling colors apart. For them, tasks like reading a train map can be hard. We have a new method to get color information from the world and turn it into sound for people with vision problems. This method works in a small device called a Personal Digital Assistant (PDA). It takes color information from a picture and sorts it like how people see colors. Then, it turns this information into sound, which users hear through speakers or headphones. In the first version of this device, users could give feedback to adjust the system, but some features were not added because of technology limits. We believe that as PDA technology gets better, we can add all these features in the future.",
        "reference": "A significant percentage of people have trouble differentiating or seeing colors. Simple tasks like using a train or subway map can be difficult for them. We introduce a new method to help visually impaired users perceive color information using non-invasive, pleasant sounds generated from everyday stimuli. We put this technique into a portable device called a Personal Digital Assistant (PDA). In this implementation, we extract color information from the input image and organize it based on how people perceive color. Then, the information is changed into sound and sent to the user through speakers or headphones. In the first version, the user could give feedback to change the system, but we couldn't add all the features due to technology limitations. We believe that we can add all the features soon as PDA technology advances."
      },
      {
        "source": "Inappropriate use of medicines increases the risk of hospital admissions for the elderly. Not only does this lead to unnecessary suffering for the patients but also incurs a great financial cost to the society. A medicine decision support system in a Personal Digital Assistant (PDA), with a barcode reader, can provide an overview of the patientsu0027 complete medicine use, and detect unsuitable drugs and drug combinations. Focusing on the elderly, our aim was to evaluate if a mobile medicine decision support system with a barcode reader is useful and user-friendly for nurses in home care. The participants received a comprehensive overview from the patientsu0027 medicine use and noted drug-drug interactions, therapeutic duplications and warnings for drugs unsuitable for elderly people. The nurses regarded that the decision support system increased prevention and safety, was useful and user-friendly. Our findings suggest that most of the content and functions were regarded as important. Therefore, this decision support system might be a useful tool for district nurses.",
        "prediction": "Using medicines in the wrong way can lead to more hospital visits for older people. This not only causes them pain but also costs a lot of money for society. A medicine decision support system on a Personal Digital Assistant (PDA) with a barcode reader can show a complete picture of what patients are taking. It can find unsafe drugs and drug combinations. We focused on older patients to see if this mobile system is helpful and easy to use for nurses in home care. The nurses got a detailed view of the patients' medicine use and found issues like drug-drug interactions, repeated therapies, and warnings for drugs that may not be safe for older people. The nurses thought the system improved safety and prevention, and they found it useful and easy to use. Our results show that most features were seen as important. So, this decision support system could be a helpful tool for community nurses",
        "reference": "Misusing medicines can make older people more likely to end up in the hospital. This causes patient suffering and financial cost to society. A support system for medicine decision, with a bar code reader, in a PDA can help identify inappropriate medication use and combinations by providing a complete overview of the patient's medication The goal was to evaluate if a mobile medicine decision support system with a barcode reader is helpful and easy to use for home care nurses working specially with older patients. The participants were provided with a complete overview of the patient's medication usage, and identified any drug interactions, duplicated medications, and any warnings about drugs that are not suitable for elderly patients. The nurses found the decision support system to be helpful, and easy to use, and improving the prevention and safety measures. Our results indicate that the majority of the content and features were considered significant. So, this system could be helpful for district nurses."
      },
      {
        "source": " :[0],\"access to patient appointment schedules can help clinicians manage time and problems better. Many large health care organizations manage clinical appointment scheduling via enterprise resource scheduling systems which are poorly accessible by clinicians. Also, staff other than the clinicianu0027s personal assistant(s) may manage scheduling, making it difficult for clinicians to stay informed of changes. Many a clinician today uses a personal digital assistant (PDA) containing basic calendaring functionality. Our âPalmOversiteâ project demonstrates the feasibility of integrating enterprise appointment schedule information into a PDA calendar, making schedule information much more readily available to the clinician.",
        "prediction": "Access to patient appointment schedules helps clinicians manage time and problems better Many large health care organizations use resource scheduling systems to manage appointments but these systems are hard for clinicians to access Sometimes staff other than the clinician's assistants handle scheduling This makes it tough for clinicians to keep track of changes Many clinicians today use personal digital assistants PDAs with basic calendar features Our PalmOversite project shows how we can connect appointment schedule information to a PDA calendar This makes it easier for clinicians to get schedule information",
        "reference": "Knowing patients' appointment schedules can help clinicians manage time and problems more effectively. Healthcare organizations often use enterprise resource scheduling systems for clinical appointment scheduling, but these systems may not be easily accessible by clinicians. Moreover, scheduling may not only be handled by the clinician's assistant(s), creating challenges for clinicians to stay updated on any changes. Many clinicians today use a personal digital assistant (PDA) with a basic calendar. Our project called 'PalmOversite' shows the practicability of integrating enterprise appointment schedule information into a PDA calendar. This makes it easier for clinicians to access their schedule information."
      },
      {
        "source": "Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of multidrug-resistant tuberculosis (MDR-TB) patients in Peru, in conjunction with the Peruvian National TB Program (NTP). Monthly bacteriology tests, which must be collected from health establishments located across this major city, are an integral part of this treatment. Currently, a SES employee visits each health establishment to collect this information by hand, process it and type it into an electronic medical record system  this :[81],\"paper, we describe the development and implementation of a personal digital assistant (PDA)-based electronic system to collect, verify and upload monthly bacteriology data into the PIH-EMR. After an initial implementation period, we performed a pilot study to test the use of this system. We completed a baseline assessment in two health districts and then implemented the electronic system in one of the districts while the control site continued to use the paper-based system during the same period. The PDA-based system had a processing time of 6.2 days, significantly lower than measurements for both the baseline [54.8] and control sites [64.4] (both pu003c0.0001). It was also able to reduce the frequency of discrepancy from 10.1% to 2.8% (pu003c0.0001) and receive positive feedback from the users. Finally, the systemâs cost would be recuperated in three months from time savings due to increased work efficiency. This system will be the subject of a larger study to determine its impact on delays, errors and costs.",
        "prediction": "Partners In Health (PIH) and Socios En Salud (SES) help most people with multidrug-resistant tuberculosis (MDR-TB) in Peru. They work with the Peruvian National TB Program (NTP). Every month, they need to collect bacteriology tests from health places around Lima. Currently, an SES worker visits each place to gather this data, then processes it and enters it into a medical record system. \n\nIn this study, we created a digital system using a personal digital assistant (PDA) to collect, check, and upload the monthly bacteriology data into the PIH electronic medical record. After a test period, we did a pilot study to evaluate the system. We assessed health data in two areas and used the PDA system in one area while the other area continued using paper records.\n\nThe PDA system completed tasks in 6.2 days, much faster than the paper method, which took 54.8 days in the first area and 64.4 days in the control area. The PDA system also lowered errors from 10.1% to 2.8%. Users gave positive feedback about the system. Additionally, the cost of the system would be recovered in three months due to time saved from better efficiency. A larger study will be done to see how this system affects delays, errors, and costs.",
        "reference": "PIH (Partners In Health) and SES (Socios En Salud) provide treatment for most of the MDR-TB (multidrug-resistant tuberculosis) patients in Peru along with the Peruvian NTP (National TB Program). Monthly bacteriology tests are necessary for this treatment and must be collected from various health establishments located throughout the city. An employee from SES is currently going to each health establishment and collecting monthly bacteriology test results by hand, processing them, and typing them into an electronic medical record system. In this paper, we explain how we made a digital system using a personal digital assistant (PDA) to gather, check, and upload monthly bacteriology data into the PIH-EMR (Partners In Health Electronic Medical Record).  After an initial period of putting the system into action, we conducted a test study to evaluate the effectiveness of using this system. We first evaluated the current system in two health districts, then introduced the electronic system in one district while the other continued using the paper-based system during the same time. The PDA-based system took only 6.2 days to process, which was significantly lower than both the baseline (54.8) and control sites (64.4) (both less than 0.0001). The PDA-based system reduced differences from 10.1% to 2.8% and received positive feedback from users. The system would pay for itself in three months due to increased efficiency and time savings. A larger study will be conducted to assess the impact of this system on delays, errors, and costs."
      },
      {
        "source": "In order to facilitate knowledge transfer between specialists and generalists and between experts and novices, and to promote interdisciplinary communication, there is a need to provide methods and tools for doing so. This interdisciplinary research team developed and evaluated a decision support tool (DST) on a personal digital assistant (PDA) for cardiac tele-triage/tele-consultation when the presenting problem was chest pain. The combined human factors methods of cognitive work analysis during the requirements-gathering phase and ecological interface design during the design phase were used to develop the DST. A pilot clinical trial was conducted at a quaternary cardiac care hospital over a 3-month period. During this time, the DST was used by the nine nursing coordinators who provide tele-triage/tele-consultation 24/7. This clinical trial validated the design and demonstrated its usefulness to advanced cardiac care nurses, its potential for use by nurses less experienced in cardiac care, and for its potential use in an interdisciplinary team environment.",
        "prediction": "To help share knowledge between specialists and generalists, and between experts and beginners, we need to provide methods and tools. An interdisciplinary research team created and tested a decision support tool (DST) on a personal digital assistant (PDA) for cardiac tele-triage and tele-consultation when there was chest pain. They used human factors methods like cognitive work analysis and ecological interface design to develop the DST. A pilot clinical trial happened at a cardiac care hospital over three months. During this time, nine nursing coordinators used the DST for tele-triage and tele-consultation 24/7. This trial confirmed the design and showed it was useful for experienced cardiac care nurses and could help less experienced nurses as well as teams from different fields.",
        "reference": "To improve communication between specialists, generalists, experts, and novices and encourage interdisciplinary collaboration, we need to develop methods and tools. An interdisciplinary research team created and tested a decision support tool (DST) on a personal digital assistant (PDA) to aid cardiac tele-triage/tele-consultation for patients with chest pain. To create the DST (Decision Support Tool), we used both cognitive work analysis and ecological interface design methods during the requirements-gathering and design phases. A trial was done for 3 months at a quaternary cardiac care hospital During the trial, nine nursing coordinators used DST for 24/7 tele-triage/tele-consultation. This clinical trial confirmed that the design is useful for advanced cardiac care nurses, as well as for less experienced nurses and interdisciplinary teams."
      },
      {
        "source": "This paper presents M-CALL, a mobile computer-assisted language learning courseware for Korean language learners. Since conventional computer-assisted language learning is often boring, it exploits a cyber pet game to increase the learnerâs interest. M-CALL runs on a personal digital assistant with public wireless LAN for mobile learning. It grows a cyber pet by solving problems of Korean language learning. Korean Proficiency Test (KPT), a nationally certified Korean language test, was used as problem sets. It consists of cyber pet game, mobile learning courseware, mobile learning system, and mobile tutoring. It provides various functions for Korean language learning. Currently, the prototype M-CALL was designed and partly implemented between mobile PDA and personal computer.",
        "prediction": "This paper is about M-CALL, a mobile course for learning Korean. Traditional learning methods can be boring, so M-CALL uses a cyber pet game to make it more fun. M-CALL works on a personal digital assistant and uses public Wi-Fi for learning on the go. Users care for a cyber pet by solving Korean language problems. The problems come from the Korean Proficiency Test, a recognized Korean language exam. M-CALL includes a game, learning tools, a learning system, and tutoring help. It offers different features for learning Korean. Right now, there is a prototype of M-CALL, which connects a mobile PDA with a personal computer.",
        "reference": "M-CALL is a mobile courseware for Korean language learners. It incorporates a cyber pet game to make it more engaging for learners than traditional computer-assisted language learning methods. M-CALL is a mobile learning system that uses a personal digital assistant with public wireless LAN (Computer network in small geographic areas). A cyber pet is raised while solving problems related to Korean language learning. The KPT, a nationally recognized exam for Korean language proficiency, served as the source material for the problem sets. It includes a virtual pet game, a mobile course for learning, a mobile learning platform, and mobile tutoring. It offers multiple features for learning Korean. Right now, a preliminary version of M-CALL has been developed and partially implemented for use on both mobile PDAs and personal computers."
      },
      {
        "source": "This study compared text entry performance of two stylus-driven soft keyboards for use in hand-held computing devices: the QWERTY and the T9. Participants transcribed text presented on a computer screen into a personal digital assistant (PDA) using a stylus and one of these two keyboards. We introduced a new psychophysical technique for measuring transcription rate that provides a composite measure of speed and accuracy. Using this technique, we calculated the maximum transcription rate for each keyboard. The results show that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9 keyboardâs apparent superior physical characteristics. An ancillary experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in visual scanning time due to perceptual grouping of the letters on the keys. Together these findings imply that the QWERTY keyboard layout remains the most effective of the currently available designs for stylus tapping on soft keyboards.",
        "prediction": "This study looked at how well two soft keyboards work with stylus pens on handheld devices. The keyboards are QWERTY and T9. People typed text from a screen into a personal digital assistant using a stylus and one of the keyboards. We used a new method to measure how fast and accurately the text was typed. This method helped us find the fastest typing rate for each keyboard. The results showed that the QWERTY keyboard had faster typing rates than the T9, even though T9 is designed better. Another experiment showed that T9's slower performance might be due to longer time needed to find the letters on the keys. Overall, these results suggest that the QWERTY keyboard is still the best option for typing on soft keyboards with a stylus.",
        "reference": "This study compared two onscreen keyboards, the QWERTY and the T9, for text entry performance on hand-held computing devices. Participants used a stylus to input text on a PDA using either a QWERTY or T9 keyboard in this study. We created a new way to measure transcription rate that considers both speed and accuracy together. We used this method to determine the fastest possible typing speed for each keyboard. The study found that the QWERTY keyboard had a higher transcription rate than the T9 keyboard, even though the T9 keyboard was physically better. Another test showed that the T9 keyboard's lower performance might be because the grouped letters on its keys require more visual scanning time. Overall, these results suggest that, among the current options, the QWERTY keyboard layout is still the most efficient for typing on touch screens with a stylus."
      },
      {
        "source": "The proliferation of mobile devices such as smart phones and Personal Digital Assistant (PDA) opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system). In Mcommerce systems, we still see many common components that we have in standard E-commerce applications, such as web servers and database servers. However, these new applications raise some unique challenges. For example, the limitations of mobile devices (e.g., small screen size and reduced CPU performance) implies that software development is partly different from desktop applications. Questions which are posed when designing M-commerce system include: âWhat kind of information do the users want to access via mobile devices?â, âHow can we provide useful applications with limited user input facility?â, âHow can we test a distributed M-commerce system?â In this paper, we discuss about some software development issues for mobile commerce systems from our experiences while developing an M-commerce system for tourists. Our prototype, easyHotel, is an useful software that allows booking hotel rooms via mobile phones.",
        "prediction": "Mobile devices like smartphones and PDAs have led to new ways of creating mobile E-commerce systems, or M-commerce. M-commerce systems share many parts with regular E-commerce applications, like web servers and database servers. However, these systems face unique challenges. For instance, mobile devices have small screens and less powerful CPUs, which makes software development different from desktop applications. Key questions when designing M-commerce systems include what information users want on their mobile devices, how to create useful apps with limited user input, and how to test a distributed M-commerce system. In this paper, we talk about some software development issues for M-commerce systems based on our experience developing an M-commerce system for tourists. Our prototype, easyHotel, is a helpful app that lets users book hotel rooms using their mobile phones.",
        "reference": "The increasing use of mobile devices like smartphones and PDAs provides opportunities for the development of new mobile e-commerce systems, also known as M-commerce (Mobile-commerce) systems. M-commerce systems share several components with traditional E-commerce applications, such as web servers and database servers. However, these new applications present some distinct challenges. For example, due to mobile devices' limitations, such as smaller screens and weaker processors (also called CPUs), software development for mobile applications is partially different from desktop applications. Designing an M-commerce system involves asking questions such as: \"What information do users want on mobile devices?\", \"How can we create useful apps with limited user input?\", and \"How do we test a distributed M-commerce system?\" In this paper, we share our experiences developing an M-commerce system for tourists and discuss software development issues for such systems. Our software prototype, easyHotel, is a helpful application enabling users to book hotel rooms through their mobile phones."
      },
      {
        "source": "It is widely acknowledged that information such as web content should be adapted for mobile platforms to account for restrictions in mobile environments. As emerging mobile platforms such as different kinds of Personal Digital Assistant (PDA) tend to vary largely in their capabilities, we suggest that adaptation should be platform-specific. Common approaches for content adaptation are automated conversion and explicit specification of adapted content, with a trade-off between quality and development/maintenance effort. As alternative avoiding this trade-off, we propose a simple object-oriented framework for content adaptation. To facilitate the use of this framework in the Web, we base our approach on the object-oriented WebComposition model and its XML-based implementation WCML. We apply our object-oriented approach to an example application to demonstrate how object-oriented specification of platform-adapted content reduces development/maintenance effort.",
        "prediction": "It is important to change web content for mobile devices because they have limits. New mobile devices like Personal Digital Assistants (PDAs) are very different in what they can do. We think changes should be specific to each platform. Common ways to adapt content include automated conversion and clear guidelines for changed content. There is a balance between quality and how much work it takes to develop and maintain. To avoid losing quality, we suggest a simple object-oriented framework for adapting content. Our method uses the object-oriented WebComposition model and its XML-based system called WCML. We show how this approach can help with an example app. It shows that using an object-oriented way to create content for different platforms can reduce the amount of work needed.",
        "reference": "It is widely recognized that information, such as web content, should be adjusted for mobile platforms to accommodate the limitations of mobile environments. As new mobile platforms, such as various types of PDAs, differ significantly in their capabilities, we propose that adaptation should be tailored to each platform. Common methods for content adaptation involve automated conversion or explicitly specifying adapted content, balancing the trade-off between quality and the effort required for development and maintenance. Instead of making this trade-off, we suggest using a straightforward object-oriented framework for content adaptation. To make this framework more accessible for use on the web, we build our approach on the object-oriented WebComposition model and its implementation, WCML, which is an application of XML. We use our object-oriented framework in an example application to show how specifying platform-adapted content using an object-oriented approach can lower development and maintenance costs."
      },
      {
        "source": "In monitoring a patientu0027s real-time vital signs through Body Area Networks (BAN), rich data sources are communicated to medical practitioners. It is essential that data is delivered in timely-context aware manner. In this paper a system is designed for patients with cardiac disorders, with an emphasis on the design of the sensing device and communication scheme chosen. Several existing wearable physiological devices (Patient Sensing Device â PSD) used in the Healthcare systems are bulky in design and are not flexible and comfortable for the elderly patients. Presented is a unique flexible, as well as detachable PSD for the comfort of patients. Also discussed is a model for transmission, storage and processing of patient related data, which ensures periodic logging of patient data without saturating communication networks. A proof of concept prototype has been developed and implemented to enable transmission of Electrocardiogram (ECG) signal and body temperature of a patient, which can be expanded to include other vital signs. Communication between a mobile smart-phone and the ECG and temperature acquisition apparatus is implemented Bluetooth. The presented Data Management System â Periodic Model (DMS â PM) is designed to manage wireless interface of sensor units with the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a Smart phone making use of the existing GSM network.",
        "prediction": "This paper talks about a new system to monitor patients' vital signs using Body Area Networks (BAN). It gives important data to doctors quickly and contextually. The focus is on patients with heart problems. The system includes a new sensing device that is flexible and comfortable, especially for older patients. Many current wearable devices are too big and not user-friendly. The paper also describes how to transmit, store, and process patient data. This system logs important data without overloading communication networks. A prototype has been created to send Electrocardiogram (ECG) signals and body temperature. It can be upgraded to track other vital signs too. The data is sent between a smartphone and the device using Bluetooth. The Data Management System - Periodic Model (DMS - PM) helps connect sensor units to the patient database at a Medical Service Provider (MSP) using a Personal Digital Assistant (PDA) or smartphone with the GSM network.",
        "reference": "Medical practitioners can access a wealth of data sources by using Body Area Networks (BAN) to monitor a patient's real-time vital signs. A BAN refers to a network of wearable or implantable devices worn on or attached to the human body for various purposes. Timely and context-aware delivery of data is crucial. This paper presents a system specifically designed for patients with cardiac disorders, focusing on the design of the sensing device and communication scheme selected. Many of the current wearable physiological devices used in healthcare systems, known as Patient Sensing Devices (PSD), are bulky and uncomfortable for elderly patients due to their inflexible design. We introduce a unique Patient Sensing Device (PSD) that is both flexible and detachable, designed for patient comfort. We also propose a model for transmitting, storing, and processing patient-related data that ensures regular logging of data without overwhelming communication networks. We have developed and implemented a proof-of-concept prototype that can transmit a patient's Electrocardiogram (ECG) signal and body temperature, potentially expanding to other vital signs. Communication between a mobile smartphone and the ECG and temperature acquisition apparatus is achieved via Bluetooth. The Data Management System - Periodic Model (DMS - PM) introduced here is created to facilitate the wireless connection between sensor units and the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a smartphone, utilizing the existing GSM network."
      },
      {
        "source": "Advancement of wireless and mobile technology has enabled additional platforms to support learning in a single learning space. Current trend integrates usage of mobile terminals such as smart PDA (personal digital assistant) in a learning system. Such devices can communicate with wireless mobile terminal and realize the intelligence exchange with its surroundings [1]. A LOCH (Language Learning Outside the Classroom) system named One Day Trip is developed to assist overseas students to learn Japanese in real life situations with the help of a PDA. This paper proposes the implementation with Knowledge Management (KM) concepts in the system to aid the teacher and learners in the learning environment.",
        "prediction": "Wireless and mobile technology has created new ways for people to learn in the same place. Now, we use mobile devices like smart PDAs in learning systems. These devices can connect with other wireless devices and share information around them. A system called One Day Trip helps foreign students learn Japanese in real-life situations using a PDA. This paper suggests using Knowledge Management ideas in the system to support teachers and students in their learning.",
        "reference": "Wireless and mobile technology progress has allowed more platforms to facilitate learning within a unified space. The current trend is to use mobile devices, such as smart PDAs, in learning systems. These devices can communicate wirelessly with mobile terminals and exchange information with the surrounding environment One Day Trip is a language learning system called LOCH (Language Learning Outside the Classroom), designed to help foreign students learn Japanese in real-life situations using a PDA. This paper suggests incorporating Knowledge Management (KM) concepts in the One Day Trip system to support both the teacher and learners in the learning environment."
      },
      {
        "source": "In recent years, we have developed applications for teaching both wired and wireless networking. These applications have been written for the Cybiko personal digital assistant, an inexpensive alternative to other hardware. Unfortunately, the Cybiko PDA was recently discontinued. As a result, these applications had to be ported to other platforms to remain useful. Instead of porting each application to individual platforms, which would prove to be extremely time consuming because of other APIu0027s and networking protocols, we created the Vassar College Messaging Layer. This layer abstracts the Cybiko networking structure and interface, allowing Cybiko applications to be ported to other platforms with minimal code alteration.",
        "prediction": "In recent years, we made apps to teach wired and wireless networking. These apps were for the Cybiko personal digital assistant, which was a cheap option. Sadly, the Cybiko PDA is no longer available. Because of this, we had to move the apps to other platforms. Instead of changing each app for different platforms, we made the Vassar College Messaging Layer. This layer simplifies the Cybiko network setup. It lets us move Cybiko apps to new platforms with very little code change.",
        "reference": "In recent years, we have created applications for teaching both wired and wireless networking. These applications are designed for the Cybiko personal digital assistant, which offers a cost-effective alternative to other hardware options. The Cybiko PDA was discontinued recently. Consequently, these applications needed to be adapted to other platforms to maintain their usefulness. To avoid the time-consuming task of porting each application to various platforms due to different APIs and networking protocols, we developed the Vassar College Messaging Layer. This layer simplifies the Cybiko networking structure and interface, making it easier to adapt Cybiko applications to different platforms without needing to make significant changes to the code."
      },
      {
        "source": "Unlike many other classes of hardware, smartcards do not have the ability to communicate securely with the user. Deprived of means to keep the owner informed, the positive properties of smartcards are difficult to utilize. We explore the area at the border between smartcards and other, more powerful (and thus more useful), machines. On the other side of this border we find the Personal Digital Assistant  :[66],\"our view, to be useful as an extension of the usersu0027 private sphere, a machine must at least have enough functionality and resources to create trustworthy digital signatures (to speak for the user, as it were). A less resourceful machine can merely act as a memory prothesis, helping the owner remembering addresses and phone  are :[121],\"designed to be tamper resistant, and as such they seem ideal as a minimal machine. However, trustworthy digital signatures can not be created by smartcards alone, simply because the user does not know what is given to the card for  :[163],\"order to be trusted--that is, being able to make trustworthy digital signatures--a smartcard must be supported by some infrastructure outside the card proper. We explore what must be included in such an infrastructure, and demonstrate that trustworthy digital signatures can in fact be made using a standard  :[211],\"argue that based on this fact, nontrivial distributed systems can be constructed by utilizing smartcards; a nontrivial system is one where holders of smartcards are \"first class citizens\". Asserting that a smartcard can act as a trusted machine gives new opportunities for designers of user-centric  that smartcards are :[257],\"here to stay, finding ways to apply them in constructive manners is prudent.",
        "prediction": "Smartcards are a type of hardware that cannot communicate securely with the user. This makes it hard to use their good features. We look into how smartcards connect with more powerful devices like Personal Digital Assistants. To be useful and protect private information, a device needs to create trustworthy digital signatures for the user. If a device does not have enough power, it can only help the owner remember things like addresses and phone numbers. \n\nSmartcards are built to resist tampering, which makes them seem like a good choice for basic tasks. However, they cannot create trustworthy digital signatures on their own because the user does not know what information is given to the card. For smartcards to be trusted and create reliable digital signatures, they need help from outside systems. We discuss what is needed for this support and show that trustworthy digital signatures can be created with a standard setup.\n\nWe suggest that by using smartcards, we can build complex systems where users with smartcards have important roles. Saying that a smartcard can be trusted opens new options for designers who focus on user needs. Since smartcards will remain important, finding useful ways to use them is a smart move.",
        "reference": "Smartcards lack the capability to communicate with the user in a secure manner, unlike other hardware classes. (Smart cards are small, portable devices that have a special chip inside. They can store and process information securely.) Without a way to keep the owner updated, it becomes challenging to take advantage of the useful features of smart cards. We look at how smart cards and powerful machines can be combined to make even better devices. We believe that Personal Digital Assistants (PDAs) are more useful than smartcards because they can extend the user's private sphere. PDAs have enough functionality and resources to create trustworthy digital signatures, which can speak for the user. A less resourceful machine can serve as a memory aid, assisting the owner in remembering addresses and phone numbers, such as [121]. These machines are designed to be tamper-resistant, making them suitable for a minimalistic purpose. To create trustworthy digital signatures, a smartcard needs support from infrastructure outside the card itself. This is because the user is not aware of what information is given to the card, making it impossible for the card to be trusted solely on its own. We investigate the necessary components of this infrastructure and show that reliable digital signatures can indeed be created using a standard method [211]. We propose that smartcards can be utilized to build nontrivial distributed systems, where smartcard holders are considered important participants or \"first class citizens\". Claiming that smartcards can function as trusted machines opens up fresh possibilities for designers focused on user-centric approaches. It is evident that smartcards are here to stay, so it is wise for designers to explore and implement them in meaningful ways."
      },
      {
        "source": "In this paper we present the main features of a system that we have developed and that provides a new kind of tele-assistance service to elderly people.apart from the functionalities offered by the current tele-assistance services, also provides a high quality, anywhere and at any time assistance. We rate the assistance as high quality because allows the monitoring of vital signs and a local detection of anomalous situations by the device that the person carries in real time. Therefore, it sends alarms autonomously when  this paper we :[84],\"explain the three main functionalities offered by AINGERU: universal assistance anywhere and at any time, monitoring of vital signs irrespective of location or time and remote monitoring by allowing authorized external persons to consult data about monitored persons using the Internet. Moreover we show how those functionalities are achieved by making use of PDAs (Personal Digital Assistant), wireless communication, Semantic Web, Web services and agent technologies.",
        "prediction": "In this paper, we describe a new system for tele-assistance for elderly people. This system offers better help than current services. It provides high-quality assistance anytime and anywhere. The system monitors vital signs and detects problems in real time. It can send alarms on its own. We explain three main features of AINGERU. First, it allows universal assistance anywhere and at any time. Second, it monitors vital signs regardless of location or time. Third, it enables remote monitoring so authorized people can check data online. We also explain how these features work using Personal Digital Assistants, wireless communication, the Semantic Web, Web services, and agent technologies.",
        "reference": "This paper introduces a new tele-assistance service for elderly people that goes beyond existing services by offering high-quality assistance anywhere and anytime. Our system provides high-quality assistance because it allows real-time monitoring of vital signs and local detection of anomalous situations through the device carried by the person. We explain the three main functions of AINGERU in this paper: universal assistance anywhere and at any time, monitoring vital signs regardless of location or time, and remote monitoring that allows authorized external individuals to access data about monitored persons via the internet. We use PDAs, wireless communication, Semantic Web (aims to enhance the World Wide Web by adding meaning to the information available online), Web services, and agent technologies to achieve the aforementioned functionalities."
      },
      {
        "source": "Objective: To evaluate the effectiveness of a personal digital assistant (PDA)âbased clinical decision support system (CDSS) on nonsteroidal anti-inflammatory drug (NSAID) prescribing safety in the outpatient  :[26],\"The design was a randomized, controlled trial conducted in a university-based resident clinic. Internal medicine residents received a PDA-based CDSS suite. For intervention residents, the CDSS included a prediction rule for NSAID-related gastrointestinal risk assessment and treatment recommendations. Unannounced standardized patients (SPs) trained to portray musculoskeletal symptoms presented to study physicians. Safety outcomes were assessed from the prescriptions given to the SPs. Each prescription was reviewed by a committee of clinicians blinded to participant, intervention group assignment, and baseline or follow-up  :[108],\"Prescriptions were judged as safe or unsafe. :[26],\"The main outcome measure was the differential change in unsafe prescribing of NSAIDs for the intervention versus the control  :[135],\"At baseline, the mean proportion of cases per physician with unsafe prescriptions for the two groups was similar (0.27 vs. 0.29, p u003e 0.05). Controlling for baseline performance, intervention participants prescribed more safely than controls after receiving the CDSS (0.23 vs. 0.45 [F = 4.24, p u003c 0.05]). With the CDSS, intervention participants documented more complete assessment of patient gastrointestinal risk from  :[198],\"Participants provided with a PDA-based CDSS for NSAID prescribing made fewer unsafe treatment decisions than participants without the CDSS.",
        "prediction": "Objective To check how well a PDA-based CDSS helps with the safe prescribing of NSAIDs in outpatient settings This study was a controlled trial in a university clinic Internal medicine residents used a PDA with CDSS The CDSS included rules for checking GI risks and giving treatment advice Trained standardized patients acted out musculoskeletal symptoms for the doctors Safety was measured by looking at the prescriptions given to these patients A group of doctors who did not know the participants or study details reviewed the prescriptions as safe or unsafe The main goal was to see the difference in unsafe NSAID prescribing between the two groups At the start the unsafe prescription rates were similar for both groups 027 vs 029 After using the CDSS the residents who had it prescribed more safely than those who did not 023 vs 045 The CDSS also helped them better assess patients' GI risks Residents using the PDA-based CDSS made fewer unsafe treatment choices than those without it",
        "reference": "We did a study to test if a clinical decision support system (CDSS) on a personal digital assistant (PDA) could improve the safety of prescribing nonsteroidal anti-inflammatory drugs (NSAIDs) in outpatient clinics. We conducted a randomized, controlled trial in a university-based resident clinic. Residents in internal medicine were given a CDSS suite based on PDA. Intervention residents were provided with a CDSS that had a prediction rule for assessing gastrointestinal risk related to NSAIDs and recommendations for treatment. Trained individuals, known as standardized patients (SPs), who were equipped with musculoskeletal symptoms, interacted with the physicians participating in the study without prior notification. The study evaluated the safety outcomes of prescriptions given to standardized patients portraying musculoskeletal symptoms. A committee of clinicians who didn't know about the participant, intervention group assignment, or the baseline or follow-up data reviewed each prescription. They determined whether a prescription was safe or unsafe. The study aimed to see if the PDA-based CDSS would result in a reduction of unsafe prescribing of NSAIDs. The main outcome measured the difference in unsafe prescribing between the intervention and control groups. At the beginning of the study, both groups had a similar proportion of unsafe prescriptions. (0.27 vs 0.29) After controlling for the baseline performance, it was found that those who received the CDSS suite prescribed nonsteroidal anti-inflammatory drugs more safely than those who didn't (0.23 vs 0.45, with statistical significance). Participants who had access to the CDSS through a PDA documented a more comprehensive assessment of gastrointestinal risk in patients. Moreover, the presence of the CDSS resulted in fewer unsafe treatment decisions compared to participants who did not have access to the CDSS."
      },
      {
        "source": "Recently pedestrian navigation has been studied by many researchers, which provides pedestrians with a similar function of car navigation. On the other hand, a 3dimensional (3D) map, which is one of major themes in machine vision research, has been utilized as a simulation tool in city and landscape planning, and other engineering fields. The 3D maps will give more intuitive information compared to conventional 2-dimensional (2D) ones. In this paper we first propose pedestrian navigation based on 3D maps, and describe technologies required and its use situations. Secondly we compare effectiveness of 2D and 3D maps for navigation by object search experiments under conditions: 3D maps with and without texture; display sizes corresponding to a mobile phone and PDA (Personal Digital Assistant). The experimental results show that 3D maps with texture on mobile phone display size, and 3D maps without texture on PDA display size are superior to 2D maps in search time and error rate. From these results, we can say the effectiveness of 3D maps in pedestrian navigation.",
        "prediction": "Recently, many researchers have studied pedestrian navigation. This helps people find their way like car navigation. A 3-dimensional (3D) map is an important tool in machine vision research. It is used for city planning, landscape planning, and other engineering areas. 3D maps give clearer information than regular 2-dimensional (2D) maps. In this paper, we first suggest using 3D maps for pedestrian navigation. We also explain the necessary technology and situations where it can be used. Next, we compare 2D and 3D maps for navigation. We did experiments to see which worked better. We tested 3D maps with and without texture, using sizes for mobile phones and PDAs. The results showed that 3D maps with texture on phone screens and 3D maps without texture on PDA screens worked better than 2D maps. They had shorter search times and fewer mistakes. This proves that 3D maps are effective for pedestrian navigation",
        "reference": "Recently many researchers have studied pedestrian navigation, which is similar to car navigation but designed for pedestrians. A 3D map is widely used in machine vision research and various engineering fields, such as city and landscape planning, as a simulation tool. 3D maps are more intuitive than 2D maps. In this paper, we suggest using 3D maps for pedestrian navigation and explain the necessary technology and possible scenarios for its application. We will conduct object search experiments to compare the effectiveness of 2D and 3D maps for navigation. The experiments will consider the following conditions: 3D maps with and without texture, and display sizes equivalent to a mobile phone and a Personal Digital Assistant (PDA). The results of the experiment suggest that 3D maps with texture on a mobile phone display and 3D maps without texture on a PDA display are better than 2D maps in terms of search time and error rate. Based on these results, we can conclude that 3D maps are effective for pedestrian navigation."
      },
      {
        "source": "Mobile agents are a competitive concept of client-server computing and are especially suitable in mobile environments, that are characterized by low bandwidth communication facilities and ad hoc connection/disconnection to stationary systems. They can be used for information retrieval and information filtering, in which case they evaluate replies and return only the relevant data. Mobile agents as a metaphor of active objects are created on a mobile device such as a Personal Digital Assistant (PDA), will be launched into the information galaxy and are fulfilling the mobile user âs task on the services available on networked stationary systems. One transmission channel for these itinerant agents is email. This paper introduces Active M 3 as an example of an active mail framework, which can be regarded as a first approach in authoring mobile agents in a graphical interactive manner. Active M 3 integrates two known concepts: active mail and multimedia mail.",
        "prediction": "Mobile agents are a new idea in client-server computing. They work well in mobile settings where internet speed is slow and connections can drop. Mobile agents help gather and filter information. They check answers and send back only what is important. These agents run on devices like Personal Digital Assistants (PDAs). They move through the information world to complete tasks using services on fixed systems. One way to communicate with these agents is through email. This paper talks about Active M3, which is an example of a system for creating mobile agents using a simple visual method. Active M3 combines two ideas: active mail and multimedia mail.",
        "reference": "Mobile agents are a competitive concept in client-server computing, particularly well-suited for mobile environments. These environments are characterized by limited bandwidth communication and the frequent connection and disconnection to stationary systems. They can be utilized for information retrieval and filtering, where they assess responses and provide only the pertinent data. Mobile agents act like active objects that can be created on a mobile device like a PDA. They are sent out to perform tasks on the networked stationary systems and fulfill the user's needs. Email serves as a transmission channel for these mobile agents. This paper presents Active M 3, which is an active mail framework that allows users to create mobile agents using a graphical interface. Active M3 is a framework that combines two concepts: active mail and multimedia mail."
      },
      {
        "source": "Digital Video Broadcasting â Handheld (DVB-H) is a technology developed as an extension of Digital Video Broadcasting â Terrestrial (DVB-T) with additional features that make it suitable for delivery to mobile devices such as phones and Personal Digital Assistant (PDAs). This paper deals with the conditions of receiving digital video broadcast type services in mobile handheld devices. The DVB-H standard is introduced and the key technology elements on data link layer and physical layer are discussed in some details. Finally the DVB-H terminal and network design is described.",
        "prediction": "Digital Video Broadcasting - Handheld (DVB-H) is a technology that comes from Digital Video Broadcasting - Terrestrial (DVB-T). It has extra features that make it good for mobile devices like phones and PDAs. This paper looks at how to receive digital video broadcasts on handheld devices. It introduces the DVB-H standard and explains important parts of the data link layer and physical layer. Lastly, it describes the design of DVB-H terminals and networks.",
        "reference": "DVB-H is a technology based on DVB-T that is designed for delivering content to mobile devices like phones and PDAs. This paper discusses how digital video broadcast services can be received on mobile handheld devices. The introduction of the DVB-H standard includes a discussion of key technology elements on the data link layer and physical layer, providing some detailed information. This paper also covers the design of DVB-H terminals and networks."
      },
      {
        "source": "Summary form only given, as follows. We present a design for a low cost but powerful and high speed communications device powered by IDTu0027s RV4640 as its processing engine. The device can achieve very high speed, thanks to the PCI bus compatible IDT ATM NIC. The device could be used as a two way pager, a set-top box, an Internet terminal, a personal digital assistant or as a video phone. The RV4640 is a very affordable 64 bit RISC processor that executes 175 dhrystone MIPS at 133 MHz. The RV4640 can be connected to a System Interface Chip which will provide I/O and memory control. The IDT77903 ATM card is a full duplexed 25 Mbps NIC with a PCI bus interface and it costs less than $100 (US). Integrating this card into our device as a network interface will make highspeed videoconferencing and multimedia applications easily implementable.",
        "prediction": "We present a design for a low-cost, fast communication device. It uses IDT's RV4640 processor. This device can work at high speed because of the compatible IDT ATM NIC. It can be a two-way pager, set-top box, Internet terminal, personal digital assistant, or video phone. The RV4640 is an affordable 64-bit RISC processor. It runs at 133 MHz and has a speed of 175 dhrystone MIPS. It can connect to a System Interface Chip for I/O and memory control. The IDT77903 ATM card is a full-duplex 25 Mbps NIC with a PCI bus interface and costs under $100. Adding this card allows for fast videoconferencing and multimedia use.",
        "reference": "Summary provided in the following. We propose a low-cost and high-speed communication device that uses IDT's RV4640 as the processing engine. This device is designed with IDT's RV4640 as the processing engine and can achieve high speed due to the PCI bus (a type of computer bus that simplifies the communication between computer components by providing a standardized interface) compatible IDT ATM NIC. This device can serve multiple purposes such as a two-way pager, set-top box, Internet terminal, personal digital assistant, or video phone. The RV4640 is a low-cost 64-bit RISC processor that runs at 133 MHz and can execute 175 dhrystone MIPS. The RV4640 can connect to a System Interface Chip for I/O (a specialized integrated circuit designed to facilitate communication between a computer system and its external devices) and memory control. The IDT77903 ATM card, which costs less than $100 (US), is a NIC with a PCI bus interface that is capable of full duplexing at 25 Mbps. Using the IDT77903 ATM card as a network interface in our device will make it easy to implement high-speed videoconferencing and multimedia applications."
      },
      {
        "source": "Dr. Who is a Microsoft research project aiming at creating a speech-centric multimodal interaction framework, which serves as the foundation for the NET natural user interface. The paper discusses MiPadu0027s design, implementation work in progress, and preliminary user study in comparison to the existing pen-based PDA interface. MiPad is the application prototype that demonstrates compelling user advantages for wireless personal digital assistant (PDA) devices, MiPad fully integrates continuous speech recognition (CSR) and spoken language understanding (SLU) to enable users to accomplish many common tasks using a multimodal interface and wireless technologies. It tries to solve the problem of pecking with tiny styluses or typing on minuscule keyboards in todayu0027s PDAs. Unlike a cellular phone, MiPad avoids speech-only interaction. It incorporates a built-in microphone that activates whenever a field is selected. As a user taps the screen or uses a built in roller to navigate, the tapping action narrows the number of possible instructions for spoken word understanding. MiPad currently runs on a Windows CE Pocket PC with a Windows 2000 machine where speech recognition is performed. The Dr Who CSR engine uses a unified CFG and n-gram language model. The Dr Who SLU engine is based on a robust chart parser and a plan-based dialog manager.",
        "prediction": "Dr. Who is a Microsoft project that aims to create a speech-based way for users to interact with devices. This project is important for the NET natural user interface. The paper talks about the MiPad design, its development, and a user study compared to older pen-based PDA interfaces. MiPad is a prototype application that shows clear benefits for wireless personal digital assistants. It uses continuous speech recognition and spoken language understanding to help users perform many common tasks easily. MiPad tries to fix issues with small styluses and tiny keyboards found in todayâs PDAs. Instead of just using speech like a phone, MiPad has a microphone that turns on when the user selects a field. When users tap the screen or use a roller to move around, it makes it easier for the system to understand spoken commands. MiPad works on a Windows CE Pocket PC with speech recognition done on a Windows 2000 computer. The Dr. Who speech recognition engine uses a combined CFG and n-gram language model. The speech understanding engine uses a strong chart parser and a dialog manager based on plans.",
        "reference": "Dr. Who is a Microsoft research project that aims to create a speech-focused system for interacting with technology. This system will serve as the foundation for a natural user interface called NET. The paper discusses MiPad's design and implementation, which are still in progress, as well as a preliminary user study comparing it to existing pen-based PDA interfaces. MiPad is a prototype application that shows how wireless personal digital assistants (PDAs) can benefit from integrating continuous speech recognition (CSR) and spoken language understanding (SLU) technologies. This allows users to perform common tasks using a multimodal interface and wireless technology. It aims to solve the issue of having to use small styluses or type on tiny keyboards on modern PDAs. MiPad does not rely solely on speech interaction, unlike a cellular phone. MiPad has a built-in microphone that turns on when a field is selected. When a user taps the screen or utilizes a built-in roller for navigation, this action reduces the range of potential instructions for spoken word comprehension. MiPad is currently operating on a Windows CE Pocket PC, with speech recognition being carried out on a Windows 2000 machine. The Windows CE Pocket PC is a PDA that runs the Windows Embedded Compact operating system. The Dr Who CSR engine combines a CFG and an n-gram language model. The Dr Who SLU engine uses a chart parser and a plan-based dialog manager."
      },
      {
        "source": "Little is known about how viable new mobile applications emerge in complex commercial environments. Research in the sociology of technology suggests that the evolution of new applications is a process of social interaction between multiple constituencies, aiming to create a common definition of mobile technology problems and solutions that is obvious only in retrospect. This theory is illustrated by the early evolution of the personal digital assistant (PDA). According to this view, established technological communities attempt to impose their own definitions of key problems and solutions on new mobile technology, thereby forcing newer players to provide a \"total system\" that completely redefines a new application area.",
        "prediction": "We do not know much about how new mobile apps develop in complex business settings. Research in the sociology of technology shows that new apps evolve through social interactions among many groups. These groups work to define mobile technology problems and solutions, but this is often clear only after it happens. This idea is shown through the early development of personal digital assistants (PDAs). Established tech groups try to impose their views on the problems and solutions in new mobile tech. This pressure makes new developers create a complete system that changes the field for new apps.",
        "reference": "We don't know much about how new mobile apps succeed in complicated business environments. Research in the sociology of technology indicates that the development of new applications involves social interaction among different groups. These groups work together to establish a shared understanding of mobile technology challenges and solutions, which often becomes clear only in hindsight. The PDA's early evolution exemplifies this theory. This idea suggests that existing technology groups try to define the problems and solutions for new mobile tech, which puts pressure on new players to create a total system that redefines the application area."
      },
      {
        "source": "In the ubiquitous environment, mobile terminals like personal digital assistant or cellular phone are used to access the Web. We implemented the procedures in a ubiquitous/universal passive viewer (u-PaV) system that transforms Web content into passive viewing content that is especially useful for mobile terminals. Extracting images and text from Web content, u-PaV generates a Macromedia Flash file, which is a popular multimedia format. Although the presentation of Web content depends on the terminal type, the Web interface of mobile terminals is designed almost the same as that of personal computers. However, comparing mobile and desktop terminals, some difference in device characteristics, such as screen resolution or sound faithfulness, affect the presentation on the terminal. Moreover, when changing the access style between interactive and passive, the presentation should be adjusted for the terminal type because the lacking information is usually not perceived after transformation. To adjust the play style of Web content to the terminal type, we developed a method for visual presentation. First, using keyword analysis, we represent the emotional aspect of a Web page by adjusting the background color of the screen. Second, we emphasize the subject of the content by the logotype of the keyword. Third, we segment the picture of the content into pieces and present one after another using visual effects. These procedures can be applied to any type of terminal.",
        "prediction": "In a common environment, mobile devices like smartphones and tablets are used to access the Web. We created a system called u-PaV that changes Web content into a format suitable for mobile viewing. This system takes images and text from the Web and makes a Macromedia Flash file, which is a well-known multimedia format. While the way Web content looks can vary by device, mobile and desktop interfaces are often similar. However, differences like screen size and sound quality can change the presentation on each device. When switching between interactive and passive viewing, the content needs to be adjusted because some information may be lost. To improve how Web content looks on different devices, we developed a method for visual presentation. First, we use keyword analysis to show the emotional tone of a Web page by changing the background color. Second, we highlight important words using bold text. Third, we break images into parts and show them one at a time with visual effects. These methods work on any type of device.",
        "reference": "In the ubiquitous environment, devices like personal digital assistants or cell phones are used to access the Internet. We created a system called ubiquitous/universal passive viewer (u-PaV) that converts Web content into a format suitable for easy viewing on mobile devices. u-PaV takes text and images from the Web and creates a multimedia file in Macromedia Flash format, a widely used multimedia format. Mobile devices and personal computers have similar Web interfaces, although they may look different depending on the device. Mobile and desktop terminals have some differences in device characteristics, such as screen resolution and sound quality, which can affect how content is presented on the device. When switching between interactive and passive access styles, the presentation needs to be adjusted for the device type because some information may be lost during transformation and not noticed by the user. We developed a visual presentation method to customize how Web content is displayed based on the device type. First, we analyze keywords to capture the emotional tone of a web page and adjust the screen's background color accordingly. Then, we use the keyword's logo to highlight the main subject of the content. Finally, we divide the content's image into sections and present them one by one using visual effects. These steps can be used on any type of device."
      },
      {
        "source": "We have developed two-way location aware system, named as âThe Beijing Explorerâ, which exchanged positioning information and usersâ situation to one another using a PDA (Personal Digital Assistant) with built-in wireless LAN and a GPS (Global Positioning System) receiver in real time. Users can see their position and their chats on the screen of a PDA using the system real-timely. The system was used for the guidance of the Palace Museum (Forbidden City) in Beijing, China. We carried on experiments two times using the system. The results of experiments show that the service using positioning data and sharing contents were valuable and interesting. The correct positioning information is important for the guidance system.",
        "prediction": "We created a two-way location aware system called âThe Beijing Explorer.â It shares positioning information and usersâ situations with each other. It uses a PDA with wireless LAN and GPS in real time. Users can see their location and chat messages on the PDA screen. The system was tested in the Palace Museum in Beijing, China. We did two experiments with the system. The results showed that using positioning data and sharing content is valuable and interesting. Correct positioning information is key for the guidance system.",
        "reference": "We created a location-aware system called \"The Beijing Explorer\" that uses a PDA with wireless LAN and GPS to exchange positioning and user information in real-time. Users can view their position and chats in real-time on the PDA screen when using the system. The system was used to guide visitors at the Palace Museum (Forbidden City) in Beijing, China. We conducted two experiments using the system. The experiment results indicate that the service was useful and engaging because it shared positioning data and content. Accurate positioning information is crucial for the guidance system."
      },
      {
        "source": "A truly personal machine, called a private machine and implemented as a Personal Digital Assistant (PDA), is fundamentally different from traditional machines. It is personal and private in an unprecedented manner, and its modus operandi is such that network and power failures will not be rare. Designing distributed systems where PDAs are treated as \"first class citizens\" is a  private :[59],\"assets (electronic money, keys for authentication and opening doors) will be stored in PDAs. Ownership and control of these :[59],\"assets and the media that store and communicate them should remain with the user. This must be reflected in the design of systems for private  :[105],\"introduce the \"open-ended argument\" to describe the design strategy we used for designing a system that is designed to reveal information to the user (as opposed to hide it). We argue and show that when systems are designed this way, the user (a human) is better able to control the system and his personal data, as he can make better decisions than the system itself based on qualitative assessment of the provided information. The system we have designed and implemented under this design guidelines is presented and discussed.",
        "prediction": "A private machine, known as a Personal Digital Assistant (PDA), is very different from regular machines. It is personal and private in a new way. This type of machine can face problems like network and power failures. \n\nWhen we design systems, we should treat PDAs as important. These PDAs will store valuable things like electronic money and keys for access. Users should own and control these important items and the methods for storing and sharing them. This is important in the design of private systems.\n\nWe introduce the \"open-ended argument\" as our design strategy. This means we create systems that show information to the user instead of hiding it. We believe that when systems are made like this, users can control their data better. They can make smarter choices than the system can by using the information given to them.\n\nWe discuss the system we designed and built based on these guidelines.",
        "reference": "A Personal Digital Assistant (PDA) used as a private machine, is fundamentally distinct from traditional machines because it is a personalized device. It offers an unprecedented level of personal and private experience, and its operation is designed to handle network and power failures, which are expected to occur frequently. In designing distributed systems, PDAs are given high importance and treated as \"first class citizens\". This means that important assets like electronic money and authentication keys will be stored in PDAs. The user should retain ownership and control of these assets and the media that stores and communicates them. This principle should be incorporated into the design of private systems. We introduced the concept of the \"open-ended argument\" to describe our design strategy, which focuses on creating systems that are intended to provide information to the user rather than hiding it. We argue and demonstrate that when systems are designed in this manner, the user (a human) gains improved control over both the system and their personal data. By enabling users to make decisions based on qualitative assessment of the information provided, they are better equipped to make informed choices compared to relying solely on the system's automated decisions. We have created a system based on the design guidelines and we will explain it."
      },
      {
        "source": "Depression is under recognized in a variety of pediatric settings. The purpose of this paper is to describe the development and initial evaluation of a personal digital assistant (PDA)-based decision support system (DSS) for pediatric depression screening in ages 8 to 18 years of age by pediatric advanced practice nurse (APN) students. Three aspects are described: selection of depression screening instrument; integration of the instrument into the PDA; and quantitative (usage) and qualitative (focus group) evaluation. Only one third of eligible patients were screened. Twenty percent of those screened were identified as at risk for mood disorder. The barriers to screening identified through focus groups included a lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor motivation and comfort, as well as perceived or real cultural barriers. Suggestions for educational, research, and interventions to integrate clinical based PDA-based screening are discussed.",
        "prediction": "Depression is not often recognized in kids. This paper talks about creating and testing a digital tool to help check for depression in children aged 8 to 18. This tool is designed for pediatric nurse students. The paper covers three main points: choosing a depression screening tool, adding it to the digital tool, and evaluating how it works through usage data and focus groups. Only one-third of the kids who could be checked were actually screened. Twenty percent of those screened were found to be at risk for mood disorders. Focus group findings showed barriers to screening like lack of time, knowledge, protocols, referrals, usability issues, motivation from mentors, and cultural barriers. The paper also offers ideas for education, research, and ways to improve screening with the digital tool.",
        "reference": "Depression often goes unnoticed in many pediatric settings. This paper aims to explain the creation and early assessment of a decision support system (DSS) that uses personal digital assistants (PDAs) for screening pediatric depression among children aged 8 to 18 years, carried out by pediatric advanced practice nurse (APN) students. Three aspects are discussed: choosing a depression screening tool, incorporating the tool into the PDA, and evaluating it through quantitative (usage) and qualitative (focus group) assessments. Only one third of eligible patients were screened. 20% of the screened patients were found to be at risk for a mood disorder. Barriers to screening were identified through focus groups, including lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor motivation and comfort, and cultural barriers. The paper discusses suggestions for integrating PDA-based screening into clinical practice through education, research, and interventions."
      },
      {
        "source": "This study explored the potential of the application of wireless and mobile computing technologies to be used in improving the efficiency of patient care and education and future developments in information and communication technologies to support healthcare professionals and medical students in healthcare research, medical education and training. The design used for this study was a systematic review of published materials obtained from EMBASE and MEDLINE online databases, and the Cochrane Library database, including personal observations. Today, more than 50% of healthcare professionals and medical students are using Personal Digital Assistant with expected growth of more than 75% by year-end 2007. In addition, wireless and mobile computing technologies allows Personal Digital Assistant to connect directly to networks or the Internet. Studies relating to processes of patient care and should evaluate mobile computing technologies as a potential timesaving tool. Wireless and mobile computing technologies is only beginning to take its first step in improving patient care and education. They have shown a positive impact on patient safety, health care efficiency, and ultimately patient satisfaction.",
        "prediction": "This study looked at how wireless and mobile computing can help improve patient care and education. It also examined future tools that can support healthcare workers and medical students in research and training. The study used a systematic review of published materials from EMBASE, MEDLINE, and the Cochrane Library, along with personal observations. More than 50% of healthcare workers and medical students used Personal Digital Assistants by 2007, and this number was expected to grow to over 75%. Wireless and mobile computing lets these devices connect to networks and the Internet. Research shows that mobile technology can save time in patient care. Wireless and mobile computing is just starting to improve patient care and education. It has already shown positive effects on patient safety, healthcare efficiency, and patient satisfaction.",
        "reference": "This study examined how wireless and mobile computing technologies can enhance patient care and education. It also explored how advancements in information and communication technologies can support healthcare professionals and medical students in research, education, and training. We conducted a systematic review for this study, analyzing published materials from databases such as EMBASE, MEDLINE, and the Cochrane Library, as well as personal observations. Over 50% of healthcare professionals and medical students currently use Personal Digital Assistants, and this number is expected to grow by more than 75% by the end of 2007. Wireless and mobile computing technologies enable Personal Digital Assistants to connect directly to networks or the Internet. Studies should examine whether mobile computing technologies can save time in patient care processes. Wireless and mobile computing technologies are still in the early stages of improving patient care and education. These technologies have positively impacted patient safety, healthcare efficiency, and patient satisfaction."
      },
      {
        "source": "Nursing students can learn many things through practical training by experiencing actual medical practice and by coming in contact with patients. Therefore practical training is an effective learning opportunity for developing the practical nursing care ability of nursing students. Moreover, at hospitals, which are important training facilities, with regard to medical safety, the use of learning tools that produce electrical waves is not possible. So, we created a learning support environment that facilitates the imagination of nursing techniques, and enables effective preparation, review, and learning at anytime and anywhere using a portable digital assistant (PDA) device for practical training. As described in this paper, we report on the outline of the educational materials named \"digital nursing dictionary\" that we developed and the evaluation of the practices using it.",
        "prediction": "Nursing students learn a lot through hands-on training with real patients. This training helps them build their nursing skills. Hospitals are key places for this training. For safety reasons, they cannot use tools that create electrical waves. To support learning, we created a system that helps students imagine nursing techniques. This system allows students to prepare, review, and learn anytime and anywhere with a portable digital assistant device. This paper talks about the \"digital nursing dictionary\" we developed and how it was evaluated in practice.",
        "reference": "Nursing students can learn through practical training and by interacting with patients in real medical settings. Practical training is effective for developing the practical nursing care ability of nursing students. Moreover, hospitals, which are important training facilities, do not allow the use of learning tools that produce electrical waves due to medical safety concerns. We developed a learning support environment that helps nursing students visualize and practice techniques. It allows for convenient preparation, review, and learning using a portable digital assistant (PDA) device, enabling anytime and anywhere practical training. We developed an educational tool called the 'digital nursing dictionary' and evaluated its effectiveness, as outlined in this paper."
      },
      {
        "source": "Limitation in display size and resolution on mobile devices is one of the main obstacles for wide-spread use of web applications in a wireless environment. Web pages are often too large for a PDA (Personal Digital Assistant) screen to present. The same problem exists for devices with low resolution such as WebTV. Manual reconstruction of web pages for these devices would ease the problem; however, the large variation of display capabilities will greatly increase the burden of web page designers since they have to customize a web page for each possible display device. In this paper, we propose a document segmentation and presentation system. The system automatically divides a web document into a number of logical segments based on the screen size and the structure and content of the document. Additional information such as overviews and summaries is also extracted to facilitate navigation. The system presents the segments and structural information of a web document to make full use of the screen for information finding.",
        "prediction": "Mobile devices have small screens and low resolution. This makes it hard to use web applications easily. Web pages are often too big for devices like PDAs. Devices with low resolution, like WebTV, have the same issue. Rebuilding web pages for every device would help, but designers would need to create many versions for each screen type. In this paper, we suggest a new system. This system breaks a web document into smaller parts based on screen size and the document's structure. It also gathers key information like summaries to help users. The system shows these parts and information clearly, making it easier to find what you need.",
        "reference": "Small screens and low resolutions on mobile devices are a major obstacle for the widespread adoption of web applications in a wireless environment. PDA screens are often too small to display entire web pages. Low-resolution devices like WebTV face the same problem. Manually reconstructing web pages for these devices would help, but the wide range of display capabilities would make it challenging for web page designers as they would have to customize each web page for every possible display device, increasing their workload. This paper suggests a system for segmenting and presenting documents. The system divides a web document into logical segments automatically, using information about the screen size, document structure, and content. The system also extracts summaries and overviews to make navigation easier. The system optimizes the use of the screen for information finding by showing the segments and structure of a web document."
      },
      {
        "source": "Take 8-bit microcontroller (C8051F005) as the nucleus and study a kind of voltage harmonic monitor device that satisfies the long-range monitor. The harmonic analysis algorithm adopts Fast Fourier Transform (FFT). This device has two work modes: ânativeâ and âremoteâ. It also can communicate with monitor center through telephone line, serial port, IC card, PDA (Personal Digital Assistant), etc.",
        "prediction": "Study an 8-bit microcontroller called C8051F005. It helps create a voltage harmonic monitor for long-range use. The device uses a Fast Fourier Transform (FFT) for harmonic analysis. It has two modes: native and remote. It can connect to a monitor center through phone lines, serial ports, IC cards, or PDAs.",
        "reference": "Study a voltage harmonic monitor device for long-range monitoring using the 8-bit microcontroller C8051F005 as the core. The harmonic analysis uses FFT. The device has two modes: \"native\" and \"remote\". It can communicate with a monitoring center via different methods such as telephone line, serial port, IC card, and PDA (Personal Digital Assistant)."
      },
      {
        "source": "With network and small screen device improvements, such as wireless abilities, increased memory and CPU speeds, users are no longer limited by location when accessing on-line information. We are interested in studying the effect of users switching from a large screen device, such as a desktop or laptop to use the same web page on a small device, in this case a PDA (Personal Digital Assistant). We discuss three common transformation approaches for display of web pages on the small screen: Direct Migration, Linear and Overview. We introduce a new Overview method, called the Gateway, for use on the small screen that exploits a userâs familiarity of a web page. The users in an initial study prefer using the Gateway and Direct Migration approach for web pages previously used on the large screen, despite the common Linear approach used by many web sites.",
        "prediction": "With better networks and small devices like phones, users can access online information anywhere. We want to study what happens when users switch from large screens, like desktops or laptops, to small ones, like PDAs. We look at three ways to show web pages on small screens: Direct Migration, Linear, and Overview. We introduce a new Overview method called the Gateway that helps users use web pages they already know. In an early study, users preferred the Gateway and Direct Migration for pages they had used on large screens, even though many sites use the common Linear method.",
        "reference": "Improvements in network and small-screen devices, such as wireless capabilities, faster CPU speeds, and increased memory, have eliminated location restrictions for accessing online information. We want to study the impact of users switching from a desktop or laptop to a PDA (Personal Digital Assistant) when accessing the same web page. We are looking at three common ways to display web pages on small screens: Direct Migration, Linear, and Overview. Gateway is our new Overview method for small screens that use the user's familiarity with a web page. Many websites use the Linear method, but an initial study showed that users prefer using the Gateway and the Direct Migration method for web pages."
      },
      {
        "source": "The limitations and constraints of mobile systems need to be adequately addressed in software development. We have been developing a taxonomy of risks based on SEIu0027s risk questionnaire and applied it during the development of a negotiation support system for a Personal Digital Assistant (PDA). In our planned research, we will explore how we can better integrate existing risk management strategies and Agile Methods (AM).",
        "prediction": "Mobile systems have limitations that need attention in software development. We created a list of risks using SEI's risk questionnaire. We used it while developing a negotiation support system for a Personal Digital Assistant (PDA). In our research, we will look into how to better combine existing risk management strategies with Agile Methods (AM)",
        "reference": "During software development, restrictions due to mobile systems need to be addressed. Based on SEI's risk questionnaire, we developed a classification of risks and applied it while developing a negotiation support system for a PDA. Risk management strategies and Agile Methods and how we can integrate them better will be studied in our future research."
      },
      {
        "source": "Expansions of mobile services and private data have required increased level of protection. Speaker recognition, one of the biometric technologies, arises lots of research interests for its simple, cheap and convenient characteristics. In this paper, a robust speaker recognition system which facilitates reliable authentication with multi-channel voices is presented. A large multi-channel corpus, including mobile phone, personal digital assistant (PDA), telephone and microphone, is collected to evaluate the system performance.",
        "prediction": "Mobile services and private data need more protection. Speaker recognition is a type of biometric technology that is popular. It is simple, cheap, and easy to use. This paper presents a strong speaker recognition system. It helps with reliable authentication using different voices. A large collection of voices from mobile phones, PDAs, telephones, and microphones is used to test how well the system works.",
        "reference": "The growth of mobile services and private data necessitates higher levels of protection. Speaker recognition, a technology using the voice of users to identify them, leads to a lot of research interest because of its simple, cheap, and convenient characteristics. This work presents a powerful speaker recognition system that makes the authentification with multi-channel voices easier. Data are collected on mobile phones, PDAs, telephones, and microphones to evaluate the system's performance."
      },
      {
        "source": "This paper presents a method to generate unique and nevertheless highly random pseudonyms in a distributed environment. More precisely, each user can now generate his pseudonym locally in his personal security environment, e.g. in his smart card or his personal digital assistant. There is no need for any information interchange between issuing parties or global data (especially keys), except unique identifiers for each user and each device of the system. Additionally the holder can prove, that he generated a specific pseudonym without revealing his identity and he can reveal his identity by disclosing the pseudonym. Whereas the verifier of a disclosed pseudonym can be sure, that the presenter of the pseudonym is the holder of the pseudonym (i.e. the person which originally generated it). The identifier of the user and the identifier of the useru0027s device will be used to generate unique pseudonyms, but to ensure pseudonymity, both components will be stored in the pseudonym in encrypted form.",
        "prediction": "This paper shows a way to make unique and random pseudonyms. Each user can create their pseudonym in their own secure place, like a smart card or a personal digital assistant. No need to share information between different parties or use global data, except for unique IDs for each user and device. The user can prove they made a pseudonym without showing their identity and can reveal their identity by sharing the pseudonym. When someone shows a pseudonym, the verifier knows they are the true holder of that pseudonym. The user's ID and device ID help create unique pseudonyms, but to keep them private, both IDs are stored in the pseudonym as encrypted data.",
        "reference": "This work presents a method to generate unique and random pseudonyms in a distributed system. Every user can now create his pseudonym locally in their own personal security environment, e.g. in his chip card or PDA. No information exchange is required between issuing parties or global data, except for unique identifiers for each user and device in the system. The holder can also prove that he generated a distinct pseudonym without revealing his identity; by divulging it, he can reveal his identity. In that case, the verifier of a divulgated pseudonym can be sure that the one who presents the pseudonym is holding it. (i.e. the person that originally created it) The user identifier and device's identifier will be used to create unique pseudonyms but to ensure anonymity with pseudonyms, both identifiers will be stored within the pseudonym in encrypted form."
      },
      {
        "source": "In todayu0027s mobile information society, location-based services play an increasingly important role. These services are to be accessed by users with a mobile end device for the use of city maps, route planning, navigation, or traffic information. Mobile end devices, however, do not have computing power or storage capacity comparable to that of a personal computer or laptop. These deficits can be bypassed by employing special methods in development of the respective applications. This paper outlines the experience gained in the development of a prototype for route computation in public transport networks to be used on a personal digital assistant. Subdivision of the route computation process into various steps for minimizing the computation expenditure on the mobile end device plays a significant role.",
        "prediction": "In todayâs world, location-based services are very important. Users access these services on mobile devices for city maps, route planning, navigation, and traffic info. However, mobile devices do not have the same power or storage as personal computers or laptops. Developers can use special methods to solve this issue. This paper shares the experience of creating a prototype for route planning in public transport. Breaking down the route planning process into steps helps reduce the work needed on mobile devices.",
        "reference": "Location-based service's role in today's mobile information society is increasing . Users can access city maps, route planning, navigation, or traffic information with their mobile devices. Compared to laptops or personal computers, mobile devices do not have the same computing power or storage capacity. This shortage can be overcome by using specific methods during the development of the respective application. This paper shows the gained experience from developing a prototype designed for a PDA that calculates routes in public transport networks. Dividing the route computation process into multiple steps to reduce the computational load on the mobile device is crucial."
      },
      {
        "source": "DIANE is a digital assistant system that aims to fasten the doctor access to various informations at the hospital such as health care facility, medical records, and also human resource data. The fasten access could be achieved by implementing face recognition and live streaming as part of the digital assistant system.",
        "prediction": "DIANE is a digital assistant system. It helps doctors access important information in the hospital. This includes health care facilities, medical records, and human resource data. DIANE uses face recognition and live streaming to make access faster.",
        "reference": "DIANE is a digital assistant system that allows the doctor a faster access patient and hospital information. This could be done with face recognition and live streaming."
      },
      {
        "source": "Digital assistants are emerging to become more prevalent in our daily lives. In interacting with these assistants, users may engage in multiple tasks within a short period of time.",
        "prediction": "Digital assistants are becoming more common in our daily lives. Users can do many tasks quickly when using these assistants",
        "reference": "Digital assistants are becoming popular in our daily lives. It will allow users to do multiple tasks in a faster way."
      },
      {
        "source": "As extensive experimental research has shown individuals suffer from diverse biases in decision-making. In our paper we analyze the effects of decision-making biases of managers in collaborative decision processes on organizational performance. In the simulations, managerial decisions which are based on different levels of organizational complexity and different incentive systems suffer from biases known from descriptive decision theory. The results illustrate how biases in combination with each other and in different organizational contexts affect organizational performance. We find that, contrary to intuition, some combinations of biases significantly improve organizational performance while these biases negatively affect organizational performance when they occur separately. This might evoke considerations whether decision-making should be as rational as possible.",
        "prediction": "Research shows that people often have biases when making decisions. In this paper, we look at how these biases affect managers working together and the performance of their organizations. Our simulations show that managerial decisions are influenced by the complexity of the organization and its incentive systems, which lead to known biases. The results reveal that biases can interact with each other in different organizational settings and impact performance. Surprisingly, some pairs of biases can actually improve how well an organization performs, while other biases hurt performance when they act alone. This raises questions about how rational decision-making should be.",
        "reference": "Research showed that people suffer from diverse biases (disproportionate weight in favor of or against an idea) in decision-making. We analyzed the effects of decision-making biases of managers on organizational performance. In the simulations, managers decisions which are based on organizational skills and rules, suffer from several known biases. The results illustrate how combined biases in different contexts affect organizational performance. Contrary to expectations, some combinations of biases improve organizational performance. However, when they occur separately, they decrease performance. This raises questions about the importance of rationality in decision-making."
      },
      {
        "source": "Big data, the enhanced ability to collect, store and analyze previously unimaginable quantities of data in tremendous speed and with negligible costs, delivers immense benefits in marketing efficiency, healthcare, environmental protection, national security and more. The central tenets of the current privacy framework, the principles of data minimization and purpose limitation, are severely strained by the big data technological and business reality. As we increasingly interact with these artificial agents in unsupervised settings, with no human mediators, their seeming autonomy and increasingly sophisticated functionality and behavior, raises legal and philosophical questions. The focus on the machine is a distraction from the debate surrounding data driven ethical dilemmas, such as privacy, fairness and discrimination. The machine may exacerbate, enable, or simply draw attention to the ethical challenges, but it is humans who must be held accountable. Policymakers should seek to devise agreed-upon guidelines for ethical data analysis and profiling. Such guidelines would address the use of legal and technical mechanisms to obfuscate data; criteria for calling out unethical, if not illegal, behavior; categories of privacy and non-privacy harms; and strategies for empowering individuals through access to data in intelligible form.",
        "prediction": "Big data means we can collect, store, and analyze huge amounts of data very quickly and at low cost. This brings great benefits to areas like marketing, healthcare, environmental protection, and national security. Right now, our privacy rules about collecting only what we need and using it for a specific purpose are challenged by big data technology. As we interact more with machines without human help, their advanced behavior raises legal and ethical questions. Focusing too much on machines distracts us from real issues like privacy, fairness, and discrimination. Machines can highlight or worsen these problems, but humans are responsible for fixing them. Policymakers need to create clear guidelines for ethical data analysis. These guidelines should include rules for protecting data, identifying unethical actions, understanding privacy harms, and helping people access their data in a clear way.",
        "reference": "Big data (the ability to collect, store and analyze huge quantities of data in a really fast and cheap way) offers immense benefits in marketing, healthcare, environment, national security and more. The principles of privacy, limitation of data collection and use are stretched by the business and technological reality of big data. Our increasing interactions with these technologies without human supervision, and their growing autonomy, functionality and behavior raises legal and philosophical questions. The focus on the machine is a distraction from the debate on ethical dilemmas about data like privacy, fairness and discrimination. The machine may influence the ethical challenges, but the humans must remain responsible. Responsible people should find guidelines for ethical data analysis and collection. These guidelines would deal with mechanisms to protect data, criteria about unethical or illegal behavior, privacy harms, and strategies to give people access to data."
      },
      {
        "source": "Amazon's Echo, and Apple's Siri have drawn attention from different user groups; however, these existing commercial VUIs support limited language options for users including native English speakers and non-native English speakers. we conducted a usability study of the Google Home Smart Speaker with 20 participants including native English and non-native English speakers to understand their differences in using the Google Home Smart Speaker. The findings show that compared with their counterparts, the native English speakers had better and more positive user experiences in interacting with the device. It also shows that users' English language proficiency plays an important role in interacting with VUIs. The findings from this study can create insights for VUI designers and developers for implementing multiple language options and better voice recognition algorithms in VUIs for different user groups across the world.",
        "prediction": "Amazon's Echo and Apple's Siri are popular with different users. However, these voice user interfaces (VUIs) have limited language options. This study looked at the Google Home Smart Speaker with 20 participants. These participants included native and non-native English speakers. The results showed that native English speakers had better experiences using the Google Home. The study also found that how well users speak English affects their interaction with VUIs. These findings can help designers and developers add more language options and improve voice recognition for different users worldwide.",
        "reference": "The VUIs (voice user interface) like Amazonâs Echo or Appleâs Siri are popular nowadays. However, they have limited language options for users. We studied the usability of the Google Home Smart Speaker with native and non-native English speakers to understand their differences in using this device. The results show that the native English speakers had a better experience with the device than the non-native. It also shows that language skills play an important role. The results of this study can help VUI developers for improving language options and voice recognition in the devices."
      },
      {
        "source": "the smart speakers cannot distinguish human voice from machine voice. a method to identify which of human or machine is sending voice commands to a smart speaker is desired. to prevent such machine-voice based attacks to a smart speaker in absence of residents, we propose a system consisting of a speaker and a microphone array to detect the existence of a human nearby, supposing it can be incorporated in a smart speaker in the future.",
        "prediction": "Smart speakers canât tell the difference between human voices and machine voices. We want a way to find out if a human or a machine is giving voice commands to a smart speaker. To stop machine voice attacks when no one is at home, we suggest a system. This system would have a speaker and a microphone array to detect if a human is nearby. We hope this can be used in smart speakers in the future.",
        "reference": "The smart speakers cannot differentiate between human voice and machine voice. A method to identify if the voice command is from a human or a machine is required. We propose a system composed of a speaker and microphones to detect the presence of humans. It could help to prevent attacks on a smart speaker with a machine voice in absence of residents"
      },
      {
        "source": "As smart speakers with voice interaction capability permeate continuously in the world, more and more people will gradually get used to the new interaction mediumâvoice. Although speech recognition, natural language processing (NLP) have been greatly improved over the past few years, users still may encounter errors from time to time like âcannot understandâ, âno requested audio resource (such as music)â, which can frustrate users. Therefore, when an error message is reported, it is vital that the smart speaker gives an effective and proper response. However, currently the response strategies adopted by leading smart speaker brands in China differed mainly on two dimensions: âapology or notâ and âhumor or neutralâ. We explored userâs preference of response strategies under two error scenariosâââcannot understandâ and âno requested audio resourceâ. Two dependent variables (satisfaction and perceived sincerity of response) were measured. The results showed that participants were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios. In the âno requested audio resourceâ scenario, humor had no significant impact on the perception of satisfaction and sincerity. But in the âcannot understandâ scenario, humorous expression decreased perceived sincerity.",
        "prediction": "More people are using smart speakers that respond to voice commands. This means voice is becoming a common way to interact with devices. Speech recognition and natural language processing have improved a lot recently. However, users still face errors like \"cannot understand\" or \"no requested audio resource.\" These errors can be frustrating. When an error happens, it is important for the smart speaker to respond well. \n\nSmart speaker brands in China use different strategies for responses. They mainly differ in two ways: whether they apologize or not and whether they use humor or stay neutral. We looked at what users prefer in two error situations: \"cannot understand\" and \"no requested audio resource.\" We measured two things: user satisfaction and how sincere they felt the response was. \n\nThe results showed that users felt more satisfied and thought the apology was more sincere in both error situations. In the \"no requested audio resource\" scenario, humor did not change feelings of satisfaction or sincerity. However, in the \"cannot understand\" scenario, using humor made the response seem less sincere.",
        "reference": "Smart speakers are becoming popular around the world and people will get used to this new way of interacting with the voice. Even with the progress of speech recognition and natural language processing (interactions between computers and human language), users may still get errors like âcannot understandâ or âno requested audio resourceâ which can frustrate users. So, it is important that the smart speaker gives an effective and proper response during an error message. The responses of the most popular brand of smart speakers are based on 2 elements, apology and humor. We studied userâs preference in two error scenarios : âcannot understandâ and âno requested resourceâ Satisfaction of the user and perceived sincerity of the response were measured. The results showed that users were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios. In the âno requested audio resourceâ scenario, humor had no impact on the satisfaction or sincerity. But in the âcannot understandâ scenario, humor decreased perceived sincerity."
      },
      {
        "source": "A pharmacophore analysis approach was used to investigate and compare different classes of compounds relevant to the drug discovery process (specifically, drug molecules, compounds in high throughput screening libraries, combinatorial chemistry building blocks and nondrug molecules). Significant differences were observed between the pharmacophore profiles obtained for the drug molecules and those obtained for the high-throughput screening compounds, which appear to be closely related to the nondrug pharmacophore distribution. It is suggested that the analysis of pharmacophore profiles could be used as an additional tool for the property-based optimization of compound selection and library design processes, thus improving the odds of success in lead discovery projects.",
        "prediction": "A pharmacophore analysis was used to study and compare different types of compounds important for finding new drugs. This includes drug molecules, high-throughput screening compounds, building blocks from combinatorial chemistry, and nondrug molecules. There were clear differences in the pharmacophore profiles for drug molecules and those for screening compounds. These differences relate closely to the distribution of nondrug pharmacophores. This analysis can help improve the process of choosing and designing compounds, which could boost success in discovering new drug leads.",
        "reference": "A pharmacophore analysis investigated and compared different compounds of the drug discovery process. Significant differences were observed between the pharmacophore profiles of the drug molecules and the high-throughput screening compounds, which appear to be related to the nondrug pharmacophore distribution. It is suggested that the analysis could be used as an additional tool for the optimization of compound selection and library design processes.."
      },
      {
        "source": "Annotation of bioassay protocols using semantic web vocabulary is a way to make experiment descriptions machine-readable. Protocols are communicated using concise scientific English, which precludes most kinds of analysis by software algorithms. Given the availability of a sufficiently expressive ontology, some or all of the pertinent information can be captured by asserting a series of facts, expressed as semantic web triples (subject, predicate, object). With appropriate annotation, assays can be searched, clustered, tagged and evaluated in a multitude of ways, analogous to other segments of drug discovery informatics. The BioAssay Ontology (BAO) has been previously designed for this express purpose, and provides a layered hierarchy of meaningful terms which can be linked to.",
        "prediction": "Using semantic web vocabulary to annotate bioassay protocols helps make experiment descriptions machine-readable. Protocols are written in clear scientific English, but this limits software analysis. With a good ontology, important information can be captured as semantic web triples, which are made up of a subject, predicate, and object. Proper annotation allows assays to be searched, grouped, tagged, and evaluated in many ways, similar to other areas of drug discovery informatics. The BioAssay Ontology (BAO) was created for this purpose and offers a structured set of useful terms.",
        "reference": "Annotation of bioassay protocols with web vocabulary can make experiment descriptions machine-readable. Protocols use concise scientific English which prevents most of analysis by software algorithms. There is a sufficient ontology, so the pertinent information can be written using semantic web triples (subject, predicate, object). With appropriate annotation, assays can be searched, clustered, tagged and evaluated. The BioAssay Ontology (BAO) has been designed for this purpose, and provides many meaningful terms."
      },
      {
        "source": "Next generation sequencing (NGS) produces massive datasets consisting of billions of reads and up to thousands of samples. Subsequent bioinformatic analysis is typically done with the help of open source tools, where each application performs a single step towards the final result. This situation leaves the bioinformaticians with the tasks to combine the tools, manage the data files and meta-information, document the analysis, and ensure reproducibility.",
        "prediction": "Next generation sequencing creates large datasets with billions of reads and many samples. Bioinformatic analysis usually uses open source tools. Each tool does one step to reach the final result. Bioinformaticians must combine the tools, manage data files and information, document the analysis, and ensure it can be repeated.",
        "reference": "Next generation sequencing (NGS) produces datasets of billions of reads and thousands of samples. The analysis is typically done with open source tools, performing a single step towards the final result. The bioinformaticians have to combine the tools, manage the files and information, document the analysis, and ensure reproducibility."
      },
      {
        "source": "SPSS Clementinel2.0 statistical software was used to mine the association rules between Etiology and traditional Chinese medicine (TCM), Syndromes and TCM, Symptoms and TCM. The classic Apriori algorithm is useful to mine cases of influenza treated by contemporary famous old Chinese medicine.",
        "prediction": "SPSS Clementine 2.0 software was used to find rules connecting Etiology with traditional Chinese medicine (TCM), Syndromes with TCM, and Symptoms with TCM. The classic Apriori algorithm helped to study cases of influenza treated by well-known Chinese medicine.",
        "reference": "SPSS Clementinel2.0 statistical software was used to extract data and find relations between traditional Chinese medicine and other medicine. The classic Apriori algorithm is useful to find cases of influenza treated by old Chinese medicine."
      },
      {
        "source": "Identifying antimicrobial resistant (AMR) bacteria in metagenomics samples is essential for public health and food safety. Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and constructing the correlations between genotype and phenotype in humans and other species. a Bayesian framework for genotype estimation for mixtures of multiple bacteria, named as Genetic Polymorphisms Assignments (GPA) has reduced the false discovery rate (FDR) and mean absolute error (MAE) in single nucleotide variant (SNV) identification.",
        "prediction": "Finding antimicrobial resistant (AMR) bacteria in metagenomics samples is important for public health and food safety. Next-generation sequencing (NGS) technology helps us identify genetic differences and understand the links between genotype and phenotype in humans and other species. A method called Genetic Polymorphisms Assignments (GPA) uses a Bayesian framework for estimating genotypes in mixtures of different bacteria. This method lowers the false discovery rate (FDR) and mean absolute error (MAE) in finding single nucleotide variants (SNVs).",
        "reference": "Identifying bacterias that are resistant to antimicrobial in samples of genetic material collected from the environment is essential for public health and food safety. Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and constructing the correlations between genotype (genetic code of an individual) and phenotype (physical characteristics of an indvidual) in humans and other species. The Genetic Polymorphism Assignements (GPA) is a framework which determines the genetic constitution of multiple bacteria while reducing the number of false positive results and improving the accuracy of calculations when identifying the variation of a single nucleotide."
      },
      {
        "source": "The CRISPR/Cas9 system was recently developed as a powerful and flexible technology for targeted genome engineering, including genome editing (altering the genetic sequence) and gene regulation (without altering the genetic sequence). These applications require the design of single guide RNAs (sgRNAs) that are efficient and specific. However, this remains challenging, as it requires the consideration of many criteria.",
        "prediction": "The CRISPR/Cas9 system is a strong and flexible tool for changing genomes. It can edit genes by altering the genetic sequence or regulate genes without changing the sequence. To use this system, we need to design single guide RNAs (sgRNAs) that work well and are precise. This is difficult because it involves many important factors.",
        "reference": "The CRISPR/Cas9 system is a powerful technology for gene editing and gene regulation. These applications require the design of single guide RNAs (which are enzymes that can delete, insert or alter DNA) that are efficient and specific. However, this remains challenging, as it requires the consideration of many criteria."
      },
      {
        "source": "The hidden connection between these reports is that gene editing could be used to solve issues related to health care allocation. Improving the health of future generations might coincide with public health goals; it might improve the health of individuals and communities, and, if successful, might be seen as a public good. However, enhancing future generations will require In Vitro Fertilisation and Pre-implantation Genetic Diagnosis. Remarkably, the necessary involvement of women in an enhancing scenario has not been discussed by its proponents. The present discourse on moral obligations of future generations, although not referring to women, seems to imply that women might be required, morally, if not legally, to reproduce with IVF. Enhancing future generations will be gendered, unless the artificial womb is developed. These are challenging issues that require a wider perspective, of both women and men. Despite the lack of a unified feminist conclusion in the discussions about the merits and risks of human genome modification, there is an urgent need to clarify the role of women in this scenario.",
        "prediction": "Gene editing can help with health care problems. It may improve the health of future generations and individual people. If it works well, it could be a benefit for everyone. To help these future generations, we will need processes like In Vitro Fertilization (IVF) and Pre-implantation Genetic Diagnosis. \n\nOne important point is that the role of women in this enhancement has not been properly discussed. The conversations about what we owe future generations suggest that women may need to use IVF to have children. This approach is gendered, meaning it focuses on women unless we create artificial wombs. \n\nThese issues are complex and need input from both women and men. Even though womenâs viewpoints are not fully represented in the talks about the risks and benefits of changing human genes, we need to clarify what role women have in these situations.",
        "reference": "Gene editing could be used to solve issues related to health care allocation. Improving the health of future generations might coincide with public health goals. However, enhancing future generations will require In Vitro Fertilisation (IVF) and Pre-implantation Genetic Diagnosis. The necessary involvement of women in an enhancing scenario has not been discussed. The discourse on moral obligations of future generations seems to imply that women might be required to reproduce with IVF. Enhancing future generations will be gendered, unless the artificial womb is developed. These are challenging issues that require a wider perspective, of both women and men. There are no unified feminist conclusion about the merits and risks of human genome modification. There is also an urgent need to clarify the role of women in this scenario."
      },
      {
        "source": "CRISPR-Cas is a tool that is widely used for gene editing. However, unexpected off-target effects may occur as a result of long-term nuclease activity. Anti-CRISPR proteins, which are powerful molecules that inhibit the CRISPR-Cas system, may have the potential to promote better utilization of the CRISPR-Cas system in gene editing, especially for gene therapy. Additionally, more in-depth research on these proteins would help researchers to better understand the co-evolution of bacteria and phages. Therefore, it is necessary to collect and integrate data on various types of anti-CRISPRs.",
        "prediction": "CRISPR-Cas is a popular tool for gene editing. But it can sometimes cause unexpected effects. These effects happen because of long-term activity from nucleases. Anti-CRISPR proteins can block the CRISPR-Cas system. These proteins might help improve the use of CRISPR-Cas in gene editing, especially in gene therapy. More research on these proteins can help scientists understand how bacteria and viruses evolved together. It is important to collect and combine data on different types of anti-CRISPRs.",
        "reference": "CRISPR-Cas is a tool used for gene editing. However, unintended genetic modifications may occur. Anti-CRISPR proteins (molecules that inhibit the CRISPR-Cas system) may improve utilization of the CRISPR-Cas system in gene editing, especially for gene therapy. More research on these proteins would help to understand the co-evolution of bacteria and bacteriophages (virus that infects and replicates within bacteria). It is necessary to collect and integrate data on various types of anti-CRISPRs."
      },
      {
        "source": "CRISPR has become a hot research area ever since its advent for its efficiency and specificity in editing almost every section of DNA sequences. Based on its function of gene perturbation, a variety of gene editing techniques have been developed to achieve different aims. The target locations of a DNA strain can be precisely broken and repaired, during which the genes can be removed, repaired, silenced, or activated. The high efficiency of CRISPR/Cas9 reagents preparation and the easiness of experiment conduction make it now a powerful tool of high-content screen.",
        "prediction": "CRISPR is a popular research tool because it is good at editing DNA. It helps scientists change genes for different purposes. With CRISPR, scientists can cut and fix DNA at specific spots. They can remove, repair, turn off, or turn on genes. CRISPR/Cas9 is easy to prepare and use in experiments. This makes it a strong tool for studying many genes at once.",
        "reference": "CRISPR is a popular research area known for its efficiency and specificity in editing DNA sequences. A variety of gene editing techniques have been developed for different aims. The target locations of a DNA strain can be precisely broken and repaired, during which the genes can be removed, repaired, silenced, or activated. The high efficiency of CRISPR/Cas9 reagents preparation and the easiness of experiment conduction make it a powerful tool."
      },
      {
        "source": "The CRISPR-Cpf1 system has been successfully applied in genome editing. However, target efficiency of the CRISPR-Cpf1 system varies among different gRNA sequences. Using machine learning technology, a SVM model was created to predict target efficiency for any given gRNAs. the first web service application, CRISPR-DT (CRISPR DNA Targeting), to help users design optimal gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and specificity is available.",
        "prediction": "The CRISPR-Cpf1 system is used for genome editing. The efficiency of this system can change based on different gRNA sequences. A machine learning model called SVM was made to predict how well gRNAs will work. The first web service, CRISPR-DT, helps users design the best gRNAs for the CRISPR-Cpf1 system by looking at both efficiency and specificity.",
        "reference": "The CRISPR-Cpf1 system (a DNA-editing technology) has been successfully applied in gene editing. However target efficiency of the CRISPR-Cpf1 system varies among different gRNA (piece of RNA that serves as a guide to DNA-targeting enzymes) sequences. Using machine learning technology, a support-vector machine model (algorithm used for data classification) was created to predict the target efficiency for any given gRNAs. CRISPR-DT (CRISPR DNA Targeting) is available. It is the first web service application to help users design optimal gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and target specificity (recognition mecanism)."
      },
      {
        "source": "Emerging self-driving vehicles are vulnerable to different attacks due to the principle and the type of communication systems that are used in these vehicles. These vehicles are increasingly relying on external communication via vehicular ad hoc networks (VANETs). VANETs add new threats to self-driving vehicles that contribute to substantial challenges in autonomous systems. These communication systems render self-driving vehicles vulnerable to many types of malicious attacks, such as Sybil attacks, Denial of Service (DoS), black hole, grey hole and wormhole attacks. In this paper, we propose an intelligent security system designed to secure external communications for self-driving and semi self-driving cars. The hybrid detection system relies on the Back Propagation neural networks (BP), to detect a common type of attack in VANETs: Denial-of-Service (DoS). The experimental results show that the proposed BP-IDS is capable of identifying malicious vehicles in self-driving and semi self-driving vehicles.",
        "prediction": "Self-driving cars face many risks because of how they communicate. They often use vehicle networks called VANETs. These networks create new problems for self-driving cars. They make it easier for attackers to carry out harmful actions like Sybil attacks, Denial of Service (DoS), black hole, grey hole, and wormhole attacks. In this paper, we suggest a smart security system to protect the communication for self-driving and semi self-driving cars. This system uses Back Propagation neural networks (BP) to find a common attack called Denial of Service (DoS) in VANETs. Our tests show that the BP-IDS can spot bad vehicles in both self-driving and semi self-driving cars.",
        "reference": "Self-driving vehicles are vulnerable to different attacks because of their communication systems. These vehicles use external communication via a network. This network add new threats to self-driving vehicles that contribute to the challenges in autonomous systems. With these communication systems, self-driving vehicles are vulnerable to many types of malicious attacks on the network. In this paper, we propose an intelligent security system to secure external communications for self-driving cars. The system will detect a common type of attack in the network: Denial-of-Service (attack trying to make network resource unavailable). The results show that the intrusion detection system is capable of identifying malicious vehicles in self-driving vehicles."
      },
      {
        "source": "Self-driving vehicle technologies are progressing rapidly and are expected to play a significant role in the future of transportation. One of the main challenges for self-driving vehicles on public roads is the safe cooperation and collaboration among multiple vehicles using sensor-based perception and inter-vehicle communications. When self-driving vehicles try to occupy the same spatial area simultaneously, they might collide with one another, might become deadlocked, or might slam on the brakes making it uncomfortable or unsafe for passengers in a self-driving vehicle. In this paper, we study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet. We present a safe protocol for merge points named Autonomous Vehicle Protocol for Merge Points, where self-driving vehicles use both vehicular communications and their own perception systems for cooperating with other self-driving and/or human-driven vehicles. Our simulation results show that our traffic protocol has higher traffic throughput, compared to simple traffic protocols, while ensuring safety.",
        "prediction": "Self-driving cars are getting better and will be very important for future travel. One big problem for these cars on public roads is how they can work together safely. They need to use sensors and talk to each other to avoid accidents. When self-driving cars try to go into the same space at the same time, they can crash or get stuck. This can make it unsafe or uncomfortable for people in the car. In this study, we look at how a self-driving car can navigate merge points, where two lanes meet and have different rules. We created a safety plan called the Autonomous Vehicle Protocol for Merge Points. This plan helps self-driving cars communicate with each other and with human-driven cars. Our simulations show that our traffic plan lets more cars move through safely compared to simpler plans.",
        "reference": "Self-driving vehicle technologies are progressing and are expected to play a significant role in the future of transportation. A main challenge for self-driving vehicles on public roads is the safe cooperation, collaboration and communication with other vehicles. When self-driving vehicles are in the same area, they might collide, become blocked, or suddenly brake and make uncomfortable or unsafe the passengers. We study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet. We present a safe protocol where self-driving vehicles use both vehicular communications and their own perception systems for cooperating with other vehicles (self-driving or human-driven). Our simulation results show that our traffic protocol leads to a better traffic flow, while ensuring safety."
      },
      {
        "source": "This paper provides a holistic study of how stock prices vary in their response to financial disclosures across different topics. Thereby, we specifically shed light into the extensive amount of filings for which no a priori categorization of their content exists. For this purpose, we utilize an approach from data mining - namely, latent Dirichlet allocation - as a means of topic modeling. This technique facilitates our task of automatically categorizing, ex ante, the content of more than 70,000 regulatory 8-K filings from U.S. companies. We then evaluate the subsequent stock market reaction. Our empirical evidence suggests a considerable discrepancy among various types of news stories in terms of their relevance and impact on financial markets. For instance, we find a statistically significant abnormal return in response to earnings results and credit rating, but also for disclosures regarding business strategy, the health sector, as well as mergers and acquisitions. Our results yield findings that benefit managers, investors and policy-makers by indicating how regulatory filings should be structured and the topics most likely to precede changes in stock valuations.",
        "prediction": "This paper studies how stock prices change based on financial disclosures about different topics. We focus on many filings that do not have a clear category. To do this, we use a data mining method called latent Dirichlet allocation for topic modeling. This method helps us automatically sort the content of over 70,000 regulatory 8-K filings from U.S. companies. We then look at how the stock market reacts afterward. Our findings show big differences in how various types of news affect financial markets. For example, we see a significant change in stock prices after earnings results and credit rating news. We also find changes due to news about business strategy, health sector updates, and mergers and acquisitions. Our results help managers, investors, and policy-makers understand how to structure regulatory filings and identify topics that may lead to changes in stock values.",
        "reference": "This paper studies how stock prices vary with financial disclosures. We particularly study the many uncategorized filings. We use latent Dirichlet allocation for topic modeling. This helps automatically predict the categories based on the content of 70,000 regulatory 8-K filings from U.S. companies, which announce significant events relevant to shareholders. We then evaluate the stock market reaction. Evidence suggests a large difference among types of news stories in relevance and impact on financial markets. For example, we find unusual returns in response to disclosures about earnings results, credit rating, business strategy, the health sector, mergers and acquisitions. Our results are useful for managers, investors and policy-makers. They show how to structure regulatory filings and which topics influence stock valuations."
      },
      {
        "source": "A significant problem of using deep learning techniques is the limited amount of data available for training. There are some datasets available for the popular problems like item recognition and classification for self-driving cars, however, it is very limited for the industrial robotics field. In previous work, we have trained a multi-objective Convolutional Neural Network (CNN) to identify the robot body in the image and estimate 3D positions of the joints by using just a 2D image, but it was limited to a range of robots produced by Universal Robots (UR). In this work, we extend our method to work with a new robot arm - Kuka LBR iiwa, which has a significantly different appearance and an additional joint. However, instead of collecting large datasets once again, we collect a number of smaller datasets containing a few hundred frames each and use transfer learning techniques on the CNN trained on UR robots to adapt it to a new robot having different shapes and visual features. We have proven that transfer learning is not only applicable in this field, but it requires smaller well-prepared training datasets, trains significantly faster and reaches similar accuracy compared to the original method, even improving it on some aspects.",
        "prediction": "A big problem with deep learning is having not enough data for training. There are some datasets for problems like item recognition and self-driving cars, but there is not much for industrial robotics. In our past work, we trained a multi-objective Convolutional Neural Network (CNN) to find the robot body in images and estimate 3D joint positions using just 2D images. This was only for robots made by Universal Robots (UR). In this study, we adapt our method to a new robot arm called Kuka LBR iiwa, which looks different and has an extra joint. Instead of gathering large datasets again, we collect smaller datasets with a few hundred frames each. We then use transfer learning with the CNN trained on UR robots to fit it to the new robot, which has different shapes and features. We show that transfer learning works well here. It needs smaller, well-prepared datasets, trains faster, and achieves similar or better accuracy than before.",
        "reference": "Limited data available for training affects the use of deep learning techniques. Datasets are available for problems such as item recognition and classification for self-driving cars, but very limited for industrial robotics. A multi-objective Convolutional Neural Network (CNN) was first trained to identify the robot in the image and find 3D positions of the joints using just a 2D image. But this only used robots made by Universal Robots (UR). Here we work with a new robot arm - Kuka LBR iiwa which looks very different and has an additional joint. We collect a number of smaller datasets and use transfer learning techniques on the CNN trained on UR robots to adapt it to a robot that looks different. Transfer learning requires smaller training datasets, learns faster and reaches similar or even better accuracy."
      },
      {
        "source": "We introduce Ignition: an end-to-end neural network architecture for training unconstrained self-driving vehicles in simulated environments. The model is a ResNet-18 variant, which is fed in images from the front of a simulated F1 car, and outputs optimal labels for steering, throttle, braking. Importantly, we never explicitly train the model to detect road features like the outline of a track or distance to other cars; instead, we illustrate that these latent features can be automatically encapsulated by the network.",
        "prediction": "We present Ignition. It is a complete neural network design for training self-driving cars in simulation. The model is a version of ResNet-18. It takes images from the front of a simulated F1 car. It gives the best labels for steering, throttle, and braking. We do not train the model to recognize road features like track outlines or distance to other cars. Instead, we show that the network can learn these important details on its own.",
        "reference": "Ignition is a neural network for training unconstrained self-driving vehicles in simulated environments. This ResNet-18 variant model receives images from the front of a simulated car and uses them to steer, throttle, or brake appropriately. The model is not explicitly trained to detect road features such as track outline or distance to other cars, as these features can automatically be calculated by the network."
      },
      {
        "source": "As for the humanoid robots, the internal noise, which is generated by motors, fans and mechanical components when the robot is moving or shaking its body, severely degrades the performance of the speech recognition accuracy. In this paper, a novel speech recognition system robust to ego-noise for humanoid robots is proposed, in which on/off state of the motor is employed as auxiliary information for finding the relevant input features. For this, we consider the bottleneck features, which have been successfully applied to deep neural network (DNN) based automatic speech recognition (ASR) system. When learning the bottleneck features to catch, we first exploit the motor on/off state data as supplementary information in addition to the acoustic features as the input of the first deep neural network (DNN) for preliminary acoustic modeling. Then, the second DNN for primary acoustic modeling employs both the bottleneck features tossed from the first DNN and the acoustics features. When the proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, the experimental results show that achieve obvious improvement (11% relative) is achieved by our algorithm over the conventional systems.",
        "prediction": "Humanoid robots have internal noise from motors, fans, and parts when they move. This noise makes it hard for them to recognize speech. This paper suggests a new speech recognition system that works well despite this ego-noise. It uses the on/off state of the motor as extra information to help find important input features. We focus on bottleneck features, which work well in deep neural network (DNN) speech recognition systems. First, we use data from the motor's on/off state along with sound features in a DNN for early acoustic modeling. Next, a second DNN uses both the bottleneck features from the first DNN and the sound features. When we tested this method on the TIMIT database, we found a 11% relative improvement in phoneme error rate (PER) compared to traditional systems.",
        "reference": "Internal noise generated by motors, fans and mechanical components severely decreases speech recognition accuracy, when the humanoid robot is moving or shaking its body. This paper presents a novel speech recognition system robust to ego-noise for humanoid robots. On/off state of the motor is used to find relevant input features. Bottleneck features have been successfully applied to automatic speech recognition (ASR) systems based on deep neural networks (DNN). The motor on/off state data and acoustic features are used as the input of the first deep neural network (DNN) for preliminary acoustic modeling. The second DNN for primary acoustic modeling uses both bottleneck features from the first DNN and acoustic ones. The proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, experimental results show that improvement (11% relative) is achieved by our algorithm over the conventional systems."
      },
      {
        "source": "Recognizing Traffic Signs using intelligent systems can drastically reduce the number of accidents happening world-wide. With the arrival of Self-driving cars it has become a staple challenge to solve the automatic recognition of Traffic and Hand-held signs in the major streets. Various machine learning techniques like Random Forest, SVM as well as deep learning models has been proposed for classifying traffic signs. Though they reach state-of-the-art performance on a particular data-set, but fall short of tackling multiple Traffic Sign Recognition benchmarks. In this paper, we propose a novel and one-for-all architecture that aces multiple benchmarks with better overall score than the state-of-the-art architectures. Our model is made of residual convolutional blocks with hierarchical dilated skip connections joined in steps. With this we score 99.33% Accuracy in German sign recognition benchmark and 99.17% Accuracy in Belgian traffic sign classification benchmark. Moreover, we propose a newly devised dilated residual learning representation technique which is very low in both memory and computational complexity.",
        "prediction": "Using smart systems to recognize traffic signs can greatly lower accidents around the world. With self-driving cars, it is important to recognize traffic and hand-held signs on busy roads. Many machine learning methods, like Random Forest and SVM, as well as deep learning, have been used to classify traffic signs. These methods work well on some data but struggle with different Traffic Sign Recognition tests. In this paper, we present a new model that performs better across several tests than current top methods. Our model uses special residual convolutional blocks with advanced connections. It achieved 99.33% accuracy in the German sign recognition test and 99.17% accuracy in the Belgian traffic sign test. We also introduce a new technique that uses less memory and is easier to run.",
        "reference": "If intelligent systems recognize traffic signs, it can reduce car accidents. For self-driving cars, we need automatic recognition of traffic and hand signs. Machine learning techniques  could be used to classify traffic signs. They perform well on a particular dataset, but fail on multiple traffic sign recognition test datasets. We proposed a new and better method. This model is based on enhanced convolutional neural networks (a deep-learning approach often used for image recognition). This model was more than 99% correct on German and Belgian sign recognition datasets. This new model is very low in both memory and computational complexity."
      },
      {
        "source": "In this paper, we present a transfer learning method for the end-to-end control of self-driving cars, which enables a convolutional neural network (CNN) trained on a source domain to be utilized for the same task in a different target domain. A conventional CNN for the end-to-end control is designed to map a single front-facing camera image to a steering command. To enable the transfer learning, we let the CNN produce not only a steering command but also a lane departure level (LDL) by adding a new task module, which takes the output of the last convolutional layer as input. The CNN trained on the source domain, called source network, is then utilized to train another task module called target network, which also takes the output of the last convolutional layer of the source network and is trained to produce a steering command for the target domain. The steering commands from the source and target network are finally merged according to the LDL and the merged command is utilized for controlling a car in the target domain. To demonstrate the effectiveness of the proposed method, we utilized two simulators, TORCS and GTAV, for the source and the target domains, respectively. Experimental results show that the proposed method outperforms other baseline methods in terms of stable and safe control of cars.",
        "prediction": "In this paper, we explain a method called transfer learning for controlling self-driving cars. This method lets a convolutional neural network (CNN) trained on one type of data work on another type. Normally, a CNN is used to turn an image from a front-facing camera into a steering command. To use transfer learning, we added a new module to the CNN. This module not only gives a steering command but also measures lane departure level (LDL). \n\nThe CNN trained on the first type of data is called the source network. We use it to train a second module called the target network. This target network also gets input from the source network and learns to create a steering command for the new type of data. We then combine the steering commands from both networks based on the LDL. The final command is used to control the car in the new environment.\n\nTo show our method works well, we used two simulators: TORCS for the source domain and GTAV for the target domain. The results show that our method does better than other standard methods for safe and stable car control.",
        "reference": "A transfer learning method to control self-driving cars is proposed, in which a convolutional neural network (CNN) is trained on one domain then used for the same task in a different domain. A conventional CNN is designed to map a single front-facing camera image to control a car. CNN produces a steering command and a lane departure level (LDL, mechanism designed to warn the driver when the vehicle begins to move out of its lane). To enable the transfer learning, a new task module takes the output of the last convolutional layer as input. The CNN trained on the source domain is then used to train the target network. It takes the output of the last convolutional layer of the source network and is trained to produce a steering command for the target domain. The steering commands from the source and target network are merged and used for car control in the target domain. Two simulators were used to evaluate the proposed method. The proposed method is more stable and safer for car control."
      },
      {
        "source": "This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE), a novel minimal simulation of a centralised financial market, based on a Limit Order Book (LOB) such as is common in major stock exchanges. Construction of BSE was motivated by the fact that most of the worldâs major financial markets have automated, with trading activity that previously was the responsibility of human traders now being performed by high-speed autonomous automated trading systems. Research aimed at understanding the dynamics of this new style of financial market is hampered by the fact that no operational real-world exchange is ever likely to allow experimental probing of that market while it is open and running live, forcing researchers to work primarily from time-series of past trading data. Similarly, university-level education of the engineers who can create next-generation automated trading systems requires that they have hands-on learning experience in a sufficiently realistic teaching environment. BSE as described here addresses both those needs: it has been successfully used for teaching and research in a leading UK university since 2012, and the BSE program code is freely available as open-source on GitHuB.",
        "prediction": "This paper talks about the Bristol Stock Exchange (BSE). It is a simple simulation of a financial market. It uses a Limit Order Book (LOB) like big stock exchanges do. The BSE was created because many major financial markets are now automated. In these markets, fast automated systems replace human traders. Researchers want to study this new market style. However, they cannot experiment with real exchanges while they are open. They must use past trading data instead. Also, students need hands-on experience to learn how to build future automated trading systems. The BSE helps with both of these needs. It has been used for teaching and research at a top UK university since 2012. The code for BSE is free to use on GitHub.",
        "reference": "This paper describes the Bristol Stock Exchange (BSE), a minimal simulation of a centralised financial market based on a Limit Order Book (LOB), a type of order to buy or sell a security at a specific price or better. BSE was built because most of the financial markets became automated. Research tries to understand the dynamics of this automated financial markets but Trainee engineers also need a realistic learning experience to build automated trading systems. BSE has been successfully used for both teaching and research since 2012. BSE code is freely available on GitHuB."
      },
      {
        "source": "Once self-driving car becomes a reality and passengers are no longer worry about it, they will need to find new ways of entertainment. The simulation results show that the accuracy of our prediction for the contents need to be cached in the areas of the self-driving car is achieved at 98.04% and our approach can minimize delay. However, retrieving entertainment contents at the Data Center (DC) can hinder content delivery service due to high delay of car-to-DC communication. To address these challenges, we propose a deep learning based caching for self-driving car, by using Deep Learning approaches deployed on the Multi-access Edge Computing (MEC) structure. First, at DC, Multi-Layer Perceptron (MLP) is used to predict the probabilities of contents to be requested in specific areas. To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units. Second, in order to cache entertainment contents stylized for car passengersâ features such as age and gender, Convolutional Neural Network (CNN) is used to predict age and gender of passengers. Through this, the self-driving car can identify the contents need to be downloaded from the MEC server and cached. Finally, we formulate deep learning based caching in the self-driving car that enhances entertainment services as an optimization problem whose goal is to minimize content downloading delay. To solve the formulated problem, a Block Successive Majorization-Minimization (BS-MM) technique is applied.",
        "prediction": "When self-driving cars become common, passengers will need new ways to be entertained. Our research shows that we can predict what content will be needed with 98.04% accuracy. This helps reduce delays. However, getting content from the Data Center (DC) can be slow because of the long communication time between the car and the DC. To fix this, we suggest using deep learning for caching in self-driving cars. We use Multi-access Edge Computing (MEC) to make this work. \n\nFirst, we use a Multi-Layer Perceptron (MLP) at the DC to predict what content will be requested in certain areas. To cut down on delays, we store the MLP results in MEC servers near the road. Second, we use a Convolutional Neural Network (CNN) to figure out the age and gender of passengers. This helps the self-driving car know what content to download and save. Finally, we treat the caching problem as an optimization issue to reduce download delays. We solve this using a method called Block Successive Majorization-Minimization (BS-MM).",
        "reference": "Once self-driving cars become reality and passengers no longer worry about it, they will need to find other forms of entertainment. Prediction accuracy was 98.04% for contents to be cached for self-driving cars. Such an approach can minimize delay. However, high communication delay can slow retrieval of entertainment content from Data Centers (DC). Self-driving cars can use deep learning caching to address these challenges. It is deployed on the Multi-access Edge Computing (MEC) structure that moves services from a centralized cloud to the network edges and closer to the customer. Multi-Layer Perceptron (MLP), a type of artificial neural network, is used to predict the content requested in specific areas. To reduce delay, MLP outputs are sent to MEC servers for roadside units. A Convolutional Neural Network (CNN) is used to predict passengersâ age and gender to cache adapted entertainment content. The self-driving car can therefore identify the contents to be downloaded and cached. Deep learning caching is formulated for the self-driving car to enhance entertainment services and minimize content downloading delay. A Block Successive Majorization-Minimization (BS-MM) technique solves the problem."
      },
      {
        "source": "Moral responsibility is a major concern in automated decision-making, with applications ranging from self-driving cars to kidney exchanges.",
        "prediction": "Moral responsibility is important in automated decision-making. This includes things like self-driving cars and kidney exchanges.",
        "reference": "Moral responsibility is a major concern in automated decision-making, from self-driving cars to kidney transplants."
      },
      {
        "source": "A key problem for autonomous car navigation is the understanding, at an object level, of the current driving situation. Addressing this issue requires the extraction of meaningful information from on-board stereo imagery by classifying the fundamental elements of urban scenes into semantic categories that can more easily be interpreted and be reflected upon (streets, buildings, pedestrians, vehicles, signs, etc.). A probabilistic method is proposed to fuse a coarse prior 3D map data with stereo imagery classification. A novel fusion architecture based on the Stixel framework is presented for combining semantic pixel-wise segmentation from a convolutional neural network (CNN) with depth information obtained from stereo imagery while integrating coarse prior depth and label information. The proposed approach was tested on a manually labeled data set in urban environments. The results show that the classification accuracy of the fundamental elements composing the urban scene was significantly enhanced by this method compared to what is obtained from the semantic pixel-wise segmentation of a CNN alone.",
        "prediction": "A big problem for self-driving cars is understanding the driving situation. To solve this, we need to get useful information from on-board stereo images. This means sorting parts of city scenes into simple categories like streets, buildings, people, cars, and signs. We suggest a method that combines rough 3D map data with stereo image classification. We created a new way to merge information from a convolutional neural network (CNN) with depth data from stereo images. This method uses both the depth and label information from the rough prior data. We tested this approach on a data set labeled by hand in city areas. The results show a big improvement in how accurately we classify the key elements of urban scenes compared to just using CNN segmentation alone.",
        "reference": "A key problem for autonomous car navigation is the understanding of the environment while driving. It needs to extract information from the sensors and cameras and classify the elements into categories so it can be easily analysed (streets, buildings, pedestrians, vehicles, signs, etc.). A method is to fuse 3D map data with classification of the sensors and cameras. This system combine image segmentation (simplify the representation of an image to facilitate its analysis) and information obtained from sensors and cameras while integrating prior information. This approach was tested on manually entered data in urban environments. The results show that the classification of elements is more accurate with this method than the image segmentation alone."
      },
      {
        "source": "This paper proposes a MATLAB/Simulink benchmark suite for an open-source self-driving system based on Robot Operating System (ROS). One approach to the development of self-driving systems is the utilization of ROS which is an open-source middleware framework used in the development of robot applications. On the other hand, the popular approach in the automotive industry is the utilization of MATLAB/Simulink which is software for modeling, simulating, and analyzing. MATLAB/Simulink provides an interface between ROS and MATLAB/Simulink that enables to create functionalities of ROS-based robots in MATLAB/Simulink. However, it is not been fully utilized in the development of self-driving systems yet because there are not enough samples for self-driving, and it is difficult for developers to adopt co-development. Therefore, we provide a MATLAB/Simulink benchmark suite for a ROS-based self-driving system called Autoware. Autoware is popular open-source software that provides a complete set of self-driving modules. The provided benchmark contains MATLAB/Simulink samples available in Autoware. They help to design ROS-based self-driving systems using MATLAB/Simulink.",
        "prediction": "This paper introduces a MATLAB/Simulink benchmark for an open-source self-driving system using Robot Operating System (ROS). ROS is a free framework used for building robot applications. In the car industry, MATLAB/Simulink is popular for modeling and simulating systems. It connects ROS with MATLAB/Simulink, allowing developers to build features for ROS-based robots in MATLAB/Simulink. However, it is not widely used for self-driving systems yet due to a lack of examples and challenges in working together. To help, we provide a benchmark for a ROS-based self-driving system called Autoware. Autoware is well-known open-source software that offers many self-driving modules. Our benchmark includes MATLAB/Simulink samples from Autoware. These samples assist in designing ROS-based self-driving systems using MATLAB/Simulink.",
        "reference": "This paper proposes MATLAB/Simulink tests for an open-source self-driving system based on Robot Operating System. One approach to the development of self-driving systems is the utilization of Robot Operating System (open-source software framework used in the development of robot applications). But the popular approach in the automotive industry is the utilization of MATLAB/Simulink (software for modeling, simulating, and analyzing). MATLAB/Simulink provides an interface that enables to create functionalities of robots (based on robot operating system). However, it is not fully utilized in the development of self-driving systems yet because there are not enough samples, and it is difficult for developers to adopt co-development. We provide MATLAB/Simulink tests for a self-driving system (based on robot operating system) called Autoware. Autoware is a popular open-source software that provides a complete set of self-driving modules. The provided tests contain MATLAB/Simulink samples available in Autoware. They help to design self-driving systems (based on robot operating system) using MATLAB/Simulink."
      },
      {
        "source": "The management of self-driving systems is becoming more complex as the development of self-driving technology progresses. One approach to the development of self-driving systems is the use of ROS; however, the system used in the automotive industry is typically designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving. These models are incompatible with ROS-based systems. To allow the two to be used in tandem, it is necessary to rewrite the C++ code and incorporate them into the ROS-based system, which makes development inefficient. Therefore, the proposed framework allows models created using MATLAB/Simulink to be used in a ROS-based self-driving system, thereby improving development efficiency. Furthermore, our evaluations of the proposed framework demonstrated its practical potential.",
        "prediction": "Managing self-driving systems is getting harder as the technology improves. One way to develop these systems is by using ROS. But in the car industry, models are mostly made with MATLAB/Simulink. These models donât work with ROS systems. To use both together, the C++ code must be rewritten for ROS. This makes development slow. The new framework lets models from MATLAB/Simulink work in a ROS-based self-driving system. This boosts development speed. Our tests show that this framework has real potential.",
        "reference": "The management of self-driving systems is becoming more complex as the development of self-driving technology progresses. Self-driving systems use Robot Operating System (open-source software framework used in the development of robot applications). However, in the automotive industry, the system is designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving. These models are incompatible with systems based on Robot Operating System. To use both, it is necessary to incorporate new code into the system based on Robot Operating System, which makes development inefficient. Therefore, the proposed framework allows models created using MATLAB/Simulink to be used in a self-driving system, which improve development efficiency. Furthermore, our evaluations of the proposed framework demonstrated its practical potential."
      },
      {
        "source": "Ensuring the safety of self-driving cars is important, but neither industry nor authorities have settled on a standard way to test them. Deploying self-driving cars for testing in regular traffic is a common, but costly and risky method, which has already caused fatalities. As a safer alternative, virtual tests, in which self-driving car software is tested in computer simulations, have been proposed. One cannot hope to sufficiently cover the huge number of possible driving situations self-driving cars must be tested for by manually creating such tests. Therefore, we developed AsFault, a tool for automatically generating virtual tests for systematically testing self-driving car software. We demonstrate AsFault by testing the lane keeping feature of an artificial intelligence-based self-driving car software, for which AsFault generates scenarios that cause it to drive off the road. A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw",
        "prediction": "Ensuring self-driving cars are safe is very important. Right now, there is no agreed way to test them by both the industry and authorities. Testing self-driving cars in real traffic is common but it is also expensive and can be dangerous. There have even been accidents with fatalities. A safer option is to use virtual tests. These tests use computer simulations to check the car software. It is hard to cover all possible driving scenarios by creating tests manually. So, we created a tool called AsFault. AsFault automatically makes virtual tests for checking self-driving car software. We show how AsFault works by testing the lane-keeping feature of AI-based self-driving car software. AsFault creates scenarios that make the car drive off the road. You can watch a video of AsFault in action at: https://youtu.be/lJ1sa42VLDw",
        "reference": "Ensuring the safety of self-driving cars is important, but there is no standard way to test them. Testing self-driving cars in regular traffic is costly and risky, and has already caused fatalities. As a safer alternative, virtual tests (self-driving car software tested in computer simulations) have been proposed. To cover the huge number of possible driving situations, self-driving cars must be tested in manually created tests. We developed AsFault, a tool for automatically generating virtual tests for testing self-driving car software. We demonstrate AsFault by testing the lane keeping feature of a self-driving car software with scenarios going off the road. A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw"
      },
      {
        "source": "With the developing of the technology on self-driving, more and more L3 driverless vehicles are launched in market, people get opportunities to experience the self-driving cars in their daily life. As a result, there is a growing demand for the autopilot experience. Natural and efficient human-computer interaction can not only improve the driving experience, but also accelerate the process of self-driving commercialization. This paper discusses eye-movement interaction, voice interaction and gesture interaction in self-driving car, and analyzes the technology, advantages and disadvantages of the existing interaction modes, and prospect the future development trend of self-driving human-computer interaction.",
        "prediction": "As technology for self-driving cars improves, more L3 driverless vehicles are available on the market. People can now experience self-driving cars in their daily lives. This has led to a higher demand for autopilot features. Good interaction between humans and computers can make driving easier and help self-driving cars become more common. This paper looks at eye movement, voice, and gesture interactions in self-driving cars. It examines the technology, pros and cons of these interaction methods, and discusses future trends in self-driving human-computer interactions.",
        "reference": "Self-driving technology is developing, more and more driverless vehicles are launched in market and accessible for people in their daily life. So there is a growing demand for the autopilot experience. Natural and efficient human-computer interaction can improve the driving experience and accelerate the process of self-driving commercialization. This paper discusses interactions with the eye, voice and gesture in self-driving car, analyzes the technology, the interaction modes, and considers the future of self-driving human-computer interaction."
      },
      {
        "source": "In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems. Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on highfidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle. It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios. The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1]. In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using vision-based imitation learning we obtain safer self-driving behavior.",
        "prediction": "Self-driving cars are becoming more common on roads. They promise to make transportation safer and more efficient. To ensure these cars work well, we need to do many software tests. These tests should happen on advanced simulators where multiple cars and people interact with the self-driving car. It is very important to test self-driving software in different tough driving situations. Most of the best self-driving companies still use humans to create these driving scenarios. In this paper, we suggest using Bayesian optimization to automate this process. This method creates difficult scenarios that can reveal problems in the self-driving software or training. These scenarios also increase the chance of collisions with virtual people and cars. We show that adding these scenarios to the training set and refining the software using vision-based imitation learning leads to safer self-driving behavior.",
        "reference": "Self-driving vehicles have become common on public roads, with the promise of a safe and efficient mode of transport. To be reliable, these vehicles need many software tests on simulators with interactions of multiple vehicles and pedestrians. It is essential that self-driving software is evaluated with many different challenging driving scenarios. The driving scenario generation still needs human contribution. We propose to automate the process and generate conflicting self-driving that expose weaknesses of self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. By incorporating the generated scenarios into the parameters of the self-driving policy, and by adjusting the policy with the imitation learning, we obtain safer self-driving behavior."
      },
      {
        "source": "At the brink of the introduction of self-driving vehicles, only little is known about how potential users perceive them. This is especially true for self-driving vehicles deployed in public transport services. In this study, the relative preferences for a trip with a self-driving bus is assessed compared to a trip with a regular bus, based on a stated preference experiment. Based on the responses of 282 respondents from the Netherlands and Germany, a discrete choice model is estimated as a Mixed Logit model including attitudes towards trust in self-driving vehicles and interest in technology. The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips. This is due to the finding that the value of travel time is about twice as high for the self-driving bus as for the regular bus for a short commuting trip. Findings from this study further suggest that the popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes. People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others. Preferences towards automated public transport services are expected to evolve along with the transition from demonstration pilots to their deployment in regular operations.",
        "prediction": "Self-driving vehicles are about to be introduced, but not much is known about how people feel about them. This is especially true for self-driving buses used in public transport. This study looks at how people prefer trips on self-driving buses compared to regular buses. We collected responses from 282 people in the Netherlands and Germany and used a Mixed Logit model to analyze attitudes like trust and interest in technology. The results show that public transport users prefer self-driving buses for short trips. This is because the value of travel time is almost twice as high for self-driving buses as for regular buses on short commutes. The study also finds that people prefer self-driving buses less when a human steward is present or when the buses operate on fixed routes. People who are interested in technology or trust automated vehicles view self-driving buses more positively. As self-driving public transport becomes more common, people's preferences are expected to change.",
        "reference": "Little is known about how potential users perceive self-driving vehicles. This is especially true for self-driving vehicles in public transport services. In this study, the preferences between a trip in a self-driving bus and a regular bus were compared. The results of 282 participants were studied, including trust in self-driving vehicles and interest in technology. The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips. The preference is about twice as high for the self-driving bus as for the regular bus for a short commuting trip. The popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes. People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others. Preferences for automated public transport services are expected to evolve with their deployment in regular operations."
      },
      {
        "source": "In the wake of the on-going digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions. While the benefits of this transformation can be massive, there are also tremendous risks to our society. After the automation of many production processes and the creation of self-driving vehicles, the automation of society is next. This is moving us to a tipping point and to a crossroads: we must decide between a society in which the actions are determined in a top-down way and then implemented by coercion or manipulative technologies (such as personalized ads and nudging) or a society, in which decisions are taken in a free and participatory way and mutually coordinated. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. The fundaments of human dignity, autonomous decision-making, and democracies are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies, but also the basis of greater efficiency and success.",
        "prediction": "The digital revolution is changing our economy and society. These changes can bring many benefits but also big risks. We have automated production and created self-driving cars. Next, we are automating society. This puts us at a key moment. We must choose between two types of societies. One has decisions made from the top down with force or tricks like personalized ads. The other has decisions made freely by everyone together. Modern technology can support both choices, but the second option is better for the economy and strategy. Our human rights, freedom to make choices, and democracy are in danger. We need to protect these values because they are essential for good societies and lead to better efficiency and success.",
        "reference": "The on-going digital revolution will dramatically transform our economy and societal institutions. But this also presents risks for our society. Automation of society is coming. We must choose either between a society in which the actions are determined top-down by coercion or manipulative technologies (such as personalized ads) or in which decisions are taken freely and cooperatively. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. Foundations of human dignity, autonomous decision-making, and democracies are weakening. These core principles of society and the basis of greater efficiency and success need to be defended."
      },
      {
        "source": "This paper addresses the financial markets problem space with particular emphasis on trading systems seen in banking today. With the advent of modern computing, cross-regional trading transactions can now be executed within milliseconds, a reality that is impossible without the advancements of software systems technology. We then move on and discuss the anatomy of a trading system and how it fits in with the banks ecosystem of vital inter-working components.",
        "prediction": "This paper looks at financial markets, especially trading systems in banks today. Modern computers allow trading across regions to happen in milliseconds. This speed would not be possible without new software technology. We will also discuss what makes up a trading system and how it works with other important parts in banks.",
        "reference": "This paper addresses problems of trading systems in banking. Modern computing allows cross-regional trading transactions within milliseconds. We then discuss how a trading system fits in with the bank ecosystem."
      },
      {
        "source": "In this paper we present queueing-theoretical methods for the modeling, analysis, and control of autonomous mobility-on-demand MOD systems wherein robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure acceptable quality of service throughout the network. We first cast an autonomous MOD system within a closed Jackson network model with passenger loss. The theoretical insights are used to design a robust, real-time rebalancing algorithm, which is applied to a case study of New York City and implemented on an eight-vehicle mobile robot testbed. The case study of New York shows that the current taxi demand in Manhattan can be met with about 8,000 robotic vehicles roughly 70% of the size of the current taxi fleet operating in Manhattan. Finally, we extend our queueing-theoretical setup to include congestion effects, and study the impact of autonomously rebalancing vehicles on overall congestion. Collectively, this paper provides a rigorous approach to the problem of system-wide coordination of autonomously driving vehicles, and provides one of the first characterizations of the sustainability benefits of robotic transportation networks.",
        "prediction": "This paper looks at ways to model, analyze, and control autonomous mobility-on-demand (MOD) systems. In these systems, self-driving cars transport customers in cities and move themselves to keep service quality high. We use a closed Jackson network model to represent an autonomous MOD system that can lose passengers. This helps us create a smart rebalancing algorithm for real-time use. We apply this to a case study in New York City with an eight-car robot testbed. The study shows that around 8,000 robotic vehicles can meet Manhattan's taxi demand. This is about 70% of the current taxi fleet size. We also consider traffic effects and examine how self-rebalancing vehicles affect congestion. Overall, this paper offers a strong method for coordinating self-driving vehicles and highlights the sustainability benefits of robotic transport networks.",
        "reference": "Queueing models are used for autonomous mobility-on-demand MOD systems. A queueing model is constructed so that queue lengths and waiting time can be predicted. In MOD systems,  robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure quality of service. We first cast an autonomous MOD system within a closed Jackson network model,a class of queueing network, with passenger loss. A real-time rebalancing algorithm is applied to a case study of New York City. It is implemented on an eight-vehicle mobile robot testbed. The current taxi demand in Manhattan can be met with about 8,000 robotic vehicles. It represents roughly 70% of the size of the current taxi fleet in Manhattan. Congestion effects are also included to study the impact of autonomously rebalancing vehicles on overall traffic jams. This paper describes the sustainability benefits of robotic transportation networks."
      },
      {
        "source": "Many model based techniques have been proposed in the literature for applying domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation. However sensor based robot control overcomes many of the difficulties of uncertain models and unknown environments which limit the domain of application of the previous methods. Furthermore, for service and manipulation tasks, it is more suitable to study the interaction between the robot and its environment at the contact point using the sensor based control, rather than specifying the joint positions and velocities required to achieve them.",
        "prediction": "Many techniques using models have been suggested for domestic tasks on humanoid robots. These include teleoperation, learning from demonstration, and imitation. However, sensor-based robot control solves many problems with uncertain models and unknown environments. This makes it better for different tasks. For service and manipulation jobs, it is more useful to look at the robot-environment interaction at the contact point. This is better than just focusing on the joint positions and speeds needed for tasks.",
        "reference": "Model based techniques exist to apply domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation. Sensor based robot control overcomes difficulties of uncertain models and unknown environments. Interaction between the robot and its environment using the sensor based control is important."
      },
      {
        "source": "Inaccurate information, in the field of library and information science, is often regarded as a problem that needs to be corrected or simply understood as either misinformation or disinformation without further consideration. Misinformation and disinformation, however, may cause significant problems for users in online environments, where they are constantly exposed to an abundance of inaccurate and/or misleading information. This paper aims to establish conceptual groundwork for future empirical research by examining the relationships among information, misinformation, and disinformation. Our analysis extends to a discussion of cues to deception, as means for detecting misinformation and disinformation. We argue that misinformation and disinformation are related yet distinct sub-categories of information. Misinformation is a multifaceted concept, more complex than simply being inaccurate or incomplete, and disinformation does not always entail misinformation.",
        "prediction": "In library and information science, wrong information is a big problem. It is often called misinformation or disinformation. Misinformation and disinformation can create serious issues for users online. People see a lot of wrong or misleading information every day. This paper looks at how information, misinformation, and disinformation are related. We also discuss ways to spot false information. We believe misinformation and disinformation are similar but different types of information. Misinformation is complicated and goes beyond just being wrong or incomplete. Disinformation isnât always the same as misinformation.",
        "reference": "Inaccurate information is often regarded as a problem that needs to be corrected or simply understood as misinformation or disinformation without further consideration. Misinformation and disinformation may cause problems online because users are constantly exposed to inaccurate and/or false information. This paper aims to establish preliminary work for future research by examining the relationships among information, misinformation, and disinformation. Our analysis extends to a discussion of means for detecting misinformation and disinformation. We argue that misinformation and disinformation are related but distinct sub-categories of information. Misinformation is more complex than simply being inaccurate or incomplete, and disinformation does not always involve misinformation."
      },
      {
        "source": "The growth of social media provides a convenient communication scheme for people, but at the same time it becomes a hotbed of misinformation. The wide spread of misinformation over social media is injurious to public interest. We design a framework, which integrates collective intelligence and machine intelligence, to help identify misinformation. The basic idea is: (1) automatically index the expertise of users according to their microblog contents; and (2) match the experts with given suspected misinformation. By sending the suspected misinformation to appropriate experts, we can collect the assessments of experts to judge the credibility of information, and help refute misinformation. In this paper, we focus on expert finding for misinformation identification. We propose a tag-based method to index the expertise of microblog users with social tags. Experiments on a real world dataset demonstrate the effectiveness of our method for expert finding with respect to misinformation identification in microblogs.",
        "prediction": "Social media makes it easy for people to communicate. However, it also spreads misinformation. This spread can hurt the public. We created a system that uses both human and machine intelligence to spot misinformation. The key ideas are: (1) automatically organize users' expertise based on their posts and (2) connect experts with questionable information. By sending this information to the right experts, we can get their opinions to check if the information is true and help correct the misinformation. This paper looks at how to find experts for identifying misinformation. We suggest a method using tags to organize users' expertise. Tests on real data show that our method works well for finding experts to help with misinformation in social media.",
        "reference": "The growth of social media leads to better communication between people, but also propagation of misinformation. The wide spread of misinformation over social media have bad consequences for public interest. We design a framework to help identify misinformation. The idea is to index the expertise of users and to match the experts with given suspected misinformation. By sending the suspected misinformation to appropriate experts, they can judge the credibility of information, and help refute misinformation. In this paper, we focus on finding appropriate experts for misinformation identification. We propose a method to index the expertise of users with tags. Experiments on a real world dataset demonstrate the effectiveness of our method for expert finding for misinformation identification."
      },
      {
        "source": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the scarcity of misinformation in support of such research. This paper aims to address the aforementioned challenges by conceptualizing misinformation and enabling the interoperability of misinformation. In particular, a representation and a model of misinformation are proposed through surveying, synthesizing, and explicating existing work in the field. The ontology-supported misinformation model can not only guide future misinformation research but also lay the foundation for building a digital misinformation library by advancing our knowledge on misinformation and by improving its sharing, management, and reuse. In addition, we present a formal methodology for managing misinformation in a digital library, and suggest future research directions related to the misinformation model.",
        "prediction": "Research on misinformation is very important. However, this research faces two big problems. First, there are not enough theoretical models. Second, there is not enough misinformation available for study. This paper aims to solve these problems by defining misinformation and making it easier to use. We propose a way to represent and model misinformation by looking at and explaining current work in this area. The new misinformation model can help guide future research and create a digital library of misinformation. This will improve our understanding of misinformation and help with sharing, managing, and reusing it. We also present a formal method for managing misinformation in a digital library and suggest future research ideas related to the misinformation model.",
        "reference": "The importance of research on misinformation has received wide recognition. Two major challenges faced by this research community are the lack of theoretical models and the rare misinformation data. This paper aims to address these challenges by conceptualizing misinformation and being able to completely understand and work on misinformation. A representation and a model of misinformation are proposed through existing work in the field. The model can guide future misinformation research and help building a digital misinformation library by advancing our knowledge on misinformation and by improving its sharing, management, and reuse. In addition, we present a methodology for managing misinformation in a digital library, and suggest future research directions."
      },
      {
        "source": "Online Social Networks OSNs have become increasingly popular means of information sharing among users. The spread of news regarding emergency events is common in OSNs and so is the spread of misinformation related to the event. We define as misinformation any false or inaccurate information that is spread either intentionally or unintentionally. In this paper we study the problem of misinformation identification in OSNs, and we focus in particular on the Twitter social network. Based on user and tweets characteristics, we build a misinformation detection model that identifies suspicious behavioral patterns and exploits supervised learning techniques to detect misinformation. Our extensive experimental results on 80294 unique tweets and 59660 users illustrate that our approach effectively identifies misinformation during emergencies. Furthermore, our model manages to timely identify misinformation, a feature that can be used to limit the spread of the misinformation.",
        "prediction": "Online Social Networks OSNs are popular for sharing information Users use OSNs to share news about emergencies but also spread false information We define misinformation as any false or wrong information that is shared on purpose or by mistake In this paper we study how to identify misinformation in OSNs with a focus on Twitter We create a model that detects misinformation based on user and tweet features This model looks for unusual behaviors and uses supervised learning techniques to find misinformation We tested our model on 80294 unique tweets and 59660 users Our results show that our approach effectively identifies misinformation during emergencies Our model can also quickly find misinformation which helps reduce its spread",
        "reference": "Social media have become popular means of information sharing. The spread of news regarding emergency events is common in social media but so is the spread of misinformation. Misinformation is any false or inaccurate information that is spread intentionally or not. In this paper we study the problem of misinformation identification in social media, and we focus in particular on Twitter. We build a misinformation detection model that identifies suspicious behavioral patterns and detect misinformation. We found 80294 unique tweets and 59660 users. It illustrates that our approach identifies misinformation during emergencies. Our model manages to timely identify misinformation, it can be used to limit the spread of the misinformation."
      },
      {
        "source": "The advent of WWW changed the way we can produce and access information. Recent studies showed that users tend to select information that is consistent with their system of beliefs, forming polarized groups of like-minded people around shared narratives where dissenting information is ignored. In this environment, users cooperate to frame and reinforce their shared narrative making any attempt at debunking inefficient. Such a configuration occurs even in the consumption of news online, and considering that 63% of users access news directly form social media, one hypothesis is that more polarization allows for further spreading of misinformation. Along this path, we focus on the polarization of users around news outlets on Facebook in different European countries (Italy, France, Spain and Germany). First, we compare the page posting behavior and the users interacting patterns across countries and observe different posting, liking and commenting rates. Second, we explore the tendency of users to interact with different pages (i.e., selective exposure) and the emergence of polarized communities generated around specific pages.",
        "prediction": "The World Wide Web has changed how we create and find information. Recent studies show that people often choose information that matches their beliefs. This leads to groups of people with similar views who ignore differing information. In these groups, users work together to support their shared ideas, making it hard to change minds. This happens even with online news. Since 63% of people get news from social media, one idea is that more polarization helps spread false information. We focus on how users become polarized around news on Facebook in Italy, France, Spain, and Germany. First, we look at how often people post and interact with content in different countries. We see different rates of posting, liking, and commenting. Second, we study how users choose which pages to interact with and how polarized communities form around specific pages.",
        "reference": "The WWW changed the ways we can produce and access information. Users tend to select information that agrees with their beliefs. They form polarized groups of like-minded people sharing narratives that ignore contradicting information. Here, users reinforce their shared narratives and can resist debunking This is the case with online news. Because 63% of users access news from social media, polarization could increase misinfomation spread. We focus on polarisation of Facebook news consumers in different European countries. Posting, liking and commenting rates differ across countries. We look at how users interact with different pages and polarized communities form around specific pages."
      },
      {
        "source": "We find that Italy is the most polarized country, followed by France, Germany and lastly Spain. Finally, we present a variation of the Bounded Confidence Model to simulate the emergence of these communities by considering the usersu0027 engagement and trust on the news. Our findings suggest that trust in information broadcaster plays a pivotal role against polarization of users online.",
        "prediction": "Italy is the most polarized country. Next is France, then Germany, and lastly Spain. We made a change to the Bounded Confidence Model. This helps us see how communities form. We looked at how users engage with and trust news. Our results show that trust in news sources is very important in reducing polarization among users online.",
        "reference": "Italy is the most polarized country, then France, Germany and Spain. A variant of the Bounded Confidence Model simulates the emergence of these communities by considering user engagement and trust in the news. Trust in an information source plays a major role against polarization of users online."
      },
      {
        "source": "Online social media provide users with unprecedented opportunities to engage with diverse opinions. We discuss the policy implications of our model, highlighting the downside of debunking strategies and suggesting alternative strategies to contrast misinformation. Simultaneously, they allow the spread of misinformation by empowering individuals to self-select the narratives they want to be exposed to, both through active (confirmation bias) and passive (personalized news algorithms) self-reinforcing mechanisms. A precise theoretical understanding of such trade-offs is still largely missing. We introduce a stylized social learning model where most participants in a network update their beliefs unbiasedly based on the arrival of new information, while a fraction of participants display confirmation bias, enabling them to reject news that are incongruent with their pre-existing beliefs. We show that this simple confirmation bias mechanism can generate permanent opinion polarisation. Furthermore, the model results in states where unbiased agents behave \"as if\" they were biased, due to their biased neighbours effectively functioning as gatekeepers, restricting their access to free and diverse information. We derive analytic results for the distribution of individual agentsâ beliefs, explicitly demonstrating the aforementioned trade-off between confirmation bias and social connectivity, which we further validate against US county-level data on the impact of Internet access on the formation of beliefs about global warming. Our findings indicate that confirmation bias in small doses may actually result in improved accuracy across individuals by preserving information diversity in a social network. However, results also indicate that when confirmation bias grows past an optimal value, accuracy declines as biased agents restrict information flow to subgroups.",
        "prediction": "Online social media give users new chances to hear different opinions. We talk about the rules that come from our model. We focus on the downsides of debunking misinformation and suggest other ways to fight it. Social media also help spread misinformation. They let users choose which stories to see. This happens through two ways: active ways like confirmation bias and passive ways like personalized news feeds. We lack a clear understanding of these trade-offs. \n\nWe present a simple social learning model. Most people in a network change their beliefs based on new information without bias. But some people show confirmation bias and reject news that doesnât match their beliefs. This bias can lead to permanent division in opinions. Our model shows that even unbiased people can act biased because their biased neighbors limit their access to varied information. \n\nWe find clear results about how individual beliefs are shared. This shows the trade-off between confirmation bias and social connections. We also confirm our findings with data from U.S. counties on how Internet access affects beliefs about global warming. Our results suggest that a little confirmation bias can help people by keeping diverse information in a social network. However, too much confirmation bias can hurt accuracy as biased people limit information flow to small groups.",
        "reference": "Social media give users opportunities to interact with different opinions. We discuss the meaning of our model for policy and the downsides of myth-busting We suggest alternatives to fight misinformation. But misinformation is spread via social media because individuals can search for information that confirms their beliefs and personalized news algorithms may supply it. Theoretical understanding of the balance between opportunities and misinformation is incomplete. We introduce a stylized social learning model. In this model, most participants in a network update their beliefs based on new information, while others show confirmation bias and can reject news that differs from their beliefs. This simple confirmation bias mechanism can create lasting opinion polarisation. Besides, in the model, unbiased people behave âas ifâ biased because biased neighbours limit their access to diverse information. With our model, we show the trade-off between confirmation bias and social connectivity. We validated the model using the data on how internet access influences beliefs on global warming. Small confirmation bias may even improve accuracy across individuals by keeping information diversity in a social network. But large confirmation bias lowers accuracy as biased individuals limit information flow to others."
      },
      {
        "source": "Superintelligence is a potential type of future artificial intelligence (AI) that is significantly more intelligent than humans in all major respects. If built, superintelligence could be a transformative event, with potential consequences that are massively beneficial or catastrophic. Meanwhile, the prospect of superintelligence is the subject of major ongoing debate, which includes a significant amount of misinformation. Superintelligence misinformation is potentially dangerous, ultimately leading bad decisions by the would-be developers of superintelligence and those who influence them. This paper surveys strategies to counter superintelligence misinformation. Two types of strategies are examined: strategies to prevent the spread of superintelligence misinformation and strategies to correct it after it has spread. In general, misinformation can be difficult to correct, suggesting a high value of strategies to prevent it. The strategies proposed can be applied to lay public attention to superintelligence, AI education programs, and efforts to build expert consensus.",
        "prediction": "Superintelligence is a future type of artificial intelligence that is much smarter than humans. If created, it could change everything, with both great benefits and serious risks. There is a lot of debate about superintelligence, and many people share false information about it. This misinformation can lead to bad choices by those working on superintelligence. This paper looks at ways to fight misinformation about superintelligence. It examines two kinds of strategies: ways to stop misinformation from spreading and ways to fix it after it has spread. Misinformation is hard to correct, so it is important to have ways to prevent it. The suggested strategies can help inform the public, improve AI education, and build agreement among experts.",
        "reference": "Superintelligence is a potential future artificial intelligence (AI) significantly more intelligent than humans. Superintelligence could be a major event, with potential consequences that are beneficial or catastrophic. The prospect of superintelligence is the subject of major debate, which includes a lot of misinformation. Superintelligence misinformation could be dangerous, and lead to bad decisions by the people that could work on the project. This paper searches for strategies to counter superintelligence misinformation. Two strategies are examined: to prevent the spread of misinformation and to correct it after it has spread. Misinformation can be difficult to correct, so preventing it seems to be the best strategy. The strategies proposed can be used to bring public attention to superintelligence, AI education programs, and efforts to build expert consensus."
      },
      {
        "source": "The widespread online misinformation could cause public panic and serious economic damages. The misinformation containment problem aims at limiting the spread of misinformation in online social networks by launching competing campaigns. Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem for the case when an arbitrary number of cascades are allowed. First, we provide a formal model for multi-cascade diffusion and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of $\\\\Omega(2^{\\\\log^{1-\\\\epsilon}n^4})$ in polynomial time unless $NP \\\\subseteq DTIME(n^{\\\\polylog{n}})$. Third, we introduce several types of cascade priority that are frequently seen in real social networks. Finally, we design novel algorithms for solving the misinformation containment problem. The effectiveness of the proposed algorithm is supported by encouraging experimental results.",
        "prediction": "Online misinformation can lead to public panic and big economic harm. The misinformation containment problem helps limit the spread of false information on social networks by starting competing campaigns. We analyze this problem when many cascades can happen at once. First, we create a formal model for multi-cascade diffusion and explain a key idea called cascade priority. Second, we show that it is hard to solve the misinformation containment problem quickly unless certain conditions are met. Third, we present different types of cascade priority often seen in real social networks. Finally, we develop new algorithms to tackle the misinformation containment problem. Our experimental results show that these algorithms work well.",
        "reference": "The online misinformation could cause public panic and serious economic damages. The goal of misinformation containment is to limit the spread of misinformation in online social networks by launching campaigns to counter misinformation. We present the first analysis of the misinformation containment problem with a random number of cascades (people observe the actions of others and then make the same choice) allowed. First, we provide a diffusion model and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of Î©(2log1âÏµn4) in polynomial time unless $NP \\subseteq DTIME(n^{\\polylog{n}})$ Third, we introduce several types of cascade priority that are frequently seen in social networks. Finally, we design algorithms for solving the misinformation containment problem. The proposed algorithm is effective and shows encouraging results."
      },
      {
        "source": "Yet contemporary work in Philosophy argues provisional belief in conspiracy theories isâat the veryâleast understandable (because conspiracies occur) and if we take an evidential approachâjudging individual conspiracy theories on their particular meritsâbelief in such theories turns out to be warranted in a range of cases. Drawing on this work, I examine the kinds of evidence typically associated with conspiracy theories, showing that the evidential problems typically associated with conspiracy theories are not unique to such theories. As such, if there is a problem with the conspiracy theoristâs use of evidence, it is one of principle: is the principle which guides their use of evidence somehow in error? I argue that whatever we might think about conspiracy theories generally, there is no prima facie case for a scepticism of conspiracy theories based purely on their use of evidence.",
        "prediction": "Some modern philosophers say that believing in conspiracy theories is at least understandable because conspiracies do happen. If we look at the evidence for each conspiracy theory, some beliefs can be justified. I will look at the types of evidence often linked to conspiracy theories. I will show that the problems with evidence for these theories are not special to them. If conspiracy theorists misuse evidence, it is a question of principle: is their way of using evidence wrong? I argue that we should not be skeptical of conspiracy theories just because of how they use evidence.",
        "reference": "To believe in conspiracy theories is understandable as conspiracies occur and if we take an evidential approach, belief in such theories turns out to be warranted in a range of cases. Drawing on this work, I examine evidence associated with conspiracy theories, showing that the evidential problems are not unique to conspiracy theories. The problem with the use of evidence of conspiracy theorist could be the principle which guides their use of it. I argue that there is no ground to be suspicious of conspiracy theories as a whole, because those are based on evidence."
      },
      {
        "source": "Conspiracy theories have gained much academic and media attention recently, due to their large impact on public events. However, little is known about how conspiracy theories are produced and developed on social media. We present a qualitative study of conspiracy theorizing on Reddit during a public health crisis--the Zika virus outbreak. Using a mixed-methods approach including content analysis and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the Zika crisis, the conditions under which Zika conspiracy theories emerge, and the particular discursive strategies through which Zika conspiracy theories developed in online forums. Our analysis shows that conspiracy talk emerged as people attempted to make sense of a public health crisis, reflecting their emergent information needs and their pervasive distrust in formal sources of Zika information. Practical implications for social computing researchers, health practitioners, and policymakers are discussed.",
        "prediction": "Conspiracy theories are getting more attention from researchers and the media. They have a big effect on public events. But we know little about how these theories form on social media. We studied conspiracy theories on Reddit during the Zika virus outbreak. We used a mixed-methods approach with content analysis and discourse analysis. We found different types of conspiracy theories related to Zika and looked at the conditions that cause them to develop. Our study shows that people create conspiracy talk to understand a public health crisis. This reflects their need for information and their distrust in official sources about Zika. We discuss practical insights for researchers, health workers, and policymakers.",
        "reference": "Conspiracy theories have gained much attention recently, due to their large impact on public events. Little is known about how conspiracy theories are produced and developed on social media. We present a study of conspiracy theory creation on Reddit during a public health crisis. Using content and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the crisis, the conditions of their creation, and the strategies of their development in online forums. Our analysis shows that conspiracy talk come from people trying to make sense of a public health crisis, which reflect their information needs and their lack of confidence in formal sources of information. Implications for social computing researchers, health practitioners, and policymakers are discussed."
      },
      {
        "source": "Conspiracy theories are omnipresent in online discussions---whether to explain a late-breaking event that still lacks official report or to give voice to political dissent. Conspiracy theories evolve, multiply, and interconnect, further complicating efforts to understand them and to limit their propagation. It is therefore crucial to develop scalable methods to examine the nature of conspiratorial discussions in online communities. What do users talk about when they discuss conspiracy theories online? What are the recurring elements in their discussions? What do these elements tell us about the way users think? This work answers these questions by analyzing over ten years of discussions in r/conspiracy---an online community on Reddit dedicated to conspiratorial discussions. We focus on the key elements of a conspiracy theory: the conspiratorial agents, the actions they perform, and their targets. For example, a narrative-motif such as \\\"governmental agency-controls-communications\\\" represents the various ways in which multiple conspiratorial statements denote how governmental agencies control information. Thus, narrative-motifs expose commonalities between multiple conspiracy theories even when they refer to different events or circumstances. In the process, these representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about. Our approach enables a population-scale study of conspiracy theories in alternative news and social media with implications for understanding their adoption and combating their spread.",
        "prediction": "Conspiracy theories are common in online talks. They help explain new events or express political views. These theories change and connect with each other, making them hard to study and control. It's important to find ways to look at how people discuss conspiracy theories online. What do users say about them? What common themes can we find? What do these themes show about how users think? This study looks at over ten years of talks in r/conspiracy, a Reddit group focused on conspiracy theories. We examine key parts of a conspiracy theory: the people involved, what they do, and who they target. For instance, a common story like \"government agency-controls-communications\" shows how people believe that government groups manage information. These story patterns reveal similarities among different conspiracy theories, even if they cover various events. By studying these patterns, we can understand how users talk about conspiracy theories. Our method allows us to study these theories on a large scale in alternative news and social media. This helps us understand why people adopt them and how to combat their spread.",
        "reference": "Conspiracy theories are omnipresent in online discussions. Conspiracy theories evolve, multiply, and interconnect, complicating how to understand them and to limit their propagation. It is crucial to develop methods to examine the nature of these conspiratorial discussions. What do users talk about? What are the recurring elements in their discussions? What do these elements tell us about the way users think? This work answers these questions by analyzing over ten years of discussions in an online community on the social media Reddit dedicated to conspiratorial discussions. We focus on the key elements of a conspiracy theory: the conspiratorial agents, the actions they perform, and their targets. For example, a narrative-motif (an idea) such as \"governmental agency-controls-communications\" represents the various ways in which multiple conspiratorial statements suggest how governmental agencies control information. Narrative-motifs expose similarities between multiple conspiracy theories even when they refer to different events or circumstances. These representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about. Our approach enables a population-scale study of conspiracy theories in alternative news and social media and ways to understand them and limit their propagation."
      },
      {
        "source": "Blockchain technology is the underlying enabling technology developed for Bitcoin, the most common cryptocurrency. Blockchain technologies have become increasingly popular with the potential to become a powerful disruptive force. Individuals and organizations may benefit from blockchain with its ability to increase secure data exchange and to make that transaction simpler and easier between entities. We investigate factors that influence an individualu0027s intention to use a blockchain cryptocurrency. We develop a model of cryptocurrency adoption grounded in the theory of planned behavior (TPB) to: identify the determinants for the acceptance of cryptocurrency and explore the relative importance of each construct. We offer empirical evidence for a better theoretical understanding of cryptocurrency adoption with practical implications in an e-government context.",
        "prediction": "Blockchain technology is the base technology for Bitcoin, the most popular cryptocurrency. Blockchain is gaining popularity and could change many areas. People and businesses can benefit from blockchain because it allows secure data sharing and makes transactions easier. We look at what affects a person's decision to use blockchain cryptocurrency. We create a model of cryptocurrency use based on the theory of planned behavior to find out what influences cryptocurrency acceptance and the importance of each factor. We provide evidence to better understand cryptocurrency use, especially in e-government.",
        "reference": "Blockchain technology is a technology developed for Bitcoin, the most common cryptocurrency. Blockchain technologies have become popular with the potential to become a powerful disruptive force. People and organizations may use it to increase secure data exchange and make transactions simpler and easier. We investigate what influence people to use a blockchain cryptocurrency. We develop a model of cryptocurrency adoption to identify how cryptocurrency is accepted. Our evidence allow a better understanding of cryptocurrency adoption."
      },
      {
        "source": "With the introduction of memory-bound cryptocurrencies, such as Monero, the implementation of mining code in browser-based JavaScript has become a worthwhile alternative to dedicated mining rigs. Based on this technology, a new form of parasitic computing, widely called cryptojacking or drive-by mining, has gained momentum in the web. A cryptojacking site abuses the computing resources of its visitors to covertly mine for cryptocurrencies. In this paper, we systematically explore this phenomenon. For this, we propose a 3-phase analysis approach, which enables us to identify mining scripts and conduct a large-scale study on the prevalence of cryptojacking in the Alexa 1 million websites. We find that cryptojacking is common, with currently 1 out of 500 sites hosting a mining script. Moreover, we perform several secondary analyses to gain insight into the cryptojacking landscape, including a measurement of code characteristics, an estimate of expected mining revenue, and an evaluation of current blacklist-based countermeasures.",
        "prediction": "New memory-based cryptocurrencies like Monero let people mine using browser-based JavaScript. This has led to a rise in a practice called cryptojacking or drive-by mining. In cryptojacking, a website uses visitors' computers to mine for cryptocurrencies without their knowledge. This paper looks at this issue closely. We suggest a 3-phase analysis method to find mining scripts and study how common cryptojacking is on the top 1 million websites. We discover that cryptojacking is frequent, with about 1 in 500 sites using a mining script. We also analyze other factors, like code features, potential mining profits, and the effectiveness of current blacklist measures against cryptojacking.",
        "reference": "Memory-bound cryptocurrencies like Monero can be mined  from a browser with JavaScript, better than with a dedicated rig. However, this technology enables cryptojacking, whereby a site covertly mines for cryptocurrencies on its visitorsâ computers. We propose a new approach to identify mining scripts. The approach was evaluated on Alexa 1 websites. Cryptojacking is common, as 1 in 500 sites host a mining script. We also measured code characteristics, estimated mining revenue, and evaluated blacklist-based countermeasures."
      },
      {
        "source": "The rise of modern blockchains has facilitated the emergence of smart contracts: autonomous programs that live and run on the blockchain. Smart contracts have seen a rapid climb to prominence, with applications predicted in law, business, commerce, and governance.  contracts :[39],\"are commonly written in a high-level language such as Ethereumu0027s Solidity, and translated to compact low-level bytecode for deployment on the blockchain. Once deployed, the bytecode is autonomously executed, usually by a %Turing-complete virtual machine. As with all programs, smart contracts can be highly vulnerable to malicious attacks due to deficient programming methodologies, languages, and toolchains, including buggy compilers. At the same time, smart contracts :[39],\"are also high-value targets, often commanding large amounts of cryptocurrency. Hence, developers and auditors need security frameworks capable of analysing low-level bytecode to detect potential security vulnerabilities. In this paper, we present Vandal: a security analysis framework for Ethereum smart contracts. Vandal consists of an analysis pipeline that converts low-level Ethereum Virtual Machine (EVM) bytecode to semantic logic relations. Users of the framework can express security analyses in a declarative fashion: a security analysis is expressed in a logic specification written in the \\souffle language.",
        "prediction": "Modern blockchains have led to smart contracts. Smart contracts are self-running programs on the blockchain. They are becoming popular in law, business, trade, and government. Smart contracts are often written in high-level languages like Solidity from Ethereum. They are changed into small low-level bytecode for use on the blockchain. Once on the blockchain, the bytecode runs by itself, usually using a virtual machine. \n\nSmart contracts can be at risk of attacks due to bad programming and tools. They are also valuable targets because they can hold a lot of cryptocurrency. So developers and testers need good security tools to check the bytecode for problems. In this paper, we introduce Vandal, a security tool for Ethereum smart contracts. Vandal has a process that turns low-level Ethereum bytecode into logical relations. Users can write security checks in a simple way using the Souffle language.",
        "reference": "Smart contracts have appeared thanks to blockchain technology. These autonomous programs are used in law, business, commerce, and governance. Smart contracts are written in a high-level language such as Ethereumâs Solidity and translated to bytecode. that live and run on the blockchain are predicted in Once deployed on the blockchain, the bytecode is autonomous. Smart contracts are vulnerable to malicious attacks due to poor programming, languages and toolchains Smart contracts can command large amounts of cryptocurrency. Developers and auditors need frameworks to detect security vulnerabilities. Vandal is a security analysis framework for Ethereum smart contracts. Vandal converts Ethereum Virtual Machine bytecode to semantic logic relations. Users can express security analyses in the SoufflÃ© language."
      },
      {
        "source": "Vandal is both fast and robust, successfully analysing over 95\\% of all 141k unique contracts with an average runtime of 4.15 seconds; outperforming the current state of the art tools---Oyente, EthIR, Mythril, and Rattle---under equivalent conditions.",
        "prediction": "Vandal is quick and strong. It analyzes more than 95% of 141,000 unique contracts in about 4.15 seconds. It works better than the best tools like Oyente, EthIR, Mythril, and Rattle under the same conditions.",
        "reference": "Vandal is both efficient (95% accuracy), fast (141k in 4.15 s) and robust. It outperforms the state of the art tools like Oyente, EthIR, Mythril, and Rattle"
      },
      {
        "source": "As Bitcoinu0027s popularity has grown over the decade since its creation, it has become an increasingly attractive target for adversaries of all kinds.",
        "prediction": "As Bitcoin has become more popular over the last ten years, it has attracted many types of attackers.",
        "reference": "One of the most powerful potential adversaries is the country of China, which has expressed adversarial positions regarding the cryptocurrency and demonstrated powerful capabilities to influence it."
      },
      {
        "source": "For decentralised P2P networks, it is very important to have a mechanism in place that allows the nodes to control resource usage and prevent flooding and denial-of-service attacks with spam. In this paper, we discuss and compare the different approaches to fully decentralised resource control that are used by projects in the cryptocurrency space. The introduced methods are then applied to design a decentralised exchange for Namecoin names (or more generally, crypto assets) as an example.",
        "prediction": "Decentralised P2P networks need a way to manage resource use. This helps stop flooding and spam attacks. This paper looks at different ways to control resources in fully decentralised systems used in cryptocurrency. We then apply these methods to create a decentralised exchange for Namecoin names or other crypto assets.",
        "reference": "In decentralised P2P networks nodes need a way  to control resource usage and prevent flooding and denial-of-service attacks. We compared different approaches to decentralised resource control in cryptocurrency projects. We designed a decentralised exchange for crypto assets, for  example Namecoin names, with these methods."
      },
      {
        "source": "Cryptocurrency is a rapid developing financial technology innovation which has attracted a large number of people around the world. The high-speed evolution, radical price fluctuations of cryptocurrency, and the inconsistent attitudes of monetary authorities in different countries have triggered panic and chain reactions towards the application and adoption of cryptocurrency and have caused public security related events. In this paper, we analyze the dynamics and systemic risk of the cryptocurrency market based on the public available price history. Furthermore, consistent with public perception, our quantitative analysis reveals that the cryptocurrency market is relatively fragile and unstable.",
        "prediction": "Cryptocurrency is a fast-growing financial technology. It has attracted many people worldwide. The quick changes in prices and different views from governments cause panic and reactions to how cryptocurrency is used. These issues also lead to public safety incidents. In this paper, we study the behavior and risks of the cryptocurrency market using public price history. Our analysis shows that the cryptocurrency market is fragile and unstable.",
        "reference": "Cryptocurrency is a financial technology innovation which has attracted many people around the world. The high-speed evolution, radical price fluctuations of cryptocurrency, and the inconsistent attitudes of monetary authorities in different countries have caused panic. In this paper, we analyze the dynamics and risks of the cryptocurrency market. Consistent with public perception, our analysis reveals that the cryptocurrency market is fragile and unstable."
      },
      {
        "source": "Cryptocurrency was built initially as a possible implementation of digital currency, then various derivatives were created in a variety of fields such as financial transactions, capital management, and even nonmonetary applications. This paper aims to offer analytical insights to help understand cryptocurrency by treating it as a financial asset. We position cryptocurrency by comparing its dynamic characteristics with two traditional and massively adopted financial assets: foreign exchange and stock. Our investigation suggests that the dynamics of cryptocurrency are more similar to stock. As to the robustness and clustering structure, our analysis shows cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market.",
        "prediction": "Cryptocurrency started as a form of digital currency. Later, many different types were made for various uses like money transfers and managing assets. This paper looks at cryptocurrency to understand it better by treating it as a financial asset. We compare cryptocurrency to two common financial assets: foreign exchange and stocks. Our research shows that the behavior of cryptocurrency is more like stocks. However, when it comes to strength and market patterns, we found that the cryptocurrency market is weaker than the stock market. So, it is a high-risk financial market right now.",
        "reference": "Cryptocurrency was initially an implementation of digital currency, then derivatives were created in various fields. This paper aims to help understand cryptocurrency. We compared cryptocurrency with foreign exchange and stock. Our investigation suggests that cryptocurrency is similar to stock. Our analysis shows that cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market."
      },
      {
        "source": "The smart device owning rate such as smart phone and smart watch is higher than ever before and mobile payment has become one of the major payment methods in many different areas. At the same time, blockchain-based cryptocurrency is becoming a nonnegligible type of currency and the total value of all types of cryptocurrency has reached USD 200 billion. Therefore, it is a natural demand to support cryptocurrency payment on mobile devices. Considering the poor infrastructure and low penetration of financial service in developing countries, this combination is especially attractive. The high storage cost and payment processing latency are the two main obstacles for mobile payment using cryptocurrency. We propose two different schemes for cryptocurrency mobile payment, one involves a centralized bank and the other one does not require any centralized party. We also provide a solution for the bank to meet KYC (know your customer)/AML (antimoney laundering) compliance requirements when it is involved in cryptocurrency mobile payment processing.",
        "prediction": "Smart devices like smartphones and smartwatches are more common than ever. Mobile payment has become a key way to pay in many places. At the same time, cryptocurrency based on blockchain is getting important. The total value of all cryptocurrencies has reached 200 billion USD. This creates a strong need for mobile devices to support cryptocurrency payments. This is especially helpful in developing countries, where financial services are less available. However, high storage costs and slow payment processing are big challenges for using cryptocurrency in mobile payments. We suggest two different ways to handle cryptocurrency payments on mobile devices. One way uses a bank, and the other does not need a central party. We also offer a way for banks to follow KYC (know your customer) and AML (anti-money laundering) rules when processing cryptocurrency mobile payments.",
        "reference": "The owning rate of smart devices is higher than ever before and mobile payment has become a major payment method. Cryptocurrency is becoming an important type of currency and the total value of cryptocurrencies has reached USD 200 billion. Therefore, support of cryptocurrency payment on mobile devices is a natural demand. Considering the poor infrastructure and the low usage of financial service in developing countries, this combination is especially attractive. The high storage cost and payment processing latency are two obstacles for cryptocurrency mobile payment. We propose two solutions, one with a centralized bank and the other one without any centralized party. We also provide a solution for the bank to meet KYC (know your customer)/AML (antimoney laundering) expectations about cryptocurrency mobile payment."
      },
      {
        "source": "Motivated by recent financial crises significant research efforts have been put into studying contagion effects and herding behaviour in financial markets. Much less has been said about influence of financial news on financial markets. We propose a novel measure of collective behaviour in financial news on the Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic risk indicator. We evaluate the NCI on financial documents from large Web news sources on a daily basis from October 2011 to July 2013 and analyse the interplay between financial markets and financially related news. We hypothesized that strong cohesion in financial news reflects movements in the financial markets. Cohesiveness is more general and robust measure of systemic risk expressed in news, than measures based on simple occurrences of specific terms. Our results indicate that cohesiveness in the financial news is highly correlated with and driven by volatility on the financial markets.",
        "prediction": "Recent financial crises have led to more research on contagion effects and herding behavior in financial markets. However, less has been studied about how financial news affects these markets. We introduce a new measure called the News Cohesiveness Index (NCI). This index can show systemic risk in financial markets. We check the NCI using daily financial news from major websites between October 2011 and July 2013. We look at how financial news affects the markets. We believe that strong ties in financial news show changes in financial markets. Cohesiveness is a broader and stronger measure of systemic risk in news than just counting specific words. Our findings show that financial news cohesiveness is closely linked to market volatility.",
        "reference": "Motivated by recent financial crises, research efforts have been put into studying contagion effects (spread of market disturbances) and herding behaviour (individuals acting collectively without centralized direction) in financial markets. Much less has been said about influence of financial news on financial markets. We propose a measure of collective behaviour in financial news on the Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic risk indicator, which signals probability of financial system crises. We evaluate the NCI on financial documents from Web news sources and analyse the relation between financial markets and financial news. We hypothesized that strong cohesion in financial news reflects variations in the financial markets. Cohesiveness is a better measure of systemic risk expressed in news, than measures based on simple occurrences of specific terms. Our results show that cohesiveness in the financial news is highly correlated with variations in the financial markets."
      },
      {
        "source": "In this paper, I propose a methodology to study the comovement between the entropy of different financial markets. The entropy is derived using singular value decomposition of the components of stock market indices in financial markets from selected developed economies, i.e., France, Germany, the United Kingdom, and the United States. I study how a shock in the entropy in the United States affects the entropy in the other financial markets. I also model the entropy using a dynamic factor model and derive a common factor behind the entropy movements in these four markets.",
        "prediction": "In this paper, I suggest a method to study how different financial markets move together. I use entropy to do this. Entropy is calculated using singular value decomposition from stock market indices in developed countries like France, Germany, the UK, and the US. I analyze how a change in entropy in the US influences the entropy in other markets. I also use a dynamic factor model to understand the common factor that drives entropy changes in these four markets.",
        "reference": "In this paper, I propose a methodology to study the comovement (correlation on profits on investment) between the entropy (randomness and uncertainty) of different financial markets. The entropy is based on the components measuring the stock market in financial markets from selected developed economies (France, Germany, the United Kingdom, and the United States). I study how a shock in the entropy in the United States affects the entropy in the other financial markets. I also model the entropy using different time variables and obtain a common factor behind the entropy movements in these four markets."
      },
      {
        "source": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones, and fraudsters have evolved with them. Smartphones are packed with functionality that can easily be used for data theft or inappropriate contact with other parties - none of which passes through company-owned systems, and is to all intents and purposes 'off the grid'. Employers need to be aware of these risks when devices are issued, along with ensuring that processes are in place when suspicions are raised, explains Philip Ridley of CCL-Forensics. Detecting 'tech-savvy' corporate fraudsters is a constant game of catch-up. It's not only about playing catch-up with the intellect, motives and awareness of the e-fraudster, but also the technologies that can be misused. What's more, the methods through which the technology can be manipulated to secrete, disguise and protect fraudulent activities - all while staying away from corporate networks where they can readily be monitored and detected - are constantly evolving. This means a company's intellectual property and sensitive data is at risk of sabotage or just good old-fashioned theft.",
        "prediction": "Using mobile phone forensics to find fraud is not new. However, mobile phones have changed into smartphones. Fraudsters have also changed with them. Smartphones have many features that can help with data theft or improper contact with others. This happens outside of company systems and is hard to track. Employers need to know about these risks when giving out devices. They also need to have plans for when there are suspicions. Detecting clever corporate fraudsters is a constant challenge. It is not just about keeping up with their skills and goals. It is also about keeping up with the technology they misuse. The ways to hide and protect fraudulent actions are always changing. This means a company's important information and data are at risk of theft or sabotage.",
        "reference": "The use of mobile phone forensics to investigate fraudulent activity is nothing new. But mobile phones have evolved into smartphones, and fraudsters have evolved with them. Smartphones have functionalities that can be used for data theft or inappropriate contact with other parties. They are out of the systems of the company and are not monitored or controlled. Employers need to be aware of these risks when devices are delivered and have processes when suspicions are raised. Detecting fraudsters with computer skills is a constant game of catch-up. It's not only about playing catch-up with the cyberfraudster, but also the technologies that can be misused. Moreover, the methods assisting fraudulent activities (still out of reach of company systems) are constantly evolving. This means a company's intellectual property and sensitive data is at risk of sabotage or theft."
      },
      {
        "source": "Phishers continue to alter the source code of the web pages used in their attacks to mimic changes to legitimate websites of spoofed organizations and to avoid detection by phishing countermeasures. Manipulations can be as subtle as source code changes or as apparent as adding or removing significant content. To appropriately respond to these changes to phishing campaigns, a cadre of file matching algorithms is implemented to detect phishing websites based on their content, employing a custom data set consisting of 17,992 phishing attacks targeting 159 different brands. The results of the experiments using a variety of different content-based approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate.",
        "prediction": "Phishers change the code of web pages to look like real websites. They do this to trick people and avoid getting caught. Changes can be small code tweaks or big content changes. To fight against this, we use file matching algorithms. These algorithms check for phishing websites based on their content. We use a data set with 17,992 phishing attacks against 159 brands. Experiments show that some methods can find over 90% of phishing sites and have few false alarms.",
        "reference": "Phishers, people who attempt to trick people over the internet to steal their money, continue to modify the web pages used in their attacks to imitate websites of spoofed organizations and to avoid detection by phishing countermeasures. Manipulations can be as subtle as changing the source code, which is the programming instructions, or as apparent as adding or removing significant content. To respond to these changes to phishing campaigns, algorithms are used to detect phishing websites based on their content, employing a data set consisting of 17,992 phishing attacks targeting 159 different brands. The results of the experiments using different approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate."
      },
      {
        "source": "Mobile devices are very common in everyoneâs day-to- day life. Nowadays such devices come with many features of desktop or laptop. Hence people can use these devices for diverse applications. As the acceptability and usability of such devices are very high, there are chances that these devices can be used for illegal activities. The percentage of mobile phones or smart phones involved in cyber crimes is in hike. So it becomes necessary to digitally analyze such devices requiring cyber forensics tools. This paper discusses different types of digital evidence present in Microsoftâs Windows Mobile smart phones and an agent based approach for logically acquiring such devices. Also it describes a tool developed for forensically acquiring and analyzing Windows Mobile devices and WinCE PDAs.",
        "prediction": "Mobile devices are common in daily life. Today, these devices have many features like desktop or laptop computers. People use mobile devices for many different tasks. Because they are easy to use, there is a risk of these devices being used for illegal activities. The number of mobile phones involved in cyber crimes is increasing. This makes it important to analyze these devices using cyber forensics tools. This paper talks about different types of digital evidence in Microsoft Windows Mobile smartphones and an agent-based approach for acquiring these devices. It also describes a tool for forensically acquiring and analyzing Windows Mobile devices and WinCE PDAs.",
        "reference": "Mobile devices are very common in everyoneâs day-to-day life. Nowadays such devices come with many features of computers. People can use these devices for diverse applications. There are chances that these devices can be used for illegal activities. The percentage of mobile phones or smart phones involved in cyber crimes is increasing. So it becomes necessary to digitally analyze such devices with cyber forensics tools. This paper discusses different types of digital evidence present in Microsoftâs Windows Mobile smart phones and how to acquire such devices. Also it describes a forensic tool for acquiring and analyzing Windows Mobile devices and personal digital assistants."
      },
      {
        "source": "Detection of different types of image editing operations carried out on an image is an important problem in image forensics. It gives the information about the processing history of an image, and also can expose forgeries present in an image. There have been a few methods proposed to detect different types of image editing operations in a single framework. However, all the operations have to be known a priori in the training phase. But, in real-forensics scenarios it may not be possible to know about the editing operations carried out on an image. To solve this problem, we propose a novel deep learning-based method which can differentiate between different types of image editing operations. The proposed method classifies image patches in a pair-wise fashion as either similarly or differently processed using a deep siamese neural network. Once the network learns feature that can discriminate between different image editing operations, it can differentiate between different image editing operations not present in the training stage. The experimental results show the efficacy of the proposed method in detecting/discriminating different image editing operations.",
        "prediction": "Detecting different types of image editing is important in image forensics. It helps us understand how an image was processed and can find fake edits. Some methods exist to detect editing in one framework, but they need to know all editing types beforehand. In real life, we may not know what edits have been made. To fix this, we suggest a new deep learning method. This method can tell apart different image editing types. It looks at image patches and compares them as similarly or differently processed using a deep siamese neural network. Once the network learns the features that help identify edits, it can also detect edits that were not included in training. Our experiments show that this method is effective in detecting different image editing types.",
        "reference": "Detection of image editing is an important task in image forensics. The edit history of an image can expose forgeries in the image. Various methods have been proposed to detect image editing operations. However all of the possible types of image manipulation must be known in advance. But, in the real world, manipulations on images are sometimes unknowable. A novel deep learning-based method can distinguish between different types of image editing operations. This method uses a deep siamese neural network to compare images two by two. Using deep learning, the computer can learn to see features of edited images as compared to unedited and learn to differentiate between different image editing operations. This method works to find out what editing an image has undergone."
      },
      {
        "source": "The increasing prevalence of Internet of Things (IoT) devices has made it inevitable that their pertinence to digital forensic investigations will increase into the foreseeable future. These devices produced by various vendors often posses limited standard interfaces for communication, such as USB ports or WiFi/Bluetooth wireless interfaces. Meanwhile, with an increasing mainstream focus on the security and privacy of user data, built-in encryption is becoming commonplace in consumer-level computing devices, and IoT devices are no exception. Under these circumstances, a significant challenge is presented to digital forensic investigations where data from IoT devices needs to be analysed. This work explores the electromagnetic (EM) side-channel analysis literature for the purpose of assisting digital forensic investigations on IoT devices. EM side-channel analysis is a technique where unintentional electromagnetic emissions are used for eavesdropping on the operations and data handling of computing devices. The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require, and must result in, no modification to the target device. The literature on various EM side-channel analysis attack techniques are discussed â selected on the basis of their applicability in IoT device investigation scenarios. The insight gained from the background study is used to identify promising future applications of the technique for digital forensic analysis on IoT devices â potentially progressing a wide variety of currently hindered digital investigations.",
        "prediction": "The use of Internet of Things (IoT) devices is growing fast. This means they will be more important in digital forensic investigations in the future. IoT devices often have limited ways to connect, like USB ports or WiFi/Bluetooth. There is also a focus on security and privacy for user data. Because of this, many devices now use built-in encryption, and IoT devices do as well. This creates challenges for digital forensic investigations when analyzing data from these devices. This work looks at electromagnetic (EM) side-channel analysis to help with digital forensics on IoT devices. EM side-channel analysis is a method that listens to unintentional electromagnetic signals to gather information about the device's operations. This method is non-intrusive, meaning it does not change the device. Various EM side-channel analysis techniques are discussed based on how they can be used for investigating IoT devices. The information from this study will help find future uses of this method for digital forensic analysis on IoT devices, which may help many current investigations.",
        "reference": "Internet of Things (IoT) devices (devices connected to the internet, collecting and sharing data) will be used in digital forensic investigations in the future. These devices have limited interfaces for communication, such as USB ports or WiFi/Bluetooth wireless interfaces. Meanwhile, with an increasing focus on the security and privacy of user data, built-in encryption (which encode information) is becoming commonplace in devices. This presents a significant challenge to digital forensic investigations, where data from IoT devices needs to be analysed. This work explores the electromagnetic (EM) side-channel analysis literature for the purpose of assisting digital forensic investigations on IoT devices. EM side-channel analysis is a technique where electromagnetic emissions are used for eavesdropping on the operations and data handling of devices. The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require no modification to the target device. The literature on various EM side-channel analysis attack techniques are discussed â selected according to their applicability in IoT device investigations. The data obtained from our survey are used to identify promising future applications of the technique for digital forensic analysis on IoT devices."
      },
      {
        "source": "The malicious alteration of machine time is a big challenge in computer forensics. Performance figures show the feasibility of our proposal. Detecting such changes and reconstructing the actual timeline of events is of paramount importance. However, this can be difficult since the attacker has many opportunities and means to hide such changes. In particular, cloud computing, host and guest machine time can be manipulated in various ways by an attacker. Guest virtual machines are especially vulnerable to attacks coming from their (more privileged) host. As such, it is important to guarantee the timeline integrity of both hosts and guests in a cloud, or at least to ensure that the alteration of such timeline does not go undetected. In this paper we survey the issues related to host and guest machine time integrity in the cloud. Further, we describe a novel architecture for host and guest time alteration detection and correction/resilience with respect to compromised hosts and guests. The proposed framework has been implemented on an especially built simulator.",
        "prediction": "Changing machine time in a harmful way is a big problem in computer forensics. Our study shows that our idea can work. Finding these changes and rebuilding the actual timeline of events is very important. But this is hard because attackers can hide their actions in many ways. In cloud computing, both host and guest machine times can be manipulated by attackers. Guest virtual machines are particularly at risk from their more powerful hosts. Therefore, we need to keep the timeline safe for both hosts and guests in the cloud. Or at least, we must make sure that any changes go unnoticed. In this paper, we look at the problems related to the time integrity of hosts and guests in the cloud. We also present a new system to detect and correct time changes from compromised hosts and guests. This framework has been tested on a special simulator.",
        "reference": "Machine timestamp falsification can be used in cyber attacks. The algorithm detects manipulations effectively. That is why it is important to detect such changes and to reconstruct the actual timeline of events. However, the hacker can try to hide their tracks. In cloud computing, hackers can manipulate host and guest machine time. Guest virtual machines use computing resources provided by a physical machine called a host. Guest virtual machines are especially vulnerable to attacks coming from their host. That is why the timeline integrity of both hosts and guests in a cloud is important. Any manipulation of such a timeline should be detected. In this paper we survey the issues related to host and guest machine time integrity in the cloud. A new algorithm is proposed to detect host and guest time manipulations and to correct or reject them. A simulator has been built for this purpose."
      },
      {
        "source": "Image tampering, being readily facilitated and proliferated by todayâs digital techniques, is increasingly causing problems regarding the authenticity of images. As the most popular multimedia data, JPEG images can be easily tampered without leaving any clues; therefore, JPEG-based forensics , including the detection of double compression, interpolation, rotation, etc., has become an active research topic in multimedia forensics. Nevertheless, the interesting issue of detecting image tampering and its related operations by using the same quantization matrix has not been fully investigated. Aiming to detect such forgery manipulations under the same quantization matrix, we propose a detection method by using shift-recompression -based reshuffle characteristic features. The learning classifiers are applied for classification. Our experimental results indicate that the approach is indeed highly effective in detecting image tampering and relevant manipulations with the same quantization matrix.",
        "prediction": "Image tampering is a big problem today due to digital techniques. It affects the trustworthiness of images. JPEG images are often altered without showing any signs. This makes JPEG-based forensics important. Researchers focus on finding issues like double compression and rotation. However, using the same quantization matrix to detect tampering has not been studied enough. To address this, we suggest a new method using shift-recompression features. We use learning classifiers for classification. Our tests show that this method is effective in finding image tampering and related changes with the same quantization matrix.",
        "reference": "Image tampering has become a serious problem with the advancement of digital techniques. JPEG images can be easily manipulated without leaving any clues. This is why researchers are trying to develop methods for JPEG image manipulation detection. However, methods based on image compression techniques, like quantization, are rarely applied. To detect such manipulations, we propose a detection method to identify inconsistencies in the quantization matrix caused by the manipulation. Then machine learning algorithms are applied to detect image manipulation. Experimental results show that the approach is highly effective in detecting image tampering."
      },
      {
        "source": "In this paper, we present a novel approach to accurately calibrate the kinematic model of a humanoid based on observations of its monocular camera. Our technique estimates the parameters of the complete model, consisting of the joint angle offsets of the whole body including the legs, as well as the camera extrinsic and intrinsic parameters. Furthermore, we developed an approach to automatically select a subset of configurations for the calibration process that yields a good trade-off between the number of observations and accuracy. Further, our approach to configuration selection yields substantially better optimization results compared to randomly chosen viable configurations. Hence, our system only requires a reduced number of configurations to achieve accurate results. Our optimization is general and the implementation, which is available online, can easily be applied to different humanoids.",
        "prediction": "In this paper, we show a new way to calibrate the movement model of a humanoid robot. We use data from its monocular camera. Our method estimates key settings for the whole body, including joint angles for the legs, and also for the camera. We created a way to pick a small number of body positions that work well for calibration. This selection gives a good balance between how many observations we need and how accurate they are. Our method performs much better than choosing positions randomly. As a result, we need fewer positions to get accurate outcomes. Our optimization method is general and can be applied easily to different humanoid robots.",
        "reference": "In this paper, we present a novel approach to accurately calibrate a humanoid and its motions (robot with human form or characteristics) based on observations of its camera. Our technique estimates the parameters of the complete model, consisting of the joint angle offsets and the camera parameters. We developed an approach to automatically select configurations for the calibration process that produces a good compromise between the number of observations and accuracy. Our approach to configuration selection generates better optimization results compared to randomly chosen viable configurations. Thus, our system only requires a reduced number of configurations to achieve accurate results. Our optimization is general and the implementation, which is available online, can easily be applied to different humanoids."
      },
      {
        "source": "In this paper, we present an integrated navigation system that allows humanoid robots to autonomously navigate in unknown, cluttered environments. From the data of an onboard consumer-grade depth camera, our system estimates the robot's pose to compensate for drift of odometry and maintains a heightmap representation of the environment. Based on this model, our system iteratively computes sequences of safe actions including footsteps and whole-body motions, leading the robot to target locations. To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles. As we demonstrate in experiments with a Nao humanoid, our system leads to robust navigation in cluttered environments and the robot is able to traverse highly challenging passages.",
        "prediction": "In this paper, we describe a navigation system for humanoid robots. This system lets robots move on their own in messy places they have never seen before. It uses data from a simple depth camera that the robot has. Our system figures out the robot's position and keeps track of the height of the ground around it. It then plans safe actions for the robot, like where to step and how to move its body, to reach a specific spot. We created a new way to check for collisions while planning. This method considers the robot's shape and the obstacles in its way. In tests with a Nao humanoid robot, our system showed strong performance in difficult environments, allowing the robot to go through tough paths.",
        "reference": "In this paper, we present a navigation system that allows humanoid robots (robots with human form or characteristics) to autonomously navigate in unknown, cluttered environments. From the data of a camera which can judge depth and distance, our system estimates the robotâs position and maintains a height representation of the environment. Our system determines safe actions (including footsteps and body motions) leading the robot to target locations. To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles. As we demonstrate in experiments, our system allows the robot to navigate in clustered environments and traverse challenging passages."
      },
      {
        "source": "In this paper, we introduce an approach to efficient robot navigation through cluttered indoor environments. We propose to estimate local obstacle densities based on already detected objects and use them to predict traversal costs corresponding to potential obstacles in regions not yet observable by the robot's sensors. By taking into account the predicted costs for path planning, the robot is then able to navigate in a more foresighted manner and reduces the risk of getting stuck in cluttered regions. As the experimental results demonstrate, our method enables the robot to efficiently navigate through environments containing cluttered regions and achieves significantly shorter completion times compared to a standard approach not using any prediction.",
        "prediction": "In this paper, we present a way for robots to move safely in messy indoor spaces. We suggest measuring how many obstacles are nearby using objects the robot has already found. This helps us guess the difficulty of moving through places that the robot can't see yet. By using these guesses in planning paths, robots can avoid getting stuck in messy areas. Our tests show that this method helps robots navigate better and finish tasks much faster than methods that do not use prediction.",
        "reference": "In this paper, we introduce an approach for robot to navigate through cluttered indoor environments. We propose to estimate obstacles based on already detected objects and use them to predict potential obstacles in regions not yet observable by the robot. The robot is then able to navigate in a more anticipated manner and reduces the risk of getting stuck. Our method enables the robot to efficiently navigate through cluttered environments and faster than a standard approach not using any prediction."
      },
      {
        "source": "In many situations, users walk on typical paths between specific destinations at which the service of a mobile robot is needed. Depending on the environment and the paths, step-by-step following of the human might not be the optimal solution since better paths for the robot exist. We propose to perform a prediction about the human's future movements and use this information in a reinforcement learning framework to generate foresighted navigation actions for the robot. Since frequent occlusions of the human will occur due to obstacles and the robot's constrained field of view, the estimate about the humans's position and the prediction of the next destination are affected by uncertainty. Our approach deals with such situations by explicitly considering occlusions in the reward function such that the robot automatically considers to execute actions to get the human in its field of view. We show in simulated and real-world experiments that our technique leads to significantly shorter paths compared to an approach in which the robot always tries to closely follow the user and, additionally, can handle occlusions.",
        "prediction": "In many cases, people walk on specific paths to get to certain places where a mobile robot is needed. Following a person step-by-step may not always be the best choice since there could be better paths for the robot. We suggest predicting where the person will go next and using this information in a learning system to help the robot navigate better. The robot may lose sight of the person due to obstacles, which makes it hard to know where the person is going. Our method handles these situations by including occlusions in the reward system so the robot knows to move to see the person better. We found in tests, both simulated and real, that our method leads to shorter paths compared to when the robot just tries to keep up with the person. It can also deal with losing sight of the person.",
        "reference": "In many situations, users walk on typical paths between specific destinations at which the service of a mobile robot is needed. Depending on the environment and the paths, following the human might not be the optimal solution because better paths for the robot exist. We propose to predict the humanâs future movements and use this information to generate navigation actions for the robot. The estimation of the humanâs position and the prediction of the next destination are uncertain because of the occlusions due to obstacles and the robotâs limited field of view. Our approach deals with considering occlusions so the robot automatically considers to execute actions to get the human in its field of view. We show that our technique leads to significantly shorter paths compared to an approach in which the robot follows the user and, additionally, can handle occlusions."
      },
      {
        "source": "An autonomous service robot often first has to search for a user to carry out a desired task. This is a challenging problem, especially when this person moves around since the robotâs field of view is constrained and the environment structure typically poses further visibility constraints that influence the perception of the user. In this paper, we propose a novel method that computes the likelihood of the userâs observability at each possible location in the environment based on Monte Carlo simulations. As the robot needs time to reach the possible search locations, we take this time as well as the visibility constraints into account when computing effective search locations. In this way, the robot can choose the next search location that has the maximum expected observability of the user. Our experiments in various simulated environments demonstrate that our approach leads to a significantly shorter search time compared to a greedy approach with background information.",
        "prediction": "An autonomous service robot needs to find a user to complete a task. This is hard when the user moves around. The robot can only see a small area and the layout of the space makes it harder to spot the user. In this paper, we introduce a new method to estimate where the user is visible using Monte Carlo simulations. Since the robot takes time to reach new locations, we consider this time and visibility limits when deciding where to search next. This way, the robot picks the location that gives the best chance to see the user. Our tests in different simulated settings show that our method is much faster than a greedy approach with extra information.",
        "reference": "An autonomous service robot often first has to search for a user to execute a task. This is a challenging problem, especially when this person moves around because the robotâs field of view is limited. The environment also poses visibility limitations that influence the perception of the user. In this paper, we propose a method that estimate the userâs observability in the environment. When estimating effective search locations, we take into account the time for the robot to reach the search location and the visibility limitations. In this way, the robot can choose the next search location that has the maximum expected observability of the user. Our experiments demonstrate that our approach leads to a significantly shorter search time compared to other approach."
      },
      {
        "source": "Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments. Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions. For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information. Considering dynamic obstacles introduces another level of complexity, since they can lead to necessary replanning or collisions at later stages. In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be efficiently planned in real time at low CPU cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.",
        "prediction": "Understanding the local environment is important for mobile robots to move safely. Most robots, like humanoids and small wheeled robots, use flat areas to navigate. Humanoids need more than just a simple 2D map because they can step over and on objects. They also need to know about height. Dynamic obstacles, or moving objects, make navigation harder because they may require rethinking the path or cause crashes later. This paper presents a system that first finds flat areas in height maps and spots dynamic obstacles. Our system then creates prediction maps to plan paths quickly and efficiently. We show through tests and simulations that our system completes calculations in less than 10 milliseconds, enabling advanced real-time 3D footstep planning.",
        "reference": "Perception of the environment is necessary for mobile robots to navigate safely in dynamic environments. Most robots (humanoids and wheeled robots) rely on planar regions. For humanoids (robots with human form or characteristics), a 2D map is not sufficient because they can step over and onto objects, so they need height information. Dynamic obstacles bring another level of complexity, because it can lead to necessary replanning or collisions. In this paper, we present a framework that extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be planned in real time at low processor cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms and allows for real-time 3D footstep planning."
      },
      {
        "source": "In this paper, a lab automation drone notional concept is introduced. Here, a robotic limb is attached to a robotic rotorcraft. The limb's gripper allows the unmanned aerial vehicle to dexterously manipulate objects such as micro-arrays and test tubes often used in high throughput systems (HTS). The resulting drone could augment existing HTS operations. The 6 degree-of-freedom (DOF) arm and gripper design are presented. Test-and-evaluation approach and results are also given.",
        "prediction": "This paper introduces a concept for a lab automation drone. It has a robotic arm attached to a flying drone. The arm has a gripper that helps the drone move small items like micro-arrays and test tubes used in high throughput systems. This drone could enhance current HTS operations. The design of the 6 degree-of-freedom arm and gripper is shown. We also share our test and evaluation results.",
        "reference": "In this paper, a concept of lab automation drone is introduced. Here, a robotic arm is attached to a drone. The armâs gripper allows the drone to manipulate objects such as chips and test tubes often used in scientific experimentations like high throughput systems. The drone could augment existing high throughput systems operations. The 6 degree-of-freedom arm and gripper design are presented. Results of evaluations and tests are also given."
      },
      {
        "source": "Robot companionship has become more popular in past years. However, humanoid gait might be somewhat unstable for these applications. Even with miniature humanoids, falls occur frequently. Thus, wheel attachments have been added onto a miniature humanoid, so it can move faster and with more stability than walking. In addition, with such attachments a robot can switch from walking to rolling when necessary. DARwIn-OP is a humanoid robot that has been used as an experimentation and performance evaluation platform. This paper discusses preliminary work regarding robot companionship applications by using a miniature humanoid capable of fetching different toys based on voice command.",
        "prediction": "Robot companions are getting more popular. But humanoid walking can be unstable. Miniature humanoid robots often fall down. To fix this, some robots have wheels added. This helps them move faster and more steadily than walking. They can also switch from walking to rolling when needed. DARwIn-OP is a humanoid robot used for testing and evaluation. This paper talks about early work with robot companions using a small humanoid that fetches toys based on voice commands.",
        "reference": "Robot companionship has become more popular in past years. However, humanoid (robots with human form or characteristics) walking might be unstable. Even with miniature humanoids, falls occur frequently. Wheels have been added onto a miniature humanoid, so it can move faster and with more stability than walking. With wheels, a robot can switch from walking to rolling when necessary. DARwIn-OP is a humanoid robot that has been used for experimentation and evaluation. This paper discusses preliminary work for robot companionship applications by using a miniature humanoid capable of fetching different toys based on voice command."
      },
      {
        "source": "In the modern era of automation and robotics, autonomous vehicles are currently the focus of academic and industrial research. The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6m/sec. We present the same results in this research and compare them with other state-of-the-art methods of vision and learning based navigation. With the ever increasing number of unmanned aerial vehicles getting involved in activities in the civilian and commercial domain, there is an increased need for autonomy in these systems too. Due to guidelines set by the governments regarding the operation ceiling of civil drones, road-tracking based navigation is garnering interest. In an attempt to achieve the above mentioned tasks, we propose an imitation learning based, data-driven solution to UAV autonomy for navigating through city streets by learning to fly by imitating an expert pilot. Derived from the classic image classification algorithms, our classifier has been constructed in the form of a fast 39-layered Inception model, that evaluates the presence of roads using the tomographic reconstructions of the input frames. Based on the Inception-v3 architecture, our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning. The data used for training the system has been captured from the drone, by flying it in and around urban and semi-urban streets, by experts having at least 6-8 years of flying experience. Permissions were taken from required authorities who made sure that minimal risk (to pedestrians) is involved in the data collection process. With the extensive amount of drone data that we collected, we have been able to navigate successfully through roads without crashing or overshooting, with an accuracy of 98.44%.",
        "prediction": "In today's world of automation and robots, autonomous vehicles are a big topic for research. MAVNet helps drones fly fast, up to 6 meters per second. We share results from our research and compare them with other top methods of vision and navigation. More drones are being used in civilian and business areas, so these systems need to work by themselves. Government rules also affect how high drones can fly, making road-tracking navigation popular. To improve drone autonomy for city flying, we suggest a learning method where drones imitate expert pilots. Our fast 39-layer Inception model checks for roads using images captured by the drone. Based on the Inception-v3 structure, our system is more efficient and accurate than other learning models. We trained our system with data collected from expert pilots, each with 6 to 8 years of flying experience. We made sure to follow rules to keep pedestrians safe during data collection. With the drone data collected, we successfully navigated roads without crashes, achieving an accuracy of 98.44%",
        "reference": "Current academic and industrial research is interested in autonomous vehicles. MAVNet computational efficiency enables the drone to fly up to 6m/sec. The solution is compared with other recent methods. Drones are increasingly used in the civilian and commercial domain and need to be autonomous. Governments set guidelines on the operation ceiling of civil drones. So, road-tracking based navigation is attracting interest. Researchers propose data-driven solutions allowing drones to autonomously navigate city streets, learning to fly by imitating an expert pilot. The algorithm, based on the Inception model, detects roads using tomographic reconstructions. The Inception model is an extension of classic image classification algorithms. The Inception-v3 architecture has better accuracy than many existing models of imitation learning. The data used for training the system was captured from the drone over urban streets, navigated by an expert pilot. Data collection requires special permission to ensure pedestrian security. The drone can navigate successfully through roads without crashing or overshooting; its accuracy is 98.44%."
      },
      {
        "source": "Advances in electronics and sensor technology have widened the scopes of networked drones to include applications as diverse as surveillance, video recording, operations, entertainment/advertising, signal emission, transportation, and delivery. These applications and services require video recording for their operations. Large drones are used singly in missions while small ones are used in formations or swarms. The small drones are proving to be useful in civilian applications. Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones. To develop group display applications, a real-time drone formation control for group display is proposed. Simulation shows that drone formation can display messages effectively.",
        "prediction": "Improvements in electronics and sensors have expanded the use of networked drones. They can now do many things like surveillance, video recording, entertainment, transportation, and delivery. These functions need video recording to work. Large drones often go on missions alone, while small drones can fly together in groups. Small drones are helpful for public uses. Using small drones for group flight and other tasks has led to the use of networked drones. A new real-time control system for drone formations is suggested for group displays. Tests show that these drone formations can effectively show messages.",
        "reference": "Advances in technology allowed drones to be used for surveillance, video recording, operations, entertainment/advertising, signal emission, transportation, and delivery. These applications and services require video recording. Large drones are used individually while small ones are used in groups. The small drones are proving to be useful in civilian applications. Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones. To develop group display applications, a real-time drone formation control for group display is proposed. Simulation shows that drone formation can display messages effectively."
      },
      {
        "source": "This study focuses on the digital marketing capabilities of tourism SMEs. The study addresses the question of how the use of ICT-based tools benefit the organisational capabilities of a company. By adopting marketing as a set-of-skills approach, the study provides new insights into the existing tourism literature on e-marketing. Initial findings indicate that the digital marketing capabilities of companies are transformed through ICT-based uptake. Four major capabilities were identified, each of which evolves as a result of using the tools. A key finding of the study is that the use of ICT-based tools transforms digital marketing capabilities from a set of abilities that enables tourism SMEs not only to float in a web-marketing stream, but also to lead such a stream.",
        "prediction": "This study looks at how tourism small and medium enterprises (SMEs) use digital marketing. It asks how ICT tools help these companies improve their skills. By viewing marketing as a skill set, the study offers new ideas about e-marketing in tourism. Early results show that using ICT tools changes the digital marketing skills of these companies. Four main skills were found, each growing from using these tools. A key result is that ICT tools help tourism SMEs not just keep up with web marketing but also lead in it",
        "reference": "This study focuses on the digital marketing capabilities of tourism small and medium-sized enterprises (SMEs). The study questions on how information and communication technology (ICT) tools can help the organisational capabilities of a company. The study provides new insights from tourism studies on digital marketing. Findings show that digital marketing capabilities of companies are transformed by ICT tools. Four major capabilities were identified, each of which evolves as a result of using the tools. A key finding of the study is that ICT tools transform these capabilities in a set of abilities for SMEs in web-marketing."
      },
      {
        "source": "The prevalence and rapid development of the Internet and mobile technology in recent decades has revamped our living styles and daily habits. To ride on the digital trend, more business activities have been engaged in the digital world. Marketing and advertising is one of typical business areas that is transformed digitally. The rise of Key Opinion Leaders (KOLs), social media platforms, and Omni-channel retailing have attracted countless business entities to consider the adoption of digital marketing tools for promoting and advertising their brands and products. However, with the increasing diversity of the types of digital marketing tools, they must be carefully selected based on a multiple number of criterion. In this paper, a fuzzy-AHP method is proposed and developed for assisting industry practitioners in systematically and effectively evaluate and select proper digital marketing tool(s) for adoption. The developed method not only streamlines the internal business process of digital marketing tool selection, but it also increases the practitioner's effectiveness of achieving the pre-defined strategic marketing objectives.",
        "prediction": "The Internet and mobile technology have changed how we live and work in recent years. Many businesses are now shifting to digital platforms. Marketing and advertising are key areas that have gone digital. The rise of Key Opinion Leaders, social media, and online retail has led many businesses to use digital marketing tools for promoting their brands and products. With so many digital marketing tools available, companies need to choose the right ones carefully. This paper presents a method called fuzzy-AHP to help businesses evaluate and select the best digital marketing tools. This method makes the selection process easier and helps businesses achieve their marketing goals more effectively",
        "reference": "The development of the Internet and mobile technology in recent decades has modified our living styles and daily habits. More business activities have been engaged in the digital world. Marketing and advertising is one of typical business areas that is transformed digitally. Many businesses consider the adoption of digital marketing tools for their promotion and advertisement, due to the rise of Key Opinion Leaders (person with expert status and influence), social media platforms, and Omni-channel retailing (multiple channels but a uniform experience for the customer). However, with the increasing diversity of digital marketing tools, they must be carefully selected. In this paper, a method to organize and analyze complex decisions is proposed and developed for assisting businesses to evaluate and select appropriate digital marketing tools. The developed method rationalizes and simplifies the process of digital marketing tool selection. It also increases effectiveness of achieving strategic marketing objectives."
      },
      {
        "source": "In this paper we revisit a topic originally discussed in 1955, namely the lack of direct evidence that muscle hypertrophy from exercise plays an important role in increasing strength. To this day, long-term adaptations in strength are thought to be primarily contingent on changes in muscle size. Given this assumption, there has been considerable attention placed on programs designed to allow for maximization of both muscle size and strength. However, the conclusion that a change in muscle size affects a change in strength is surprisingly based on little evidence. We suggest that these changes may be completely separate phenomena based on: (1) the weak correlation between the change in muscle size and the change in muscle strength after training; (2) the loss of muscle mass with detraining, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load resistance training, yet divergent results in strength.",
        "prediction": "This paper looks at a topic that started in 1955. It questions whether muscle growth from exercise really helps increase strength. Many believe that long-term strength changes depend mainly on muscle size. Because of this belief, there is a lot of focus on exercise programs that aim to increase both muscle size and strength. However, the idea that bigger muscles mean more strength has little evidence to back it up. We suggest that muscle size and strength changes may not be linked. This is based on: (1) the weak relationship between muscle size changes and strength changes after training, (2) loss of muscle mass when not training but keeping strength, and (3) similar muscle growth seen in both low-weight and high-weight training, but different strength results.",
        "reference": "In this paper we revisit a topic originally discussed in 1955, namely the lack of evidence that muscle growth plays an important role in increasing strength. To this day, long-term adaptations in strength are thought to be related to changes in muscle size. Given this assumption, training programs made for increasing both muscle size and strength were popular. However, the conclusion that a change in muscle size has an influence on strength is surprisingly based on little evidence. We suggest that these changes may be based on: (1) the weak correlation between the change in muscle size and the change in muscle strength after training; (2) the loss of muscle mass with the interruption of training, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load strength training, yet different results in strength."
      },
      {
        "source": "Low-intensity occlusion (50-100 mm hg) training provides a unique beneficial training mode for promoting muscle hypertrophy. Training at intensities as low as 20% 1 repetition maximum with moderate vascular occlusion results in muscle hypertrophy in as little as 3 weeks. A typical exercise prescription calls for 3 to 5 sets to volitional fatigue with short rest periods. The metabolic buildup causes positive physiologic reactions, specifically a rise in growth hormone that is higher than levels found with higher intensities. Occlusion training is applicable for those who are unable to sustain high loads due to joint pain, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts.",
        "prediction": "Low-intensity occlusion training uses pressure of 50-100 mm hg. It helps muscles grow bigger, known as hypertrophy. You can train with weights that are as light as 20% of your max. In just 3 weeks, this can lead to muscle growth. A common exercise routine includes 3 to 5 sets until you feel tired, with short rest breaks. This type of training builds up important substances in the body. It increases growth hormone more than traditional high-intensity training. Occlusion training is good for people who can't lift heavy weights. This includes those with joint pain, recovering from surgery, in heart rehab, athletes easing off, and astronauts.",
        "reference": "Low-intensity occlusion training, which is a training method with blood flow restriction, provides a unique beneficial training mode for muscle growth. Training at intensities as low as 20% of maximum strength with moderate occlusion results in muscle growth in 3 weeks. A typical exercise consists of 3 to 5 sets to muscle failure with short rest periods. The metabolic accumulation causes positive physiologic reactions, specifically a rise in growth hormone, which is one of the main hormone responsible of muscle growth, that is higher than levels found with higher intensities. Occlusion training is applicable for those who are unable to sustain high loads due to joint pain, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts."
      },
      {
        "source": "Current dogma suggests aerobic exercise training has minimal effect on skeletal muscle size. We and others have demonstrated that aerobic exercise acutely and chronically alters protein metabolism and induces skeletal muscle hypertrophy. These findings promote an antithesis to the status quo by providing novel perspective on skeletal muscle mass regulation and insight into exercise-countermeasures for populations prone to muscle loss.",
        "prediction": "Current belief is that aerobic exercise does not change muscle size much. However, we and others have shown that aerobic exercise affects protein metabolism both in the short and long term. This leads to bigger skeletal muscles. Our findings challenge the traditional view and give new insights on how muscle mass is controlled and how exercise can help people at risk of losing muscle.",
        "reference": "Current belief suggests cardio exercise training has minimal effect on muscle size. We and others have demonstrated that cardio exercise alters protein metabolism (responsible for protein synthesis and muscle growth) and induces muscle growth. These findings against the current belief provide a novel perspective on muscle mass regulation and insight into exercise to prevent muscle loss."
      },
      {
        "source": "Stretch training is widely used in a variety of fitness-related capacities such as increasing joint range of motion, preventing contractures and alleviating injuries. Moreover, some researches indicate that stretch training may induce muscle hypertrophy; however, studies on the topic have been primarily relegated to animal and in vitro models. The purpose of this brief review was to evaluate whether stretch training is a viable strategy to induce muscle hypertrophy in humans. Of the 10 studies identified, 3 observed some significantly positive effects of stretch training on muscle structure. Intriguingly, in these studies, the stretching was carried out with an apparatus that aided in its performance, or with an external overload. Of the 5 available studies that integrated stretching into a resistance training programme, 2 applied the stretching in the interset rest period and were the ones that showed enhanced muscle growth. In conclusion, passive, low-intensity stretch does not appear to confer beneficial changes in muscle size and architecture; alternatively, albeit limited evidence suggests that when stretching is done with a certain degree of tensile strain (particularly when loaded, or added between active muscle contractions) may elicit muscle hypertrophy.",
        "prediction": "Stretch training is common in fitness. It helps improve joint movement, prevent tight muscles, and reduce injuries. Some research suggests stretch training might help muscles grow bigger. However, most studies have been done on animals or in labs. This review looked at if stretch training can help muscle growth in humans. Out of 10 studies, 3 found good results for muscle structure. These studies used special equipment or added weight while stretching. Of 5 studies that combined stretching with resistance training, 2 did stretching during breaks and showed more muscle growth. In conclusion, gentle stretching alone does not seem to make muscles bigger. However, some evidence suggests that stretching with added weight or during muscle contractions may help muscle growth.",
        "reference": "Stretch training is used in a variety of fitness capacities such as increasing flexibility, preventing contractures (shortening of muscle) and reduce injuries. Moreover, some researches indicate that stretch training may induce muscle growth. The purpose of this review was to evaluate if stretch training is a viable strategy to induce muscle growth in humans. Of the 10 studies identified, 3 observed positive effects of stretch training on muscles. In these studies, the stretching was performed with external help like equipment or load. Of the 5 available studies that integrated stretching into strength training, 2 applied the stretching in the rest period between the sets and were the ones that showed enhanced muscle growth. In conclusion, passive, low-intensity stretch does not appear to produce beneficial changes in muscles but evidence suggests that when stretching is done with a certain intensity (particularly when loaded, or added between active muscle contractions), it may induce muscle growth."
      },
      {
        "source": "Cycle training is widely performed as a major part of any exercise program seeking to improve aerobic capacity and cardiovascular health. However, the effect of cycle training on muscle size and strength gain still requires further insight, even though it is known that professional cyclists display larger muscle size compared to controls. Therefore, the purpose of this review is to discuss the effects of cycle training on muscle size and strength of the lower extremity and the possible mechanisms for increasing muscle size with cycle training. It is plausible that cycle training requires a longer period to significantly increase muscle size compared to typical resistance training due to a much slower hypertrophy rate. Cycle training induces muscle hypertrophy similarly between young and older age groups, while strength gain seems to favor older adults, which suggests that the probability for improving in muscle quality appears to be higher in older adults compared to young adults. For young adults, higher-intensity intermittent cycling may be required to achieve strength gains. It also appears that muscle hypertrophy induced by cycle training results from the positive changes in muscle protein net balance.",
        "prediction": "Cycle training is an important part of exercise programs. It helps improve aerobic capacity and heart health. However, we still need to understand how cycle training affects muscle size and strength. We know that professional cyclists have bigger muscles than others. This review will look at how cycle training affects the muscles in the lower body and how it might increase muscle size.\n\nCycle training may take longer to increase muscle size than regular weight training. This is because the muscles grow more slowly with cycling. Cycle training helps both young and older people build muscle. However, older adults may gain strength more easily. This suggests that older adults might improve muscle quality better than young adults. Young adults may need to do higher-intensity cycling to gain strength. \n\nCycle training seems to increase muscle size by improving the balance of muscle protein in the body.",
        "reference": "Cycling training is performed as a major part of any training program which objective is to improve cardiovascular capacities and health. However, the effect of cycling training on muscle size and strength still requires a better comprehension. Therefore, the purpose of this review is to discuss the effects of cycling training on muscle size and strength of the legs and the possible mechanisms for increasing muscle size with cycling training. It is plausible that cycling training requires a longer period to significantly increase muscle size compared to strength training due to a much slower muscle growth rate. Cycling training induces muscle growth similarly between young and older people, while strength gain seems to favor older adults. For young adults, series of high-intensity cycling may be required to achieve strength gains. It also appears that muscle growth induced by cycling training results from the positive changes in protein balance, which is the balance between protein intake which leads to muscle growth and protein loss which leads to muscle loss)."
      },
      {
        "source": "Resistance training is the most effective method to increase muscle mass. It has also been shown to promote many health benefits. Although it is deemed safe and of clinical relevance for treating and preventing a vast number of diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies. Similarly, an inverted U-shaped relationship between training dose/volume and physiological response has been hypothesized to exist. However, the majority of available evidence supports a clear dose-response relationship between resistance training volume and physiological responses, such as muscle hypertrophy and health outcomes. Additionally, there is a paucity of data to support the inverted U-shaped response. The overarching principle argued herein is that volume is the most easily modifiable variable that has the most evidenced-based response with important repercussions, be these muscle hypertrophy or health-related outcomes.",
        "prediction": "Resistance training is the best way to increase muscle mass. It also offers many health benefits. It is safe and helps prevent many diseases. Many studies focus on exercise that takes less time and works well. There may be a pattern like an inverted U where more training leads to different results. Most research shows there is a clear link between how much you train and your body's response, such as muscle growth and health benefits. There is not much evidence for the inverted U pattern. The main idea is that the amount of training is easy to change and has proven effects on muscle growth and health outcomes.",
        "reference": "Strength training is the most effective method to increase muscle mass. It has also been shown to promote many health benefits. Although it is helpful for treating and preventing diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies. Similarly, an inverted U-shaped relationship (which means that the efficiency increases until a point, and then starts decreasing) between training volume and physiological response has been hypothesized to exist. However, evidence supports a clear correlation between resistance training volume (number of exercises, sets, etc.) and physiological responses, such as muscle growth and health outcomes. Additionally, there is a lack of data to support the inverted U-shaped response. The principle suggested is that volume is the most easily modifiable variable that has the most important response, for muscle growth or health outcomes."
      },
      {
        "source": "Although the effects of short versus long inter-set rest intervals in resistance training on measures of muscle hypertrophy have been investigated in several studies, the findings are equivocal and the practical implications remain unclear. Current evidence indicates that both short and long inter-set rest intervals may be useful when training for achieving gains in muscle hypertrophy. Novel findings involving trained participants using measures sensitive to detect changes in muscle hypertrophy suggest a possible advantage for the use of long rest intervals to elicit hypertrophic effects. However, due to the paucity of studies with similar designs, further research is needed to provide a clear differentiation between these two approaches.",
        "prediction": "Many studies have looked at how short and long rest times between sets affect muscle growth in resistance training. The results are not clear, and it's hard to know what this means for training. Evidence shows that both short and long rest times can help build muscle. Some new studies with trained people suggest that long rest times might work better for muscle growth. But since there are not many studies with the same setup, more research is needed to understand these two methods better.",
        "reference": "The effects of short versus long rest intervals between sets in strength training on muscle growth have been investigated in several studies but the findings and the practical implications are unclear. Current evidence indicates that both short and long rest intervals may be useful for muscle growth. Novel findings suggest for trained people a possible advantage for the use of long rest intervals to induce muscle growth. However, due to the lack of studies with similar methodologies, further research is needed to provide a clear differentiation between these two approaches."
      },
      {
        "source": "Memory is a process in which information is encoded, stored, and retrieved. For vertebrates, the modern view has been that it occurs only in the brain. This review describes a cellular memory in skeletal muscle in which hypertrophy is 'remembered' such that a fibre that has previously been large, but subsequently lost its mass, can regain mass faster than naive fibres. A new cell biological model based on the literature, with the most reliable methods for identifying myonuclei, can explain this phenomenon. According to this model, previously untrained fibres recruit myonuclei from activated satellite cells before hypertrophic growth. Even if subsequently subjected to grave atrophy, the higher number of myonuclei is retained, and the myonuclei seem to be protected against the elevated apoptotic activity observed in atrophying muscle tissue. Fibres that have acquired a higher number of myonuclei grow faster when subjected to overload exercise, thus the nuclei represent a functionally important 'memory' of previous strength. This memory might be very long lasting in humans, as myonuclei are stable for at least 15 years and might even be permanent. However, myonuclei are harder to recruit in the elderly, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice.",
        "prediction": "Memory is how we encode, store, and retrieve information. In vertebrates, it has been thought that memory happens only in the brain. This review shows a type of memory in skeletal muscle. When muscles grow bigger, they can \"remember\" this growth. If a muscle fiber gets smaller but has been big before, it can grow back faster than new fibers. A new model explains this by looking at myonuclei, which are important for muscle growth. Fibers that havenât trained before can get myonuclei from activated satellite cells before they grow larger. Even if they lose size later, they keep more myonuclei. These myonuclei are protected from cell death that happens in shrinking muscles. Fibers with more myonuclei grow quickly with exercise overload, showing that myonuclei are like a memory of past strength. This memory may last a long time in humans, as myonuclei can stay stable for at least 15 years, possibly forever. However, it is harder to get new myonuclei in older people. If this muscle memory really exists in humans, early strength training should be recommended for public health.",
        "reference": "Memory is a process in which information is encoded, stored, and retrieved. For vertebrates, it has been said that it occurs only in the brain. This review describes a cellular memory in muscles in which muscle growth is 'remembered' such that a fibre that has lost its mass, can regain it faster than untrained fibres. A new model, with the most reliable methods for identifying myonuclei (nuclei in muscle fiber), can explain this phenomenon. According to this model, previously untrained fibres recruit myonuclei from activated satellite cells (quiescent cells acting as a reserve population of cells for regeneration of muscle) before muscle growth. Even after grave muscle loss, the higher number of myonuclei is retained, and the myonuclei seem to be protected against programmed cell death observed during muscle loss. Fibres that have acquired a higher number of myonuclei grow faster during strength exercise, thus the nuclei represent a functionally important 'memory' of previous strength. This memory might be very long lasting in humans, as myonuclei are stable for at least 15 years and might even be permanent. However, myonuclei are harder to recruit for old people, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice."
      },
      {
        "source": "It has been hypothesized that eating small, frequent meals enhances fat loss and helps to achieve better weight maintenance. Several observational studies lend support to this hypothesis, with an inverse relationship noted between the frequency of eating and adiposity. The purpose of this narrative review is to present and discuss a meta-analysis with regression that evaluated experimental research on meal frequency with respect to changes in fat mass and lean mass. Feeding frequency was positively associated with reductions in fat mass and body fat percentage as well as an increase in fat-free mass. However, sensitivity analysis of the data showed that the positive findings were the product of a single study, casting doubt as to whether more frequent meals confer beneficial effects on body composition. In conclusion, although the initial results of this meta-analysis suggest a potential benefit of increased feeding frequencies for enhancing body composition, these findings need to be interpreted with circumspection.",
        "prediction": "Eating small meals often may help with losing fat and keeping a healthy weight. Some studies suggest that eating more often is linked to less body fat. This review looks at a study that analyzed research about meal frequency and its effects on fat and lean mass. Eating more often was linked to less fat and a lower body fat percentage, as well as more muscle mass. However, further analysis showed that the positive results came from just one study. This raises questions about whether eating more meals truly helps body composition. In conclusion, while the initial results hint at benefits from eating more frequently, these findings should be viewed carefully.",
        "reference": "It has been hypothesized that eating small, frequent meals enhances fat loss and helps for better weight maintenance. Several studies support this hypothesis, with a link between the frequency of eating and being overweight. This review aims to present and discuss a research on meal frequency with respect to changes in body mass. Eating frequency was positively associated with reductions in fat mass and increasing in fat-free mass. However, the positive findings were the product of a single study, leaving a doubt about the beneficial effect of frequent meals on body composition. In conclusion, although the initial results suggest a potential benefit of increased eating frequencies for enhancing body composition, these findings need to be carefully interpreted."
      },
      {
        "source": "Inactive adults experience a 3% to 8% loss of muscle mass per decade, accompanied by resting metabolic rate reduction and fat accumulation. Ten weeks of resistance training may increase lean weight by 1.4 kg, increase resting metabolic rate by 7%, and reduce fat weight by 1.8 kg. Benefits of resistance training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem. Resistance training may assist prevention and management of type 2 diabetes by decreasing visceral fat, reducing HbA1c, increasing the density of glucose transporter type 4, and improving insulin sensitivity. Resistance training may enhance cardiovascular health, by reducing resting blood pressure, decreasing low-density lipoprotein cholesterol and triglycerides, and increasing high-density lipoprotein cholesterol. Resistance training may promote bone development, with studies showing 1% to 3% increase in bone mineral density. Resistance training may be effective for reducing low back pain and easing discomfort associated with arthritis and fibromyalgia and has been shown to reverse specific aging factors in skeletal muscle.",
        "prediction": "Inactive adults lose 3% to 8% of muscle mass every ten years. They also have a lower resting metabolic rate and gain more fat. Ten weeks of resistance training can add 1.4 kg of lean weight, raise resting metabolic rate by 7%, and cut fat weight by 1.8 kg. \n\nResistance training has many benefits. It improves physical performance, movement control, walking speed, independence, brain function, and self-esteem. It can help prevent and manage type 2 diabetes by lowering visceral fat and HbA1c. It also boosts glucose transporter type 4 and improves insulin sensitivity.\n\nResistance training is good for heart health. It can lower blood pressure, decrease bad cholesterol (LDL) and triglycerides, and raise good cholesterol (HDL). \n\nThis training can help bones grow stronger. Studies show a 1% to 3% increase in bone mineral density. It may also help reduce low back pain and ease discomfort from arthritis and fibromyalgia. \n\nResistance training can reverse some aging effects in muscles.",
        "reference": "Per decade, inactive adults experience a muscle loss of 3% to 8%, a reduction of resting metabolic rate (energy consumed by the body at rest) and fat accumulation. Ten weeks of strength training may increase fat-free mass by 1.4 kg, resting metabolic rate by 7%, and reduce fat weight by 1.8 kg. Benefits of strength training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem. Strength training may assist prevention and management of type 2 diabetes by decreasing abdominal fat, reducing HbA1c which is a form of hemoglobin linked to a sugar, increasing the density of glucose transporter type 4, and improving insulin sensitivity. Strength training may enhance cardiovascular health, by reducing resting blood pressure, decreasing 'bad' cholesterol and triglycerides (main constituents of body fat), and increasing 'good' cholesterol. Strength training may promote bone development, with studies showing 1% to 3% increase in bone mineral density. Strength training may be effective for reducing low back pain, joint and muscle pain, and reverse specific aging factors in muscles."
      },
      {
        "source": "We hypothesized that compared to post-exercise protein intake, co-ingestion of alcohol would down-regulate translation initiation signaling and decrease rates of MPS.",
        "prediction": "We think that having alcohol with protein after exercise will lower translation initiation signaling and reduce muscle protein synthesis rates",
        "reference": "We assumed that consumption of protein and alcohol (compared to protein only) would reduce protein synthesis."
      },
      {
        "source": "Eight healthy physically active male subjects (age 21.4Â±4.8 yr, body mass (BM) 79.3Â±11.9 kg, peak oxygen uptake (VO2peak) 48.1Â±4.8 mLÂ·kgâ1Â·minâ1, leg extension one repetition maximum (1RM) 104Â±20 kg; values are mean Â± SD) who had been participating in regular exercise (3 times wkâ1 for >6 months) volunteered for this study.",
        "prediction": "Eight healthy active male subjects aged about 21 years participated in this study. They weighed around 79 kg and had a peak oxygen uptake of about 48 mL per kg per minute. Their leg extension strength was about 104 kg. They exercised regularly, three times a week for over six months.",
        "reference": "Eight healthy physically active men (3 trainings per week for at least 6 months) volunteered for this study."
      },
      {
        "source": "The study employed a randomized counter-balanced, cross-over design in which each subject completed bouts of consecutive resistance, continuous and intermittent high-intensity exercise with either post-exercise ingestion of alcohol-carbohydrate (ALC-CHO), alcohol-protein (ALC-PRO) or protein only (PRO) beverages on three separate occasions.",
        "prediction": "The study used a randomized design. Each participant did exercises that included resistance and high-intensity workouts. They had these workouts with drinks after exercising. The drinks were alcohol with carbohydrates, alcohol with protein, or just protein. Each participant had these drinks on three different days.",
        "reference": "Subjects did high intensity exercise and just after consumed an alcohol-carbohydrate, an alcohol-protein or a protein drink in three separate occasions."
      },
      {
        "source": "Resistance exercise consisted of eight sets of five repetitions at â¼80% of 1RM.",
        "prediction": "Resistance exercise included eight sets of five reps at about 80% of the maximum weight you can lift once",
        "reference": "Training consisted of eight sets of five repetitions of leg extension at 80% of their maximum strength."
      },
      {
        "source": "After completion of the final set, subjects rested for 5 min before commencing 30 min of continuous cycling at â¼63% PPO (â¼70% VO2peak).",
        "prediction": "After finishing the last set, the participants rested for 5 minutes. Then, they started cycling for 30 minutes at about 63% of their Peak Power Output. This is around 70% of their maximum oxygen uptake.",
        "reference": "After 5 minutes rest, subjects cycled for 30 minutes at medium intensity,"
      },
      {
        "source": "Upon completion, subjects rested on the bike for 2 min before undertaking 10Ã30 s high intensity intervals at â¼110% of PPO, with 30 s active recovery (â¼50% PPO) between each work bout.",
        "prediction": "After finishing, the subjects relaxed on the bike for 2 minutes. Then they did 10 sets of 30 seconds of hard work at about 110% of their best effort. Between each set, they had 30 seconds of easier activity at about 50% of their best effort.",
        "reference": "then 5 minutes at high intensity."
      },
      {
        "source": "Immediately following exercise and after 4 h recovery, subjects ingested a 500 mL solution of either protein (PRO, 25 g whey protein powder; ISO8, Musashi, Melbourne, VIC Australia) or an energy-match in the form of CHO (25 g maltodextrin, International Health Investments, Helensvale, QLD Australia).",
        "prediction": "After exercise and a 4-hour rest, the subjects drank a 500 mL solution. This solution was either protein or carbs. The protein used was 25 g of whey protein powder from Musashi. The carbs were 25 g of maltodextrin from International Health Investments.",
        "reference": "Immediately following exercise and after 4 h recovery, subjects consumed a 500mL drink of protein or carbohydrates."
      },
      {
        "source": "Furthermore, a CHO-based meal (1.5 gÂ·kgâ1 BM) was consumed â¼2 h post-exercise, immediately after the muscle biopsy, according to recommendations for post-exercise glycogen recovery [24].",
        "prediction": "A CHO meal with 1.5 grams per kilogram of body mass was eaten about 2 hours after exercise. This meal was taken right after the muscle biopsy. This follows the advice for recovering glycogen after exercise.",
        "reference": "A carbohydrate meal was consumed 2 h after exercise, according to recommendation for glycogen recovery."
      },
      {
        "source": "The 8 h time frame represents an important phase of post-exercise recovery [1] as well as the period during which blood alcohol concentrations are likely to be elevated by a post-event drinking binge [14].",
        "prediction": "The 8-hour time frame is important for recovery after exercise. It is also the time when blood alcohol levels are likely high from drinking after an event.",
        "reference": "The 8 h period after exercise is an important phase for recovery but also the period during which blood alcohol level may be the highest after excessive consumption of alcohol."
      },
      {
        "source": "The alcohol ingestion protocol (1.5 gÂ·kgâ1 BM; 12Â±2 standard drinks) began 1 h post-exercise and was consumed in 6 equal volumes of 1 part vodka (â¼60 mL) to four parts orange juice (â¼240 mL, 1.8 g CHOÂ·kgâ1 BM) during a 3 h period.",
        "prediction": "The alcohol drinking plan started 1 hour after exercise. Each person drank 1.5 grams per kilogram of body mass, which is about 12 drinks. The drink was mixed with 1 part vodka and 4 parts orange juice. This mix was consumed in 6 equal portions over 3 hours.",
        "reference": "The alcohol consumption started 1 h after exercise with 6 drinks (60mL of vodka and 240mL of orange juice) and during 3 h."
      },
      {
        "source": "The focus of the early post-exercise period (i.e., 1â8 h) is to enhance physiological processes that are critical for reversing the exercise-induced disturbances to homeostasis and physiological function and for promoting adaptations to training [1].",
        "prediction": "The early post-exercise period is 1 to 8 hours after working out. This time is important for helping the body recover and return to balance. It helps fix any problems caused by exercise. It also supports the body in adapting to training.",
        "reference": "The period after exercise (1-8h) enhances the body's processes that reverse the effects of the exercise and promotes adaptation to the training."
      },
      {
        "source": "For the PRO condition, orange juice was consumed with a matched volume of water in place of the alcohol.",
        "prediction": "In the PRO condition, people drank orange juice and the same amount of water instead of alcohol.",
        "reference": "For the protein drink, orange juice was consumed with water instead of alcohol."
      },
      {
        "source": "Subjects ingested the beverages within 5 min every 30 min.",
        "prediction": "Subjects drank the beverages within 5 minutes every 30 minutes",
        "reference": "Subjects consumed the drinks in 5 minutes every 30 minutes."
      },
      {
        "source": "Blood, cell signaling and mRNA data were analyzed by two-way ANOVA (two factor: time Ã treatment) with repeated measures and myofibrillar protein synthesis was analyzed by one-way ANOVA with repeated measures.",
        "prediction": "We studied blood, cell signaling, and mRNA data using two-way ANOVA. This method looks at two factors: time and treatment. We also used one-way ANOVA to analyze myofibrillar protein synthesis with repeated measures.",
        "reference": "Data (blood, protein synthesis, responses, etc.) were analyzed several times for the 3 different consumptions of drinks."
      },
      {
        "source": "The first novel finding of this study was that mTOR signaling and rates of myofibrillar protein synthesis (MPS) following concurrent resistance, continuous and intermittent high-intensity exercise, designed to mimic the metabolic profile of many team sports, were impaired during the early (8 h) recovery phase by the ingestion of large amounts (1.5 gâ¢kgâ1 BM) of alcohol.",
        "prediction": "This study found that mTOR signaling and myofibrillar protein synthesis were affected after exercise. Both resistance training and high-intensity exercise were used, similar to what is done in team sports. Drinking a lot of alcohol, about 1.5 grams per kilogram of body mass, hurt recovery in the first 8 hours.",
        "reference": "The first finding of this study was that the mTOR enzyme (responsible for muscle growth) and protein synthesis (after exercise) were reduced by an excessive alcohol consumption during the 8 h period of recovery."
      },
      {
        "source": "These outcomes were most evident (37% reduction in rates of MPS) when alcohol was consumed in the absence of post-exercise protein intake, as is likely to occur when intoxication reduces the athlete's compliance to sound recovery practices.",
        "prediction": "These results showed a 37% drop in MPS rates when alcohol was drunk without protein after exercise. This likely happens when being drunk makes it hard for athletes to follow good recovery practices.",
        "reference": "Consequences were most evident when alcohol was consumed without protein (37 % reduction of protein synthesis)."
      },
      {
        "source": "However, a second finding was that even when protein was consumed in amounts shown to be optimally effective to stimulate MPS [8] during post-exercise recovery, the intake of alcohol reduced MPS by â¼24%, representing only a partial ârescueâ of the anabolic response compared with protein alone.",
        "prediction": "A second finding was that when people consumed enough protein to help muscle protein synthesis (MPS) after exercise, drinking alcohol still reduced MPS by about 24%. This means that alcohol only partly helped the body recover compared to just protein alone.",
        "reference": "A second finding was that even with protein consumption, alcohol reduced protein synthesis by around 24%."
      },
      {
        "source": "The mechanistic target of rapamycin complex 1 (mTORC1) is a central node for integrating nutrient (i.e. amino acid) and exercise/contraction signal transduction [31], [32].",
        "prediction": "mTORC1 is an important part of how cells respond to nutrients like amino acids and exercise signals",
        "reference": "mTOR is important in absorption of nutrients (like amino acids) and in sending signals to the body to produce an effort."
      },
      {
        "source": "In conclusion, the current data provide the novel observation that alcohol impairs the response of MPS in exercise recovery in human skeletal muscle despite optimal nutrient provision.",
        "prediction": "In conclusion, the data show a new finding. Alcohol affects how MPS works during exercise recovery in human muscle, even when nutrients are adequate.",
        "reference": "The data from this study show that alcohol reduce the protein synthesis after exercise even with an optimal consumption of nutrients."
      },
      {
        "source": "The quantity of alcohol consumed in the current study was based on amounts reported during binge drinking by athletes.",
        "prediction": "The amount of alcohol used in this study came from reports of binge drinking by athletes",
        "reference": "The quantity of alcohol consumed in this study was based on consumption by athletes during binge drinking."
      },
      {
        "source": "However, published reports suggest intakes of some individuals can be significantly greater [9], [50], which is of concern for many reasons related to health and safety [13].",
        "prediction": "Some people may take in much more than what's normal This is worried about for many health and safety reasons",
        "reference": "However, reports show that some individuals can consume higher quantities, which is a concern for health and safety issues."
      },
      {
        "source": "Recommended nutritional strategies to maximize recovery in skeletal muscle include protein for enhancing rates of protein synthesis and carbohydrate for replenishing glycogen stores [2],[3].",
        "prediction": "To help muscles recover, eat protein to boost protein creation and carbohydrates to restore glycogen levels",
        "reference": "Nutritional strategies to optimize muscle recovery include proteins which are recommended to allow protein synthesis (production of new proteins which improve, for example, muscle mass) and carbohydrates to recharge glycogen stores (energy storage)."
      },
      {
        "source": "Regrettably, there has been difficulty in finding an educational message with alcohol consumption related to sports performance that has resonance with athletes.",
        "prediction": "It has been hard to find a clear message about alcohol use and sports performance that connects with athletes",
        "reference": "Regrettably, it is difficult to find an educational message about alcohol consumption and sport performances that speaks to athletes."
      },
      {
        "source": "Given the need to promote protein synthesis that underpins adaptation, repair and regeneration of skeletal muscle the results of the current study provide clear evidence of impaired recovery when alcohol is consumed after concurrent (resistance, continuous and intermittent high-intensity) exercise even in the presence of optimal nutritional conditions.",
        "prediction": "The study shows that drinking alcohol after intense exercise can hurt muscle recovery. This is true even when nutrition is good. Protein synthesis is important for muscle adaptation, repair, and regeneration.",
        "reference": "Considering the importance of protein synthesis (adaptation, repair and regeneration of muscles), the results of this study provide evidence of reduced recovery when alcohol is consumed after exercise, even with an optimal consumption of nutrients."
      },
      {
        "source": "We propose our data is of paramount interest to athletes and coaches.",
        "prediction": "Our data is very important to athletes and coaches",
        "reference": "We consider our data crucial for athletes and coaches."
      },
      {
        "source": "Our findings provide an evidence-base for a message of moderation in alcohol intake to promote recovery after exercise with the potential to alter current sports culture and athlete practices.",
        "prediction": "Our results show that drinking alcohol in moderation can help recovery after exercise. This could change how sports are viewed and how athletes behave.",
        "reference": "Our findings provide evidence for a message of moderation in alcohol consumption to promote recovery after exercise, with the potential to change sport cultures and athlete practices."
      },
      {
        "source": "Muscle contraction and the intake of leucine-rich protein sources activate independent but complimentary signaling responses that converge at the mechanistic target of rapamycin (mTOR) to stimulate protein translation enhancing rates of muscle protein synthesis [4]â[6].",
        "prediction": "Muscle contraction and leucine-rich proteins work in their own ways but also work together. They both affect a process called mTOR. This process helps make proteins and increases muscle protein synthesis",
        "reference": "Muscle contraction and consumption of leucine-rich protein (essential amino acid composing proteins) induce reactions which increase the protein synthesis."
      },
      {
        "source": "The ingestion of â¼20â25 g of high quality protein soon after exercise [7], repeated every 4 h [8] has been shown to maximise the anabolic response in skeletal muscle.",
        "prediction": "Eating about 20-25 grams of good protein shortly after exercise helps build muscle. Doing this every 4 hours can give the best results.",
        "reference": "Consumption of 20-25 g of high quality protein after exercise and repeated every 4 h showed an optimal anabolic response (increasing muscle mass) of the muscles."
      },
      {
        "source": "The cultural environment surrounding some sports often involves the intake of large amounts of alcohol after training and competition, with athletes in several team sports being particularly at risk of âbinge drinkingâ practices [9]â[11].",
        "prediction": "Some sports have a culture of drinking a lot of alcohol after training and competitions. Athletes in team sports are more likely to binge drink.",
        "reference": "Several studies showed that athletes are more likely to drink alcohol to excess (50-65% drink above dangerous level)."
      },
      {
        "source": "The outcomes of binge drinking after exercise are likely to include the direct effect of alcohol on physiological processes as well as the indirect effect on the athlete's recovery due to not eating or resting adequately as a result of intoxication.",
        "prediction": "Binge drinking after exercise can harm recovery. Alcohol directly affects the body. It also makes it hard for athletes to eat and rest properly.",
        "reference": "Consequences of an excessive consumption after exercise are direct effect on the body but also indirect effect on the recovery due to an inappropriate eating and rest."
      },
      {
        "source": "Although the concurrent consumption of carbohydrate can partially offset the deleterious effects of alcohol intake on post-exercise glycogen resynthesis [14], the effect of alcohol consumption on muscle protein synthesis is unknown.",
        "prediction": "Drinking carbohydrates with alcohol may help reduce the negative effects of alcohol on glycogen recovery after exercise. However, we do not know how alcohol affects muscle protein synthesis.",
        "reference": "Consumption of carbohydrates can partially counter balance the effects of alcohol on the recharge of glycogen stores but the effect on muscle protein synthesis are unknown."
      },
      {
        "source": "The aim of the current study was to determine the effect of alcohol intake on anabolic cell signaling and rates of myofibrillar protein synthesis (MPS) in humans during recovery from a bout of strenuous exercise approximating stresses an athlete may experience in training and performance for various team sports such as various football and rugby codes, and court sports.",
        "prediction": "The goal of this study was to see how alcohol affects anabolic cell signaling and myofibrillar protein synthesis in people. This was looked at during recovery from hard exercise similar to what athletes face in training and sports like football, rugby, and basketball.",
        "reference": "The aim of this study was to determine the effect of alcohol on anabolism and protein synthesis in humans during recovery following an effort an athlete could do (in rugby or football for example)."
      },
      {
        "source": "Human aging results in a variety of changes to skeletal muscle. Sarcopenia is the age-associated loss of muscle mass and is one of the main contributors to musculoskeletal impairments in the elderly. Previous research has demonstrated that resistance training can attenuate skeletal muscle function deficits in older adults, however few articles have focused on the effects of resistance training on functional mobility. The purpose of this systematic review was to 1) present the current state of literature regarding the effects of resistance training on functional mobility outcomes for older adults with skeletal muscle function deficits and 2) provide clinicians with practical guidelines that can be used with seniors during resistance training, or to encourage exercise. We set forth evidence that resistance training can attenuate age-related changes in functional mobility, including improvements in gait speed, static and dynamic balance, and fall risk reduction. Older adults should be encouraged to participate in progressive resistance training activities, and should be admonished to move along a continuum of exercise from immobility, toward the recommended daily amounts of activity.",
        "prediction": "Human aging causes changes in skeletal muscle. Sarcopenia is the loss of muscle mass that happens with age. It is a major reason for muscle problems in older people. Previous studies show that resistance training can help improve muscle function in older adults. However, not many studies have looked at how resistance training affects mobility. This review aims to 1) summarize research on resistance training and mobility for older adults with muscle issues and 2) offer practical tips for doctors to help seniors with resistance training or to encourage them to exercise. Our findings show that resistance training can help with age-related problems in mobility. It can improve walking speed, balance, and reduce the risk of falls. Older adults should be encouraged to do progressive resistance training exercises. They should also be guided to gradually increase their activity levels from no movement to the recommended daily amounts of exercise.",
        "reference": "Human aging results in a variety of changes to muscles. Sarcopenia is the age-associated muscle loss and is one of the main contributors to muscle disorders in older adults. Previous research has demonstrated that strength training can attenuate muscle function deficits in older adults, however few articles have focused on the effects of strength training on mobility. The purpose of this review was to present the effects of strength training on mobility for older adults with muscle function deficits and to provide guidelines that can be used with seniors during strength training. We present evidence that strength training can attenuate age-related changes in mobility, including improvements in walking speed, static and dynamic balance, and fall risk reduction. Older adults should be encouraged to participate in strength training activities, and should avoid immobility."
      },
      {
        "source": "Maximizing the hypertrophic response to resistance training (RT) is thought to be best achieved by proper manipulation of exercise program variables including exercise selection, exercise order, length of rest intervals, intensity of maximal load, and training volume. An often overlooked variable that also may impact muscle growth is repetition duration. Duration amounts to the sum total of the concentric, eccentric, and isometric components of a repetition, and is predicated on the tempo at which the repetition is performed. We conducted a systematic review and meta-analysis to determine whether alterations in repetition duration can amplify the hypertrophic response to RT. Results indicate that hypertrophic outcomes are similar when training with repetition durations ranging from 0.5 to 8 s. From a practical standpoint it would seem that a fairly wide range of repetition durations can be employed if the primary goal is to maximize muscle growth. Findings suggest that training at volitionally very slow durations (>10s per repetition) is inferior from a hypertrophy standpoint, although a lack of controlled studies on the topic makes it difficult to draw definitive conclusions.",
        "prediction": "To get the most muscle growth from resistance training, it is important to manage several factors. These factors include what exercises to do, the order of exercises, how long to rest, how much weight to use, and the amount of training. Another important factor that people often forget is how long each repetition takes. This duration includes the time for lifting, lowering, and holding the weight. We did a study to see if changing how long each repetition takes can help muscle growth during resistance training. Our results show that muscle growth is similar with repetition durations between 0.5 to 8 seconds. This means you can use a variety of repetition lengths if your goal is to grow muscles. However, training with very slow repetitions over 10 seconds seems less effective for muscle growth. More controlled studies are needed to be sure about this finding.",
        "reference": "Maximizing the muscle growth following strength training can be done by manipulating variables like exercise selection, exercise order, rest intervals, intensity of maximal load, and training volume (number of exercises, sets, etc.). A neglected variable that also may impact muscle growth is repetition duration. Total duration of a repetition is the sum of the contraction, the lengthening and isometric (static contraction) and is based on the tempo. We conducted a review and analysis of multiple studies to determine if modification of repetition duration can amplify the muscle growth. Results indicate that muscle growth is similar when training with repetition durations from 0.5 to 8 s. Using a wide range of repetition durations can be employed if the primary goal is to maximize muscle growth. Findings suggest that training at very slow durations (>10s per repetition) is less efficient for muscle growth, although a lack of studies on the topic makes it difficult to draw definitive conclusions."
      },
      {
        "source": "Recovery from exercise refers to the time period between the end of a bout of exercise and the subsequent return to a resting or recovered state. It also refers to specific physiological processes or states occurring after exercise that are distinct from the physiology of either the exercising or the resting states. In this context, recovery of the cardiovascular system after exercise occurs across a period of minutes to hours, during which many characteristics of the system, even how it is controlled, change over time. Some of these changes may be necessary for long-term adaptation to exercise training, yet some can lead to cardiovascular instability during recovery. Furthermore, some of these changes may provide insight into when the cardiovascular system has recovered from prior training and is physiologically ready for additional training stress. This review focuses on the most consistently observed hemodynamic adjustments and the underlying causes that drive cardiovascular recovery and will highlight how they differ following resistance and aerobic exercise. Primary emphasis will be placed on the hypotensive effect of aerobic and resistance exercise and associated mechanisms that have clinical relevance, but if left unchecked, can progress to symptomatic hypotension and syncope. Finally, we focus on the practical application of this information to strategies to maximize the benefits of cardiovascular recovery, or minimize the vulnerabilities of this state. We will explore appropriate field measures, and discuss to what extent these can guide an athlete's training.",
        "prediction": "Recovery from exercise is the time needed to return to rest after working out. It includes specific body processes that happen after exercise. Recovery of the heart and blood system can take minutes to hours. During this time, many aspects of the heart and its control change. Some changes help the body get used to exercise, while others may cause heart problems during recovery. Changes in recovery can show when the heart is ready for more training. This review looks at the most common changes in blood flow and what causes them. It will also show how recovery differs after weight lifting and aerobic exercises. We will focus on how aerobic and resistance exercises lower blood pressure and the important processes involved. If not managed, this can lead to low blood pressure and fainting. Finally, we will discuss how to use this information to improve heart recovery and reduce risks. We will look at effective measures and talk about how much they can help athletes in their training.",
        "reference": "Recovery from exercise refers to the time period between the end of exercise and the return to a resting or recovered state. It also refers to specific physiological processes occurring after exercise. Recovery of the cardiovascular system occurs across a period of minutes to hours, during which many characteristics of the system change over time. Some of these changes may be necessary for long-term adaptation to exercise training, yet some can lead to cardiovascular instability during recovery. These changes may provide insight into when the cardiovascular system has recovered and is physiologically ready for additional training. This review focuses on the most consistently observed blood flow adjustments and the causes that drive cardiovascular recovery and how they differ following strength and cardio exercise. First we focus on the effect leading to low blood pressure of cardio and strength exercise and associated mechanisms, which can progress to symptomatic hypotension (low blood pressure) and fainting. Finally, we focus on the practical application to maximize the benefits of cardiovascular recovery, or minimize the vulnerabilities. We will explore measures, and discuss how these can guide an athlete's training."
      },
      {
        "source": "Exercise and physical activity are increasingly becoming key tools in the treatment and prevention of several medical conditions including arthritis and diabetes; this notion has been termed \"exercise as medicine\". Exercise has favorable effects on reducing cardiovascular risk, inflammation, cachexia, and hypertension, in addition to increasing physical functioning, strength, and cardio-respiratory capacity. Chronic kidney disease, a condition that affects around 10% of the population, is often overlooked as a target for exercise-based therapy. Despite the vast range of severity in kidney disease (e.g., pre-dialysis, dialysis, transplant), exercise has a potential role in all patients suffering from the condition. In this review, we summarise the important role exercise may have in the clinical management of kidney disease and how this form of 'medicine' should be best administered and 'prescribed'.",
        "prediction": "Exercise and physical activity are becoming important for treating and preventing medical conditions like arthritis and diabetes. This idea is called \"exercise as medicine.\" Exercise helps lower heart risks, inflammation, weight loss, and high blood pressure. It also improves physical strength and breathing. Chronic kidney disease affects about 10% of people and is often not seen as a reason to use exercise therapy. Kidney disease can be mild or severe, like pre-dialysis, dialysis, or transplant, but exercise can help all patients. This review looks at the role of exercise in managing kidney disease and how it can be best used as treatment.",
        "reference": "Exercise and physical activity are key tools in the treatment and prevention of several medical conditions including joint disorders and diabetes. Exercise can reduce cardiovascular risk, inflammation, illness causing muscle loss, and hypertension, in addition to increasing physical functioning, strength, and cardio-respiratory capacity. Chronic kidney disease, a condition that affects around 10% of the population, is often neglected as a target for exercise-based therapy. Despite the vast range of severity in kidney disease, exercise has a potential role in all patients suffering from the condition. In this review, we summarise the potential important role of exercise in the management of kidney disease and how this form of 'medicine' should be used."
      },
      {
        "source": "Blood flow restriction (BFR) is an effective clinical intervention used to increase strength in healthy individuals. However, its effects on pain and function in individuals with knee pain are unknown. Objective: To determine the effectiveness of adding BFR to resistance exercise for pain relief and improvement of function in patients with knee pain. Methods: Systematic review with meta-analysis of randomized clinical trials. Randomized clinical trials that compared resistance exercise with or without BFR to treat knee pain and function in individuals older than 18 years of age with knee pain were included. The pooled standardized mean difference (SMD) estimate showed that resistance exercises with BFR was not more effective than resistance exercises for reducing pain (SMD: -0.37cm, 95% CI=-0.93, 0.19) and improving knee function (SMD=-0.23 points, 95% CI=-0.71, 0.26) in patients with knee pain.",
        "prediction": "Blood flow restriction (BFR) is a method used to help people get stronger. Its effects on knee pain are not clear. The aim of this study was to see if BFR helps reduce pain and improve function in knee pain patients. We reviewed studies that looked at resistance exercises with or without BFR for knee pain. Only studies with people over 18 years old were included. The results showed that resistance exercises with BFR did not work better than exercises alone for reducing pain and improving knee function.",
        "reference": "Exercise with blood flow restriction (BFR) is used to increase strength in healthy individuals. However, its effects on individuals with knee pain are unknown. The objective is to determine the effectiveness of adding BFR to strength exercise for pain relief and improvement of function in patients with knee pain. We conducted a review and analysis of multiple studies. Studies that compared strength exercise with or without BFR to treat knee pain and function. The results showed that resistance exercises with BFR was not more effective than strength exercises for reducing pain and improving knee function in patients with knee pain."
      },
      {
        "source": "In Japan, there were an estimated 43 million patients with hypertension in 2010. The management of this condition is given the highest priority in disease control, and the importance of lifestyle changes for the prevention and treatment of hypertension has been recognized in Japan. In particular, emphasis has been placed on increasing the levels of activities of daily living and physical exercise (sports). In this literature review, we examined appropriate exercise prescriptions (e.g., type, intensity, duration per session, and frequency) for the prevention and treatment of hypertension as described in Japanese and foreign articles. This review recommends safe and effective whole-body aerobic exercise at moderate intensity (i.e., 50-65% of maximum oxygen intake, 30-60 min per session, 3-4 times a week) that primarily focuses on the major muscle groups for the prevention and treatment of hypertension. Resistance exercise should be performed at low-intensity without breath-holding and should be used as supplementary exercise, but resistance exercise is contraindicated in patients with hypertension who have chest symptoms such as chest pain.",
        "prediction": "In Japan, about 43 million people had high blood pressure in 2010. Managing this condition is very important for health. Lifestyle changes can help prevent and treat high blood pressure. In Japan, there is a focus on increasing daily activities and exercise like sports. This review looks at suitable exercise plans for preventing and treating high blood pressure from both Japanese and foreign studies. It recommends safe, whole-body aerobic exercise at a moderate level. This means working at 50-65% of your maximum breathing capacity for 30-60 minutes, 3-4 times a week. This exercise should target the main muscle groups. Strength training should be light and without holding your breath, and it can be an additional exercise. However, people with high blood pressure who have chest pain should not do strength training.",
        "reference": "In Japan, 43 million patients had high blood pressure in 2010. The management of this condition and the importance of lifestyle changes for the prevention and treatment of high blood pressure has been recognized in Japan. In particular, increasing the levels of activities of daily living and physical exercise. In this review, we examined appropriate exercise prescriptions (e.g., type, intensity, duration per session, and frequency) for the prevention and treatment of high blood pressure. This review recommends full body cardio exercise at moderate intensity (i.e., 50-65% of maximum intensity, 30-60 min per session, 3-4 times a week) that focuses on the major muscle groups. Strength exercise should be performed at low-intensity without breath-holding and should be used as supplementary exercise, but it is contraindicated in patients with high blood pressure who have chest symptoms such as chest pain."
      },
      {
        "source": "Physical activity has proved to be an effective means of preventing several diseases and improving general health. Common sense advices call for late inception of intense, strength training-related activities, like weight lifting and plyometrics, which are usually postponed at the end of the growth age, even among sport practitioners. However, such advices seem to have a mainly anecdotal nature. Current literature does not seem to have any particular aversion against the practice of strength training by children and adolescents, provided that some safety rules are followed, like medical clearance, proper instruction from a qualified professional and progressive overload. At the same time, several studies provide consistent findings supporting the benefits of repeated, intense physical efforts in young subjects. Improved motor skills and body composition, in terms of increased fat free mass, reduced fat mass and enhanced bone health, have been extensively documented, especially if sport practice began early, when the subjects were pubescent. It can be therefore concluded that strength training is a relatively safe and healthy practice for children and adolescents.",
        "prediction": "Physical activity helps prevent diseases and improve health. Many say that intense strength training like weight lifting should start later, after growth finishes. However, this advice is mostly based on personal stories. Research does not have a strong rule against strength training for children and teens if safety measures are followed. This includes getting medical approval, having proper training, and increasing difficulty gradually. Many studies show that young people benefit from doing intense physical activities. They improve their motor skills and body composition. This means more muscle, less fat, and better bone health, especially if they start sports early during puberty. So, strength training is safe and healthy for children and teens.",
        "reference": "Physical activity has many benefits like preventing diseases and improving general health. In popular opinion, it is recommended to start intense physical activities like weight lifting and plyometrics (exercises like sprint and jumps) after adolescence. But this advice does not seem to be based on facts. We did not find any recommendation against strength training at a young age if it is well supervised with safety rules, medical clearance, proper instruction from a professional and progressive overload (gradual increase of stress on muscle and nervous system). Several studies showed many benefits of repeated, intense physical efforts in young people. Improved motor skills and body composition (muscle mass increased, fat mass decreased, healthier bone) were found in studies, especially if sport practice began during puberty. We can conclude that strength training is a safe and healthy practice for children and adolescents."
      },
      {
        "source": "recently, there has been a renewed public interest in IFast. Given the importance of nutrition in optimizing athletic performance, there is a concern about the effects of IFast on athletics. Looking at high-intensity, endurance, and resistance exercises, studies have been varied but are uniform in showing that there is no benefit to athletic performance while fasting.",
        "prediction": "Recently, there is a growing public interest in IFast. Nutrition is important for improving athletic performance. Many people are concerned about how IFast affects athletes. Studies on high-intensity, endurance, and resistance exercises show mixed results. However, all studies agree that there is no benefit to athletic performance when fasting.",
        "reference": "Nowadays, people are interested in intermittent fasting (an eating pattern where you cycle between periods of eating and fasting) Nutrition is important for the optimization of sport performance so there is a concern about the effects of intermittent fasting on performance. Studies showed that there are no benefit in high-intensity, endurance or strength training while fasting."
      },
      {
        "source": "Nearly every physically active person encounters periods in which the time available for exercise is limited (e.g., personal, family, or business conflicts). During such periods, the goal of physical training may be to simply maintain (rather than improve) physical performance. Similarly, certain special populations may desire to maintain performance for prolonged periods, namely athletes (during the competitive season and off-season) and military personnel (during deployment). In general populations, endurance performance can be maintained for up to 15 weeks when training frequency is reduced to as little as 2 sessions per week or when exercise volume is reduced by 33â66% (as low as 13â26 minutes per session), as long as exercise intensity (exercising heart rate) is maintained. Strength and muscle size (at least in younger populations) can be maintained for up to 32 weeks with as little as 1 session of strength training per week and 1 set per exercise, as long as exercise intensity (relative load) is maintained; whereas, in older populations, maintaining muscle size may require up to 2 sessions per week and 2â3 sets per exercise, while maintaining exercise intensity. Our primary conclusion is that exercise intensity seems to be the key variable for maintaining physical performance over time, despite relatively large reductions in exercise frequency and volume.",
        "prediction": "Many active people have times when they cannot exercise much due to personal or work issues. During these times, the goal of training is to maintain physical performance instead of improving it. This applies to athletes during their seasons and to military personnel during their deployments. General endurance can be kept up for 15 weeks if training goes down to 2 sessions each week or if exercise volume is cut by 33-66%. This means 13-26 minutes per session, as long as the intensity of the workout stays the same. For strength and muscle size, younger people can maintain this for 32 weeks with just 1 session of strength training each week and 1 set per exercise while keeping intensity. Older people may need 2 sessions per week and 2-3 sets per exercise to maintain muscle size, also while keeping intensity. The main takeaway is that exercise intensity is crucial for maintaining physical performance even with less frequent and shorter workouts.",
        "reference": "Physically active people encounter periods with limited time available for exercise. During such periods, the goal of training may be to simply maintain physical performance. Some people may also desire to maintain performance for prolonged periods, like athletes during competitive season or militaries during deployment. Endurance performance can be maintained for up to 15 weeks with 2 trainings per week, or with a reduction of 13â26 minutes per training, as long as exercise intensity (exercising heart rate) is maintained. Strength and muscle size can be maintained for up to 32 weeks with 1 strength training per week and 1 set per exercise, as long as exercise intensity (load) is maintained. In older populations, maintaining muscle size may require up to 2 trainings per week and 2â3 sets per exercise, while maintaining exercise intensity. Exercise intensity seems to be the key variable for maintaining physical performance, even with reduction of frequency and volume (number of exercises, sets, etc.)"
      },
      {
        "source": "Nutrient timing is a popular nutritional strategy that involves the consumption of combinations of nutrients--primarily protein and carbohydrate--in and around an exercise session. Some have claimed that this approach can produce dramatic improvements in body composition. It has even been postulated that the timing of nutritional consumption may be more important than the absolute daily intake of nutrients. The post-exercise period is widely considered the most critical part of nutrient timing. Theoretically, consuming the proper ratio of nutrients during this time not only initiates the rebuilding of damaged muscle tissue and restoration of energy reserves, but it does so in a supercompensated fashion that enhances both body composition and exercise performance. Several researchers have made reference to an anabolic âwindow of opportunityâ whereby a limited time exists after training to optimize training-related muscular adaptations. However, the importance - and even the existence - of a post-exercise âwindowâ can vary according to a number of factors. Not only is nutrient timing research open to question in terms of applicability, but recent evidence has directly challenged the classical view of the relevance of post-exercise nutritional intake with respect to anabolism.",
        "prediction": "Nutrient timing is a common nutrition strategy. It focuses on eating certain nutrients, mainly protein and carbohydrates, before and after exercise. Some people believe this method can greatly improve body composition. Some even say that when you eat may matter more than how much you eat in a day. The time after exercise is seen as the most important for nutrient timing. Eating the right mix of nutrients then helps repair muscle and restore energy in a way that boosts body composition and exercise performance. Researchers talk about an anabolic \"window of opportunity.\" This is a short time after training to get the best results. However, the need for this post-exercise \"window\" can depend on many factors. Also, recent studies have questioned how important post-exercise nutrition really is for building muscle.",
        "reference": "Nutrient timing is a popular nutritional strategy that involves the consumption of combinations of nutrients around an exercise session. Some people say that this approach can produce dramatic improvements in body composition. It has even been hypothesized that the timing may be more important than the total daily intake of nutrients. The post-exercise period is considered the most important part of nutrient timing. In theory, consuming the proper ratio of nutrients during this time allows the rebuilding of damaged muscle tissue and restoration of energy reserves, but also enhances both body composition and exercise performance. Researchers have made reference to an anabolic âwindow of opportunityâ (a limited time after training to optimize muscular adaptations). However, the importance - and even the existence - of a post-exercise âwindowâ can vary according to a number of factors. Research is uncertain about the applicability of nutrient timing. Besides, the relevance of post-exercise nutritional intake concerning anabolism (increasing muscle mass) has been challenged by recent evidence."
      },
      {
        "source": "Lack of time is among the more commonly reported barriers for abstention from exercise programs. The aim of this review was to determine how strength training can be most effectively carried out in a time-efficient manner by critically evaluating research on acute training variables, advanced training techniques, and the need for warm-up and stretching. When programming strength training for optimum time-efficiency we recommend prioritizing bilateral, multi-joint exercises that include full dynamic movements (i.e. both eccentric and concentric muscle actions), and to perform a minimum of one leg pressing exercise (e.g. squats), one upper-body pulling exercise (e.g. pull-up) and one upper-body pushing exercise (e.g. bench press). Exercises can be performed with machines and/or free weights based on training goals, availability, and personal preferences. Weekly training volume is more important than training frequency and we recommend performing a minimum of 4 weekly sets per muscle group using a 6â15 RM loading range (15â40 repetitions can be used if training is performed to volitional failure). Advanced training techniques, such as supersets, drop sets and rest-pause training roughly halves training time compared to traditional training, while maintaining training volume. However, these methods are probably better at inducing hypertrophy than muscular strength, and more research is needed on longitudinal training effects. Finally, we advise restricting the warm-up to exercise-specific warm-ups, and only prioritize stretching if the goal of training is to increase flexibility.",
        "prediction": "Lack of time is a common reason people avoid exercise. This review looks at how to do strength training effectively in less time. We focus on training variables, advanced techniques, and the need for warm-up and stretching. For efficient strength training, we suggest using bilateral and multi-joint exercises. These include both eccentric and concentric movements. It is essential to include one leg exercise like squats, one upper-body pulling exercise like pull-ups, and one upper-body pushing exercise like bench press. You can use machines or free weights based on your goals and preferences. The total amount of training is more important than how often you train. We recommend at least 4 sets per muscle group each week, using weights that allow for 6 to 15 reps. If you reach failure, you can do 15 to 40 reps. Advanced techniques like supersets, drop sets, and rest-pause training can cut training time in half while keeping the volume. These methods may improve muscle size better than strength, and more studies are needed to explore their long-term effects. Lastly, keep warm-ups specific to your exercises and focus on stretching only if you want to increase flexibility.",
        "reference": "Lack of time is one of the most common reason for not exercising. The aim of this review was to determine how strength training can be time-efficient by evaluating research on training variables, advanced training techniques, and the need for warm-up and stretching. We recommend choosing bilateral (with the two arms or legs), multi-joint (multiple joints involved) exercises that include full dynamic movements and to perform a minimum of one leg pressing exercise (e.g. squats), one pulling exercise (e.g. pull-up) and one pushing exercise (e.g. bench press). Exercises can be performed with machines and/or free weights. Weekly training volume (number of exercises, sets, etc.) is more important than training frequency and we recommend a minimum of 4 weekly sets per muscle group using a load that permits to do 6 to 15 repetitions. Advanced training techniques like combining exercises with no rest or shortening the rest time while using lighter weights can cuts the training time in half, while maintaining training volume. However, these methods are probably better to increase muscle mass than strength. Finally, we advise exercise-specific warm-ups, and stretching only if the goal of training is to increase flexibility."
      },
      {
        "source": "Training frequency is considered an important variable in the hypertrophic response to regimented resistance exercise. The purpose of this paper was to conduct a systematic review and meta-analysis of experimental studies designed to investigate the effects of weekly training frequency on hypertrophic adaptations. Results showed no significant difference between higher and lower frequency on a volume-equated basis. Meta-regression analysis of non-volume-equated studies showed a significant effect favoring higher frequencies, although the overall difference in magnitude of effect between frequencies of 1 and 3+ days per week was modest. In conclusion, there is strong evidence that resistance training frequency does not significantly or meaningfully impact muscle hypertrophy when volume is equated. Thus, for a given training volume, individuals can choose a weekly frequency per muscle groups based on personal preference.",
        "prediction": "Training frequency is important for muscle growth when doing resistance exercise. This paper reviews studies that look at how often you train each week affects muscle growth. The results showed no big difference in muscle growth between high and low training frequencies when the volume is the same. A separate analysis of studies that did not match volume showed that higher frequencies had some benefits. However, the overall difference between training 1 day or 3 or more days a week was small. In conclusion, there is strong evidence that how often you train does not greatly affect muscle growth when the volume is equal. So, people can choose how often to train each week based on what they prefer.",
        "reference": "Training frequency is an important variable for hypertrophy (increasing muscle mass) in strength training. The purpose of this paper was to conduct a review and analysis of multiple studies investigating the effects of weekly training frequency on hypertrophy. Results showed no significant difference between higher and lower frequency with the same training volume (number of exercises, sets, etc.). Analysis of studies with different training volumes showed better results for higher frequencies, although the difference between frequencies of 1 and 3+ days per week was small. In conclusion, there is strong evidence that resistance training frequency does not significantly impact muscle hypertrophy when training volume is the same. Thus, for a given training volume, individuals can choose a weekly frequency per muscle groups based on personal preference."
      },
      {
        "source": "A variety of specialized training techniques have been advocated as a means to heighten muscle growth. Forced repetitions/drop sets, supersets, and heavy negatives, in particular, have been purported to enhance the hypertrophic response to resistance exercise. This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to resistance training programs.",
        "prediction": "Many special training methods can help increase muscle growth. Techniques like forced repetitions, drop sets, supersets, and heavy negatives are said to improve muscle size. This article will look at how these methods can help with muscle growth and how they can be used in resistance training plans.",
        "reference": "A variety of training techniques have been suggested to support muscle growth. Forced repetitions/drop sets (use lighter weight or receiving help to continue the set), supersets (combining exercises with no rest), and heavy negatives (lowering phase of the lift), are pretended to enhance hypertrophy (increasing muscle mass). This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to strength training."
      },
      {
        "source": "The quest to increase lean body mass is widely pursued by those who lift weights. Research is lacking, however, as to the best approach for maximizing exercise-induced muscle growth. Bodybuilders generally train with moderate loads and fairly short rest intervals that induce high amounts of metabolic stress. Powerlifters, on the other hand, routinely train with high-intensity loads and lengthy rest periods between sets. Although both groups are known to display impressive muscularity, it is not clear which method is superior for hypertrophic gains. It has been shown that many factors mediate the hypertrophic process and that mechanical tension, muscle damage, and metabolic stress all can play a role in exercise-induced muscle growth. Therefore, the purpose of this paper is twofold: (a) to extensively review the literature as to the mechanisms of muscle hypertrophy and their application to exercise training and (b) to draw conclusions from the research as to the optimal protocol for maximizing muscle growth.",
        "prediction": "Many people who lift weights want to increase lean body mass. However, there is not much research on the best way to grow muscles from exercise. Bodybuilders usually use moderate weights with short rest times, which creates a lot of metabolic stress. Powerlifters use heavy weights and take longer breaks between sets. Both groups are strong, but it is unclear which training method is better for muscle growth. Several factors affect muscle growth, including mechanical tension, muscle damage, and metabolic stress. This paper has two main goals: to review the research on how muscles grow and to find the best training methods for maximizing muscle growth.",
        "reference": "Increasing muscle mass is the goal of many people who lift weights. Research is lacking, however, as to the optimal way to induce muscle growth. Bodybuilders train with moderate loads and short rest intervals. Powerlifters, on the other hand, train with high-intensity loads and lengthy rest periods. Although both groups are known to display impressive muscularity, it is not clear which method is superior for increasing muscle mass. It has been shown that many factors mediate the process of muscle growth and that mechanical tension, muscle damage, and metabolic stress all can play a role in muscle growth. Therefore, the purpose of this paper is to review the literature as to the mechanisms of muscle hypertrophy and their application to exercise training and to draw conclusions from the research as to the optimal way to induce muscle growth."
      }
    ]
  ]
}