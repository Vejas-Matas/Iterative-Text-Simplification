In the modern era of automation and robotics, autonomous vehicles are being researched by both academics and industries.
Drones used in both personal and business settings, there is an increased need for autonomy in these systems too.
Due to guidelines set by the governments regarding the operation ceiling of civil drones, road-tracking based navigation is garnering interest.
In an attempt to achieve the above mentioned tasks, we propose a computer-based learning method to driving by learning to fly by copying a skilled pilot.
Derived from the classic image classification algorithms, our classifier has been built using a fast 39-layered Inception model, that evaluates the presence of roads using tomographic reconstructions of the input frames.
Our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning using a New architecture.
The data used for training the system has been captured from the drone, by flying it in and around city streets, by experts with extensive flying experience.
Permissions were taken from required authorities who ensured that pedestrian safety was a priority during data collection process.
With the extensive amount of drone data that we collected, we have been able to navigate safely through roads, with an accuracy of 98.44%.
The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6m/sec.
We present the same results in this research and compare them with other state-of-the-art navigation methods.
Recognizing Traffic Signs using intelligent systems can drastically reduce the number of accidents happening world-wide.
With the rise of self-driving cars, it has become a big challenge to recognize traffic signs on the main streets.
Machine learning techniques such as Random Forest and deep learning models has been proposed for classifying traffic signs.
Though they reach good performance on a specific dataset, but fall short of tackling multiple Traffic Sign Recognition benchmarks.
In this paper, we propose a novel and new architecture that performs well on multiple tests with better overall score than the state-of-the-art architectures.
blocks that pass information from one layer to the next Our model is made of these blocks joined in steps.
With this we score 99.33% Accuracy in German sign recognition benchmark and 99.17% Accuracy in Belgian traffic sign classification benchmark.
Moreover, we propose a newly devised advanced learning method which is very low in both memory and computational complexity.
We introduce Ignition: a neural network system for training unconstrained self-driving vehicles in simulated environments.
The model is a ResNet-18 variant, which is fed images from a simulated racing car, and outputs labels for steering, braking.
Importantly, we don't train the model to detect features like the outline of a track or distance to other cars. Instead, these features can be automatically encapsulated by the network.
In this paper, we present a method for controlling self-driving cars using a specific type of artificial intelligence, which enables a trained AI model to be used for the same task in a different location.
A conventional CNN is used to control the vehicle for the end-to-end control is designed to translate a camera image into a steering command.
To enable the transfer learning, we let the CNN produce not only a steering command but also a lane departure level (LDL) by adding a new module, which uses the output of the last layer as input.
The CNN trained on the source domain, called source network, is then utilized to train another task module called target network, which also uses the output of the source network's final layer and is trained to produce a steering command for the target domain.
Commands from the source and target are finally merged according to the LDL and the merged command is utilized for controlling a car in the target domain.
To demonstrate the effectiveness of the proposed method, we utilized two simulators, TORCS and GTAV, were used for the source and target domains, respectively.
Experimental results show that the proposed method outperforms other baseline methods in terms of stable and safe control of cars.
A significant problem of using deep learning techniques is a lack of training data.
There are some datasets available for recognition and classification for self-driving cars, however, it is very limited for the industrial robotics field.
In previous work, we have trained a special type of artificial intelligence to identify the robot body in the image and calculate the positions of the joints by using just a 2D image, but it was limited to a range of robots produced by Universal Robots (UR).
In this work, we extend our method to work with a new robot arm - Kuka LBR iiwa, with a distinct design and extra joint.
However, instead of collecting large datasets once again, we collect a number of smaller datasets containing a few hundred frames each and using the knowledge of a pre-trained model to adapt to a new robot.
Transfer learning is applicable in this field, but it works best with smaller, well-prepared datasets, trains significantly faster and reaches similar accuracy compared to the original method, even improving it on some aspects.
Automated decisions raise important moral concerns, with applications ranging from self-driving cars to kidney exchanges.
In this paper we present queueing-theoretical methods for the studying and managing of autonomous mobility-on-demand systems wherein self-driving vehicles transport customers within cities and balance their routes to provide good service.
We first cast an autonomous system within a closed Jackson network model with passenger loss.
Researchers use theoretical insights to design a robust rebalancing system, which is applied to a case study of New York City and implemented on an eight-vehicle mobile robot testbed.
The case study of New York shows that the current taxi demand in Manhattan can be met with about 8,000 robotic vehicles roughly 70% of the size of the current taxi fleet operating in Manhattan.
We extend our basic traffic model to include congestion effects, and study the impact of autonomously rebalancing vehicles on overall congestion.
This paper presents a new way to coordinate self-driving cars in a large network, and provides one of the first characterizations of the sustainability benefits of robotic transportation networks.
In the wake of the digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions.
While the benefits of this transformation can be significant, there are also tremendous risks to our society.
After the automation of many production processes and the creation of self-driving vehicles, automation is moving beyond cars and factories.
This is moving us to a tipping point and to a crossroads: we must decide between a society where actions are controlled by those in power, often through advertising and persuasion or a society, in which decisions are taken in a free and participatory way and mutually coordinated.
Modern technology enables both, but the latter has economic and strategic benefits.
The core values of human dignity and democracy are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies, but also the basis of greater efficiency and success.
Once self-driving cars will become a reality and passengers are no longer worry about it, they will need to find new ways of entertainment.
However, retrieving entertainment contents at the Data Center (DC) can hinder content delivery service due to a slow connection between the car and the data center.
To address these challenges, we propose a deep learning based caching for self-driving car, by using artificial intelligence techniques are used on the car's edge computing system.
First, at DC, a type of neural network called Multi-Layer Perceptron predicts which contents are likely to be requested in specific areas.
To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units.
Second, in order to cache entertainment contents stylized for car passengers’ features such as age and gender, a computer model is used to guess the age and gender of passengers.
Through this, the self-driving car can download the necessary files from the Edge server and cached.
Finally, we formulate caching in the driverless car that enhances entertainment services as an optimization problem whose goal is to reduce wait time.
A Reduce and simplify is applied.
Our simulation results show that our predictions for self-driving cars are accurate at 98% and our approach saves time.
This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE), a simple stock market simulation, based on the same rules as major stock exchanges.
Construction of BSE was motivated by the fact that most major financial markets have automated, with trading now being done by computers.
Research aimed at understanding the dynamics of this new style of financial market is hampered by the fact that markets can't be tested when open, forcing researchers to work primarily from time-series of past trading data.
Specialized education for engineers who design advanced trading systems requires that they have hands-on learning experience in a sufficiently realistic teaching environment.
BSE is described in this section addresses both those needs: it has been successfully used for teaching and research in a UK university since 2012, and the BSE program code is freely available as open-source on GitHuB.
This paper provides a holistic study of how stock prices react to financial news.
Thereby, we specifically shed light into the extensive amount of filings for which no a priori categorization of their content is classified.
For this purpose, we utilize an approach from data mining - namely, a specific statistical method used for topic modeling.
This technique facilitates our task of automatically categorizing, ahead of time, the content of over 70,000 company filings from the US.
We then look at the market's next move.
Our empirical evidence suggests a considerable discrepancy among different kinds of news in terms of their relevance and impact on financial markets.
For instance, we find a statistically significant abnormal return in response to earnings results and credit rating, but also for business strategy, health sector, and mergers and acquisitions.
Our results yield findings that benefit managers, investors and policy-makers by indicating how companies file information to regulators and events that can affect stock prices.
This paper addresses the financial markets with a focus on banking trading systems today.
With the advent of modern computing, cross-regional trading transactions can now be executed within milliseconds, a reality that is impossible without the advancements of software systems technology.
We then move on and discuss the anatomy of a trading system and how it fits in with the banks ecosystem of vital inter-working components.
As for the humanoid robots, internal noise is generated by the robot's movement and mechanical parts, severely degrades the performance of the speech recognition accuracy.
A new speech recognition system that works well in noisy environments for robots that mimic human-like movements, the motor's on/off state helps improve the system's performance.
For this, we consider the bottleneck features, which have been successfully applied to deep neural network (DNN) based automatic speech recognition (ASR) system.
When learning the key features to focus on, we first exploit the motor on/off state data as supplementary information in addition to the acoustic features as the input of the first deep neural network (DNN) for preliminary acoustic modeling.
The first DNN for primary acoustic modeling employs both the bottleneck features tossed from the first DNN and the acoustics features. The first DNN uses features from the first DNN and acoustics features.
When the proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, the experimental results show that our algorithm shows a significant improvement of 11% compared to the conventional systems.
Many techniques have been proposed in the literature for applying domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation.
Robots controlled by sensors can handle uncertain situations and unknown environments. However, it overcomes many of the difficulties of uncertain models and unknown environments which limit the domain of application of the previous methods.
Furthermore, for service and manipulation tasks, it is more suitable to study the interaction between the robot and its environment at the contact point using the sensor based control, rather than specifying the exact movements of the robot's joints required to achieve them.
Online social media provide users with unprecedented opportunities to engage with diverse opinions.
Simultaneously, they allow the spread of misinformation by empowering individuals to select the news they want to see, through biases in what they actively choose and algorithms that recommend what they're likely to be interested in, both through active (confirmation bias) and passive (personalized news algorithms) feedback loops.
A theoretical understanding of trade-offs is still lacking.
We introduce a stylized social learning model where most participants in a network update their beliefs unbiasedly based on the arrival of new information, while a fraction of participants display confirmation bias by rejecting news that contradict their existing views.
We show that this simple confirmation bias mechanism can generate permanent opinion polarisation.
Furthermore, the model results in states where unbiased agents behave "as if" they were biased, because their neighbors are biased, they act as gatekeepers, limiting access to diverse information.
We get results showing how people's opinions are distributed, explicitly demonstrating the balance between how people confirm their own opinions and the influence of others, which we further validate against US county-level data on the impact of Internet access on the formation of beliefs about global warming.
Our findings indicate that confirmation bias in small doses may actually result in improved accuracy across individuals by preserving information diversity in a social network.
When bias grows too strong, accuracy declines as biased agents restrict information flow to subgroups.
We discuss the policy implications of our model, highlighting the downside of ways to correct false information and suggesting alternative strategies to contrast misinformation.
The advent of WWW changed the way we can produce and access information.
Recent studies showed that users tend to select information that is consistent with their system of beliefs, forming groups of people with similar views around common stories where dissenting information is ignored.
In this environment, users cooperate to frame and work on their shared story making any attempt at debunking inefficient.
Such a configuration occurs even in the consumption of news online, and considering that 63% of users access news directly from social media, one hypothesis is that increased polarization spreads misinformation.
Along this path, we focus on the polarization of users around news outlets on Facebook in different European countries (Italy, France, Spain and Germany).
First, we compare the page posting behavior and the user interactions across different countries and observe different posting, liking and commenting rates.
Second, we explore users' interactions with different pages and the emergence of polarized communities generated around specific pages.
Italy is the most divided, followed by France, then Germany and lastly Spain.
Finally, we present a variation of the Bounded Confidence Model to model the formation of these communities by considering the users' engagement and trust on the news.
Our findings suggest that trust in information broadcaster plays a pivotal role against polarization of users online.
For decentralised P2P networks, it is very important to have a mechanism in place that allows the nodes to control resource usage and prevent flooding and denial-of-service attacks with spam.
In this paper, we discuss and compare the different approaches to decentralized management of resources that are used by projects in the cryptocurrency market.
The introduced methods are then applied to design a peer-to-peer exchange for Namecoin names (or more generally, crypto assets) as an example.
With the introduction of specialized cryptocurrencies, such as Monero, the mining code in web browsers has become a worthwhile alternative to dedicated mining rigs.
Based on this technology, a new form of parasitic computing, cryptojacking, or drive-by mining has gained momentum in the web. A cryptojacking site abuses the computing resources of its visitors to covertly mine for cryptocurrencies.
In this paper, we systematically explore this phenomenon. We suggest a three-step analysis to study this phenomenon.
We find that cryptojacking is common, with currently 1 in 500 websites.
Moreover, we perform a code analysis, an estimate of expected revenue, and an evaluation of current blacklist-based countermeasures.
The rise of modern blockchains has facilitated the emergence of smart contracts: autonomous programs that live and run on the blockchain.
Smart contracts have seen a rapid climb to prominence, with applications predicted in law, business, commerce, and governance. They are commonly written in a high-level language like Solidity, which is used for Ethereum, and then compiled for deployment on the blockchain.
Once deployed, the bytecode is autonomously executed, usually by a powerful computer.
As with all programs, smart contracts can be highly vulnerable to malicious attacks due to deficient programming methods, including faulty compilers.
At the same time, smart contracts are also valuable targets that get a lot of cryptocurrency.
Developers and auditors need security frameworks capable of examining the code to detect potential security vulnerabilities.
In this paper, we present A tool for analyzing Smart contracts.
Vandal consists of an analysis pipeline that converts low-level Ethereum code to logical rules.
Users of the framework can express security analyses in a declarative fashion: Security analysis is expressed in a technical document written in a programming language.
Vandal is both fast and robust, successfully analysing over 95% of all 141,000 contracts with an average runtime of 4.15 seconds; outperforming the current state of the art tools---Oyente, EthIR, Mythril, and Rattle---under equivalent conditions.
As Bitcoinu0027s popularity has grown over the decade since its creation, it has become an increasingly attractive target for adversaries of all kinds.
Image tampering, is now easily spread, is increasingly causing problems regarding the authenticity of images.
As the most popular multimedia data, JPEG images can be easily tampered without leaving any clues; therefore, forensic analysis of JPEG images has become a significant focus in research.
Nevertheless, the interesting issue of detecting image tampering has not been fully investigated.
Aiming to detect such forgeries under the same quality settings, we propose a detection method by using a special characteristic feature.
The learning classifiers are applied for classification.
Our experimental results indicate that this approach is effective in detecting image tampering.
The malicious change of machine time is a big challenge in digital forensics.
Detecting such changes and reconstructing the actual timeline of events is of paramount importance.
However, this can be difficult since the attacker has various ways to conceal changes.
In particular, computer time and data transfer can be manipulated in various ways by an attacker.
Guest virtual machines are especially vulnerable to attacks coming from their (more privileged) host.
Ensure the timeline is secure for both the server and the user in a cloud, or at least to ensure that the alteration of such timeline does not go undetected.
In this paper we survey the issues related to host and guest computer time accuracy in the cloud.
Further, we describe a new architecture for detecting and correcting changes to infected hosts and users.
The proposed framework has been implemented on a custom-built simulator.
Performance figures show the feasibility of our proposal.
Detection of various image editing techniques carried out on an image is an important problem in image forensics.
It gives the information about how the image was processed, and also can expose forgeries present in an image.
There have been a few methods proposed to detect different types of image editing operations in a single framework.
However, all the operations have to be known at the start in the learning process.
But, real-life forensic cases it may not be possible to know about editing an image.
To solve this problem, we propose a new machine learning approach which can differentiate between different types of image editing operations.
The proposed method classifies image patches in a pair-wise fashion as either similarly or differently processed using a deep neural network.
Once the network learns feature that can discriminate between different image editing operations, it can differentiate between different image editing operations not present in the training stage.
The experimental results show the efficacy of the proposed method in detecting different image editing operations.
Digital assistants are emerging to become more prevalent in our daily lives. Users engage in multiple tasks with these assistants in a short time.
DIANE is a digital assistant system that aims to fasten the doctor access to various information at the hospital such as health facility, medical records, and also human resource data. Access can be made easier by using face recognition and live streaming as part of the digital assistant system.
extensive research has shown individuals suffer from diverse biases in decision-making.
In our paper we analyze the effects of biases in decision-making of managers in decision-making processes among managers on organizational performance.
In the simulations, managerial decisions which are based on various levels of complexity and different incentive systems suffer from biases known from descriptive decision theory.
The results illustrate how biases interacting with each other and in different organizational contexts affect organizational performance.
We find that, contrary to intuition, various combinations of biases significantly improve organizational performance while these biases negatively affect organizational performance when they occur separately.
This might evoke considerations whether decision-making should be as rational as possible.
Perception of the local environment is a precondition for mobile robots to safely navigate various environments.
Most robots rely on planar regions.
For humanoids, a 2D map isn't enough, we also need to know the height of objects. They can step over and onto objects and therefore need height information.
Considering dynamic obstacles adds more complexity, since they can lead to necessary replanning or collisions at later stages.
In this paper, we present a framework that first extracts flat areas in maps and detects dynamic obstacles.
Our system then uses this information to create a set of maps that help plan paths quickly.
We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one cycle and allows for foresighted 3D footstep planning.
A service robot looks for a user to carry out a desired task.
This is a challenging problem, especially when this person moves around since the robot’s field of view is constrained and the environment creates obstacles that affect how the user sees things.
In this paper, we propose a novel method that calculates the probability of the user being visible at each point in space using computer simulations.
As the robot needs time to reach the possible search locations, we take this time as well as the visibility constraints into account when determining the search locations.
In this way, the robot can choose the next search location that has the maximum expected observability of the user.
Our experiments in various environments demonstrate that our approach leads to a significantly shorter search time compared to a greedy approach with background information.
In many situations, users walk on typical paths. at which the service of a mobile robot is needed.
Following a human step-by-step might not be the best choice, as a robot may find a more efficient route since better paths for the robot exist.
We aim to predict the human's future movements and use this information in a learning system to generate navigation actions for the robot.
Occlusions will often block the robot's view of the human. Since occlusions will often block the robot's view of the human, the estimate about the human's position and the prediction of the next destination are affected by uncertainty.
Our approach deals with such situations by considering obstacles when giving rewards such that the robot automatically considers to execute actions to get the human in its field of view.
We show in real-world experiments that our technique leads to much shorter paths compared to the robot follows the user and can handle obstacles.
In this paper, we introduce an approach to efficient robot navigation through cluttered indoor environments.
We propose to estimate local obstacle densities based on already detected objects and use them to predict traversal costs corresponding to obstacles in areas the robot can't see yet.
The robot is then able to navigate in a more planned approach and reduces the risk of getting stuck in cluttered regions.
As the experimental results demonstrate, our method enables the robot to efficiently navigate through cluttered spaces and achieves significantly shorter completion times compared to a standard approach not using any prediction.
In this paper, we present an integrated navigation system that allows robots to navigate in complex spaces.
From the data of an onboard consumer-grade depth camera, our system corrects the robot's position to account for small errors in its movement and maintains a heightmap representation of the environment.
Based on this model, our system iteratively computes sequences of safe actions, steps and movements, leading the robot to target locations.
To efficiently check for collisions during planning, we developed a new method to help the robot avoid obstacles.
As we demonstrate in experiments with a robot robot, our system leads to robust navigation in cluttered environments and the robot is able to traverse highly challenging passages.
In this paper, we present a new method to improve the motion model of a humanoid robot based on observations of its monocular camera.
Our technique estimates the parameters of the complete model, consisting of the joint angle offsets of the body and legs, as well as the camera settings.
Furthermore, we developed an approach to automatically select a selection of configurations for calibration that yields a good trade-off between the number of observations and accuracy.
Further, our approach to configuration selection yields better results compared to random choices.
Hence, our system only needs a few settings to work correctly.
Our optimization is general and the implementation can be found online and applied to various robots.
In this paper, a lab automation drone concept is introduced.
A robot arm is attached to a rotorcraft.
The limb's gripper allows the unmanned aerial vehicle to dexterously manipulate objects such as micro-arrays and test tubes often used in high throughput systems (HTS).
The resulting drone could enhance current operations.
The 6 degree-of-freedom (DOF) arm and gripper design are presented.
Test-and-evaluation approach and results are also given.
Robot companionship has become more popular in past years.
However, humanoid gait might be somewhat unstable for these applications.
Even with miniature humanoids, falls occur frequently.
Thus, wheel attachments have been added onto a miniature humanoid, so it can move faster and with more stability than walking.
In addition, with such attachments a robot can switch from walking to rolling when necessary.
DARwIn-OP is a humanoid robot that has been used as an experimentation and performance evaluation platform.
This paper discusses robot companionship by using a miniature humanoid capable of fetching toys with voice commands.
Advances in electronics and sensors have made drones useful for many tasks like surveillance, video recording, and delivery.
These applications and services require video recording for their operations.
Large drones are used singly in missions while small ones are used in formations or swarms.
The small drones are proving to be useful in civilian applications.
Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones.
To develop group display applications, a real-time drone control system for group display is proposed.
Simulation shows that drone formation can display messages effectively.
The rise of the Internet and mobile technology in recent decades has revamped our living styles and daily habits.
To ride on the digital trend, more business activities have been engaged in the digital world.
Marketing and advertising is one of typical business areas that is transformed digitally.
The rise of Important Influencers, social media platforms, and Omni-channel retailing have attracted countless business entities to consider the adoption of digital marketing tools for promoting and advertising their brands and products.
However, with the growing variety of digital marketing tools, they must be carefully selected based on several criteria.
In this paper, a fuzzy decision-making method is proposed and developed for assisting industry experts in evaluate and select proper digital marketing tools.
The developed method not only streamlines selecting digital tools, but it also increases the practitioner's effectiveness of achieving marketing objectives.
This study focuses on the digital marketing capabilities of tourism SMEs.
The study addresses the question of how the use of ICT-based tools benefit the company's performance.
By adopting marketing as a skills-based approach, the study provides new insights into the existing tourism literature on e-marketing.
Initial findings indicate that the digital marketing capabilities of companies are changed by digital technology.
Four major capabilities were identified, each of which evolves as a result of using the tools.
A key finding of the study is that the use of ICT-based tools transforms digital marketing capabilities for tourism businesses, enabling them to lead in online marketing.
Big data, the ability to collect and analyze data, delivers immense benefits in healthcare, marketing, environmental protection and national security.
The central tenets of the current privacy framework, the principles of data minimization and purpose, are severely strained by the big data technological and business reality.
As we increasingly interact with artificial agents without human supervision, their seeming autonomy and advanced capabilities, raises legal and philosophical questions.
The focus on the machine is a distraction from the debate surrounding privacy and ethics.
The machine may raise awareness of ethical challenges, but it is humans who must be held accountable.
Policymakers should seek to devise agreed-upon guidelines for ethical data analysis and profiling.
Such guidelines would address the use of legal and technical mechanisms to obfuscate data; criteria for reporting unethical behavior; types of harm related to privacy; and ways to help people understand their data.
As smart speakers become widely used in the world, people will become accustomed to voice interaction.
Although speech recognition, natural language processing (NLP) have been greatly improved over the past few years, users still may encounter errors from time to time like “cannot understand”, “no requested audio resource (such as music)”, which can frustrate users.
Therefore, when an error message is reported, it is vital that the smart speaker gives a good response.
However, currently the response strategies adopted by leading smart speaker brands in China differed mainly on two dimensions: “apology or not” and “humor or neutral”.
We explored user’s preference of response strategies under two error scenarios——“cannot understand” and “no requested audio resource”.
Two dependent variables (satisfaction and perceived sincerity of response) were measured.
People were more satisfied and found the apology sincere when smart speaker apologized in both error scenarios.
In the “no requested audio” scenario, humor had no significant impact on the perception of satisfaction and sincerity.
But in the “cannot understand” scenario, humorous expression decreased perceived sincerity.
the smart speakers cannot distinguish human voice from machine voice.
a method to identify which of human or machine is sending voice commands to a smart speaker is desired.
to prevent voice hacking when no one is home, we propose a system consisting of a speaker and a microphone array to detect the existence of a human nearby, supposing it can be incorporated in a smart speaker in the future.
Amazon's Echo, and Apple's Siri have drawn attention from different user groups; however, these existing commercial VUIs support limited language options for users including native English speakers and non-native English speakers.
we conducted a usability study of the Google Home Smart Speaker with 20 participants, including both native and non-native English speakers to understand their differences in using the Google Home Smart Speaker.
The findings show that compared to others, the native English speakers had better and more positive user experiences in interacting with the device.
It also shows that English language skills play an important role in working with Voice User Interfaces.
The findings from this study can create insights for VUI designers and developers can improve voice recognition in multiple languages for various user groups worldwide.
A pharmacophore analysis was used to compare different types of compounds for drug development (specifically, drug molecules, compounds in screening libraries, building blocks and nondrug molecules).
Significant differences were observed between the drug and screening compound profiles, which are similar, but not identical to those that are not related to drugs.
Pharmacophore profiles can be used as an additional tool for the optimization of compound selection and library design processes, thus improving the odds of success in lead discovery projects.
Lab experiment descriptions made machine-readable is a way to make experiment descriptions machine-readable.
Protocols are communicated using concise scientific English, which limits most kinds of analysis by software algorithms.
Given the availability of a suitable ontology, some or all of the pertinent information can be captured by asserting a series of facts, expressed as semantic web triples (subject, predicate, object).
With appropriate annotation, assays can be searched and analyzed in various ways, similar to other parts of drug development.
BioAssay Ontology has been designed for this purpose, and provides a hierarchy of meaningful terms.
Next generation sequencing (NGS) produces large amounts of data and up to thousands of samples.
Subsequent bioinformatic analysis is typically done with the help of open source tools, where each tool makes a single step towards the final result.
This situation leaves bioinformaticians with tasks such as combining tools, managing data, and documenting the analysis, to ensure the results can be repeated.
SPSS Clementinel2.0 statistical software was used to mine the relationships between diseases and their treatments in traditional Chinese medicine, and between symptoms and traditional Chinese medicine.
The classic Apriori algorithm is useful to mine cases of influenza treated by traditional Chinese medicine.
Identifying antimicrobial resistant (AMR) bacteria in genomic samples is essential for public health and food safety.
Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and studying the relationship between genetic information and characteristics in humans and other species.
A method using statistical probability for identifying genetic mixtures named as Genetic Polymorphisms Assignments (GPA) has reduced the false discovery rate (FDR) and mean absolute error (MAE) in single nucleotide variant (SNV) identification.
CRISPR-Cas is a tool that is widely used for gene editing.
Unwanted side effects may occur as a result of long-term nuclease activity.
Anti-CRISPR proteins, which are powerful molecules that inhibit the genetic editing system, may have the potential to promote better utilization of the genetic editing system in gene treatment.
More research on these proteins would help us understand how bacteria and phages evolve together.
Therefore, it is necessary to collect and integrate data on various types of anti-CRISPRs.
The CRISPR/Cas9 system was recently developed as a powerful and flexible technology for targeted genome engineering, including editing the genome.
These applications require the design of guide RNAs.
However, this remains challenging, as it requires the consideration of many criteria.
CRISPR has become a hot research area ever since its advent for its ability to edit DNA sequences precisely.
Several gene editing techniques have been developed to achieve different aims.
The target locations of a DNA strain can be broken and repaired, during which the genes can be changed, or activated.
The efficient preparation of CRISPR/Cas9 reagents and the easiness of experiment conduction make it now a powerful tool of high-content screen.
The hidden connection between these reports is that gene editing can help with healthcare problems.
Improving the health of future generations might coincide with public health goals; it might improve the health of individuals and communities, and, if successful, might be seen as a public good.
However, enhancing future generations will require Fertility and genetic testing.
Remarkably, the role of women in a positive situation has not been discussed by its proponents.
The present discourse on moral obligations of future generations, although not referring to women, seems to imply that women might be required, morally, to reproduce with IVF.
Enhancing future generations will be gendered, if artificial wombs are developed.
These are challenging issues that require a view from a broader perspective.
Despite the lack of a clear understanding of women's role in human genome modification, there is an urgent need to clarify the role of women in this scenario.
The CRISPR-Cpf1 system has been successfully applied in genome editing.
However, target efficiency of the CRISPR-Cpf1 system varies among different gRNA sequences.
A model was created to predict the effectiveness of specific genetic changes.
the first web service application, CRISPR-DT, a tool to help users design the best gRNAs for the CRISPR-Cpf1 system, to help users design the best gRNAs for the CRISPR-Cpf1 system by considering both target efficiency and specificity is available.
A major issue for self-driving cars is understanding the current driving situation.
Addressing this issue requires getting information from images by identifying the main elements of urban scenes that can be understood (streets, buildings, pedestrians, vehicles, signs, etc.).
A probabilistic method is proposed to fuse a coarse 3D map with stereo images.
A novel fusion architecture based on the Stixel framework is presented for combining image segmentation with a type of neural network with depth information obtained from stereo imagery while integrating coarse prior depth and label information.
The proposed approach was tested on a manually labeled data set in urban environments.
The results show that the classification accuracy of the elements that make up the city was significantly enhanced by this method compared to what is obtained from the semantic pixel-wise segmentation of a CNN alone.
In recent years self-driving cars are becoming more common on roads, with the promise of bringing safety and better transportation systems.
Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on realistic simulators, with multiple vehicles and pedestrians interacting with the self-driving vehicle.
It is therefore of critical importance to ensure that self-driving software is tested in various driving simulations.
Current methods for creating driving scenarios are adopted by leading self-driving car companies, still relies on human input [1].
In this paper we propose to automate the process using Bayesian optimization to test how well self-driving cars handle unexpected situations, and increase the risk of collision with simulated pedestrians and vehicles.
We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by refining the model with visual learning we obtain safer self-driving behavior.
With the development of self-driving technology, more and more L3 driverless vehicles are launched in market, people get opportunities to experience the self-driving cars in their daily life.
As a result, there is a growing demand for the autopilot experience.
Natural and efficient human-computer interaction can not only improve the driving experience, but also accelerate the process of self-driving commercialization.
This paper discusses eye-movement interaction, voice interaction and gesture interaction in driverless car, and analyzes the technology, advantages and disadvantages of the existing interaction modes, and prospect the future development trend of human-machine interaction.
Self-driving cars are becoming more advanced and will likely change transportation in the future.
One of the main challenges for self-driving vehicles on public roads is the safe interaction among multiple vehicles.
When self-driving vehicles try to occupy the same spatial area simultaneously, they might crash into each other, might slam on the brakes making it uncomfortable or unsafe for passengers in a self-driving vehicle.
In this paper, we study how a self-driving vehicle can safely navigate merge points, where two lanes meet.
We present a safe protocol for merge points named Autonomous Vehicle Protocol for Merge Points, where self-driving vehicles use sensors and communication with other vehicles for cooperating with other vehicles.
Our findings show that our traffic protocol has higher traffic throughput, compared to simple traffic protocols, while ensuring safety.
Emerging self-driving vehicles are vulnerable to different attacks due to the type of communication systems that are used in these vehicles.
These vehicles are increasingly relying on external communication via vehicle-to-vehicle communication networks.
Self-driving cars face new risks due to vehicle-to-vehicle networks.
These communication systems render self-driving vehicles vulnerable to many types of malicious attacks, such as Sybil, DoS, black hole, and other types of cyber attacks.
In this paper, we propose an intelligent security system designed to secure communications for self-driving and semi self-driving cars.
The hybrid detection system relies on the neural networks, to detect a common type of attack in VANETs: Denial-of-Service (DoS).
The experimental results show that the new vehicle security system is capable of identifying malicious vehicles in self-driving and partially self-driving vehicles.
This paper proposes a benchmark for testing self-driving cars using a special computer system based on a system that allows developers to build autonomous vehicles.
One approach to the development of self-driving systems is the utilization of ROS which is an open-source software for robot development.
On the other hand, the popular approach in the automotive industry is the use of a popular software.
MATLAB/Simulink connects to ROS. It enables to create robot capabilities in MATLAB/Simulink.
However, it hasn't been fully used in the development of self-driving systems yet because there are not enough data for self-driving, and it's hard for developers to adopt new ideas.
Therefore, we provide a MATLAB/Simulink benchmark suite for a self-driving system called Autoware.
Autoware is popular open-source software that provides a collection of self-driving features.
The provided benchmark contains MATLAB/Simulink samples available in Autoware.
They help to design self-driving systems using MATLAB/Simulink.
Ensuring the safety of self-driving cars is important, but neither industry nor authorities have settled on a standard way to test them.
Testing self-driving cars in normal traffic is a common, but costly and risky method, which has already caused fatalities.
As a safer alternative, virtual tests, in which self-driving car software is tested in computer simulations, have been proposed.
One can't test all possible driving scenarios for self-driving cars.
Therefore, we developed AsFault, a tool for automatically generating virtual tests for testing self-driving car software.
We test AsFault by testing the lane keeping feature of an artificial intelligence-based self-driving car software, for which AsFault generates scenarios that cause it to drive off the road.
A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw
At the beginning of self-driving vehicles, not much is known about how users react to them.
This is especially true for self-driving vehicles deployed in public transport services.
In this study, the relative preferences for a trip with a self-driving bus is assessed compared to a trip with a regular bus, based on a survey where people express their preferences.
A model is used to estimate people's choices regarding self-driving vehicles. Including attitudes towards trust in self-driving vehicles and interest in technology.
The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips.
This is due to the finding that the value of travel time is about twice as high for the self-driving bus as for the regular bus for a short trip.
Findings from this study further suggest that the popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes.
People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others.
Preferences towards automated public transport services are expected to evolve along with the transition from demonstration pilots to their deployment in regular operations.
The management of self-driving systems is becoming more complex as the development of self-driving technology progresses.
One approach to the development of self-driving systems is the use of ROS; however, the system used in the automotive industry is typically designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving.
These models are incompatible with ROS-based systems.
To allow the two to be used in tandem, it is necessary to adapt the code to work with the ROS system, which slows down development.
Therefore, the proposed framework allows created with a popular tool to be used in a ROS-based self-driving system, thereby improving development efficiency.
Furthermore, our evaluations showed the framework works well in practice.
Online Social Networks OSNs have become increasingly popular means of information sharing among users.
The spread of news about emergencies is common in social networks and so is the spread of false information related to the event.
We define as misinformation any false or inaccurate information that is spread either intentionally or unintentionally.
In this paper we study the problem of identifying misinformation online, and we focus on identifying misinformation on Twitter.
Based on user and tweets characteristics, we build a misinformation checker that identifies problematic behavior and exploits machine learning methods to detect misinformation.
Our experimental results were based on 80,000 unique tweets from 60,000 users illustrate that our approach effectively identifies misinformation during emergencies.
Furthermore, our model can identify misinformation quickly, a feature that can be used to limit the spread of the misinformation.
Superintelligence is a potential type of future artificial intelligence (AI) that is significantly more intelligent than humans in all major respects.
If built, superintelligence could be a transformative event, with potential consequences that are massively beneficial or catastrophic.
The idea of superintelligence is a topic of debate, and there's a lot of misinformation. Meanwhile, the prospect of superintelligence is the subject of major ongoing debate, which includes a lot of misinformation
Superintelligence misinformation is potentially dangerous, ultimately leading bad decisions by the developers of superintelligence and influencers.
This paper surveys strategies to counter advanced misinformation.
Two types of strategies are examined: ways to prevent misinformation and correcting it afterwards.
In general, misinformation can be difficult to correct, suggesting a need to prevent it.
The strategies proposed can be applied to lay public attention to highly advanced intelligence, AI education programs, and building agreement among experts.
Online misinformation could cause public panic and serious economic damages.
The problem of stopping false information aims at limiting the spread of false information in online social networks by launching competing campaigns.
Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem for the case when many cascades happen.
First, we provide a model for multiple cascades and introduce a key concept.
Second, we show that the misinformation containment problem cannot be approximated within a factor of this explains how computer science handles difficult problems, essentially showing that the problem is very hard to solve in a specific time frame unless this describes how computer science handles difficult problems.
Third, we introduce different types of cascade priority that are frequently seen in real social networks.
Finally, we design novel algorithms for solving the misinformation containment problem.
The effectiveness of the proposed algorithm is supported by encouraging experimental results.
Inaccurate information, in the field of library studies, is often regarded as a problem that needs to be corrected or simply understood as either misinformation or disinformation without further consideration.
Misinformation and disinformation, however, may cause significant problems for users in online environments, where they are exposed to a lot of false information.
This paper aims to develop a foundation for future research by examining the relationships among information, misinformation, and disinformation.
Our analysis extends to a discussion of cues to deception, to detect false information.
We argue that misinformation and disinformation are related but different types of information.
Misinformation is a multifaceted concept, more than just being wrong or missing information. Disinformation does not always entail misinformation.
The growth of social media provides a convenient communication scheme for people, but at the same time it becomes a hotbed of misinformation.
The wide spread of misinformation over social media is injurious to public interest.
We design a framework, which combines human and artificial intelligence, to help identify misinformation.
Analyze user expertise from their online posts and match the experts with given suspected misinformation.
By sending the suspected misinformation to appropriate experts, we can get feedback from experts to help refute misinformation.
In this paper, we focus on expert finding for misinformation identification.
We propose a tag system to identify users' expertise.
Experiments on a real world dataset demonstrate the effectiveness of our method for identifying experts in online posts.
The importance of research on misinformation has received wide recognition.
Two major challenges faced by this research community are the lack of theoretical models and the scarcity of misinformation in support of such research.
This paper aims to address the aforementioned challenges by understanding misinformation and enabling the interoperability of misinformation.
In particular, a model of misinformation are proposed through surveying, summarizing, and explaining existing work in the field.
A model for identifying misinformation can not only guide future misinformation research but also lay the foundation for building a library for managing misinformation by advancing our knowledge on misinformation and by improving its sharing, management, and reuse.
In addition, we present a formal methodology for managing misinformation in a digital library, and suggest future research directions related to the misinformation model.
Conspiracy theories have gained much academic and media attention, due to their effect on public events.
However, little is known about how conspiracy theories spread on social media.
We present a qualitative study of  conspiracy theories  on Reddit during a public health crisis--the Zika virus outbreak.
Using a combination of content and discourse analysis, we identified when Zika conspiracy theories occurred, what factors contributed to them emerging, and the discursive strategies through which Zika conspiracy theories developed in online forums.
Our analysis shows that conspiracy talk emerged as people attempted to make sense of a health crisis, reflecting their emerging information needs and their distrust in formal sources of Zika information.
Practical implications for social computing researchers, health practitioners, and policymakers are discussed.
Conspiracy theories are omnipresent in online discussions---whether to explain a recent event with no official explanation or to give voice to political dissent.
Conspiracy theories evolve, multiply, and interconnect, further complicating efforts to understand and control them.
It is therefore crucial to develop scalable methods to understand the nature of conspiracy theories in online communities.
What do users talk about when they discuss conspiracy theories online? What are the recurring elements in their discussions? What do these elements tell us about the way users think? This work answers these questions by studying online discussions on the r/conspiracy community on Reddit for over 10 years.
We focus on the key elements of a conspiracy theory: the people involved in the conspiracy, the things they do, and their targets.
A type of pattern or theme, such as "government control of information" represents the various ways in which several suspicious claims denote how governmental agencies control information.
They expose common themes between many conspiracy theories even when they refer to different events or circumstances.
In the process, these representations help us understand how users discuss conspiracy theories and offer us a means to interpret what they talk about.
Our approach enables a study of conspiracy theories in different media and news with implications for understanding their adoption and combating their spread.
Modern research suggests that believing in conspiracy theories is not entirely unreasonable, as conspiracies do happen, and a closer look at each theory can sometimes show it to be true. believing in such theories turns out to be warranted in a range of cases.
Drawing on this work, illustrating that conspiracy theories have the same kinds of evidence problems as other theories, showing that conspiracy theories have the same problems as other theories.
As such, if there is a problem with the conspiracy theorist’s use of evidence, it is one of principle: is the way they use evidence somehow in error? I argue that whatever we might think about conspiracy theories generally, there is no basic case for a scepticism of conspiracy theories based purely on their use of evidence.
Cryptocurrency is a rapid developing financial technology innovation which has attracted a large number of people around the world.
The high-speed evolution, radical price fluctuations of cryptocurrency, and different countries have varying views on cryptocurrency and have caused public security related events.
In this paper, we analyze the risks associated with the cryptocurrency market based on the public available price history.
Furthermore, consistent with public perception, our analysis shows that the cryptocurrency market is relatively fragile and unstable.
Blockchain technology is the technology that supports Bitcoin, the most common cryptocurrency.
Blockchain technologies have become increasingly popular with the potential to become a significant change.
Individuals and organizations may benefit from blockchain with its ability to increase secure data exchange and to make it easier to exchange between entities.
We investigate what affects someone's decision to use a cryptocurrency.
We develop a model to understand why people adopt cryptocurrencies to: identify the factors that influence the acceptance of cryptocurrency and explore how important each factor is.
We offer a better understanding with effects in government.
Cryptocurrency was built initially as a possible implementation of digital currency, then various derivatives were created in fields like finance and management.
This paper aims to offer analytical insights to help understand cryptocurrency by treating it as a financial asset.
We position cryptocurrency by comparing its dynamic characteristics with two traditional and massively adopted financial assets: foreign exchange and stock.
Our investigation suggests that the behavior of cryptocurrency are more similar to stock
Our research found the cryptocurrency market is more fragile than the stock market, thus it is currently a high-risk financial market.
The smart device owning rate such as smartphones and smartwatches is higher than ever before and mobile payment has become one of the major payment methods in many different areas.
At the same time, blockchain cryptocurrency is becoming a type of currency and the total value of all types of cryptocurrency has reached USD 200 billion.
Therefore, it is a natural demand to support cryptocurrency payment on mobile devices.
Considering the poor infrastructure and limited access to financial services in developing countries, this combination is especially attractive.
The high storage cost and payment processing delays are main issues for mobile payments with cryptocurrencies.
We propose two different methods for mobile payments, one using a bank and the other does not need a bank.
We also provide a solution for the bank to meet anti-money laundering and know your customer regulations when it is involved in cryptocurrency mobile payment processing.
Recent research has focused on the impact of financial crises on markets, studying how they spread and investor behavior.
Much less has been said about influence of financial news on financial markets.
We propose a new way to measure how financial news is connected on the web, and show that it can be used as a systemic risk indicator.
We evaluate the financial data from news sources on a daily basis from October 2011 to July 2013 and analyse the relationship between financial markets and news.
We assumed that strong cohesion in financial news reflects movements in the financial markets.
Cohesiveness is a more general measure of risk, than measures based on simple occurrences of specific terms. expressed in news, than measures based on simple occurrences of specific terms.
Our results indicate that financial news consistency is highly correlated with and driven by market instability.
In this paper, I propose a way to look at financial markets.
The entropy is derived using break down of stock market data in financial markets from selected developed economies, i.e., France, Germany, the United Kingdom, and the United States.
I study how economic shocks in the US impact other financial markets.
I use a model to analyze the uncertainty using a dynamic approach. find a common reason for the changes in these markets.
Mobile devices are very common in everyone’s day-to- day life.
Nowadays such devices come with many features of desktop or laptop.
Hence people can use these devices for diverse applications.
As the usability of these devices are very high, these devices can be used for illegal activities.
The percentage of mobile phones and smart phones involved in cyber crimes is on the rise.
So it becomes necessary to digitally analyze such devices using specialized tools.
This paper discusses different types of digital evidence present in Windows Mobile phones and a software approach for safely extracting data from the device.
A tool developed for collecting and examining Windows Mobile devices and WinCE PDAs.
The growing number of IoT devices has made it inevitable that they will be involved in digital forensic investigations in the future.
These devices produced by many vendors often posses limited standard interfaces for communication, such as USB ports or wireless connections.
Meanwhile, people are now focusing on data security, encryption is now common in many devices, including those used in the Internet of Things.
Under these circumstances, a significant challenge is presented to digital investigations of data from smart devices.
This work explores the electromagnetic analysis literature for the purpose of assisting digital forensic investigations on IoT devices.
EM side-channel analysis is a technique where computer operations can be spied on.
EM side-channel approaches are non-intrusive to assist digital forensic investigations as these attacks require, and must result in, no modification to the target device.
The literature on various EM security attack methods are discussed – selected on the basis of their investigating IoT devices.
The insight gained from the background study is used to identify future applications of the technique for digital forensic analysis on IoT devices – expanding the range of digital investigations that can be done.
The use of mobile phone forensics to investigate fraudulent activity is nothing new.
But mobile phones have evolved into smartphones, and fraudsters have evolved with them.
Smartphones are packed with functionality that can easily be used for data theft or inappropriate contact with other parties - none of which passes through their own systems, and is to all intents and purposes 'off the grid'.
Employers need to be aware of these risks when devices are issued, along with ensuring that processes are in place when suspicions are raised, explains Philip Ridley of CCL-Forensics.
Detecting corporate fraudsters is a constant game of catch-up.
It's not only about keeping up with the smartness of the cyber scammer, but also the technologies that can be abused.
What's more, the methods through which the technology can be manipulated to secrete, disguise and protect fraudulent activities - all while avoiding corporate networks that can be easily tracked.
This means a company's intellectual property and sensitive data is at risk of sabotage or just good old-fashioned theft.
They continue to change the code of websites used in their attacks to mimic legitimate sites and avoid detection.
Manipulations can be as subtle as code changes or as apparent as adding or removing significant content.
To appropriately respond to these changes to phishing campaigns, a cadre of file matching algorithms is implemented to detect phishing websites based on their content, using a large database of 18,000 phishing attacks on 159 different brands.
The results of the experiments using a variety of different content-based approaches demonstrate that some can achieve a detection rate of over 90% with few false alarms.
The focus of the short period after exercise (1-8 hours) is to enhance physiological processes that are critical for reducing the effects of exercise on the body and for helping the body adapt to exercise [1].
Recommended nutritional strategies to maximize recovery in skeletal muscle include protein to support muscle growth for replenishing glycogen stores
Muscle contraction and the intake of leucine-rich protein sources activate independent but complimentary signaling responses that converge at the mTOR pathway to stimulate protein translation enhancing rates of muscle protein synthesis [4]–[6].
The ingestion of 20-25 grams of high-quality protein soon after exercise has been shown to maximise the anabolic response in skeletal muscle.
The cultural environment surrounding some sports often involves the intake of large amounts of alcohol after training and competition, with athletes in several team sports being particularly at risk of “binge drinking” practices [9]–[11].
The outcomes of binge drinking after exercise are likely to include the direct effect of alcohol on physiological processes as well as the impact on recovery due to poor eating and resting habits caused by drinking too much.
Although the concurrent consumption of carbohydrate can partially offset the deleterious effects of alcohol intake on post-exercise glycogen resynthesis, Consuming carbohydrates after drinking can reduce some of the negative effects of alcohol on the body's ability to restore its energy stores after exercise. the effect of alcohol consumption on muscle protein synthesis is unknown.
The aim of the current study was to determine the effect of alcohol intake on cell signaling and protein synthesis in muscle fibers during recovery from a bout of strenuous exercise approximating stresses an athlete may experience in training and performance for various team sports such as various football and rugby codes, and court sports.
We hypothesized that compared to post-exercise protein intake, co-ingestion of alcohol would down-regulate translation production initiation and decrease rates of MPS.
Eight healthy physically active male subjects (age 21.4±4.8 yr, body mass (BM) 79.3±11.9 kg, peak oxygen uptake (VO2peak): 48.1 mL/kg/min ± 4.8 mL/kg/min, leg extension one repetition maximum (1RM) 104±20 kg; values are mean ± SD) who had been participating in regular exercise (three times a week for >6 months) volunteered for this study.
The study employed a standardized test design in which each subject completed bouts of consecutive resistance, continuous and intermittent high-intensity exercise with a post-exercise drink of alcohol or carbs on three separate occasions.
Resistance exercise consisted of eight sets of five repetitions at 80% of maximum strength.
After completion of the final set, subjects rested for 5 min before commencing 30 min of continuous cycling at about 63% of their maximum power output (∼70% of their aerobic capacity).
Upon completion, subjects rested on the bike for 2 min before undertaking 10 seconds of high-intensity exercise at 110% of their personal peak output, with 30 seconds of recovery between each exercise.
Immediately following exercise and after 4 h recovery, subjects ingested a 500 mL solution of either protein or a carbohydrate match.
Furthermore, a simple carbohydrate meal (1.5 grams per kilogram body mass) was consumed 2 hours post-exercise, immediately after the muscle biopsy, according to recommendations for post-exercise glycogen recovery [24].
The 8 h time frame represents an important phase of post-exercise recovery [1] as well as the period during which blood alcohol levels are likely to be high after a drinking binge [14].
The alcohol ingestion protocol (1.5 grams of alcohol per kilogram of body weight; 12 drinks with a 2-drink variation) began 1 h post-exercise and was consumed in 6 equal volumes of 1 part vodka (∼60 mL) to four parts orange juice (∼240 mL, 1.8 g CHO·kg−1 BM) during a 3 h period.
For the PRO condition, orange juice was consumed with a matched volume of water in place of the alcohol.
Subjects ingested the beverages within 5 min every 30 min.
Blood, cell signaling and mRNA data were analyzed by Two-way analysis of data over time and treatment. myofibrillar protein synthesis was analyzed by one-way ANOVA with repeated measures.
The novel finding of this study was that muscle protein synthesis following concurrent resistance, continuous and intermittent high-intensity exercise, designed to mimic the metabolic profile of many team sports, were impaired during the early (8 h) recovery phase by the ingestion of 1.5 grams of alcohol per kilogram.
These outcomes were most evident (37% reduction in rates of MPS) when alcohol was consumed in the absence of protein intake after exercise, a 37% reduction in muscle protein synthesis, when drinking alcohol after exercise makes it harder for athletes to recover properly.
When protein was consumed in amounts known to work best to boost muscle protein synthesis, the intake of alcohol reduced muscle protein synthesis by ∼24%, representing only a partial ‘rescue’ of the anabolic response compared with protein alone.
The mechanistic target of rapamycin complex 1 (mTORC1) is a central node for integrating signals from nutrients and physical activity [31], [32].
In conclusion, the current data provide the novel observation that alcohol impairs the response of muscle protein synthesis in exercise recovery despite optimal nutrient provision.
The quantity of alcohol consumed in the current study was based on amounts reported during binge drinking by athletes.
Some studies show that some people consume more than others, which is of concern for many reasons related to health and safety [13].
Regrettably, there has been difficulty in finding an educational message with alcohol consumption related to sports performance that has resonance with athletes. The reading level is around a high school level.
Given the need to promote protein synthesis that helps muscles repair and grow the current study shows that alcohol slows down recovery when consumed after exercise that includes weightlifting and high-impact activities even in the presence of optimal nutritional conditions.
We propose our data is of paramount interest to athletes and coaches.
Our research indicates a message about drinking less to promote recovery after exercise can benefit athletes.
In this paper we revisit a topic originally discussed in 1955, namely the lack of direct evidence that muscle hypertrophy from exercise has a direct link to muscle growth.
To this day, long-term adaptations in strength are primarily due to changes in muscle size.
Given this assumption, a lot of attention has been given to programs that help build muscle size and strength.
However, the conclusion that muscle size affects strength is surprisingly based on little evidence.
We suggest that these changes may be completely separate phenomena based on: (1) the weak link between muscle size and strength after training; (2) the loss of muscle mass with detraining, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load resistance training, yet divergent results in strength.
Low-intensity occlusion (50-100 mmHg) training provides a unique beneficial training mode for promoting muscle hypertrophy.
Training at intensities as low as 20% 1 repetition maximum with some blood flow restriction results in muscle hypertrophy in as little as 3 weeks.
A typical exercise prescription calls for 3 to 5 sets to exhaustion with short rest periods.
The metabolic buildup causes a rise in growth hormone that is higher than levels found with higher intensities.
Occlusion training is applicable for those with joint pain, surgery patients, cardiac rehabilitation, athletes who are unloading, and astronauts.
Current dogma suggests aerobic exercise training has minimal effect on skeletal muscle size.
We and others have demonstrated that aerobic exercise changes muscle structure over time and induces skeletal muscle hypertrophy.
These findings promote an antithesis to the status quo by providing novel perspective on muscle mass regulation and insight into exercise-countermeasures for populations prone to muscle loss.
Stretch training is widely used in a variety of fitness-related capacities such as increasing joint range of motion, preventing muscle stiffness and alleviating injuries.
Moreover, some studies suggest that stretching can cause muscle growth, but most research has been done on animals and lab tests.
The purpose of this brief review was to determine if stretch training works to build muscle.
Of the 10 studies identified, 3 observed some significantly positive effects of stretch training on muscle structure.
Intriguingly, in these studies, done using a machine or with an external overload.
Of 5 studies that combined stretching with resistance training, 2 applied the stretching in the interset rest period and were the ones that showed enhanced muscle growth.
In conclusion, passive, low-intensity stretch does not appear to confer beneficial changes in muscle size and architecture; alternatively, when stretching is done with some strain, it may help build muscle mass.
Cycle training is widely performed as a major part of any exercise program to improve heart and lung health.
The effect of cycle training on muscle size and strength gain still requires further insight, although professional cyclists have larger muscles compared to non-athletes.
Therefore, the purpose of this review is to discuss the effects of cycle training on muscle size and strength of the lower extremity and the possible mechanisms for increasing muscle size with cycle training.
It is plausible that cycle training takes longer to build muscle compared to regular weight training due to a slower muscle growth rate.
Exercise programs cause muscle growth in both young and older people, while strength gain seems to favor older adults, which means muscle quality improves more in older adults than in young adults.
For young adults, more intense cycling may be required to achieve strength gains.
Muscle growth due to regular exercise results from increased protein production in the muscles.
Resistance training is the most effective method to increase muscle mass.
It has also been shown to promote many health benefits.
Although it is deemed safe and of clinical relevance for treating and preventing a small and minimal dose of exercise has been the focus of a great number of research studies.
Similarly, a U-shaped relationship between training dose and physiological response has been hypothesized to exist.
However, the majority of the evidence supports a relationship between how much resistance training is done and the body's physical responses, such as muscle growth and overall health.
There is a lack of data to support the inverted U-shaped response.
The overarching principle argued herein is that volume is the most easily modifiable variable that has the most well-supported response with important repercussions, be these muscle hypertrophy or health-related outcomes.
Although the effects of short vs long rest breaks in resistance training on measures of muscle hypertrophy have been investigated in several studies, the findings are equivocal and the practical implications remain unclear.
Current evidence indicates that both short and long rest breaks may be useful when training for achieving gains in muscle hypertrophy.
Novel findings involving trained individuals using measures to detect changes in muscle hypertrophy suggest a possible advantage for the use of long rest intervals to elicit hypertrophic effects.
However, due to the paucity of studies with similar designs, more research is needed to compare these two approaches.
Memory is a process in which information is encoded, stored, and retrieved.
For vertebrates, the modern view has been that it occurs only in the brain.
This review describes a cellular memory in skeletal muscle in which hypertrophy is 'remembered' such that a fibre that was once large, but then shrank, can regain mass faster than naive fibres.
A new cell model based on the literature, with the most advanced methods for identifying muscle cell nuclei, can explain this phenomenon.
According to this model, previously untrained muscle fibers get new nuclei from satellite cells before muscle growth.
Even if subsequently weakened, more myonuclei is retained, and the myonuclei seem to be protected against the elevated apoptotic activity observed in atrophying muscle tissue.
Fibres that have gained more muscle nuclei grow faster when subjected to overload exercise, thus the nuclei represent a functionally important 'memory' of previous strength.
This memory might be very long lasting in humans, as neurons are stable for at least 15 years and might even be permanent.
Muscle cells in older people are harder to activate, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice.
It has been hypothesized that eating small, frequent meals enhances fat loss and helps to achieve better weight maintenance.
Studies show that eating less often is linked to lower body fat.
The purpose of this narrative review is to present and discuss an analysis of research studies that tested the effects of meal frequency with respect to changes in fat mass and lean mass.
Feeding frequency was positively associated with reductions in fat mass and body fat percentage as well as an increase in fat-free mass.
The positive findings were mainly due to one study, raising doubts about whether more frequent meals confer beneficial effects on body composition.
In conclusion, although the initial results of this meta-analysis suggest a potential benefit of increased feeding frequencies for enhancing body composition, these findings need to be interpreted with circumspection.
Inactive adults experience a 5% loss of muscle mass per decade, accompanied by resting metabolic rate reduction and fat accumulation.
Resistance training for 10 weeks can help you gain some muscle and lose fat.
Benefits of resistance training include improved physical performance, balance and coordination, walking speed, functional independence, thinking and problem-solving skills, and self-confidence.
Resistance training may assist prevention and management of type 2 diabetes by decreasing visceral fat, reducing HbA1c, increasing the efficiency of insulin transport, and improving insulin sensitivity.
Resistance training may enhance cardiovascular health, by reducing resting blood pressure, lowering bad cholesterol and triglycerides, and increasing high-density lipoprotein cholesterol.
Resistance training may promote bone development, Bone density increases by 1-3%.
Resistance training may be effective for reducing back pain and easing discomfort caused by arthritis and fibromyalgia and has been shown to reverse specific aging factors in skeletal muscle.
Physical activity has proved to be an effective means of preventing several diseases and improving general health.
Common sense advices call for late inception of strong, strength-related activities, like weight lifting and plyometrics, which are usually postponed at the end of the growth age, even among sport practitioners.
However, such advices seem to have a mainly anecdotal nature.
Current literature does not seem to have any particular aversion against the practice of strength training by children and adolescents, provided that some safety rules are followed, like medical clearance, proper instruction from a qualified professional and progressive overload.
At the same time, many studies provide consistent findings supporting the benefits of repeated, intense physical efforts in young subjects.
Improved motor skills and overall physical health have been extensively documented, especially if sport practice began early, when the subjects were pubescent.
Strength training is a relatively safe and healthy practice for children and adolescents. Strength training is safe for kids and teens.
Human aging results in a variety of changes to skeletal muscle.
Sarcopenia is the age-associated loss of muscle mass and is one of the main contributors to musculoskeletal impairments in the elderly.
Previous research has demonstrated that resistance training can attenuate muscle weakness in older adults, however few articles have focused on the effects of resistance training on functional mobility.
The purpose of this systematic review was to 1) present the current state of literature regarding the effects of resistance training on mobility outcomes for older adults with muscle weakness and 2) provide clinicians with practical guidelines that can be used with seniors during resistance training, or to encourage exercise.
We set forth evidence that resistance training can reduce the effects of aging, including improvements in gait speed, static and dynamic balance, and fall risk reduction.
Older adults should be encouraged to participate in progressive resistance training activities, and should be admonished to move along a continuum of exercise from immobility, toward the recommended daily amounts of activity.
Maximizing the hypertrophic response to resistance training (RT) is thought to be best achieved by adjusting the exercise program with factors like the type of exercise, its order, rest periods, and the intensity.
An often overlooked variable that also may impact muscle growth is length of sets.
Duration amounts to the sum total of the muscle types (concentric, eccentric, and isometric) components of a repetition, and is based on the repetition's tempo.
We conducted a review to see if changing the length of repetition can increase muscle growth in response to radiation therapy.
Results indicate that growth outcomes are similar when training with repetition durations ranging from 0.5 to 8 s.
From a practical standpoint it would seem that a fairly wide range of repetition durations can be employed if the primary goal is to maximize muscle growth.
Findings suggest that training at very slow speeds (>10 seconds per repetition) is not ideal for muscle growth, although a lack of controlled studies on the topic makes it difficult to draw definitive conclusions.
Recovery from exercise refers to the time period between the end of a session of exercise and the subsequent return to a resting or recovered state.
It also refers to changes in the body that happen after physical activity that are distinct from the body's state when it is at rest or in motion.
In this context, recovery of the cardiovascular system after exercise occurs over a short period, many aspects of the cardiovascular system change.
Some of these changes may be necessary for long-term adaptation to exercise training, some can cause heart problems after exercise.
Furthermore, some of these changes may provide insight into when the cardiovascular system has recovered from previous training and is ready for more exercise.
This review focuses on the most consistently observed changes in blood flow and the underlying reasons that help the heart recover and will highlight how they differ following resistance and aerobic exercise.
Primary emphasis will be placed on the hypotensive effect of aerobic and resistance exercise and associated mechanisms that can lead to symptoms like dizziness and fainting if left untreated.
Finally, we focus on the practical application of this information to maximize the benefits of cardiovascular recovery or reduce its vulnerabilities.
We will explore appropriate field measures, and discuss to what extent these can guide an athlete's training.
Exercise and physical activity are increasingly becoming key tools in the treatment and prevention of several medical conditions including arthritis and diabetes; this notion has been termed "exercise as medicine".
Exercise has favorable effects on reducing heart disease risk, inflammation, and weight loss, in addition to increasing physical functioning, strength, and cardio-respiratory capacity.
Chronic kidney disease, a condition that affects about 1 in 10 people, is often overlooked as a target for exercise-based therapy.
Despite the vast range of severity in kidney disease (pre-dialysis, dialysis, and kidney transplant), exercise has a potential role in all patients suffering from the condition.
In this review, we summarise the important role exercise may have in the care of kidney disease and how this form of treatment should be best administered and 'prescribed'.
Blood flow restriction (BFR) is an effective way to improve strength for healthy people.
However, its effects on pain in people with knee pain are unknown.
To determine the effectiveness of adding a special blood flow technique to weight training for pain relief and improvement of function in patients with knee pain.
Methods: Systematic review of clinical trials.
Studies that compared exercise with and without a blood flow restriction that treated knee pain and function in individuals older than 18 years of age with knee pain were included.
The pooled mean difference estimate showed that resistance exercises with BFR was not more effective than resistance exercises for reducing pain (a difference of 0.37cm, with a range of -1.93 to 0.19) and improving knee function (a reduction of 0.23 points, with a range of -0.71 to 0.26) in patients with knee pain.
In Japan, there were an estimated 43 million patients with hypertension in 2010.
This condition is given top priority in disease management, Lifestyle changes are crucial for preventing and treating high blood pressure, and this has been recognized in Japan.
In particular, emphasis has been placed on increasing the levels of activities of daily living and physical exercise (sports).
In this literature review, we examined appropriate exercise prescriptions (e.g., type, intensity, and duration) for the prevention and treatment of hypertension as described in Japanese and foreign articles.
This review recommends safe and effective whole-body aerobic exercise at moderate intensity (i.e., 50-65% of maximum oxygen intake, 30-60 min per session, 3-4 times a week) that primarily focuses on the major muscle groups for the prevention and treatment of hypertension.
Resistance exercise should be performed at low-intensity without breath-holding and should be used as supplementary exercise, but not recommended for people with high blood pressure who experience chest pain.
recently, there has been a renewed public interest in IFast.
Given the importance of nutrition in optimizing athletic performance, there is a concern about the effects of IFast on athletics.
Looking at high-intensity, endurance, and resistance exercises, studies have been varied but are showing that fasting does not improve athletic performance.
Nearly every physically active person encounters periods in which the time available for exercise is limited (e.g., personal, family, or business conflicts).
During such periods, the goal of physical training is to maintain performance.
Similarly, certain groups may desire to maintain performance for prolonged periods, namely athletes during their competitive season.
In general populations, endurance performance can be maintained for up to 15 weeks when training frequency is reduced to 2 sessions per week or less, with a decrease in exercise time, as long as exercise intensity is maintained.
Strength and muscle size (at least in younger populations) can be maintained for up to 32 weeks with as little as 1 session of strength training per week and 1 set per exercise, as long as exercise intensity (relative load) is maintained; whereas, in younger populations, maintaining muscle size may require 2 sessions per week and 2-3 sets per exercise, while maintaining exercise intensity.
Our primary conclusion is that exercise intensity seems to be the key variable for maintaining physical performance over time, despite big cuts in exercise frequency and volume.
Nutrient timing involves consuming a mix of nutrients, mainly protein and carbs, around exercise.
Some people think this approach can lead to better body shape.
It has even been suggested that when we eat what we eat may be more important than how much we eat.
The post-workout period is widely considered the most critical part of nutrient timing.
In a scientific sense, consuming the proper ratio of nutrients during this time not only initiates the rebuilding of damaged muscle and restoration of energy reserves, but it does so in a supercompensated fashion that enhances both body composition and exercise performance.
Several researchers have made reference to an optimal time for muscle growth whereby after training to optimize muscle growth.
However, the importance - and even the existence - of a post-exercise 'window' can vary depending on several factors.
Not only is nutrient timing research open to question in terms of applicability, but recent evidence has questioned the traditional understanding of the importance of nutrition after exercise.
Time constraints are a common reason for not exercising.
The aim of this review was to determine how strength training can be most effectively carried out in a time-efficient manner by evaluating recent research on training methods, advanced training techniques, and the need for stretching and warming up.
When programming strength training for optimum time-efficiency we recommend prioritizing bilateral, multi-joint exercises that include full dynamic movements (i.e. both muscle lengthening and shortening actions), and to perform a minimum of one leg pressing exercise (e.g. squats), one upper-body pulling exercise (e.g. pull-up) and one upper-body pushing exercise (e.g. bench press).
Exercises can be performed with machines and/or free weights based on training goals, availability, and personal preferences.
Weekly training volume is more important than training frequency and we recommend performing a minimum of 4 weekly sets per muscle group using a loading range of 6 to 15 repetitions, (15-40 repetitions can be used if training is performed to volitional failure).
Advanced training techniques, such as supersets, drop sets and rest-pause training cuts training time in half compared to traditional training, while maintaining training volume.
Research is needed to understand how this method affects muscle growth, but it may not be the best way to build strength.
Finally, we advise restricting the warm-up to use exercise-specific warm-ups and stretch if your goal is to improve flexibility.
Training frequency is considered an important variable in the muscle growth response to regimented resistance exercise.
The purpose of this paper was to conduct various studies designed to investigate the effects of regular exercise frequency on muscle growth.
Results showed no significant difference between higher and lower frequency on a per volume basis.
An analysis of the combined results of the studies that controlled for differences in study size showed a significant effect favoring higher frequencies, although the difference was relatively small.
There is evidence that resistance training frequency does not affect muscle growth as long as the volume remains the same.
Thus, for a specific amount of training, individuals can choose a weekly frequency per muscle groups based on personal preference.
A variety of various training methods have been advocated as a means to build muscle.
Forced repetitions/drop sets, supersets, and heavy negatives, in particular, have been purported to enhance the muscle growth response to weight training.
This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to resistance training programs.
The quest to increase lean body mass is pursued by weightlifters.
There is a lack of research, however, as to the best approach for building muscle through exercise.
Bodybuilders generally train with moderate loads and short rest intervals that stress the body.
Powerlifters, on the other hand, routinely train with high loads and long rest periods.
Although both groups are known to display impressive muscularity, it is unclear which method is more effective for muscle growth.
It has been shown that several factors contribute to muscle growth and that mechanical tension, muscle damage, and metabolic stress all can play a role in exercise-induced muscle growth.
Therefore, the purpose of this paper is to review the literature on how muscles grow and to draw conclusions from the research as to the optimal protocol for maximizing muscle growth.
New technology in mobile devices can be helpful in fighting wildfires, enabling end-users to easily conduct several everyday tasks, such as access to data and information, sharing of intelligence and coordination of personnel and vehicles.
This work describes an innovative mobile application for wildfire information management that works on mobile devices and acts as a complementary tool to the web-based version of the AEGIS platform for wildfire prevention and management.
Several tasks can be accomplished from the AEGIS App, such as routing, search for nearby facilities and firefighting support, access to weather data and maps of emergency resources, including water, gas and evacuation sites.
An innovative feature of AEGIS App is the support of these tasks by a digital assistant for artificial intelligence named Cortana (developed by Microsoft) that allows information utilization through voice commands.
The application is to be used by firefighting personnel in Greece and is potentially expected to contribute towards a more sophisticated transferring of information and knowledge between wildfire operation centers and firefighting units in the field.
In recent years, mobile technologies have developed and applied in education fields, and some mobile devices include e-book, smartphone, and PDA.
Some of the mobile carriers uses special technologies to connect to wireless networks to make effective use and provide students new learning experiences differed from the past learning.
In view of the application of mobile technology in education, some previous studies have addressed that mobile learning is a meaningful learning that can improve the interaction between students and the situations and reach the purposes of learning.
In the main stream of mobile learning, using mobile carriers with suitable learning methods or strategies in mobile learning activities for different students to enhance learning have gradually become a important and concern issue.
The purpose of this study is to investigate the learning achievement and learning attitude of elementary school students on a school garden project when they use mobile carriers and competitive learning strategies.
The experimental results show that the competitive learning group have better learning outcome than non-competitive learning group.
After completing the learning activity, the two groups of students presented high positive attitudes towards learning.
This paper proposes a wireless patient monitoring system which integrates an ECG transmitter, GPS device and a mobile phone to acquire physiological signals and transmit them to a local server via Bluetooth.
This paper proposes an electrophysiological wireless patient monitoring system which integrates a Wireless ECG signal transmitter, GPS device and a mobile phone to acquire and transmit vital signs to a local server via Bluetooth wireless technology.
Four types of monitoring systems were designed for wireless communication, including a control center, a local monitor, mobile devices, and a website for patients and doctors.
Four types of monitors were designed for wireless communication, including a control center, a local monitor unit, mobile devices (personal digital assistant; PDA), and a Web page (for both patient and doctor).
The use of various monitor units is created to fulfill different medical personnel requirements and wishes.
The use of types of monitor units is created to fulfill different medical needs.
This application was developed to improve mobility for the patients and also for the medical personnel, which will improve health care and patient lifestyle.
This application was developed to promote mobility and flexibility for the patients and also for the medical personnel, which further will improve health care and patient's lifestyle.
As various kinds of output devices emerged, such as highresolution printers or a display of PDA(Personal Digital Assistant), the importance of high-quality resolution conversion has been increasing.
As various kinds of output devices emerged, such as high-end printers or mobile devices, the importance of high-quality resolution conversion has been increasing.
This paper proposes a new method for enlarge pictures.
This paper proposes a new method for enlarging image with high quality.
One of the largest problems on image enlargement is the exaggeration of the jaggy edges.
One of the largest problems on image enlargement is the exaggeration of the jaggy edges.
To remedy this problem, we propose a new interpolation method, which uses a computer algorithm to predict the missing pixels.
To remedy this problem, we propose a new interpolation method, which uses a computer algorithm to calculate the best interpolation.
The experimental results are shown and evaluated.
The experimental results are shown and evaluated.
Our methods are effective is discussed by comparing with the conventional methods.
The effectiveness of our methods is discussed by comparing with the conventional methods.
A significative percentage of the human population have trouble seeing colors.
A significative percentage of the human population have trouble seeing or distinguishing colours.
For them, everyday tasks like navigating through a train or metro network map becomes demanding.
For them, everyday tasks like navigating train or metro maps becomes demanding.
We present a new method for getting color information from everyday objects and surroundings and presenting it to people with impaired vision as pleasant, non-invasive sound.
We present a new way to extract color from everyday objects and presenting it to visually impaired users as pleasant, non-invasive sound.
This technique was implemented inside a Digital Assistant portable device.
In this implementation, colour information is extracted from the input image and categorised according to how people group colours.
In this implementation, colour information is extracted from the input image and categorised based on how people see colours.
This information is converted into sound and sent to the user via speakers or headphones.
Users can give feedback to adjust the system in the original version. However several features such as these were not implemented because the current technology is limited. We are confident that the full implementation will be possible in the near future as PDA technology improves.
In the original implementation, it is possible for the user to send its feedback to reconfigure the system, however several features such as these were not implemented because the current technology is limited. We believe the full implementation will be possible in the near future, thanks to advancements in technology.
Inappropriate use of medicines increases the risk of hospital admissions for the elderly.
Inappropriate use of medicines increases the risk of hospital admissions for the elderly.
This leads to excessive pain for the patients but also incurs a great financial cost to the society.
This leads to unnecessary suffering for the patients but also incurs a great financial cost to the society.
A medicine decision support system in a Digital Assistant, with a barcode reader, can provide an overview of the patients' complete medicine use, and detect potentially bad medicine combinations.
Focusing on the elderly, our aim was to evaluate if a mobile medicine decision support system with a barcode reader is useful and user-friendly for nurses in home care.
Focusing on the elderly, our aim was to evaluate if a mobile medicine advisor with a barcode reader is useful and user-friendly for nurses in home care.
The participants received a comprehensive overview from the patients' medicine use and noted drug interactions, therapeutic duplications and warnings for drugs unsuitable for elderly people.
The participants received a comprehensive overview from the patients' medicine use and noted drug interactions and potential side effects for the elderly people.
The nurses regarded that the system made the nurses safer, was useful and user-friendly.
The nurses regarded that the decision support system increased prevention and safety, was useful and user-friendly.
Our findings suggest that most of the content and functions were regarded as important.
Our findings suggest that most of the content and functions were regarded as important.
Therefore, this decision support system might be a useful tool for district nurses.
 :[0],"access to patient appointment schedules can help clinicians manage time and problems better.
 :[0],"access to patient appointment schedules can help clinicians manage time and problems better.
Many large health care organizations manage clinical appointment scheduling via special computer systems that are hard for clinicians to use.
Many large health care organizations manage clinical appointment scheduling via the systems are hard to use.
Also, staff other than the clinician's assistants may manage scheduling, making it difficult for clinicians to stay informed.
Also, other staff members may manage scheduling, making it difficult for clinicians to stay informed of changes.
Many a clinician today uses a personal digital assistant (PDA) containing basic calendaring functionality.
Many clinicians today use a personal digital assistant with basic calendar features.
Our "PalmOversite" project demonstrates the feasibility of integrating schedule information into a PDA calendar, making schedule information much more readily available to the clinician.
Our “PalmOversite” project demonstrates the feasibility of integrating enterprise appointment schedule information into a PDA calendar, making schedule information much more readily available to the clinician.
Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of drug-resistant tuberculosis patients in Peru, in conjunction with the Peruvian TB Program.
Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of multidrug-resistant tuberculosis (MDR-TB) patients in Peru, in conjunction with the Peruvian National TB Program (NTP).
Regular health tests are collected from various health centers across the city, which are an integral part of this treatment.
Monthly bacteriology tests, which must be collected from health establishments located across this major city, are an integral part of this treatment.
A healthcare worker visits each health establishment to collect this information by hand, process it and type it into a computerized medical file. This: [81],"paper, we describe the development and implementation of an electronic system to collect and upload monthly lab test results to the patient's medical record system.
A health worker visits each health establishment to collect and enter the information into the electronic medical record. This: [81],"paper, we describe the development and implementation of a personal digital assistant (PDA)-based electronic system to collect, verify and upload monthly bacteriology data into the PIH-EMR.
We performed a trial period to test the use of this system.
After a first trial period, we performed a study to check this system.
We completed a baseline assessment in two health districts and then implemented the electronic system in one of the districts while the control site used paper-based records during the same time.
We completed a baseline assessment in two local health areas and then implemented the electronic system in one of the areas while the control site continued to use the paper system during the same period.
The system had a processing time of 6.2 days, which is faster than the baseline (54.8 days) and control sites (64.4 days).
The computer-based system had a processing time of 6.2 days, significantly lower than measurements for both the reference [54.8] and control sites [64.4] (both < 0.0001).
It was also able to reduce the frequency of discrepancy from 10.1% to 2.8% (a significant reduction) and receive positive feedback from the users.
It was also able to reduce the discrepancy rate from 10.1% to 2.8% and receive positive feedback from the users.
The system's cost would be paid back in three months due to increased productivity.
This system will be the subject of a larger study to determine its impact on delays, errors and costs.
In order to facilitate knowledge transfer between experts and non-experts, and to promote interdisciplinary communication, there is a need to provide methods and tools for doing so.
In order to facilitate knowledge transfer between experts and non-experts, and to promote interdisciplinary communication, there is a need to provide methods and tools for doing so.
A research team developed and evaluated a decision tool on a mobile device for cardiac tele-triage/tele-consultation when the presenting problem was chest pain.
A research team developed and evaluated a decision support tool (DST) on a personal digital assistant (PDA) for cardiac tele-triage/tele-consultation when the presenting problem was chest pain.
The combined human factors and ecological interface design during the requirements-gathering and design phases were used to develop the DST.
A pilot clinical trial was conducted at a specialized heart care hospital over a 3-month period.
During this time, nine staff members who provide medical consultations 24/7 were using the DST.
This clinical trial validated the design and demonstrated its usefulness to advanced cardiac care nurses, its potential for use by less experienced nurses and in team environments.
This clinical trial validated the design and demonstrated its usefulness to experienced cardiac nurses, its potential for use by nurses with less experience in cardiac care, and for its potential use in a team of healthcare professionals.
This paper presents M-CALL, a mobile language learning app for Korean learners.
Since computer-assisted language learning is often boring, it exploits a cyber pet game to increase the learner’s interest.
M-CALL runs on a personal digital assistant with public Wi-Fi for mobile learning.
M-CALL runs on a personal digital device with wireless internet for mobile learning.
It grows a cyber pet by solving problems of Korean language learning.
Korean Proficiency Test (KPT), a nationally certified Korean language test, was used as problem sets.
It consists of cyber pet game, mobile learning courseware, learning system on mobile devices, and mobile tutoring.
It provides various functions for Korean language learning.
Currently, the prototype M-CALL was designed and partly implemented between mobile PDA and personal computer.
This study compared performance of two types of handheld keyboards: QWERTY and T9
Participants entered text on a computer into a PDA using a stylus or a keyboard.
Participants transcribed text presented on a computer screen into a personal digital assistant (PDA) using a stylus and one of these two keyboards.
We introduced a physical technique for measuring transcription rate that provides a composite measure of speed and accuracy.
We introduced a special technique for measuring writing speed and accuracy.
Using this technique, we calculated the maximum transcription rate for each keyboard.
The results show that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9 keyboard’s apparent superior physical characteristics.
The results show that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9's physical characteristics.
An ancillary experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in visual scanning time due to difficulties in seeing the letters on the keys.
An ancillary experiment demonstrated that the poorer performance of the T9 layout resulted from increased visual scanning time due to how our brains group the letters on the keys.
The QWERTY layout is the most effective keyboard design for stylus tapping on soft keyboards.
Together these findings imply that the QWERTY keyboard layout remains the most effective of the available designs for stylus tapping on soft keyboards.
The growth of mobile devices like smartphones and mobile assistants opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system).
The proliferation of mobile devices such as smartphones opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system).
In E-commerce systems, we still see many common components that we have in standard E-commerce applications, such as web servers and database servers.
In E-commerce systems, we still see many common components that we have in standard E-commerce applications, such as web servers and database servers.
However, these new applications raise some unique challenges.
The limitations of mobile devices (e.g., small screen size and reduced CPU performance) Software development is somewhat different from desktop applications.
Questions which are posed when designing M-commerce system include: “What kind of information do users want to access on their mobile devices?”, “How can we create useful apps with minimal user input?”, “How can we test an M-commerce system?” In this paper, we discuss about some software issues for mobile commerce systems from our experiences while developing an M-commerce system for tourists.
Our prototype, easyHotel, is an useful software that allows booking hotel rooms via mobile phones.
It is acknowledged that information such as web content should be adapted for mobile platforms to account for restrictions in mobile environments.
As emerging mobile platforms such as smartphones and tablets tend to vary largely in their capabilities, we suggest that adaptation should be platform-specific.
Common approaches for content adaptation are automated conversion and explicit specification of adapted content, with a trade-off between quality and cost.
As alternative avoiding this trade-off, we propose a basic framework for adapting content.
As alternative avoiding this trade-off, we propose a simple object-oriented framework for content adaptation.
To facilitate the use of this framework in the Web, we base our approach on the object-oriented WebComposition model and its XML-based implementation WCML.
Using an object-oriented approach to develop an application reduces maintenance work. We apply this approach to an example application to demonstrate how this reduces development/maintenance effort.
We apply our object-oriented approach to an example application to demonstrate how way of adapting content to different platforms reduces development/maintenance effort.
In monitoring a patient's real-time vital signs through wireless sensors on the body, rich data sources are communicated to medical practitioners.
It is essential that data is delivered in timely-context aware manner.
In this paper a system for patients with heart problems, with a focus on the sensing device and communication system.
In this paper a system is designed for patients with cardiac disorders, with a focus on the sensing device and communication method.
Wearable physiological devices used in the Healthcare systems are bulky in design and are not flexible and comfortable for the elderly patients.
Several existing wearable health monitoring devices used in the Healthcare systems are bulky in design and are not flexible and comfortable for the elderly patients.
Presented is a unique flexible, as well as detachable PSD for the comfort of patients.
Also discussed is a model for patient data management, which ensures periodic logging of patient data without saturating communication networks.
Also discussed is a system for managing patient data, which ensures periodic logging of patient data without saturating communication networks.
A proof of concept prototype has been developed and implemented to enable transmission of Electrocardiogram (ECG) signal and body temperature of a patient, which can be expanded to include other vital signs.
A proof of concept prototype has been developed and implemented to transmit ECG and body temperature of a patient, which can be expanded to include other vital signs.
Communication between a mobile smart-phone and the heart rate and temperature monitor is implemented Bluetooth.
Communication between a mobile smart-phone and the ECG and temperature monitor is implemented Bluetooth.
The DMS system is designed to connect sensor units with patient data at a medical service provider through a smartphone or a personal digital assistant making use of the existing GSM network.
Advancement of wireless and mobile technology has enabled new platforms to support learning.
Advancement of wireless and mobile technology has enabled additional platforms to support learning in a single learning environment.
Current trend integrates usage of mobile terminals such as smartphones in a learning system.
Current trend integrates usage of mobile terminals such as smart PDA in a education system.
Such devices can communicate with wireless mobile terminal and realize the exchange information with its environment [1].
A language learning outside the classroom system named One Day Trip is developed to assist overseas students to learn Japanese in real life situations with the help of a PDA.
This paper proposes the implementation with ways to manage and share knowledge in the system to aid the teacher and learners in the learning environment.
In recent years, we have developed applications for teaching both wired and wireless networking.
These applications have been written for the Cybiko personal digital assistant, an inexpensive alternative to other hardware.
Unfortunately, the Cybiko PDA was recently discontinued.
As a result, these applications had to be ported to other platforms to remain useful.
Instead of porting each application to individual platforms, which would prove to be time consuming because of other technical issues. We created the Vassar College Messaging Layer.
This layer abstracts the Cybiko networking structure and interface, allowing Cybiko applications to be adapted to other platforms.
Unlike many other types of hardware, smartcards cannot communicate securely with the user.
Deprived of means to keep the owner informed, the positive properties of smartcards are difficult to utilize.
We explore the area between smartcards and more powerful machines.
On the other side of this border we find the Personal Digital Assistant :[66],"our view, to be useful as an extension of the users' private sphere, a machine must at least have enough functionality to create secure digital signatures for the user.
On the other side of this border we find the Personal Digital Assistant  :[66],"be useful as an extension of the user's personal space, a machine must at least have enough functionality and resources to generate secure digital signatures to represent the user, as it were.
A less resourceful machine can merely act as a memory prothesis, helping the owner remembering addresses and phone are :[121],"designed to be secure, and as such they seem ideal as a simple machine.
However, a smartcard alone cannot create trustworthy digital signatures, because the user doesn't know what data is being stored on the card, so it needs external support to function properly. Digital signatures can not be created by smartcards alone, simply because the user does not know what is given to the card for order to be trusted--that is, being able to make trustworthy digital signatures--a smartcard must be supported by some infrastructure outside the card proper.
Trustworthy digital signatures can't be made using just a smartcard, they also require external support. Digital signatures can not be created by smartcards alone, a smartcard must be supported by some infrastructure outside the card proper.
We explore what must be included in such an infrastructure, and demonstrate that trustworthy digital signatures can in fact be made using a standard  :[211],"argue that based on this fact, systems that use smartcards can be designed to be more complex, but still practical and useful, giving card holders special status."
Smartcards are here to stay, finding ways to apply them in constructive manners is prudent.
In this paper we present the main features of a system that we have developed and that provides a new kind of tele-assistance service to elderly people. excluding the services already offered by current tele-assistance
In this paper we present the key features of the system that we have developed and that provides a new kind of assistance service to elderly people.apart from the functionalities offered by the current tele-assistance services, also provides high-quality assistance available anywhere and at any time.
We rate the assistance as high quality because allows the monitoring of vital signs and a local detection of anomalous situations by the device that the person carries in real time.
We rate the assistance as high quality because it allows the monitoring of vital signs and real-time detection by the device.
Therefore, it sends alarms autonomously when  this paper we :[84],"explain the three main functionalities offered by AINGERU: universal assistance anywhere and any time, monitoring of vital signs no matter where or time and remote monitoring by allowing authorized external persons to consult data about monitored persons using the Internet.
Therefore, it sends alarms autonomously when  this paper we :[84],"explain the three main functionalities offered by AINGERU: available anywhere and at any time, monitoring of vital signs irrespective of location or time and remote monitoring by authorized external access to monitored persons' data.
Moreover we show how those functionalities are achieved by making use of PDAs (Personal Digital Assistant), wireless communication, Specialized web technologies.
To evaluate the effectiveness of a computer-based medical guidance system on nonsteroidal anti-inflammatory drug (NSAID) prescribing safety in the setting, the study was a controlled trial conducted at a teaching hospital.
To evaluate the effectiveness of a computer-based medical guidance system on pain medication prescribing safety in the outpatient setting, the study was a controlled trial in a university clinic.
Internal medicine residents received a mobile-based clinical decision support system.
Internal medicine residents received a PDA-based CDSS suite.
For intervention residents, the Computerized Decision Support System included a prediction rule for risk assessment for stomach problems caused by NSAIDs and treatment recommendations.
For intervention residents, the CDSS includes a system to predict which patients are at risk for stomach problems from NSAIDs and provide treatment suggestions.
unannounced volunteer patients presented to study physicians to portray musculoskeletal symptoms.
Safety outcomes were assessed from the prescriptions given to the SPs.
Safety outcomes were assessed from the prescriptions given to the SPs.
Each prescription was reviewed by a team of doctors who didn't know which group the participants belonged to: Prescriptions were judged as safe or unsafe.
Each prescription was reviewed by a committee of doctors who didn't know which group the participants belonged to :[108],"Prescriptions were judged as safe or unsafe.
The main outcome measure was the change in safe prescribing of NSAIDs between the two groups. At the start, the two groups had a similar rate of potentially harmful prescriptions.
The main outcome measure was the change in unsafe prescribing of NSAIDs for the intervention versus the control At baseline, the rate of unsafe prescriptions was similar for both groups (27% vs. 29%)
Intervention participants were safer after receiving the CDSS compared to those who didn't. This was shown by a significant improvement in their performance.
Controlling for baseline performance, participants who received the CDSS made safer prescriptions compared to those who didn't (0.23 vs. 0.45)
With the CDSS, intervention participants documented more complete assessment of patient gastrointestinal risk from  :[198],"Those given a CDSS for prescribing NSAIDs made fewer bad decisions than those who didn't have it.
Recently pedestrian navigation has been studied by many researchers, which provides pedestrians with a similar function of car navigation.
On the other hand, a 3D map has been utilized as a simulation tool in city and landscape planning, and other engineering fields.
The 3D maps will give more intuitive information compared to conventional 2-dimensional (2D) ones.
In this paper we first propose navigation for pedestrians using 3D maps, and describe technologies required and its use situations.
We compare effectiveness of 2D and 3D maps for navigation; display sizes corresponding to a mobile phone and PDA (Personal Digital Assistant).
The experimental results show that 3D maps on mobile phones and PDA screens are better than 2D maps in search time and accuracy.
From these results, we can say the effectiveness of 3D maps in pedestrian navigation.
Mobile agents are a competitive concept of client-server computing and are especially suitable in mobile environments, that are characterized by low bandwidth communication facilities and ad hoc connection/disconnection to stationary systems.
They can be used for information retrieval and filtering, in which case they evaluate replies and return only the relevant data.
Mobile agents are created on a mobile device like a smartphone, will be launched into the information galaxy and are fulfilling the mobile user ‘s task on the services available on networked stationary systems.
One transmission channel for these itinerant agents is email.
This paper introduces Active M 3 as an example of an active mail framework, which can be regarded as a first approach in creating mobile agents in a graphical interface.
Active M 3 combines email and messaging.
Digital Video Broadcasting — Handheld (DVB-H) is a technology developed as an extension of Digital Video Broadcasting — Terrestrial (DVB-T) with additional features that make it suitable for delivery to mobile devices such as phones and Personal Digital Assistant (PDAs).
This paper deals with the conditions of receiving digital video broadcast type services in mobile handheld devices.
The DVB-H standard is introduced and key technology elements for data and signal transmission are discussed in some details.
Finally the DVB-H terminal and network design is described.
I still don't have the original passage to accept or simplify. Please provide it so I can proceed.
We present a design for a low cost and fast communications device powered by IDTu0027s RV4640 as its processing engine.
The device can achieve very high speed, thanks to the fast network card.
The device could be used as a two way pager, a set-top box, an Internet terminal, a personal digital assistant or as a video phone.
The RV4640 is a very affordable 64 bit RISC processor that executes 175 dhrystone MIPS at 133 MHz.
The RV4640 can be connected to an Interface Chip which will provide Input/Output and memory control.
The IDT77903 ATM card is a high-speed network card with a standard computer connection and it costs less than $100 (US).
Integrating this card into our device as a network interface will make video and multimedia applications easily implementable.
Dr. Who is a Microsoft research project aiming at creating a speech-centric multimodal interaction framework, which serves as the foundation for the voice interface.
The paper discusses MiPad's design, ongoing implementation work, and preliminary user study in comparison to the existing pen-based PDA interface.
MiPad is the application prototype that demonstrates compelling user advantages for wireless personal digital assistant (PDA) devices, MiPad fully integrates speech recognition and spoken language understanding to enable users to accomplish many common tasks using a multimodal interface and wireless technologies.
It tries to solve the problem of typing with small styluses or typing on keyboards in today's personal digital assistants.
Unlike a cellular phone, MiPad avoids speech-only interaction.
It incorporates a built-in microphone that activates whenever a field is selected.
When a user taps the screen, it helps the system understand what they want to say.
MiPad currently runs on a Windows CE Pocket PC with a Windows 2000 operating system where speech is recognized.
The Dr Who CSR engine uses a Context-Free Grammar and n-gram language model.
The Dr Who SLU engine is based on a parser and a dialog manager.
New mobile applications emerge in complex commercial environments.
Research in the sociology of technology suggests that the evolution of new applications is a process of social interaction between multiple constituencies, aiming to create a clear definition of mobile technology problems and solutions that becomes clear after the fact.
This theory is illustrated by the development of PDAs.
They impose their own definitions on new technologies, thereby forcing newer players to provide a 'total system' that completely redefines a new application area.
In the ordinary environment, mobile terminals like personal digital assistant or cellular phone are used to access the Web.
We implemented the procedures in a simple viewer system that transforms Web content into passive viewing content that is especially useful for mobile devices.
Extracting images and text from Web content, u-PaV generates a Flash file, which is a popular multimedia format.
The presentation of Web content depends on the device being used. The Web interface of mobile terminals is designed almost the same as that of personal computers.
However, comparing mobile and desktop terminals, some difference in device characteristics, such as screen size, affect the presentation on the terminal.
Moreover, when changing the access style between interactive and non-interactive, the presentation should be adjusted for the terminal type because the lacking information is usually not perceived after transformation.
To adjust the play style of Web content to the terminal type, we developed a method for visual presentation.
First, using keyword analysis, we represent the emotional aspect of a Web page by adjusting the background color of the screen.
Second, we emphasize the subject of the content by the logotype of the keyword.
Third, we segment the picture of the content into pieces and present one after another using visual effects.
These procedures can be applied to any type of terminal.
We have developed a location aware system that shares information between devices, named as “The Beijing Explorer”, which exchanged positioning information and users’ situation to one another using a PDA (Personal Digital Assistant) with built-in wireless LAN and a GPS (Global Positioning System) receiver in real time.
Users can see their position and their chats on the screen of a PDA using the system real-timely.
The system was used for the guidance of the Palace Museum (Forbidden City) in Beijing, China.
We carried on experiments two times using the system.
The results show that the service using positioning data and sharing contents were valuable and interesting.
The correct positioning information is important for the guidance system.
A truly personal machine, called a personal digital assistant, is fundamentally different from traditional machines.
It is personal and private in an unprecedented manner, and its operation will cause frequent power outages.
Designing distributed systems where PDAs will be used as secure storage devices for digital assets, including money and access keys. assets (electronic money, keys for authentication and opening doors) will be stored in PDAs.
Ownership and control of these assets and the media that store and communicate them should remain with the user. Reference [59]
This must be reflected in the design of systems for private :[105],"introduce the concept of an open-ended argument to describe our design strategy for a system that shares information with the user (as opposed to hide it).
When systems are designed in a user-friendly way, the user has more control over their personal data and can make better decisions.
The system we have designed and implemented is presented and discussed.
Depression is often missed in children and teenagers.
The purpose of this paper is to describe the development and initial evaluation of a computer-based system to help with medical decisions for pediatric depression in ages 8 to 18 by experienced pediatric nurses in training.
Three aspects are described: selection of depression screening instrument; integration of the instrument into the PDA; and quantitative (usage) and qualitative (focus group) evaluation.
Only one third of eligible patients were screened.
Twenty percent of those screened were identified as at risk for mood disorder.
The barriers to screening identified through focus groups included a lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor comfort and motivation, as well as perceived or real cultural barriers.
Suggestions for educational, research, and interventions to integrate digital screening are discussed.
This study explored the potential of the application of new mobile technologies to improve patient care and education and future developments in information and communication technologies to support healthcare professionals and students in research and education.
The design used for this study was a systematic review of published materials obtained from EMBASE, MEDLINE, and Cochrane Library databases, and the personal observations.
Today, more than 50% of healthcare professionals and medical students are using Personal Digital Assistant with expected growth of more than 75% by year-end 2007.
In addition, wireless and mobile devices allows Personal Digital Assistant to connect to the internet.
Studies relating to processes of patient care and should evaluate mobile computing technologies as a potential timesaving tool.
Mobile devices is only beginning to take its first step in improving patient care and education.
They have shown a positive impact on patient safety, efficiency of healthcare, and ultimately patient satisfaction.
Nursing students can learn many things through practical training by experiencing actual medical practice and by coming in contact with patients.
Therefore hands-on training is an effective learning opportunity for developing the nursing skills of nursing students.
Moreover, at hospitals (that are also training centers), with regard to medical safety, the use of learning tools that produce electrical waves is not possible.
The learning support environment helps to imagine nursing techniques, and allows for preparation, review, and learning anywhere and at any time using a portable digital assistant (PDA) device for practical training.
We describe the educational materials in the digital nursing dictionary that we developed and the evaluation of the practices using it.
Limitation in display size and resolution on mobile devices is one of the main obstacles for wide-spread use of web applications in a wireless environment.
Web pages are often too large for a handheld device screen to present.
The same problem exists for devices with low resolution such as WebTV.
Manual reconstruction of web pages for these devices would ease the problem; however, a wide range of display options will greatly increase the burden of web page designers since they have to customize a web page for each device.
In this paper, we propose a document segmentation and presentation system.
The system automatically divides a web document into a number of logical segments based on the screen size and the structure and content of the document.
Additional information such as overviews and summaries is also extracted to facilitate navigation.
The system presents the segments and structural information of a web document to make full use of the screen for information finding.
Take 8051F05 as the nucleus and study a kind of voltage harmonic monitor device that satisfies the long-range monitor.
The harmonic analysis algorithm adopts Fast Fourier Transform (FFT).
This device has two work modes: ”native” and ”remote”.
It also can communicate with monitor center through telephone line, computer ports and cards, etc.
With new devices and smaller screens, such as wireless technology, increased memory and CPU speeds, you can access online information from anywhere.
We are interested in studying the effect of users switching from a computer to a small device, such as a PDA (Personal Digital Assistant).
We discuss three common transformation approaches for display of web pages on the small screen: Direct Migration, Linear and Overview.
We introduce a new Overview method, called the Gateway, for use on the small screen that uses a user's existing knowledge of the web page.
The users in an initial study prefer using the Gateway and Direct Migration approach for web pages previously used on the large screen, despite many websites use a simple layout.
The limitations and constraints of mobile systems need to be adequately addressed in software development.
We have been developing a taxonomy of risks based on a risk assessment tool and applied it during the development of a digital assistant.
In our planned research, we will explore how we can better integrate current risk management practices and Agile Methods (AM).
Expansions of mobile services and private data have required higher level of protection.
Speaker recognition, one of the biometric technologies, arises lots of research interests for its simple, cheap and convenient characteristics.
In this paper, a reliable speaker recognition system which facilitates reliable authentication with multiple voices is presented.
A large collection of data, including mobile phone, personal digital assistant (PDA), telephone and microphone, is collected to evaluate the system performance.
This paper presents a method to generate unique and highly random pseudonyms in a distributed environment.
More precisely, each user can now generate his pseudonym locally in his personal security environment, e.g.
in his smart card or his personal digital assistant.
There is no need for any information interchange between issuing parties or global data (especially keys), except user and device IDs.
He can prove he made the pseudonym without showing his identity and he can reveal his identity by disclosing the pseudonym.
Whereas the verifier of a disclosed pseudonym can be sure, the holder of the pseudonym is the one presenting it
the person which originally generated it).
The identifier of the user and the identifier of the user's device will be used to create a unique pseudonym, which is encrypted.
In todayu0027s mobile information society, location-based services play an increasingly important role.
These services are to be accessed by users with a mobile end device for the use of city maps, route planning, navigation, or traffic information.
Mobile end devices, however, do not have processing power or storage space like a regular computer or laptop.
These deficits can be bypassed by employing special methods in the respective applications.
This paper outlines the experience gained in the creation of a route-finding system for public transportation to be used on a personal digital assistant.
Breaking down the route calculation plays a significant role.
