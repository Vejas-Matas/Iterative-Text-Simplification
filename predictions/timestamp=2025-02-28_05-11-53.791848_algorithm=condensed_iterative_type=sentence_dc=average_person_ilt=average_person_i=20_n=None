In the modern era of automation and robotics, autonomous vehicles are currently the focus of academic and industrial research.
With the ever increasing number of unmanned aerial vehicles getting involved in activities in the civilian and commercial domain, there is an increased need for autonomy in these systems too.
Due to guidelines set by the governments regarding the operation ceiling of civil drones, road-tracking based navigation is garnering interest.
In an attempt to achieve the above mentioned tasks, we propose an imitation learning based, data-driven solution to UAV autonomy for navigating through city streets by learning to fly by imitating an expert pilot.
Derived from the classic image classification algorithms, our classifier has been constructed in the form of a fast 39-layered Inception model, that evaluates the presence of roads using the tomographic reconstructions of the input frames.
our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning, using a specific model architecture.
The data used for training the system has been captured from the drone, by flying it in and around urban and semi-urban streets, by experts having at least 6-8 years of flying experience.
Permissions were obtained. Minimal risk (to pedestrians) is involved in the data collection process.
We collected extensive data from drones and were able to avoid crashes and stay on course with an accuracy of 98.44%.
The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6m/sec.
We present the same results in this research and compare them with other state-of-the-art methods of vision and learning based navigation.
Recognizing Traffic Signs using intelligent systems can drastically reduce the number of accidents happening world-wide.
With the arrival of Self-driving vehicles it has become a staple challenge to solve the automatic recognition of Traffic signs on main roads.
Machine learning techniques has been proposed for classifying traffic signs, using various machine learning models.
Though they reach state-of-the-art performance on a particular data-set, but fall short of tackling multiple Traffic Sign Recognition benchmarks.
In this paper, we propose a novel and one-for-all architecture that aces multiple benchmarks with better overall score than the state-of-the-art architectures.
Our model is made of residual convolutional blocks with skip connections joined in steps.
With this we score 99.33% Accuracy in German sign recognition benchmark and 99.17% Accuracy in Belgian traffic sign classification benchmark.
Moreover, we propose a newly devised dilated residual learning representation technique which is very low in both memory and computational complexity.
We introduce a specialized computer system for training self-driving vehicles in environments.
A special computer model (ResNet-18) looks at pictures from the front of a simulated F1 car and gives instructions on how to steer, accelerate, and brake.
Importantly, we don't explicitly train the model to detect road features; instead, we show it can learn from them automatically.
In this paper, we present a way to use a car's AI to drive in a new area, by training it on a similar area first. a way to make a car drive by itself, using a type of AI trained on one area to drive in another area.
A conventional CNN for the end-to-end control is designed to map a single front-facing camera image to a steering command.
To enable the transfer learning, we let the CNN produce not only a steering command but also a lane departure level (LDL) by adding a new task module, which takes the output of the last convolutional layer as input.
The source network is a special computer vision model. It's used to train a second model called the target network. The target network makes steering decisions.
The steering commands are combined into a final command that is used to control the car.
To demonstrate the effectiveness of the proposed method, we utilized two simulators, TORCS and GTAV, for the source and the target domains, respectively.
Experimental results show that the proposed method outperforms other baseline methods in terms of stable and safe control of cars.
A significant problem of using machine learning techniques is the limited amount of data available for training.
There are some datasets available for the popular problems like item recognition and classification for self-driving cars, however, it is very limited for the industrial robotics field.
In previous work, we have trained a multi-objective Convolutional Neural Network (CNN) to identify the robot body in the image and estimate 3D positions of the joints by using just a 2D image, but it was limited to a range of robots produced by Universal Robots (UR).
In this work, we extend our method to work with a new robot arm - Kuka LBR iiwa, which has a significantly different appearance and an additional joint.
However, instead of collecting large datasets once again, we collect a small number of smaller datasets and use transfer learning techniques on the CNN trained on UR robots to adapt it to a new robot having different shapes and visual features.
We have proven that transfer learning is not only applicable in this field, but it requires smaller well-prepared training datasets, trains significantly faster and reaches similar accuracy compared to the original method, even improving it on some aspects.
Moral responsibility is a major concern in automated decision-making, with applications ranging from self-driving cars to kidney exchanges.
In this paper we present queueing-theoretical methods for the modeling, analysis, and control of autonomous mobility-on-demand MOD systems wherein robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure acceptable quality of service throughout the network.
We first cast an autonomous MOD system within a closed Jackson network model with passenger loss.
Theoretical insights help design a balancing system, which is applied to a study of New York City and implemented on an eight-vehicle mobile robot testbed.
The case study of New York shows that the current taxi demand in Manhattan can be met with around 8,000 robotic taxis, roughly 70% of the size of the current taxi fleet operating in Manhattan.
Finally, we extend our queueing-theoretical setup to include congestion effects, and study the impact of autonomously rebalancing vehicles on overall congestion.
Collectively, this paper provides a rigorous approach to the problem of system-wide coordination of autonomously driving vehicles, and provides one of the first characterizations of the sustainability benefits of robotic transportation networks.
In the wake of the on-going digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions.
While the benefits of this transformation can be massive, there are also tremendous risks to our society.
After the automation of many production processes and the creation of self-driving vehicles, the future of automation is next.
This is moving us to a tipping point and to a crossroads: we must decide between a society in which the actions are determined in a top-down way and then implemented by coercion or manipulative technologies (such as personalized ads and nudging) or a society, in which decisions are taken in a free and participatory way and mutually coordinated.
Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits.
The fundaments of human dignity, autonomous decision-making, and democracies are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies, but also the basis of greater efficiency and success.
Once self-driving car becomes a reality and passengers are no longer worry about it, they will need to find new ways of entertainment.
The data center is a central location for storing and receiving entertainment. A slow connection between the car and the data center causes delays in content delivery.
To address these challenges, we propose a deep learning based caching for self-driving car, by using specialized computer systems.
First, at DC, Multi-Layer Perceptron (MLP) is used to predict the probabilities of contents to be requested in specific areas.
To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units.
Second, in order to cache entertainment contents stylized for car passengers’ features such as age and gender, Convolutional Neural Network (CNN) is used to predict age and gender of passengers.
Through this, the self-driving car can identify the contents need to be downloaded from the MEC server and cached.
Finally, we formulate deep learning based caching in the self-driving car that enhances entertainment services as an optimization problem whose goal is to minimize content downloading delay.
To solve the formulated problem, a Block Successive Majorization-Minimization (BS-MM) technique is applied.
Our prediction for the self-driving car is accurate, achieving 98.04% accuracy, and our approach reduces delays.
This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE), a novel minimal simulation of a centralised financial market, based on a Limit Order Book (LOB) such as is common in major stock exchanges.
Construction of BSE was motivated by the fact that most of the world’s major financial markets have automated, with trading activity that previously was the responsibility of human traders now being performed by high-speed autonomous automated trading systems.
Research aimed at understanding the dynamics of this new style of financial market is hampered by the fact that no operational real-world exchange is ever likely to allow experimental probing of that market while it is open and running live, forcing researchers to work primarily from time-series of past trading data.
Similarly, university-level education of the engineers who can create next-generation automated trading systems requires that they have hands-on learning experience in a sufficiently realistic teaching environment.
BSE as described here addresses both those needs: it has been successfully used for teaching and research in a leading UK university since 2012, and the BSE program code is freely available as open-source on GitHuB.
This paper provides a study of how stock prices vary in their response to financial news across different topics.
We specifically shed light into a large number of unclassified documents for which no automatic categorization of their content exists.
For this purpose, we utilize an approach from data mining - namely, latent Dirichlet allocation - as a means of topic modeling.
This technique facilitates our task of automatically categorizing, the content of over 70,000 U.S. company filings.
We then evaluate the subsequent stock market reaction.
We found that different news stories have varying effects on the stock market. Our research found a big difference between news stories that affect the stock market.
For instance, we find a statistically significant abnormal return in response to earnings results and credit rating, but also for disclosures regarding business strategy, the health sector, as well as mergers and acquisitions.
Our results yield findings that benefit managers, investors and policy-makers by indicate how regulatory filings should be structured and the topics most likely to precede changes in stock valuations.
This paper addresses the financial markets problem space with particular emphasis on trading systems seen in banking today.
With the advent of modern computing, cross-regional trading transactions can now be executed within milliseconds, a reality that is impossible without the advancements of software systems technology.
We then move on and discuss a trading system and its role in a bank's systems.
As for the humanoid robots, the internal noise, which is generated by motors, fans and mechanical components when the robot is moving or shaking its body, severely degrades the performance of the speech recognition accuracy.
In this paper, a novel speech recognition system robust to ego-noise for humanoid robots is proposed, in which on/off state of the motor is employed as auxiliary information for finding the relevant input features.
Special features that have been used in speech recognition systems have been successfully applied to deep neural network based speech recognition system.
When learning the bottleneck features to catch, we first exploit the motor on/off state data as supplementary information in addition to the acoustic features as the input of the first deep neural network (DNN) for preliminary acoustic modeling.
Then, the second DNN for primary acoustic modeling employs both the bottleneck features tossed from the first DNN and the acoustics features.
Our method is tested and shows a significant improvement over other systems, on a special sound error rate on a specific speech database.
Many model based techniques have been proposed in the literature for applying domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation.
However sensor based robot control overcomes many of the difficulties of uncertain models and unknown environments which limit the domain of application of the previous methods.
For service and manipulation tasks, it is more suitable to study the way the robot interacts with its environment at the point of touch, rather than specifying the joint positions and velocities required to achieve them using sensors.
Online social media provide users with unprecedented opportunities to engage with diverse opinions.
They allow the spread of misinformation by empowering individuals to, choose the news they like, which can lead to seeing only stories that agree with them, by choosing news they like and seeing stories that agree with them.
A clear understanding of the trade-offs is still unclear.
Most people in the network update their beliefs based on new information, but some people are biased and reject news that disagree with what they already believe.
We show that this simple a way people think that makes them agree with what they already believe can generate permanent opinion changes.
Furthermore, the model results in states where unbiased agents act like they're biased, because their biased neighbors limit their access to free and diverse information.
We studied how people's beliefs work, demonstrating the trade-off between confirmation bias and social connectivity, which we further validate against US county-level data on the impact of Internet access on the formation of beliefs about global warming.
Our findings indicate that confirmation bias in small doses may actually result in improved accuracy across individuals by keeping a variety of ideas in a group.
However, results also indicate that when confirmation bias grows past an optimal value, accuracy declines as biased agents restrict information flow to subgroups.
We discuss the policy implications of our model, highlighting the downside of debunking strategies and suggesting alternative strategies to contrast misinformation.
The advent of WWW changed the way we can produce and access information.
Recent studies showed that users tend to select information that is consistent with their system of beliefs, forming groups of people with the same opinions.
In this environment, users cooperate to share their story making any attempt at debunking inefficient.
Such a configuration occurs even in the consumption of news online, and considering that 63% of users access news directly from social media, one hypothesis is that more polarization allows for further spreading of misinformation.
Along this path, we focus on the polarization on Facebook in different European countries (Italy, France, Spain and Germany).
We compare the user behavior across countries and observe different posting, liking and commenting rates.
Second, we explore users tend to visit different pages and the emergence of polarized communities generated around specific pages.
Italy is the most divided country, followed by France, Germany and lastly Spain.
Finally, we present a special model that simulates how communities form, taking into account user engagement and trust in news.
trust in information broadcaster influences how people become divided online, division among people online plays a key role in reducing division
In order to prevent attacks, P2P networks need a system to control resource usage.
In this paper, we discuss and compare the different approaches to fully decentralised resource control that are used by projects in the cryptocurrency space.
The introduced methods are then applied to design a decentralised exchange for Namecoin names (or more generally, crypto assets) as an example.
With the introduction of memory-bound cryptocurrencies, such as Monero, the implementation of mining code in browser-based JavaScript has become a worthwhile alternative to dedicated mining rigs.
Based on this technology, a new form of parasitic computing, widely called cryptojacking or drive-by mining, has gained momentum in the web. A cryptojacking site abuses the computing resources of its visitors to covertly mine for cryptocurrencies.
In this paper, we systematically explore this phenomenon. For this, we propose a 3-phase analysis approach, which enables us to identify mining scripts and conduct a large-scale study on the prevalence of cryptojacking in the Alexa 1 million websites.
cryptojacking is common, Many sites are hacked for mining
We also study the cryptojacking landscape, including code patterns, hacker earnings, and security measures. We also look at how hackers use code, how much they can earn, and current security methods.
The rise of modern blockchains has facilitated the emergence of smart contracts: autonomous programs that live and run on the blockchain.
Smart contracts have seen a rapid climb to prominence, with applications predicted in law, business, commerce, and governance. Smart contracts are written in a high-level language and then translated for deployment on the blockchain.
Once deployed, the bytecode is autonomously executed, usually by a %Turing-complete virtual machine.
As with all programs, smart contracts can be highly vulnerable to malicious attacks due to deficient programming methodologies, languages, and toolchains, including buggy compilers.
At the same time, smart contracts are also valuable targets, often worth a lot of money.
Hence, developers and auditors need security frameworks capable of analysing low-level bytecode to detect potential security vulnerabilities.
In this paper, we present Vandal: a tool to check the security of Ethereum contracts.
Vandal consists of an analysis pipeline that converts low-level Ethereum Virtual Machine (EVM) bytecode to semantic logic relations.
Users of the framework can express security analyses in a logic language called \souffle. Security analysis is expressed in \souffle.
Vandal is fast and robust, analysing most contracts quickly; it can analyze most contracts quickly, and it does this fast enough to process over 95% of all contracts in just 4.15 seconds; it outperforms the current best tools under equivalent conditions.
As Bitcoinu0027s popularity has grown over the decade since its creation, it has become an increasingly attractive target for adversaries of all kinds.
Image tampering, being readily facilitated and proliferated by today’s digital techniques, is increasingly causing problems regarding the authenticity of images.
As the most popular multimedia data, JPEG images can be easily tampered without leaving any clues; therefore, JPEG image forensics, which includes techniques like detecting changes to the image, has become an active research topic in multimedia forensics.
Nevertheless, the interesting issue of detecting image tampering and its related operations by using the same quantization matrix has not been fully investigated.
Aiming to detect such forgery manipulations under the same quantization matrix, we propose a detection method by using shift-recompression -based reshuffle characteristic features.
The learning classifiers are applied for classification.
Our experimental results indicate that the approach is indeed highly effective in detecting image tampering and relevant manipulations with the same quantization matrix.
The malicious alteration of machine time is a big challenge in computer forensics.
Understanding such changes and reconstructing the timeline of events is of paramount importance.
However, this can be difficult since the attacker has many ways to hide the changes.
In particular, cloud computing, host and guest machine time can be manipulated in various ways by an attacker.
Guest virtual machines are especially vulnerable to attacks coming from their (more privileged) host.
As such, it is important to ensure the timeline is secure for both hosts and guests in the cloud.
In this paper we survey the issues related to host and guest machine time integrity in the cloud.
Further, we describe a novel architecture for host and guest time alteration detection and correction/resilience with respect to compromised hosts and guests.
The proposed framework has been implemented on an especially built simulator.
Performance figures show the feasibility of our proposal.
Detecting edited images is an important problem in image forensics.
It gives the information about the processing history of an image, and also can expose forgeries present in an image.
There have been a few methods proposed to detect various types of image editing.
However, all the operations have to be known a priori in the training phase.
But, in real-forensics scenarios it may not be possible to know about the editing operations carried out on an image.
To solve this problem, we propose a novel deep learning-based method which can differentiate between different types of image editing operations.
The proposed method classifies image patches in a pair-wise fashion as either similarly or differently processed using a special type of AI.
Once the network learns feature that can discriminate between different image editing operations, it can differentiate between different image editing operations not present in the training stage.
The proposed method is effective in detecting edited images.
Digital assistants are becoming more common in our daily lives. In interacting with these assistants, users may engage in multiple tasks within a short period of time.
DIANE is a digital assistant system that aims to fasten the doctor access to various informations at the hospital such as health care facility, medical records, and also human resource data. The fasten access could be achieved by implementing face recognition and live streaming as part of the digital assistant system.
As extensive experimental research has shown individuals suffer from diverse biases in decision-making.
We analyze the effects of decision-making biases of managers in collaborative decision processes on organizational performance.
In the simulations, managerial decisions which are based on different levels of complexity and different incentive systems make decisions biased.
The results illustrate how biases affecting different organizations affect organizational performance.
Some combinations of biases are good for performance, but not when used separately. Surprisingly, these biases can improve performance when combined, but hurt it when they happen alone.
This might evoke considerations whether decision-making should be as rational as possible.
Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments.
Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions.
For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information.
Considering dynamic obstacles introduces another level of complexity, since they can cause problems later on.
In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles.
Our system then uses this information to make predictions, in which paths can be efficiently planned in real time at low CPU cost.
We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.
An autonomous service robot often first has to search for a user to carry out a desired task.
This is a difficult problem, when the person moves around, it's harder for the robot to see because its field of view is constrained and the environment structure typically poses further visibility constraints that influence the perception of the user.
In this paper, we propose a novel method that computes the likelihood of the user’s observability at each possible location in the environment based on Monte Carlo simulations.
As the robot needs time to reach the possible search locations, we take this time as well as the visibility constraints into account when computing effective search locations.
In this way, the robot can choose the next search location that has the maximum expected observability of the user.
Our experiments in various simulated environments demonstrate that our approach leads to a significantly shorter search time compared to a greedy approach with background information.
In many situations, users walk on typical paths between specific destinations by a mobile robot.
Depending on the environment and the paths, step-by-step following of the human might not be the optimal solution since better paths for the robot exist.
We propose to predict the human's future movements and use this information in a reinforcement learning framework to generate foresighted navigation actions for the robot.
Since frequent occlusions will occur due to obstacles and the robot's constrained field of view, the estimate about the humans's position and the prediction of the next destination are affected by uncertainty.
Our approach deals with such situations by explicitly considering occlusions in the reward function such that the robot automatically considers to execute actions to get the human in its field of view.
We show in simulated and real-world experiments that our technique leads to significantly shorter paths compared to an approach in which the robot always tries to closely follow the user and, additionally, can handle occlusions.
In this paper, we introduce an approach to maneuvering a messy house.
We propose to estimate local obstacle densities based on already detected objects and use them to predict traversal costs corresponding to potential obstacles in regions not yet observable by the robot's sensors.
The robot uses predictions to plan its path. It reduces the risk of getting stuck in cluttered regions, including accounting for costs, and is more aware of what's ahead.
As the experimental results demonstrate, our method enables the robot to efficiently navigate through environments containing cluttered regions and achieves significantly shorter completion times compared to a standard approach not using any prediction.
In this paper, we present an integrated navigation system that allows humanoid robots to autonomously navigate in unknown, cluttered environments.
From the data of a special depth camera, our system helps the robot know where it is and keeps a map of the space around it.
Based on this model, our system iteratively computes sequences of safe actions including footsteps and whole-body motions, leading the robot to target locations.
To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles.
As we demonstrate in experiments with a Nao humanoid, our system leads to robust navigation in cluttered environments and the robot is able to traverse highly challenging passages.
In this paper, we present a novel approach to accurately calibrate the kinematic model of a humanoid based on observations of its monocular camera.
Our technique estimates the parameters of the complete model, consisting of the joint angle offsets of the whole body including the legs, as well as the camera extrinsic and intrinsic parameters.
Furthermore, we developed an approach to automatically select a subset of configurations for the calibration process that yields a good trade-off between the number of observations and accuracy.
Further, our approach to choosing settings yields substantially better optimization results compared to randomly chosen viable configurations.
Hence, our system only requires a reduced number of configurations to achieve accurate results.
Our optimization is general and the implementation, which is available online, can easily be applied to different humanoids.
In this paper, a lab automation drone notional concept is introduced.
Here, a robotic limb is attached to a robotic rotorcraft.
The limb's gripper allows it to manipulate objects such as micro-arrays and test tubes.
The resulting drone could augment existing HTS operations.
The 6 degree-of-freedom (DOF) arm and gripper design are presented.
Test-and-evaluation approach and results are also given.
Robot companionship has become more popular in past years.
However, humanoid gait might be somewhat unstable for these applications.
Even with miniature humanoids, falls occur frequently.
Thus, wheel attachments have been added onto a miniature humanoid, so it can move faster and with more stability than walking.
In addition, with such attachments a robot can switch from walking to rolling when necessary.
DARwIn-OP is a humanoid robot that has been used as an experimentation and performance evaluation platform.
This paper discusses preliminary work regarding robot companionship applications by using a miniature humanoid capable of fetching different toys based on voice command.
Advances in electronics and sensor technology have widened the scopes of networked drones to include applications as diverse as surveillance, video recording, operations, entertainment/advertising, signal emission, transportation, and delivery.
These applications and services require video recording for their operations.
Drones are used alone or in groups.
The small drones are proving to be useful in civilian applications.
Using small drones for applications such as group flight, entertainment, and other uses lead to deployment of networked drones.
To develop control of drones in display, a drone display control is proposed.
Simulation shows that drone formation can display messages effectively.
The prevalence and rapid development of the Internet and mobile technology in recent decades has revamped our living styles and daily habits.
To ride on the digital trend, more business activities have been engaged in the digital world.
Marketing and advertising is typical business areas that is transformed digitally.
The rise of Important Influencers, social media platforms, and Omni-channel retailing have attracted countless business entities to consider the adoption of digital marketing tools for promoting and advertising their brands and products.
However, with the increasing diversity of the types of digital marketing tools, they must be carefully selected based on a multiple number of criterion.
A new method is proposed to help industry professionals choose the right digital marketing tools.
The developed method not only streamlines the internal business process of digital marketing tool selection, but it also increases the practitioner's effectiveness of achieving the pre-defined strategic marketing objectives.
This study focuses on the digital marketing for small tourist businesses.
The study addresses the question of how the use of ICT-based tools benefit the organisational capabilities of a company.
By adopting marketing as a set-of-skills approach, the study provides new insights into the existing tourism literature on e-marketing.
The digital marketing capabilities of companies are transformed through digital technology.
Four major capabilities were identified, each of which evolves as a result of using the tools.
A key finding of the study is that the use of ICT-based tools transforms digital marketing capabilities from a set of abilities that enables tourism SMEs not only to float in a web-marketing stream, but also to lead such a stream.
Big data delivers immense benefits in marketing efficiency, healthcare, environmental protection, national security and more. Collecting, storing, and analyzing large amounts of data quickly and at a low cost.
The central tenets of the current privacy framework, the principles of data minimization and purpose limitation, are severely strained by the big data technological and business reality.
As we increasingly interact with these artificial agents in unsupervised settings, with no human mediators, their seeming autonomy and increasingly sophisticated functionality and behavior, raises legal and philosophical questions.
The focus on the machine is a distraction from the debate surrounding data driven ethical dilemmas, such as privacy, fairness and discrimination.
The machine may exacerbate, enable, or simply draw attention to the ethical challenges, but it is humans who must be held accountable.
Policymakers should seek to devise agreed-upon guidelines for ethical data analysis and profiling.
Such guidelines would address the use of legal and technical mechanisms to obfuscate data; criteria for calling out unethical, if not illegal, behavior; categories of privacy and non-privacy harms; and strategies for empowering individuals through access to data in intelligible form.
As smart speakers with voice interaction capability become more popular in everyday life, more and more people will gradually get used to the new interaction medium–voice.
Although speech recognition, natural language processing (NLP) have been greatly improved over the past few years, users still may encounter errors from time to time like “cannot understand”, “no requested audio resource (such as music)”, which can frustrate users.
Therefore, when an error message is reported, it is vital that the smart speaker gives an effective and proper response.
However, currently the response strategies adopted by leading smart speaker brands in China differed mainly on two dimensions: “apology or not” and “humor or neutral”.
We explored user’s preference of response strategies under two error scenarios——“cannot understand” and “no requested audio resource”.
Two dependent variables (satisfaction and perceived sincerity of response) were measured.
The results showed that participants were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios.
In the “no requested audio resource” scenario, humor had no significant impact on the perception of satisfaction and sincerity.
But in the “cannot understand” scenario, humorous expression decreased perceived sincerity.
the smart speakers cannot distinguish human voice from machine voice.
A way to figure out whether a human or a machine is sending voice commands to a smart speaker is needed.
To prevent such hacking attempts when no one is home, we propose a system consisting of a speaker and a microphone array to detect the existence of a human nearby, supposing it can be incorporated in a smart speaker in the future.
Amazon's Echo, and Apple's Siri have drawn attention from different user groups; however, these existing commercial VUIs support limited language options for users including native English speakers and non-native English speakers.
we conducted a usability study of the Google Home Smart Speaker with 20 participants including native English and non-native English speakers to understand their differences in using the Google Home Smart Speaker.
The findings show that compared with their counterparts, the native English speakers had better and more positive user experiences in interacting with the device.
It also shows that users' English language proficiency plays an important role in interacting with VUIs.
The findings from this study can create insights for VUI designers and developers for implementing multiple language options and better voice recognition algorithms in VUIs for different user groups across the world.
A pharmacophore analysis approach was used to investigate and compare different classes of compounds relevant to the drug discovery process (specifically, drug molecules, compounds in high throughput screening libraries, combinatorial chemistry building blocks and nondrug molecules).
Significant differences were observed between the pharmacophore profiles obtained for the drug molecules and those obtained for the high-throughput screening compounds, which appear to be closely related to the nondrug pharmacophore distribution.
It is suggested that pharmacophore profiles can help select the best compounds, making it easier to find successful leads.
Annotation of bioassay protocols using semantic web vocabulary is a way to make experiment descriptions machine-readable.
Protocols are communicated using concise scientific English, which precludes most kinds of analysis by software algorithms.
Given the availability of a sufficiently expressive ontology, some or all of the pertinent information can be captured by asserting a series of facts, expressed as semantic web triples (subject, predicate, object).
Assays can be searched, clustered, tagged and evaluated in many ways, analogous to other segments of drug discovery informatics.
The BioAssay Ontology is a tool designed for a specific purpose, and helps organize terms.
NGS produces large datasets of many reads and samples.
Subsequent bioinformatic analysis is typically done with the help of open source tools, where each application performs a single step towards the final result.
This situation leaves the bioinformaticians with the tasks to combine the tools, manage the data files and meta-information, document the analysis, and ensure reproducibility.
SPSS Clementinel2.0 statistical software was used to mine the association rules between Etiology and traditional Chinese medicine (TCM), Syndromes and TCM, Symptoms and TCM.
The classic Apriori algorithm is useful to mine cases of influenza treated by contemporary famous old Chinese medicine.
Identifying antimicrobial resistant (AMR) bacteria in metagenomics samples is essential for public health and food safety.
Next-generation sequencing (NGS) technology has provided a powerful tool in identifying the genetic variation and constructing the correlations between genotype and phenotype in humans and other species.
a Bayesian framework for genotype estimation for mixtures of multiple bacteria, named as Genetic Polymorphisms Assignments (GPA) has reduced the false discovery rate (FDR) and mean absolute error (MAE) in single nucleotide variant (SNV) identification.
CRISPR-Cas is a tool that is widely used for gene editing.
Unexpected side effects may happen due to long-term enzyme activity.
Anti-CRISPR proteins, which are powerful molecules that inhibit the CRISPR-Cas system, may have the potential to promote better utilization of the CRISPR-Cas system in gene editing, especially for treating diseases.
Additionally, more in-depth research on these proteins would help researchers to better understand the co-evolution of bacteria and phages.
Therefore, it is necessary to collect and integrate data on various types of anti-CRISPRs.
The CRISPR/Cas9 system was recently developed as a powerful and flexible technology for targeted genome engineering, including genome editing (altering the genetic sequence) and gene regulation (without altering the genetic sequence).
These applications require the design of single guide RNAs (sgRNAs).
However, this remains challenging, as it requires the consideration of many criteria.
CRISPR has become a hot research area ever since its advent for its efficiency and specificity in editing almost every section of DNA sequences.
Based on its function of gene perturbation, a variety of gene editing techniques have been developed to achieve different aims.
The target locations of a DNA strain can be precisely broken and repaired, during which the genes can be removed, repaired, silenced, or activated.
The high efficiency of gene editing tool preparation and the easiness of experiment conduction make it now a powerful tool, a powerful way to analyze many things at once.
The hidden connection between these reports is that gene editing could be used to solve issues related to health care allocation.
Improving the health of future generations might coincide with public health goals; it might improve the health of individuals and communities, and is a public good.
However, enhancing future generations will require In Vitro Fertilisation and Pre-implantation Genetic Diagnosis.
Remarkably, the necessary involvement of women in an enhancing scenario has not been discussed by its proponents.
The present discourse on moral obligations of future generations, although not referring to women, seems to imply that women might be required, morally, if not legally, to reproduce with IVF.
Future generations will be gendered, unless a new way to grow babies is developed.
These are challenging issues that require a wider perspective, of both women and men.
Despite the lack of a unified feminist conclusion in the discussions about the merits and risks of human genome modification, there is an urgent need to clarify the role of women in this scenario.
The CRISPR-Cpf1 system has been successfully applied in genome editing.
However, target efficiency of the CRISPR-Cpf1 system varies among different gRNA sequences.
Using machine learning technology, a SVM model was created to predict target efficiency for any given gRNAs.
the first web service application, CRISPR-DT (CRISPR DNA Targeting), to help users design optimal guide RNA for the CRISPR system by considering both target efficiency and specificity
A key problem for autonomous car navigation is the understanding, at an object level, of the current driving situation.
Addressing this issue requires the extraction of meaningful information from on-board stereo imagery by classifying the fundamental elements of urban scenes into semantic categories that can more easily be interpreted and be reflected upon (streets, buildings, pedestrians, vehicles, signs, etc.).
A probabilistic method is proposed to fuse a coarse prior 3D map data with stereo imagery classification.
A novel fusion architecture is presented for combining images with depth information from stereo cameras and prior knowledge, using a type of neural network, based on the Stixel framework.
The proposed approach was tested on a manually labeled data set in urban environments.
The results show that the classification accuracy of the fundamental elements composing the urban scene was significantly enhanced by this method compared to what is obtained from the semantic pixel-wise segmentation of a CNN alone.
In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems.
Increasing the reliability of these vehicles on the road requires software tests are run on realistic simulators, where many vehicles and people interact with the vehicle.
It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios.
The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1].
In this paper we propose to automate the process using a special kind of computer program to create scenarios that test how well self-driving cars work, and how they handle unexpected events, that expose self-driving policies that are flawed or not well-trained, and increase the risk of collision with simulated pedestrians and vehicles.
We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using visual learning we obtain safer self-driving behavior.
With the developing of the technology on self-driving, more and more L3 driverless vehicles are launched in market, people get opportunities to experience the self-driving cars in their daily life.
As a result, there is a growing demand for the autopilot experience.
Natural and efficient human-computer interaction can not only improve the driving experience, but also accelerate the process of self-driving commercialization.
This paper discusses eye-movement interaction, voice interaction and gesture interaction in self-driving car, and analyzes the technology, advantages and disadvantages of the existing interaction modes, and prospect the future development trend of self-driving human-computer interaction.
Self-driving vehicle technologies are progressing rapidly and are expected to play a significant role in the future of transportation.
One of the main challenges for self-driving vehicles on public roads is the safe cooperation and collaboration among multiple vehicles using sensors and inter-vehicle communications.
When self-driving vehicles try to be in the same place at the same time, they might collide with one another, might become deadlocked, or might slam on the brakes making it uncomfortable or unsafe for passengers in a self-driving vehicle.
In this paper, we study how a self-driving vehicle can safely navigate merge points, where two lanes with different priorities meet.
We present a safe protocol for merge points named Autonomous Vehicle Protocol for Merge Points, where self-driving vehicles use both vehicular communications and their own perception systems for cooperating with other self-driving and/or human-driven vehicles.
Our simulation results show that our traffic protocol has higher traffic throughput, compared to simple traffic protocols, while ensuring safety.
Emerging self-driving vehicles are vulnerable to different attacks due to the principle and the type of communication systems that are used in these vehicles.
These vehicles are increasingly relying on external communication via vehicular ad hoc networks (VANETs).
VANETs add new threats to self-driving vehicles that contribute to substantial challenges in autonomous systems.
These communication systems render self-driving vehicles vulnerable to many types of malicious attacks, such as Sybil attacks, Denial of Service (DoS), black hole, grey hole and wormhole attacks.
In this paper, we propose an intelligent security system designed to secure external communications for self-driving and semi self-driving cars.
The system uses a special kind of artificial intelligence to detect a common type of attack in vehicle networks: Denial-of-Service (DoS).
The experimental results show that the proposed BP-IDS is capable of identifying malicious vehicles in self-driving and semi self-driving vehicles.
This paper proposes a benchmark suite for a self-driving car system using a special computer program.
One approach to the development of self-driving systems is the utilization of ROS which is an open-source middleware framework used in the development of robot applications.
On the other hand, the popular approach in the automotive industry is the utilization of MATLAB/Simulink which is software for modeling, simulating, and analyzing.
MATLAB/Simulink provides an interface between ROS and MATLAB/Simulink that enables to create functionalities of ROS-based robots in MATLAB/Simulink.
However, it is not been fully utilized in the development of self-driving systems yet because there are not enough samples for self-driving, and it is difficult for developers to adopt co-development.
Therefore, we provide a MATLAB/Simulink benchmark suite for a ROS-based self-driving system called Autoware.
Autoware is popular open-source software that provides a complete set of self-driving modules.
The provided benchmark contains MATLAB/Simulink samples available in Autoware.
They help design self-driving systems using a specific software.
Ensuring the safety of self-driving cars is important, but neither industry nor authorities have settled on a standard way to test them.
Deploying self-driving cars for testing in regular traffic is a common, but costly and risky method, which has already caused fatalities.
As a safer alternative, virtual tests, in which self-driving car software is tested in computer simulations, have been proposed.
One cannot hope to sufficiently cover many driving scenarios self-driving cars need to be tested for.
Therefore, we developed AsFault, a tool for creating virtual tests for self-driving cars.
We demonstrate AsFault by testing the lane keeping feature of an artificial intelligence-based self-driving car software, for which AsFault generates scenarios that cause it to drive off the road.
A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw
At the brink of the introduction of self-driving vehicles, only little is known about how potential users perceive them.
This is especially true for self-driving vehicles deployed in public transport services.
In this study, the relative preferences for a trip with a self-driving bus is assessed compared to a trip with a regular bus, based on a stated preference experiment.
Based on the responses of 282 respondents from the Netherlands and Germany, a discrete choice model is estimated as a Mixed Logit model including attitudes towards trust in self-driving vehicles and interest in technology.
Passengers prefer self-driving buses for short trips.
This is due to the finding that the value of travel time is about twice as high for the self-driving bus as for the regular bus for a short commuting trip.
Findings from this study further suggest that the popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes.
People who currently show a strong interest in technology or trust in automated vehicle technology perceive the self-driving busses better than others.
Preferences towards automated public transport services are expected to evolve along with the transition to regular use.
The management of self-driving systems is becoming more complex as the development of self-driving technology progresses.
One approach to the development of self-driving systems is the use of ROS; however, the system used in the automotive industry is typically designed using MATLAB/Simulink, which can simulate and evaluate the models used for self-driving.
These models are incompatible with ROS-based systems.
To allow the two to be used in tandem, it is necessary to rewrite the C++ code and incorporate them into the ROS-based system, which makes development inefficient.
Therefore, the proposed framework allows models created using MATLAB/Simulink to be used in a ROS-based self-driving system, thereby improving development efficiency.
Furthermore, our evaluation of the framework demonstrated its practical potential.
Online Social Networks OSNs have become increasingly popular means of information sharing among users.
Misinformation about emergency events is common in OSNs and so is the spread of misinformation related to the event.
We define as misinformation any false or inaccurate information that is spread either intentionally or unintentionally.
In this paper we study the problem of misinformation identification in OSNs, and we focus in particular on the Twitter social network.
Based on user and tweets characteristics, we build a misinformation detection model that identifies suspicious behavioral patterns and exploits supervised learning techniques to detect misinformation.
Our results were tested on a large number of tweets and illustrate that our approach effectively identifies misinformation during emergencies.
Furthermore, our model manages to timely identify misinformation, a feature that can be used to limit the spread of the misinformation.
Superintelligence is a potential type of future artificial intelligence (AI) that is very much more intelligent than humans.
If built, superintelligence could be a transformative event, with potential consequences that are massively beneficial or catastrophic.
There's a big debate about the risk of superintelligence with a lot of false information.
Superintelligence misinformation is potentially dangerous, ultimately leading bad decisions by the would-be developers of superintelligence and those who influence them. This could be very dangerous and lead to poor decisions by those creating or advise it, leading to bad decisions by those who develop it.
This paper surveys strategies to counter superintelligence misinformation.
Two types of strategies are examined: strategies to prevent the spread of superintelligence misinformation and strategies to correct it after it has spread.
In general, misinformation can be difficult to correct, suggesting a high value of strategies to prevent it.
The strategies proposed can be applied to lay public attention to , and efforts to build expert consensus on how to teach people about new technologies.
The widespread online misinformation could cause public panic and serious economic damages.
The problem to limit false information in online social networks by launching competing campaigns.
Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem for the case when many cascades are allowed.
First, we provide a formal model for multi-cascade diffusion and introduce an important concept called as cascade priority.
Second, we show that the misinformation containment problem cannot be approximated within a factor of $\\Omega(2^{\\log^{1-\\epsilon}n^4})$ in polynomial time unless $NP \\subseteq DTIME(n^{\\polylog{n}})$.
Third, we introduce several types of cascade priority that are frequently seen in real social networks.
Finally, we design novel algorithms for solving the misinformation containment problem.
The effectiveness of the proposed algorithm is supported by encouraging experimental results.
Information that is not accurate, in the field of library and information science is often regarded as a problem that needs to be corrected or simply understood as either misinformation or disinformation without further consideration.
Misinformation and disinformation, however, may cause significant problems for users in online environments, where they are constantly exposed to an abundance of inaccurate and/or misleading information.
This paper aims to lay the foundation for future research by examining the relationships among information, misinformation, and disinformation.
Our analysis extends to a discussion of ways to detect lies and false information.
We argue that misinformation and disinformation are related yet distinct sub-categories of information.
Misinformation is a multifaceted concept, more complex than simply being inaccurate or incomplete, and disinformation does not always entail misinformation.
The growth of social media provides a convenient communication scheme for people, but at the same time it becomes a hotbed of misinformation.
The wide spread of misinformation over social media is injurious to public interest.
We design a framework, which integrates collective intelligence and machine intelligence, to help identify misinformation.
The basic idea is: (1) automatically index the expertise of users according to their microblog contents; and (2) match the experts with given suspected misinformation.
By sending the suspected misinformation to appropriate experts, we can collect the assessments of experts to judge the credibility of information, and help refute misinformation.
In this paper, we focus on expert finding for misinformation identification.
We propose a method to identify the expertise of microblog users.
We tested our method on real social media posts to see if it can identify experts and correct misinformation.
The importance of research on misinformation has received wide recognition.
Two major challenges faced by this research community are the lack of theoretical models and the scarcity of misinformation in support of such research.
This paper aims to address the aforementioned challenges by conceptualizing misinformation and enabling the interoperability of misinformation.
In particular, a representation and a model of misinformation are proposed through studying and combining existing research in the field.
The ontology-supported misinformation model can not only guide future misinformation research but also lay the foundation for building a digital misinformation library by advancing our knowledge on misinformation and by improving its sharing, management, and reuse.
In addition, we present a formal methodology for managing misinformation in a digital library, and suggest future research directions related to the misinformation model.
Conspiracy theories have gained much academic and media attention recently, due to their large impact on public events.
However, little is known about how conspiracy theories spread on social media.
We present a qualitative study of conspiracy theorizing on Reddit during a public health crisis--the Zika virus outbreak.
Using a mixed-methods approach including content analysis and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the Zika crisis, the conditions under which Zika conspiracy theories emerge, and the particular discursive strategies through which Zika conspiracy theories developed in online forums.
"Our analysis shows that conspiracy talk emerged as people attempted to make sense of a public health crisis, reflecting their emergent information needs and their pervasive distrust in formal sources of Zika information."
Practical implications for social computing researchers, health practitioners, and policymakers are discussed.
Conspiracy theories are omnipresent in online discussions---whether to explain a late-breaking event that still lacks official report or to give voice to political dissent.
Conspiracy theories grow and spread, making it hard to stop them.
It is therefore crucial to study the topic of conspiracy theories in online communities.
People discuss conspiracy theories online and share common themes. Users discuss various topics when they talk about conspiracy theories online. We studied online discussions about conspiracy theories over a decade. What do these elements tell us about the way users think? We studied these themes to understand user thinking patterns.
We focus on the key elements of a conspiracy theory: the conspiratorial agents, the actions they perform, and their targets.
For example, a narrative-motif such as \"governmental agency-controls-communications\" represents the various ways in which multiple conspiratorial statements denote how governmental agencies control information.
Thus, narrative-motifs expose commonalities between multiple conspiracy theories even when they refer to different events or circumstances.
In the process, these representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about.
Our approach enables a population-scale study of conspiracy theories in alternative news and social media with implications for understanding their adoption and combating their spread.
Yet contemporary work in Philosophy argues that conspiracies do happen, so it's somewhat reasonable to believe in them. If we examine each theory closely, it turns out that sometimes believing in them is justified in a range of cases.
Drawing on this work, I examine the kinds of evidence typically associated with conspiracy theories, showing that the evidential problems typically associated with conspiracy theories are not unique to such theories.
As such, if there is a problem with the conspiracy theorist’s use of evidence, it is one of principle: is the principle which guides their use of evidence somehow in error? I argue that whatever we might think about conspiracy theories generally, there is no good reason to doubt conspiracy theories just because of how they use evidence.
Cryptocurrency is a rapid developing financial technology innovation which has attracted a large number of people around the world.
The price fluctuations of cryptocurrency and the uncertainty around authorities' attitudes have caused panic and chain reactions towards the application and adoption of cryptocurrency and have caused public security related events.
We analyze the risk of the cryptocurrency market based on the public available price history and its dynamics and systemic risk.
Furthermore, as seen by the public, our analysis shows that the cryptocurrency market is relatively fragile and unstable.
Blockchain technology is the underlying enabling technology developed for Bitcoin, the most common cryptocurrency.
Blockchain technologies have become increasingly popular with the potential to become a powerful disruptive force.
Individuals and organizations may benefit from blockchain with its ability to increase secure data exchange and to make that transaction simpler and easier between entities.
We investigate factors that influence an individualu0027s intention to use a blockchain cryptocurrency.
We develop a model of cryptocurrency adoption grounded in the theory of planned behavior (TPB) to identify the determinants for the acceptance of cryptocurrency and explore the relative importance of each construct.
We offer empirical evidence for a better theoretical understanding of cryptocurrency adoption with practical implications in an e-government context.
Cryptocurrency was built initially as a possible implementation of digital currency, then various derivatives were created in a variety of fields such as financial transactions, capital management, and even nonmonetary applications.
This paper aims to offer analytical insights to help understand cryptocurrency by treating it like a financial asset.
We position cryptocurrency by comparing its dynamic characteristics with two traditional and massively adopted financial assets: foreign exchange and stock.
Our investigation suggests that the dynamics of cryptocurrency are more similar to stock.
As to the robustness and clustering structure, our analysis shows cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market.
Mobile devices like smartphones and watches have become one of the major payment methods in many different areas.
At the same time, blockchain-based cryptocurrency is becoming a nonnegligible type of currency and the total value of all types of cryptocurrency has reached USD 200 billion.
Therefore, it is a natural demand to support cryptocurrency payment on mobile devices.
Considering poor infrastructure in developing countries, this combination is especially attractive.
The high storage cost and payment processing latency are the two main obstacles for mobile payment using cryptocurrency.
We propose two different schemes for cryptocurrency mobile payment, one uses a bank, the other doesn't.
We also provide a solution for the bank to meet KYC (know your customer)/AML (antimoney laundering) compliance requirements when it is involved in cryptocurrency mobile payment processing.
Motivated by recent financial crises significant research efforts have been put into studying financial market crises.
Much less has been said about influence of financial news on financial markets.
We propose a novel measure of collective behaviour in financial news on the Web, News Cohesiveness Index (NCI), and show that it can be used as a systemic risk indicator.
We evaluate the NCI on financial documents from October 2011 to July 2013 and analyze the interplay between financial markets and news.
We hypothesized that strong cohesion in financial news reflects movements in the financial markets.
Cohesiveness is a general measure of a bigger problem affecting the news, than measures based on simple occurrences of specific terms.
Our results indicate that The news about the financial markets is closely related to the market's ups and downs.
In this paper, I propose a methodology to study the comovement between the entropy of different financial markets.
The entropy is derived using singular value decomposition of the components of stock market indices in financial markets from selected developed economies, i.e., France, Germany, the United Kingdom, and the United States.
I study how a shock in the entropy in the United States affects the entropy in the other financial markets.
I also model the entropy using a dynamic factor model and derive a common factor behind the entropy movements in these four markets.
Mobile devices are very common in everyone’s day-to- day life.
Nowadays such devices come with many features of desktop or laptop.
Hence people can use these devices for diverse applications.
These devices are very easy to use, there are chances that these devices can be used for illegal activities.
The percentage of mobile phones or smart phones involved in cyber crimes is in hike.
So it becomes necessary to analyze such devices using special computer tools.
This paper discusses different types of digital evidence present in Microsoft’s Windows Mobile smart phones and an agent based approach for logically acquiring such devices.
A tool developed for forensically acquiring and analyzing Windows Mobile devices and WinCE PDAs
The increasing prevalence of Internet of Things (IoT) devices has made it inevitable that their pertinence to digital forensic investigations will increase into the foreseeable future.
These devices produced by various vendors often have simple ways to connect, like USB ports or wireless connections.
Meanwhile, with an increasing mainstream focus on the security and privacy of user data, built-in encryption is becoming commonplace in consumer-level computing devices, and IoT devices are no exception.
Under these circumstances, a significant challenge is presented to digital forensic investigations where data from IoT devices needs to be analysed.
This work explores the digital forensic investigations on IoT devices, focusing on an analysis that uses signals to steal data.
EM side-channel analysis is a technique where unintentional electromagnetic emissions are used for eavesdropping on the operations and data handling of computing devices.
The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require, and must result in, no modification to the target device.
The literature on various types of attacks that use electromagnetic signals are discussed – selected on the basis of their applicability in IoT device investigation scenarios.
The insight gained from the background study is used to identify promising future applications of the technique for digital forensic analysis on IoT devices. This potentially helps a wide variety of digital investigations.
The use of mobile phone forensics to investigate fraudulent activity is nothing new.
But mobile phones have evolved into smartphones, and fraudsters have evolved with them.
Smartphones are packed with functionality that can easily be used for data theft or inappropriate contact with other parties - none of which passes through company-owned systems, and is to all intents and purposes 'off the grid'.
Employers need to be aware of the risks when devices are issued, and having a way to deal with suspicions, explains Philip Ridley of CCL-Forensics.
Detecting 'tech-savvy' corporate fraudsters is a constant game of catch-up.
It's not only about playing catch-up with the intellect, motives and awareness of the e-fraudster, but also the technologies that can be misused.
The methods through which the technology can be manipulated to hide fraudulent activities - all while avoiding corporate networks that can easily detect them - are constantly evolving.
This means a company's intellectual property and sensitive data is at risk of sabotage or just good old-fashioned theft.
Phishers continue to alter their website code to mimic changes to legitimate websites of spoofed organizations and to avoid detection by phishing countermeasures.
Manipulations can be as subtle as source code changes or as apparent as adding or removing significant content.
To appropriately respond to these changes to phishing campaigns, algorithms are implemented to detect phishing websites based on their content, using a large data set of known phishing attacks.
The results of the experiments using a variety of different content-based approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate.
The focus of the early post-exercise period is to enhance physiological processes that are critical for reducing the effects of exercise on the body and for promoting adaptations to training.
Recommended nutritional strategies to help muscles recover with protein and carbs, which replenish energy stores [2],[3].
When eating leucine-rich foods sends signals that work together to help build muscle by stimulating protein growth
The ingestion of about 20-25 grams of good quality protein soon after exercise [7], repeated every 4 h [8] has been shown to maximise the anabolic response in skeletal muscle.
The cultural environment surrounding some sports often involves the intake of large amounts of alcohol after training and competition, with athletes in several team sports being particularly at risk of “binge drinking” practices [9]–[11].
The outcomes of binge drinking after exercise are likely to include the direct effect of alcohol on physiological processes as well as the indirect effect on the athlete's recovery due to not eating or resting adequately as a result of intoxication.
Although the concurrent consumption of carbohydrate can partially offset the deleterious effects of alcohol intake on post-exercise glycogen resynthesis [14], the effect of alcohol consumption on muscle protein synthesis is unknown.
The aim of the current study was to determine the effect of alcohol intake on anabolic cell signaling and rates of myofibrillar protein synthesis (MPS) in humans during recovery from a bout of strenuous exercise approximating stresses an athlete may experience in training and performance for team sports like football, rugby, and basketball.
We hypothesized that co-ingestion of alcohol would slow down the process that starts protein production and decrease rates of muscle protein synthesis after exercise.
Eight healthy physically active subjects (age 21.4±4.8 yr, body mass 79 kg, peak oxygen uptake 48.1 mL·kg−1·min−1, leg strength 104 kg; values are average ± standard deviation) who had been participating in regular exercise (3 times a week for more than 6 months) volunteered for this study.
The study employed a specialized study design in which each subject completed bouts of consecutive resistance, continuous and intermittent high-intensity exercise with either post-exercise ingestion of alcohol-carbohydrate (ALC-CHO), alcohol-protein (ALC-PRO) or protein only (PRO) beverages on three separate occasions.
Resistance exercise consisted of eight sets of five repetitions at ∼80% of 1RM.
After completion of the final set, subjects rested for 5 min before commencing 30 min of continuous cycling at ∼63% PPO (∼70% VO2peak).
Upon completion, subjects rested on the bike for 2 min before undertaking 10 sets of 30 seconds of high-intensity exercise, with 30 seconds of rest in between, at maximum effort.
Immediately following exercise and after 4 h recovery, subjects drank a drink with either protein or sugar to match the energy they used during exercise. They consumed 25g of a protein supplement.
Furthermore, a special post-exercise meal with carbohydrates (1.5 grams of carbs per kilogram of body weight) was consumed ∼2 h post-exercise, immediately after the muscle biopsy, according to recommendations for post-exercise glycogen recovery [24].
This 8 h time frame represents an important recovery after exercise, when blood alcohol levels might be high after drinking, as well as the time when drinking after the event can affect blood alcohol levels.
The alcohol ingestion protocol (1.5 grams of alcohol per kilogram of body weight; 12 drinks, with a possible 2 drinks more or less) began 1 h post-exercise and was consumed in 6 equal volumes of 1 part vodka (∼60 mL) to four parts orange juice (∼240 mL, 1.8 g CHO·kg−1 BM) during a 3 h period.
Orange juice was consumed with a matched volume of water in place of the control condition.
Subjects ingested the beverages within 5 min every 30 min.
Blood, cell signaling and mRNA data were analyzed by two-way ANOVA (two factor: time × treatment) with repeated measures and myofibrillar protein synthesis was analyzed by one-way ANOVA with repeated measures.
The first novel finding of this study was that muscle protein production and muscle repair following intense team sports-like exercise were impaired during the early (8 h) recovery phase by the ingestion of large amounts (1.5 g•kg−1 BM) of alcohol.
When athletes drink alcohol after a workout, they are less likely to follow good recovery habits, which can lead to a 37% decrease in muscle protein synthesis.
However, a second finding was that even when protein was consumed in amounts shown to be optimally effective to stimulate MPS [8] during post-exercise recovery, the intake of alcohol reduced MPS by ∼24%, representing only a partial ‘rescue’ of the anabolic response compared with protein alone.
The mechanistic target of rapamycin complex 1 (mTORC1) is a central node for integrating nutrient (i.e. amino acid) and exercise/contraction signal transduction [31], [32].
In conclusion, the current data provide the novel observation that alcohol impairs the response of MPS in exercise recovery in human skeletal muscle despite optimal nutrient provision.
The quantity of alcohol consumed in the current study was based on amounts reported during binge drinking by athletes.
However, published reports suggest intakes of some individuals can be significantly greater [9], [50], which is of concern for many reasons related to health and safety [13].
It's hard to find reliable information about how drinking affects sports performance.
Given the need to support muscle repair and growth the results of the current study provide clear evidence of impaired recovery when alcohol is consumed after high-intensity exercise even in the presence of optimal nutritional conditions, and protein synthesis that helps repair and grow muscle.
We propose our data is of paramount interest to athletes and coaches.
Our findings provide a clear message to drink in moderation to promote recovery after exercise with the potential to alter current sports culture and athlete practices.
In this paper we revisit a topic originally discussed in 1955, namely the lack of direct evidence that muscle hypertrophy from exercise plays an important role in increasing strength.
To this day, long-term adaptations in strength are mainly due to muscle growth.
Given this assumption, there has been considerable attention placed on programs designed to allow for maximization of both muscle size and strength.
However, the conclusion that muscle size affects strength is surprisingly based on little evidence.
We suggest that these changes may be completely separate phenomena based on: (1) a little relationship between muscle size and strength after training; (2) the loss of muscle mass with detraining, yet a maintenance of muscle strength; and (3) muscle growth between low-load and high-load resistance training, yet divergent results in strength.
Low-intensity occlusion (50-100 mm hg) training provides a unique beneficial training mode for promoting muscle hypertrophy.
Training at intensities as low as 20% 1 repetition maximum with moderate vascular occlusion results in muscle hypertrophy in as little as 3 weeks.
A typical exercise prescription calls for 3 to 5 sets to volitional fatigue with short rest periods.
The metabolic buildup causes positive effects on the body, specifically a rise in growth hormone that is higher than levels found with higher intensities.
Occlusion training is applicable for those who are unable to sustain high loads, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts.
Current dogma suggests aerobic exercise training has minimal effect on skeletal muscle size.
We and others have demonstrated that aerobic exercise acutely and chronically alters protein metabolism and induces skeletal muscle hypertrophy.
These findings promote an antithesis to the status quo by providing novel perspective on skeletal muscle mass regulation and insight into exercise-countermeasures for populations prone to muscle loss.
Stretch training is widely used in a variety of fitness-related capacities such as increasing joint range of motion, preventing contractures and alleviating injuries.
Moreover, some researches indicate that stretch training may induce muscle hypertrophy; however, studies on the topic have been primarily relegated to animal and in vitro models.
The purpose of this brief review was to evaluate whether stretch training is a viable strategy to build muscle in humans.
10 studies were examined, 3 observed some positive effects of stretch training on muscle structure.
Intriguingly, in these studies, The stretching was done with a machine or an external weight.
2 of the studies that combined stretching and weightlifting showed better results. 5 available studies that integrated stretching into a resistance training programme, 2 applied the stretching in the interset rest period and were the ones that showed enhanced muscle growth.
In conclusion, passive, low-intensity stretch does not appear to confer beneficial changes in muscle size and architecture; alternatively, albeit limited evidence suggests that when stretching is done with a certain degree of tensile strain (particularly when loaded, or added between active muscle contractions) may elicit muscle hypertrophy.
Cycle training is widely performed as a major part of any exercise program seeking to improve heart and lung health.
However, the effect of cycle training on muscle size and strength gain still requires further insight, even though it is known that professional cyclists display larger muscle size compared to controls.
Therefore, the purpose of this review is to discuss the effects of cycle training on muscle size and strength in the legs and the ways that cycle training can make muscles bigger.
It is plausible that cycle training requires a longer period to significantly increase muscle size compared to typical resistance training due to a much slower hypertrophy rate.
Exercise programs work well for both young and older people, and older adults tend to get stronger faster. However, older adults tend to see greater strength gains from this type of training.
For young adults, higher-intensity intermittent cycling may be required to achieve strength gains.
Muscle hypertrophy induced by cycle training results from the positive changes in muscle protein balance.
Resistance training is the most effective method to increase muscle mass.
It has also been shown to promote many health benefits.
Although it is considered safe and of clinical relevance for treating and preventing a vast number of diseases, a minimal dose of exercise has been the focus of a great number of research studies.
Similarly, an inverted U-shaped relationship between training dose/volume and physiological response has been hypothesized to exist.
Resistance training has a clear effect on muscle growth and overall health when done in larger amounts, and it can improve muscle growth and overall health.
Additionally, there is a paucity of data to support the inverted U-shaped response.
The principle argued herein is that volume is the most modifiable variable that has the most proven response with significant effects on muscle growth.
Although the effects of short versus long inter-set rest intervals in resistance training on measures of muscle hypertrophy have been investigated in several studies, the findings are equivocal and the practical implications remain unclear.
Current evidence indicates that both short and long inter-set rest intervals may be useful when training for achieving gains in muscle hypertrophy.
Novel findings involving trained participants using measures sensitive to detect changes in muscle hypertrophy suggest a possible advantage for the use of long rest intervals to elicit hypertrophic effects.
However, more research is needed to figure out the difference between the two approaches.
Memory is a process in which information is encoded, stored, and retrieved.
For vertebrates, the modern view has been that it occurs only in the brain.
This review describes a muscle memory in which hypertrophy is 'remembered' such that a fibre that has previously been large, but subsequently lost its mass, can regain mass faster than naive fibres.
A new cell biological model based on the literature, with the most reliable methods for identifying myonuclei, can explain this phenomenon.
According to this model, previously untrained fibres recruit myonuclei from activated satellite cells before hypertrophic growth.
Even if muscle tissue weakens, the number of muscle cell nuclei is preserved, and these cells are less likely to die off as the muscle shrinks, the muscle cells seem to be protected from dying off as they shrink.
Fibres that have acquired a higher number of myonuclei grow faster when subjected to overload exercise, thus the nuclei represent a functionally important 'memory' of previous strength.
This memory might be very long lasting in humans, as it lasts a long time, more than 15 years, and might never go away.
However, myonuclei are harder to recruit in the elderly, and if the long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice.
It has been hypothesized that eating small, frequent meals enhances fat loss and helps to achieve better weight maintenance.
Several observational studies lend support to this hypothesis, with an inverse relationship noted between the frequency of eating and adiposity.
The purpose of this narrative review is to present and discuss a meta-analysis with regression that evaluated experimental research on meal frequency with respect to changes in fat mass and lean mass.
Eating frequency was associated with weight loss and losing fat and gaining muscle.
Further research is needed to confirm if eating more frequently really helps with weight, since one study suggests that eating more often may not be as effective as thought, since its results are uncertain.
In conclusion, although the initial results of this meta-analysis suggest a potential benefit of increased feeding frequencies for enhancing body composition, these findings need to be interpreted with circumspection.
Inactive adults lose about 5% of their muscle mass and gain fat.
Ten weeks of resistance training may increase lean weight by 1.4 kg, increase resting metabolic rate by 7%, and reduce fat weight by 1.8 kg.
Benefits of resistance training include improved physical performance, movement control, walking speed, functional independence, cognitive abilities, and self-esteem.
Resistance training may assist prevention and management of type 2 diabetes by lowering body fat, reducing blood sugar levels, and making the body more responsive to insulin. This is achieved by improving the cells' ability to take in glucose and by lowering HbA1c levels.
Resistance training may enhance cardiovascular health, by reducing resting blood pressure, lowering bad cholesterol and triglycerides, and raising good cholesterol.
Resistance training may promote bone development, with studies showing 1% to 3% increase in bone mineral density.
Resistance training may be effective for reducing low back pain and easing discomfort associated with arthritis and fibromyalgia and has been shown to reverse specific aging factors in skeletal muscle.
Physical activity has proved to be an effective means of preventing several diseases and improving general health.
Common sense advices call for late inception of intense, strength training-related activities, like weight lifting and plyometrics, which are usually postponed at the end of the growth age, even among sport practitioners.
However, such advices seem to have a mainly anecdotal nature.
Current literature does not seem to have any particular aversion against the practice of strength training by children and adolescents, provided that some safety rules are followed, like medical clearance, proper instruction from a qualified professional and progressive overload.
At the same time, several studies provide consistent findings supporting the benefits of repeated, intense physical efforts in young subjects.
Improved motor skills and body composition, in terms of increased fat free mass, reduced fat mass and enhanced bone health, have been extensively documented, especially if sport practice began early, when the subjects were pubescent.
It can be therefore concluded that strength training is a relatively safe and healthy practice for children and adolescents.
Human aging results in a variety of changes to skeletal muscle.
Sarcopenia is the age-associated loss of muscle mass and is one of the main contributors to musculoskeletal impairments in the elderly.
Research has shown that resistance training can reduce muscle weakness in older adults, however few articles have focused on the effects of resistance training on functional mobility.
The purpose of this review was to 1) present the current state of literature regarding the effects of resistance training on functional mobility outcomes for older adults with muscle weakness and 2) provide clinicians with practical guidelines that can be used with seniors during resistance training, or to encourage exercise.
We set forth evidence that resistance training can reduce the impact of aging on movement and balance, making it easier to walk and avoid falls.
Older adults should be encouraged to participate in progressive resistance training activities, and should be admonished to move along a continuum of exercise from immobility, toward the recommended daily amounts of activity.
Maximizing the hypertrophic response to resistance training (RT) is thought to be best achieved by choosing the right exercises, rest time, and volume, and controlling the intensity and intervals, for good results from training.
An often overlooked variable that also may impact muscle growth is repetition duration.
Duration amounts to the speed of repetition, and is related to the type of muscle used.
We conducted a thorough review of existing research to determine whether alterations in repetition duration can amplify the hypertrophic response to RT.
Results indicate that muscle growth is similar when training with short to long repetition durations.
In practice, a wide range of repetition durations can be used to build muscle.
Findings suggest that training at volitionally very slow durations (>10s per repetition) is inferior from a hypertrophy standpoint, although a lack of controlled studies on the topic makes it difficult to draw definitive conclusions.
Recovery from exercise refers to the time period between the end of a bout of exercise and the subsequent return to a resting or recovered state.
Changes in the body that occur after exercise, that are different from rest and exercise. It also refers to specific processes or states occurring after exercise that are different from either the state of exercise or rest.
In this context, recovery of the cardiovascular system after exercise occurs over a period of minutes to hours, during which many characteristics of the system, even how it is controlled, change over time.
Some of these changes may be necessary for long-term adaptation to exercise training, yet some can lead to cardiovascular instability during recovery.
Furthermore, some of these changes may provide insight into when the heart has recovered from previous exercise and is ready for more exercise.
This review focuses on the most consistent changes in blood flow and the main reasons why the heart recovers following resistance and aerobic exercise.
Primary emphasis will be placed on the hypotensive effect of aerobic and resistance exercise and related factors that doctors look for, but if left unchecked, can progress to symptomatic hypotension and syncope.
Finally, we focus on the practical application of this information to strategies to maximize the benefits of cardiovascular recovery, or minimize the vulnerabilities of this state.
We will explore appropriate field measures, and discuss how well these can help the athlete.
Exercise and physical activity are increasingly becoming key tools in the treatment and prevention of several medical conditions including arthritis and diabetes; this notion has been termed "exercise as medicine".
Exercise has favorable effects on reducing cardiovascular risk, inflammation, cachexia, and hypertension, in addition to increasing physical functioning, strength, and cardio-respiratory capacity.
Chronic kidney disease, a condition that affects around 10% of the population, is often overlooked as a target for exercise-based therapy.
Despite the vast range of severity in kidney disease (e.g., pre-dialysis, dialysis, transplant), exercise has a potential role in all patients suffering from the condition.
In this review, we summarise the important role exercise may have in the kidney disease treatment and how this form of 'medicine' should be best administered and 'prescribed'.
Blood flow restriction is an effective specialized treatment used to increase strength in healthy individuals.
However, its effects on pain and function in individuals with knee pain are unknown.
Objective: To determine the effectiveness of adding BFR to resistance exercise for pain relief and improvement of function in patients with knee pain.
Methods: Systematic review with meta-analysis of randomized clinical trials.
Randomized clinical trials that compared resistance exercise with or without BFR to treat knee pain and function in individuals older than 18 years of age with knee pain were included.
The pooled standardized mean difference (SMD) estimate showed that resistance exercises with BFR was not more effective than resistance exercises for reducing pain (SMD: -0.37cm, a range of -0.93 to 0.19) and improving knee function (SMD=-0.23 points, a range of -0.71 to 0.26) in patients with knee pain.
In Japan, there were an estimated 43 million patients with hypertension in 2010.
The management of this condition is given the highest priority in disease control, and the importance of lifestyle changes for the prevention and treatment of hypertension has been recognized in Japan.
In particular, emphasis has been placed on increasing the levels of activities of daily living and physical exercise (sports).
In this literature review, we examined appropriate exercise prescriptions (e.g., type, intensity, duration per session, and frequency) for the prevention and treatment of hypertension as described in Japanese and foreign articles.
This review recommends safe and effective whole-body aerobic exercise at moderate intensity that primarily focuses on the major muscle groups for the prevention and treatment of hypertension.
Regular exercise is good for you, but people with high blood pressure and chest pain should avoid it, but used as supplementary exercise.
recently, there has been a renewed public interest in IFast.
Given the importance of nutrition in optimizing athletic performance, there is a concern about the effects of IFast on athletics.
Studies show that fasting has no benefit for intense exercises, studies are consistent in showing this.
People who exercise often have times when they can't exercise.
When the periods last long, the goal is to maintain physical performance.
Similarly, certain special populations may desire to maintain performance for prolonged periods, namely athletes (during the competitive season and off-season) and military personnel (during deployment).
In general, endurance performance can be maintained for up to 15 weeks, as long as you keep the same intensity.
For younger people, strength and muscle size can be maintained for 32 weeks with 1 session of strength training per week and 1 set per exercise. In younger populations, you may need to exercise 2 times a week and 2–3 sets per exercise, while maintaining exercise intensity. Older adults may need to exercise more often and with more sets to maintain muscle size.
Our primary conclusion is that exercise intensity is the key to maintaining physical performance, even with reduced exercise frequency and volume.
Nutrient timing is a popular nutritional strategy that involves the consumption of mainly protein and carbs around exercise time.
Some have claimed that this approach can produce dramatic improvements in body composition.
It has even been thought that when we eat has a bigger impact than the total amount of nutrients we consume.
The post-exercise period is widely considered the most critical part of nutrient timing.
Theoretically, consuming the proper ratio of nutrients during this time not only initiates the rebuilding of damaged muscle tissue and restoration of energy reserves, but it does so in a supercompensated fashion that enhances both body composition and exercise performance.
Several researchers have made reference to an anabolic “window of opportunity” whereby a limited time exists after training to optimize training-related muscular adaptations.
However, the importance - and even the existence - of a post-exercise ‘window’ can vary due to several factors.
Not only is nutrient timing research open to question in terms of applicability, but recent evidence has directly challenged the traditional idea of how exercise affects nutrient intake.
Lack of time is among the more commonly reported barriers for abstention from exercise programs.
The aim of this review was to determine how strength training can be most effectively carried out in a time-efficient manner by reviewing existing research on training variables, advanced training techniques, and the need for warm-up and stretching.
When programming strength training for optimum time-efficiency we recommend prioritizing multi-joint exercises that include full dynamic movements (i.e. both eccentric and concentric muscle actions), and to perform a minimum of one leg pressing exercise (e.g. squats), one upper-body pulling exercise (e.g. pull-up) and one upper-body pushing exercise (e.g. bench press).
Exercises can be performed with machines and/or free weights based on training goals, availability, and personal preferences.
Weekly training volume is more important than training frequency and we recommend performing a minimum of 4 weekly sets per muscle group using a 6–15 RM loading range (15–40 repetitions can be used if training is performed to volitional failure).
Advanced training techniques, such as special training methods reduce training time, but still allow for the same amount of work compared to traditional training.
These methods are better at building muscle than getting stronger, but we need more research to understand how they work over time.
Finally, we advise restricting the warm-up to exercise-specific warm-ups, and only prioritize stretching if the goal of training is to increase flexibility.
Training frequency is key to muscle growth from weightlifting.
The purpose of this paper was to conduct a systematic review and meta-analysis of experimental studies designed to investigate the effects of weekly training frequency on hypertrophic adaptations.
Results showed no significant difference between higher and lower frequency on a volume-equated basis.
Meta-regression analysis of non-volume-equated studies showed a significant effect favoring higher frequencies, although the overall difference in magnitude of effect between frequencies of 1 and 3+ days per week was modest.
In conclusion, there is strong evidence that resistance training frequency does not significantly or meaningfully impact muscle hypertrophy when volume is equated.
Thus, for a given training volume, individuals can choose a weekly frequency per muscle groups based on personal preference.
A variety of specialized training techniques have been advocated as a means to heighten muscle growth.
Forced repetitions/drop sets, supersets, and heavy negatives, help to increase muscle growth from weight training.
This article will explore the potential role of these techniques and show ways to use resistance training.
The quest to increase lean body mass is widely pursued by those who lift weights.
Research is lacking, however, as to the best approach for maximizing exercise-induced muscle growth.
Bodybuilders generally train with moderate loads and short rest periods cause a lot of stress on the body.
Powerlifters, on the other hand, routinely train with high-intensity loads and lengthy rest periods between sets.
Although both groups are known to display impressive muscularity, it is not clear which method is superior for hypertrophic gains.
It has been shown that muscle damage and metabolic changes lead to muscle growth during exercise. Muscle damage and changes in metabolism contribute to muscle growth during exercise.
Therefore, the purpose of this paper is twofold: (a) to extensively review the literature as to the mechanisms of muscle hypertrophy and their application to exercise training and (b) to draw conclusions from the research as to the optimal protocol for maximizing muscle growth.
Abstract   Novel technological advances in mobile devices and applications can be exploited in wildfire confrontation, enabling end-users to easily conduct several everyday tasks, such as access to data and information, sharing of intelligence and coordination of personnel and vehicles.
This work describes an innovative mobile application for wildfire information management that works on mobile phones and helps with wildfire prevention and management.
Several tasks can be done through the AEGIS App, such as search for nearby facilities and support, and access to weather data and visualization of fire management data (water sources, gas refill stations, evacuation sites etc.).
An innovative feature of AEGIS App is the support of these tasks by a digital assistant for artificial intelligence named Cortana (developed by Microsoft for Windows Phone devices), that allows information utilization through voice commands.
The application is to be used by firefighting personnel in Greece and is potentially expected to contribute towards a more sophisticated transferring of information and knowledge between wildfire fighting units in the field.
In recent years, mobile technologies have developed and applied in education fields, and some mobile emerging carriers with mobile technologies include a personal digital assistant (PDA), smart phone, and e-book.
Some of the mobile carriers combines context-aware technologies or involve into wireless network environments to make effective use through the combination of learning scenarios and technologies, and then provide students new learning experiences differed from the past learning.
In view of the application of mobile technology in education, some previous studies have addressed that mobile learning is a meaningful learning that can improve the interaction between students and the situations and reach the purposes of learning.
In the mobile learning environment, using mobile carriers with suitable learning methods or strategies in mobile learning activities for different students to enhance learning have gradually become a important and concern issue.
The purpose of this study is to study how well students learn and feel about learning on a campus plant learning activity with the help of mobile carriers and competitive learning strategies for young students.
The experimental results show that the competitive learning group of students have better learning performance than non-competitive learning group of students.
After completing the learning activity, the two groups of students presented high positive attitudes.
This paper proposes an electrophysiological wireless patient monitoring system which integrates a Wireless ECG signal transmitter, GPS device and a mobile phone to acquire physiological signals and transmit them to a local server via Bluetooth wireless technology.
This paper proposes an electrophysiological wireless patient monitoring system which integrates a Wireless ECG signal transmitter, GPS device and a mobile phone to acquire physiological signals and transmit them to a local server via Bluetooth wireless technology.
Four kinds of monitor units were specially designed for a wireless communication, including a control center , a local monitor unit, mobile devices (personal digital assistant; PDA), and a Web page (for both patient and doctor).
Four types of monitors were designed for wireless communication, including a control center and a local monitor unit, as well as a mobile device and a website for patients and doctors.
The use of various monitor units is created to fulfill different medical personnel requirements and wishes.
The use of various monitor units is created to fulfill different medical personnel requirements and wishes.
This application was developed to promote the mobility and flexibility for the patients and also for the medical personnel, which further will improve both the quality of health care and lifestyle of the patient.
This application was developed to help patients and medical staff move around, making healthcare better and improving patient care.
As various kinds of output devices emerged, such as highresolution printers or a display of PDA(Personal Digital Assistant), the importance of high-quality resolution conversion has been increasing.
As various kinds of output devices emerged, such as highresolution printers or a display of PDA(Personal Digital Assistant), the importance of high-quality resolution conversion has been increasing.
Explains a new method for enlarging image with high quality.
This paper proposes a new method for enlarging image with high quality.
One of the largest problems on image enlargement is the exaggeration of the jaggy edges.
One of the largest problems on image enlargement is the exaggeration of the jaggy edges.
To remedy this problem, we propose a new interpolation method, which uses artificial neural network to determine the optimal values of interpolated pixels.
To remedy this problem, we propose a new interpolation method, which uses artificial neural network to determine the optimal values of interpolated pixels.
The experimental results are shown and evaluated.
The experimental results are shown and evaluated.
The effectiveness of our methods is discussed by comparing with the conventional methods.
Our methods are compared to the standard methods.
Many people have trouble seeing colours. A big part of the population suffer from impairments in seeing colours.
A large part of the human population suffer from impairments in their capacity to see colours.
For them, everyday tasks like using a train map becomes demanding.
For them, everyday tasks like navigating through a train or metro network map becomes demanding.
We present a novel technique for extracting colour information from everyday natural stimuli and presenting it to visually impaired users as pleasant, non-invasive sound.
We present a novel technique for extracting colour information from everyday natural stimuli and presenting it to visually impaired users as pleasant, non-invasive sound.
This technique was implemented inside a Personal Digital Assistant (PDA) portable device.
In this implementation, colour information is extracted from the input image and categorised according to how human observers segment the colour space.
In this implementation, colour information is extracted from the image and organised based on how people see colours.
This information is subsequently converted into sound and sent to the user via speakers or headphones.
In the original implementation, it is possible for the user to send its feedback to reconfigure the system, however several features such as these were not implemented because the current technology is limited.We are confident that the full implementation will be possible in the near future as PDA technology improves.
In the original implementation, it is possible for the user to send its feedback to reconfigure the system, however several features such as these were not implemented because the current technology is limited.We are confident that the full implementation will be possible in the near future as PDA technology improves.
Misuse of medicines increases the risk of hospital admissions for the elderly.
Inappropriate use of medicines increases the risk of hospital admissions for the elderly.
Not only does this lead to unnecessary suffering for the patients but also incurs a great financial cost to the society.
Not only does this lead to unnecessary suffering for the patients but also incurs a great financial cost to the society.
A computer system in a digital assistant, with a barcode reader, can provide an overview of the patient's complete medicine use, and detect unsuitable drugs and drug combinations.
Focusing on the elderly, our aim was to evaluate if a mobile medicine decision support system with a barcode reader is useful and user-friendly for nurses in home care.
Focusing on the elderly, our aim was to evaluate if a mobile medicine decision support system with a barcode reader is useful and user-friendly for nurses in home care.
The participants received a comprehensive overview from the patientsu0027 medicine use and noted drug-drug interactions, therapeutic duplications and warnings for drugs unsuitable for elderly people.
The participants received a comprehensive overview from the patients' medicine use and noted warnings about medications that can interact or be bad for older people.
The nurses regarded that the decision support system increased prevention and safety, was useful and user-friendly.
The nurses regarded that the decision support system increased prevention and safety, was useful and user-friendly.
Our findings suggest that most of the content and functions were regarded as important.
Our findings suggest that most of the content and functions were regarded as important.
Therefore, this decision support system might be a useful tool for district nurses.
 :[0],"access to patient appointment schedules can help clinicians manage time and problems better.
 :[0],"access to patient appointment schedules can help clinicians manage time and problems better.
Many large health care organizations manage clinical appointment scheduling via enterprise resource scheduling systems which are poorly accessible by clinicians.
Many large health care organizations manage clinical appointment scheduling via enterprise resource scheduling systems which are poorly accessible by clinicians.
Also, staff other than the clinicianu0027s personal assistant(s) may manage scheduling, making it difficult for clinicians to stay informed of changes.
Staff other than the clinician's personal assistant(s) may manage scheduling, making it difficult for clinicians to stay informed of changes.
Many a clinician today uses a personal digital assistant (PDA) containing basic calendaring functionality.
Many a clinician today uses a personal digital assistant (PDA) containing basic calendaring functionality.
Our "PalmOversite" project demonstrates the feasibility of integrating appointment schedule information into a PDA calendar, making schedule information much more readily available to the clinician.
Our “PalmOversite” project demonstrates the feasibility of integrating enterprise appointment schedule information into a PDA calendar, making schedule information much more readily available to the clinician.
Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of multidrug-resistant tuberculosis (MDR-TB) patients in Peru, in conjunction with the Peruvian National TB Program (NTP).
Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of tuberculosis that is resistant to many drugs patients, working with the Peruvian National TB Program (NTP).
Monthly bacteriology tests, which must be collected from health establishments located across this major city, are an integral part of this treatment.
Monthly bacteriology tests, which must be collected from health establishments, are an integral part of this treatment in the city.
A SES employee visits each health establishment to collect this information by hand, process it and type it into an electronic medical record system. We describe the development and implementation of a digital health record system using a personal assistant to collect, verify and upload monthly bacteriology data into the PIH-EMR.
Currently, a SES employee visits each health establishment to collect this information by hand, process it and type it into an electronic medical record system  this :[81],"paper, we describe the development and implementation of a personal digital assistant (PDA)-based electronic system to collect, verify and upload monthly bacteriology data into the PIH-EMR.
After an initial implementation period, we performed a pilot study to test the use of this system.
We tested the system after it was set up to test the system during a test phase.
We completed a baseline assessment in two health districts and then implemented the electronic system in one of the districts while the control site continued to use the paper-based system during the same period.
We did a health check in two areas, and then introduced a new computer system in one area, while the other area kept using paper.
The PDA-based system had a processing time of 6.2 days, significantly lower than measurements for both the baseline [54.8] and control sites [64.4] (both pu003c0.0001).
The PDA-based system had a processing time of 6.2 days, significantly lower than measurements for both the baseline [54.8] and control sites [64.4] (both pu003c0.0001).
It was also able to reduce the frequency of discrepancy from 10.1% to 2.8% and receive positive feedback from the users.
It was also able to reduce the frequency of discrepancy from 10.1% to 2.8% (pu003c0.0001) and receive positive feedback from the users.
Finally, the system’s cost would be recuperated in three months from time savings due to increased work efficiency.
This system will be the subject of a larger study to determine its effects on problems and expenses.
In order to facilitate knowledge transfer between specialists and generalists and between experts and novices, and to promote interdisciplinary communication, there is a need to provide methods and tools for doing so.
In order to facilitate knowledge transfer between specialists and generalists and between experts and novices, and to promote interdisciplinary communication, there is a need to provide methods and tools for doing so.
A team of experts tested a tool on a smartphone for heart problems.
A team evaluated a tool on a smartphone for heart consultation when someone had chest pain.
Human factors were used to design and develop the DST using special methods to understand how people work and design interfaces.
A pilot clinical trial was conducted at a quaternary cardiac care hospital over a 3-month period.
During this time, the nine nursing coordinators who provide around the clock medical consultations.
This clinical trial tested the design and showed its usefulness in cardiac care for both experienced and less experienced nurses, as well as those working in a team of different professionals.
This clinical trial tested and showed its effectiveness to advanced cardiac care nurses, as well as its potential use by other nurses and in a team environment, including those less experienced.
This paper presents M-CALL, a mobile computer-assisted language learning courseware for Korean language learners.
Since conventional computer-assisted language learning is often boring, it exploits a cyber pet game to increase the learner’s interest.
runs on a smartphone for mobile learning.
It runs on a computer for learning on-the-go.
It grows a cyber pet by solving problems of Korean language learning.
Korean Proficiency Test (KPT), a nationally certified Korean language test, was used as problem sets.
It consists of cyber pet game, mobile learning courseware, mobile learning system, and mobile tutoring.
It provides various functions for Korean language learning.
A new call system was developed and set up between mobile PDA and personal computer.
This study compared text entry performance of two stylus-driven soft keyboards for use in hand-held computing devices: the QWERTY and the T9.
Participants transcribed text presented on a computer screen into a personal digital assistant (PDA) using a stylus and one of these two keyboards.
Participants transcribed text presented on a computer screen into a personal digital assistant (PDA) using a stylus and one of these two keyboards.
We introduced a new way to measure how fast people transcribe.
We introduced a new psychophysical technique for measuring transcription rate that provides a composite measure of speed and accuracy.
Using this technique, we calculated the maximum transcription rate for each keyboard.
Transcription rates were higher for the QWERTY keyboard. despite the T9 being well-made
The results show that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9 keyboard's design being better.
An ancillary experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in visual scanning time due to perceptual grouping of the letters on the keys.
An ancillary experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in visual scanning time due to perceptual grouping of the letters on the keys.
Together these findings imply that the QWERTY keyboard layout remains the most effective of the currently available designs for stylus tapping on soft keyboards.
Together these findings imply that the QWERTY keyboard layout remains the most effective of the currently available designs for stylus tapping on soft keyboards.
The proliferation of mobile devices such as smart phones and Personal Digital Assistant (PDA) opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system).
The proliferation of mobile devices such as smart phones and Personal Digital Assistant (PDA) opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system).
In Mcommerce systems, we still see many common components that we have in standard E-commerce applications, such as web servers and database servers.
We still see many common components in online shopping systems, like regular stores, like web servers and database servers.
However, these new applications raise some unique challenges.
For example, the limitations of mobile devices (e.g., small screen size and reduced CPU performance) implies that software development is partly different from desktop applications.
We need to know what users want to access on their mobile devices. We also need to figure out how to create useful apps with limited user input. How can we test a distributed M-commerce system? The challenges we faced while creating a mobile commerce system for tourists. In this paper, we discuss about these challenges from our experiences.
Our prototype, easyHotel, is an useful software that allows booking hotel rooms via mobile phones.
It is widely acknowledged that information such as web content should be adapted for mobile platforms to account for restrictions in mobile environments.
Various emerging mobile platforms such as different kinds of Personal Digital Assistant (PDA) vary in their capabilities, we suggest that adaptation should be platform-specific.
There are two main ways to adapt content: automated conversion and customizing, with a trade-off between quality and effort.
We propose a simple framework for adapting content avoiding the trade-off.
As alternative avoiding this trade-off, we propose a simple object-oriented framework for content adaptation.
To facilitate the use of this framework in the Web, we base our approach on the object-oriented WebComposition model and its XML-based implementation WCML.
We apply our object-oriented approach to an example application to demonstrate how object-oriented specification of platform-adapted content reduces development/maintenance effort.
We apply our approach to an example application that makes development and maintenance easier to demonstrate how this reduces development and maintenance effort.
In monitoring a patientu0027s real-time vital signs through Body Area Networks (BAN), rich data sources are communicated to medical practitioners.
It is essential that data is delivered in timely-context aware manner.
In this paper a system is designed for patients with cardiac disorders, with an emphasis on the design of the sensing device and communication scheme chosen.
In this paper a system is designed for patients with cardiac disorders, with an emphasis on the design of the sensing device and communication scheme chosen.
Several existing wearable physiological devices (Patient Sensing Device — PSD) used in the Healthcare systems are bulky in design and are not flexible and comfortable for the elderly patients.
Several existing wearable medical devices used in the healthcare are bulky in design and are not flexible and comfortable for the elderly patients.
Presented is a unique flexible, as well as detachable PSD for the comfort of patients.
Also discussed is a system for storing and sending patient related data, which ensures periodic logging of patient data without saturating communication networks.
Also discussed is a model for transmission, storage and processing of patient related data, which ensures periodic logging of patient data without saturating communication networks.
A working model was built and tested to send ECG and body temperature of a patient, which can be expanded to include other vital signs.
A proof of concept prototype has been developed and implemented to enable transmission of heart signal and body temperature of a patient, which can be expanded to include other vital signs.
Communication between a mobile smart-phone and the ECG and temperature acquisition apparatus is implemented Bluetooth.
Communication between a mobile smart-phone and the ECG monitor is implemented Bluetooth.
The presented Data Management System is designed to manage wireless interface of sensor units with the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a Smart phone using the regular mobile network.
Advancement of wireless and mobile technology has enabled additional platforms to support learning in a single learning space.
Advancement of wireless and mobile technology has enabled additional platforms to support learning in a single learning space.
Current trend integrates usage of mobile terminals such as smart PDA (personal digital assistant) in a learning system.
Current trend integrates usage of mobile terminals such as smart PDA (personal digital assistant) in a learning system.
Such devices can communicate with mobile terminal and exchange information with its surroundings [1].
One Day Trip is a system that helps overseas students learn Japanese in real-life situations using a special device called a personal digital assistant.
This paper proposes the implementation with Knowledge Management (KM) concepts in the system to aid the teacher and learners in the learning environment.
In recent years, we have developed applications for teaching both wired and wireless networking.
These applications have been written for the Cybiko personal digital assistant, an inexpensive alternative to other hardware.
Unfortunately, the Cybiko PDA was recently discontinued.
As a result, these applications had to be ported to other platforms to remain useful.
Instead of porting each application to individual platforms, which would prove to be extremely time consuming because of other APIu0027s and networking protocols, we created the Vassar College Messaging Layer.
This layer abstracts the Cybiko networking structure and interface, allowing Cybiko applications to be ported to other platforms with minimal code alteration.
Unlike many other classes of hardware, smartcards do not have the ability to communicate securely with the user.
Smartcards are hard to use because they lack updates for the owner. The positive properties of smartcards are difficult to utilize.
We explore the area at the border between smartcards and other, more powerful (and thus more useful), machines.
On the other side of this border we find the Personal Digital Assistant :[66], our view, to be useful as a personal assistant, a machine must at least have enough functionality and resources to create trustworthy digital signatures to represent the user.
On the other side of this border we find the Personal Digital Assistant  :[66],"our view, to be useful as an extension of the usersu0027 private sphere, a machine must at least have enough functionality and resources to create trustworthy digital signatures (to speak for the user, as it were).
A less resourceful machine can merely act as a memory prothesis, helping the owner remembering addresses and phone  are :[121],"designed to be tamper resistant, and as such they seem ideal as a minimal machine.
However, trustworthy digital signatures can not be created by smartcards alone, simply because the user does not know what is given to the card for  :[163],"order to be trusted--that is, being able to make trustworthy digital signatures--a smartcard must be supported by some infrastructure outside the card proper.
However, trustworthy digital signatures can not be created by smartcards alone, simply because the user does not know what is given to the card for  :[163],"order to be trusted--that is, being able to make trustworthy digital signatures--a smartcard must be supported by some infrastructure outside the card proper.
We explore what must be included in such an infrastructure, and demonstrate that trustworthy digital signatures can in fact be made using a standard  :[211],"argue that based on this fact, nontrivial distributed systems can be constructed by utilizing smartcards; a nontrivial system is one where holders of smartcards are "first class citizens".
Asserting that a smartcard can act as a trusted machine gives new opportunities for designers of user-centric  that smartcards are :[257],"here to stay, finding ways to apply them in constructive manners is prudent.
In this paper we present the main features of a system that we created for elderly people.apart from the functionalities offered by the current tele-assistance services, also provides anytime assistance.
In this paper we present the main features of a system that we have developed and that provides special assistance for older people. also provides a high quality, anywhere and at any time assistance.
We rate the assistance as high quality because allows the monitoring of vital signs and a local detection of anomalous situations by the device that the person carries in real time.
We rate the assistance as high quality because allows the monitoring of vital signs and a local detection of anomalous situations by the device that the person carries in real time.
explain the three main functionalities offered by AINGERU: available assistance at any time, monitoring of vital signs irrespective of location or time and remote monitoring by allowing authorized external persons to consult data about monitored persons using the Internet.
Therefore, it sends alarms autonomously when  this paper we :[84],"explain the three main functionalities offered by AINGERU: universal assistance anywhere and at any time, monitoring of vital signs irrespective of location or time and remote monitoring by allowing authorized external persons to consult data about monitored persons using the Internet.
Moreover we show how those functionalities are achieved by making use of PDAs (Personal Digital Assistant), wireless communication, Semantic Web, Web services and agent technologies.
Objective: To evaluate the effectiveness of a personal digital assistant (PDA)–based clinical decision support system (CDSS) on nonsteroidal anti-inflammatory drug (NSAID) prescribing safety in the outpatient  :[26],"The design was a randomized, controlled trial conducted in a university-based resident clinic.
Objective: To evaluate the effectiveness of a personal digital assistant (PDA)–based clinical decision support system (CDSS) on nonsteroidal anti-inflammatory drug (NSAID) prescribing safety in the outpatient  :[26],"The design was a randomized, controlled trial conducted in a university-based resident clinic.
Internal medicine residents received a PDA-based CDSS suite.
Internal medicine residents received a PDA-based CDSS suite.
For intervention residents, the system included a rule for predicting stomach problems from painkillers and suggesting treatments.
The system helped predict if NSAIDs will cause stomach problems and suggested treatments for residents.
Unannounced standardized patients (SPs) trained to portray musculoskeletal symptoms presented to study physicians.
Safety outcomes were assessed from the prescriptions given to the SPs.
Safety outcomes were assessed from the prescriptions given to the SPs.
Each prescription was reviewed by a committee of clinicians blinded to the participant's details,"Prescriptions were judged as safe or unsafe.
Each prescription was reviewed by a committee of clinicians blinded to participant, intervention group assignment, and baseline or follow-up  :[108],"Prescriptions were judged as safe or unsafe.
:[26],"The main outcome measure was the differential change in unsafe prescribing of NSAIDs for the intervention versus the control  :[135],"At baseline, the mean proportion of cases per physician with unsafe prescriptions for the two groups was similar (0.27 vs. 0.29, p u003e 0.05).
The main outcome measure was the change in unsafe prescribing of NSAIDs between the two groups. The number of doctors in both groups who prescribed unsafe NSAIDs was similar (27% vs. 29%).
Controlling for baseline performance, intervention participants prescribed more safely than controls after receiving the CDSS (0.23 vs. 0.45 [F = 4.24, p u003c 0.05]).
Controlling for baseline performance, intervention participants prescribed more safely than controls after receiving the CDSS (0.23 vs. 0.45). F = 4.24, p < 0.05
With the CDSS, intervention participants documented more complete assessment of patient gastrointestinal risk from  :[198]. Those who used a special tool for prescribing medications made fewer mistakes than those who didn't.
Recently pedestrian navigation has been studied by many researchers, which provides pedestrians with a similar function of car navigation.
On the other hand, a 3dimensional (3D) map, which is one of major themes in machine vision research, has been utilized as a simulation tool in city and landscape planning, and other engineering fields.
The 3D maps will give more intuitive information compared to conventional 2-dimensional (2D) ones.
In this paper we first propose pedestrian navigation based on 3D maps, and describe technologies required and its use situations.
We compared 2D and 3D maps to see how well they help with navigation. We tested these maps on different devices such as phones and tablets by object search experiments under conditions: 3D maps with and without texture.
The experimental results show that 3D maps on small screens are better than 2D maps in search time and error rate.
From these results, we can say the effectiveness of 3D maps in pedestrian navigation.
Mobile agents are a competitive concept. They are especially suitable for mobile devices, which often have slow internet connections and can lose connection to the main system.
They can be used for information retrieval and information filtering, in which case they evaluate replies and return only the relevant data.
Mobile agents as a metaphor of active objects are created on a mobile device such as a Personal Digital Assistant (PDA), will be launched into the information galaxy and are fulfilling the mobile user ‘s task on the services available on networked stationary systems.
One common way to communicate with these agents is via email.
This paper introduces Active M 3 as an example of a first approach in controlling mobile devices in a visual way.
Active M 3 integrates two known concepts: active mail and multimedia mail.
DVB-H is a technology developed as an extension of DVB-T with additional features that make it suitable for delivery to mobile devices such as phones and Personal Digital Assistant (PDAs).
This paper deals with the conditions of receiving digital video broadcast type services in mobile handheld devices.
The DVB-H standard is introduced and the key technology elements on data link layer and physical layer are discussed in some details.
Finally the DVB-H terminal and network design is described.
Please provide the passage.
We present a design for a low cost but powerful and high speed communications device powered by a specific computer chip.
The device can achieve very high speed, thanks to the PCI bus compatible IDT ATM NIC.
The device could be used as a two way pager, a box that connects to the internet, a personal assistant, or as a video phone.
The RV4640 is a very affordable 64 bit RISC processor that executes 175 dhrystone MIPS at 133 MHz.
The RV4640 can be connected to a System Interface Chip which will provide I/O and memory control.
The IDT77903 ATM card is a full duplexed 25 Mbps NIC with a PCI bus interface and it costs less than $100 (US).
Integrating this card into our device as a network interface will make highspeed videoconferencing and multimedia applications easily implementable.
Dr. Who is a Microsoft research project aiming at creating a speech-centric multimodal interaction framework, which serves as the foundation for the NET natural user interface.
MiPad's design and user study compared to a common handheld writing device.
MiPad is the application prototype that demonstrates compelling user advantages for wireless personal digital assistant (PDA) devices, MiPad fully integrates continuous speech recognition (CSR) and spoken language understanding (SLU) to enable users to accomplish many common tasks using a multimodal interface and wireless technologies.
It tries to solve the problem of pecking with tiny styluses or typing on minuscule keyboards in todayu0027s PDAs.
Unlike a cellular phone, MiPad avoids speech-only interaction.
It incorporates a built-in microphone that activates whenever a field is selected.
As a user taps the screen or uses a built-in roller to navigate, the tapping action narrows the number of possible instructions for spoken word understanding.
MiPad currently runs on a basic mobile device with a computer where speech recognition is performed.
The Dr Who CSR engine uses a unified CFG and n-gram language model.
The Dr Who SLU engine is based on a robust chart parser and a plan-based dialog manager.
Little is known about how new mobile apps succeed in the market.
Research in the sociology of technology suggests that the evolution of new applications is a process of social interaction between multiple constituencies, aiming to create a common definition of mobile technology problems and solutions that is obvious only in retrospect.
This theory is illustrated by the early evolution of the personal digital assistant (PDA).
According to this view, established technological communities attempt to impose their own definitions of key problems and solutions on new mobile technology, thereby forcing newer players to provide a "total system" that completely redefines a new application area.
In the ubiquitous environment, mobile terminals like personal digital assistant or cellular phone are used to access the Web.
We implemented the procedures in a ubiquitous/universal passive viewer (u-PaV) system that transforms Web content into passive viewing content that is especially useful for mobile terminals.
Extracting images and text, u-PaV generates a Flash file, which is a popular multimedia format.
Although the presentation of Web content depends on the terminal type, the Web interface of mobile terminals is designed almost the same as that of personal computers.
However, comparing mobile and desktop terminals, some difference in device characteristics, such as screen resolution or sound faithfulness, affect the presentation on the terminal.
Moreover, when changing the access style between interactive and passive, the presentation should be adjusted for the terminal type because the lacking information is usually not perceived after transformation.
To adjust the play style of Web content to the terminal type, we developed a method for visual presentation.
We change the background color of the screen to show the emotions of a web page.
Second, we emphasize the subject of the content by the logotype of the keyword.
We break the picture into parts and show them one by another using visual effects.
These procedures can be applied to any type of terminal.
The location-sharing system, named as “The Beijing Explorer”, which exchanged positioning information and users’ situation to one another using a PDA with built-in wireless LAN and a GPS receiver in real time.
Users can see their position and their chats on the screen of a PDA using the system real-timely.
The system was used for the guidance of the Palace Museum (Forbidden City) in Beijing, China.
We ran the experiments twice using the system.
The results of experiments show that the service using positioning data and sharing contents were valuable and interesting.
The correct positioning information is important for the guidance system.
A truly personal machine, called a private machine and implemented as a computer assistant, is fundamentally different from traditional machines.
It is personal and private in an unprecedented manner, and its modus operandi is such that network and power failures will not be rare.
Designing distributed systems where PDAs are treated as "first class citizens" is a private :[59],"assets (electronic money, keys for unlocking doors and authentication) will be stored in PDAs.
Ownership and control of these :[59],"assets and the media that store and communicate them should remain with the user.
This must be reflected in the design of systems for private  :[105],"introduce the "open-ended argument" to describe the design strategy we used for designing a system that is designed to reveal information to the user (as opposed to hide it).
We argue and show that when systems are designed this way, the user (a human) is better able to control the system and his personal data, as he can make better decisions than the system itself based on understanding of the information.
The system we have designed and implemented under this design guidelines is presented and discussed.
Depression is under recognized in a variety of pediatric settings.
The purpose of this paper is to describe the development and initial evaluation of a personal digital assistant (PDA)-based decision support system (DSS) for pediatric depression screening in ages 8 to 18 years of age by pediatric advanced practice nurse (APN) students.
Three aspects are described: selection of depression screening instrument; integration into a personal digital assistant; and evaluation through quantitative (usage) and qualitative (focus group) evaluation.
Only one third of eligible patients were screened.
Twenty percent of those screened were identified as at risk for mood disorder.
The barriers to screening identified through focus groups included a lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, cultural and personal factors.
Suggestions for educational, research, and screenings using a special screening device are discussed.
This study explored the potential of the application of wireless and mobile computing technologies to be used in improving the efficiency of patient care and education and future developments in information and communication technologies to support healthcare professionals and medical students in healthcare research, medical education and training.
The design used for this study was a systematic review of published materials obtained from EMBASE and MEDLINE online databases, and the Cochrane Library database, including personal observations.
Today, more than 50% of healthcare professionals and medical students are using Personal Digital Assistant with expected growth of more than 75% by year-end 2007.
In addition, wireless and mobile computing technologies allows Personal Digital Assistant to connect directly to networks or the Internet.
Studies relating to processes of patient care and should evaluate mobile computing technologies as a potential timesaving tool.
Wireless and mobile computing technologies is only beginning to take its first step in improving patient care and education.
They have shown a positive impact on patient safety, health care efficiency, and ultimately patient satisfaction.
Nursing students can learn many things through practical training by experiencing actual medical practice and by coming in contact with patients.
Therefore practical training is an effective learning opportunity for developing the practical nursing care ability of nursing students.
Moreover, at hospitals, which are training facilities, the use of special devices is not allowed due to safety concerns.
So, we created a learning support environment that facilitates the imagination of nursing techniques, and enables effective preparation, review, and learning at anytime and anywhere using a portable digital assistant (PDA) device for practical training.
As described in this paper, we report on the outline for the digital nursing dictionary and the evaluation of its use.
Limitation in display size and resolution on mobile devices is one of the main obstacles for wide-spread use of web applications in a wireless environment.
Web pages are often too large for a PDA screen to present.
The same problem exists for devices with low resolution such as WebTV.
Rebuilding web pages for devices would ease the problem; however, the many different display types will greatly increase the burden of web page designers since they have to customize a web page for each possible display type.
In this paper, we propose a document segmentation and presentation system.
The system automatically divides a web document into a number of logical segments based on the screen size and the structure and content of the document.
Additional information such as overviews and summaries is also extracted to facilitate navigation.
The system presents the segments and structural information of a web document to make full use of the screen for information finding.
Take 8-bit microcontroller (C8051F005) as the nucleus and study a kind of voltage harmonic monitor device that satisfies the long-range monitor.
The harmonic analysis algorithm adopts Fast Fourier Transform (FFT).
This device has two work modes: ”native” and ”remote”.
It also can communicate with a monitoring center through telephone line, serial port, IC card, PDA (Personal Digital Assistant), etc.
Users can access online information anywhere due to new technology and portable devices, faster computers and wireless abilities, increased memory and CPU speeds.
We are interested in studying the effect of users switching from a large screen device, such as a desktop or laptop to use the same web page on a small device, in this case a PDA (Personal Digital Assistant).
We discuss three common transformation approaches for display of web pages on the small screen: Direct Migration, Linear and Overview.
We introduce a new Overview method, called the Gateway, for use on the small screen that exploits a user’s familiarity of a web page.
They prefer a different method for web pages that were on big screens, unlike many other websites.
The limitations and constraints of mobile systems need to be adequately addressed in software development.
We have been developing a taxonomy of risks based on SEIu0027s risk questionnaire and applied it during the development of a negotiation support system for a Personal Digital Assistant (PDA).
In our planned research, we will explore how we can better integrate existing risk management strategies and Agile Methods (AM).
Mobile services and private data have required increased level of protection.
Speaker recognition, one of the biometric technologies, arises lots of research interests for its simple, cheap and convenient characteristics.
In this paper, a robust speaker recognition system which facilitates reliable authentication with multi-channel voices is presented.
A large multi-channel corpus, including mobile phone, personal digital assistant (PDA), telephone and microphone, is collected to evaluate the system performance.
This paper presents a method to generate unique and nevertheless highly random pseudonyms in a distributed environment.
More precisely, each user can now generate his pseudonym locally in his personal security environment, e.g.
in his smart card or his personal digital assistant.
There is no need for any information interchange between issuing parties or global data (especially keys), except unique identifiers for each user and each device of the system.
The holder can prove he generated a specific pseudonym without revealing his identity and he can reveal his identity by disclosing the pseudonym.
Whereas the verifier of a disclosed pseudonym can be sure, that the presenter of the pseudonym is the holder of the pseudonym (i.e.
You haven't provided the passage yet. Please provide the passage for me to work with.
User and device identifiers are used to create a unique pseudonym, which is then encrypted to ensure anonymity. This pseudonym will be used to generate unique pseudonyms, but to ensure pseudonymity, both components will be stored in the pseudonym in encrypted form.
In today's mobile information society, location-based services play an increasingly important role.
These services are to be accessed by users with a mobile end device for the use of city maps, route planning, navigation, or traffic information.
Mobile end devices, however, do not have computing power or storage capacity comparable to that of a personal computer or laptop.
These deficits can be bypassed by employing special methods in the actual applications.
This paper outlines the experience gained in the development of a route planner for public transport to be used on a personal device.
Breaking down this process into steps to save phone cost plays a significant role.
