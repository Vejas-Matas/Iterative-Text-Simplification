In the modern era of automation, autonomous vehicles are currently the focus of academic and industrial research.
With the ever increasing number of drones being used in both civilian and commercial settings, there is an increased need for autonomy in these systems too.
Due to guidelines set by the governments regarding drone height limits, road-following navigation is garnering interest.
In an attempt to achieve the above mentioned tasks, we propose an learning from a pilot using machines.
Derived from the classic image classification algorithms, our classifier has been constructed in the form of a fast A 39-layered Inception model is used to evaluate the presence of roads in the input images.
Our system performs better in terms of processing complexity and accuracy than many existing models for imitation learning.
The data used for training the system has been captured from the drone, by flying it in and around urban and suburban streets, by experienced pilots.
Permissions were taken from required authorities who ensured a minimal risk to pedestrians during data collection.
With the extensive amount of drone data that we collected, we have been able to navigate successfully through roads without crashing or overshooting, with an accuracy of 98.44%.
The computational efficiency of MAVNet enables the drone to fly at high speeds of up to 6m/sec.
We present the same results in this research and compare them with other advanced methods of vision and navigation.
Recognizing traffic signs can reduce accidents worldwide.
With the arrival of Self-driving cars it has become a staple challenge to solve the automatic recognition of Traffic and Hand-held signs in the major streets.
Machine learning techniques such as Random Forest, SVM, and deep learning have been used to classify traffic signs.
Though they reach good performance on a specific dataset, but fall short of tackling multiple Traffic Sign Recognition benchmarks.
In this paper, we propose a novel and new universal architecture that aces multiple benchmarks with better overall score than the current best architectures.
Our model is made of residual convolutional blocks with dilated skip connections.
With this we score high accuracy in German and Belgian sign recognition.
Moreover, we propose a newly devised dilated residual learning representation technique which is very low in both memory and computational complexity.
We introduce Ignition: an neural network system for training unconstrained self-driving vehicles in simulated environments.
The model is a standard neural network model, which is fed in images from a car simulator, and outputs steering, throttle, and braking information.
Importantly, we never explicitly train the model to detect road features like the outline of a track or distance to other cars; instead, we show that these latent features can be automatically learned by the model.
In this paper, we present a transfer learning method for self-driving cars, which enables a convolutional neural network trained on a specific dataset to be utilized for the same task in a different target domain.
A standard computer vision model for direct control is designed to map a single front-facing camera image to a steering command.
To enable the transfer learning, we let a steering command and a lane departure level are produced by a new module that uses the output of the last convolutional layer.
The CNN trained on the source domain, called source network, is then utilized to train another task module called target network, which also uses the output of the source network's last layer and is trained to produce a steering command for the target domain.
The steering commands from the source and target network are combined and the combined command is utilized for controlling a car in the target domain.
We used two simulators, TORCS and GTAV, for the source and target domains.
Experimental results show that the proposed method outperforms other baseline methods in terms of stable and safe control of cars.
A significant problem is the limited amount of data available for training.
There are some datasets available for the popular problems like item recognition and classification for self-driving cars, however, it is very limited for the industrial robotics field.
In previous work, we have trained a neural network that identifies the robot in an image and estimates its 3D structure from a 2D image, but it was limited to a range of robots produced by Universal Robots (UR).
In this work, we extend our method to work with a new robot arm - Kuka LBR iiwa, which has a distinct appearance and an additional joint.
However, instead of collecting large datasets once again, we collect a number of smaller datasets containing a few hundred frames each and use applying the knowledge from the existing robot model to the new robot.
We have proven that transfer learning is not only applicable in this field, but it requires smaller, high-quality training datasets, trains significantly faster and reaches similar accuracy compared to the original method, even improving it on some aspects.
Moral responsibility is a major concern in automated decision-making, with applications ranging from self-driving cars to kidney exchanges.
In this paper we present mathematical models for the modeling, analysis, and control of self-driving vehicles wherein robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure acceptable quality of service throughout the network.
We first cast an autonomous system within a network model with passenger loss.
New insights are used to design a simple rebalancing algorithm, which is applied to a case study of New York City and implemented on an eight-vehicle mobile robot testbed.
The case study of New York shows that the current taxi demand in Manhattan can be met with around 8,000 robotic taxis, about 70% of the current number of taxis in Manhattan.
Finally, we extend our queueing-theoretical setup to include congestion effects, and study the impact of autonomously rebalancing vehicles on overall congestion.
Collectively, this paper provides a rigorous approach to the problem of system-wide coordination of autonomously driving vehicles, and provides one of the first characterizations of the sustainability benefits of robotic transportation networks.
In the wake of the digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions.
While the benefits of this change can be big, there are also tremendous risks to our society.
After the automation of processes and the creation of driverless vehicles, the automation of society is next.
We're at a critical moment: do we choose a society where decisions are made from the top down, or one where people are free to participate and decide together.
Modern information and communication systems (ICT) enable both, but the latter has economic benefits.
The fundaments of human dignity, autonomous decision-making, and democracies are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies, but also the basis of greater efficiency and success.
Once self-driving car is available and passengers won't worry about it, they will need to find new ways of entertainment.
However, retrieving entertainment contents at the Data Center (DC) can hinder content delivery due to delay in communication with the Data Center.
To address these challenges, we propose caching for self-driving cars, by using Computer techniques are applied to edge computing systems.
First, at DC, Multi-Layer Perceptron (MLP) is used to predict the probabilities of contents to be requested in specific areas.
To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units.
Second, in order to cache entertainment contents stylized for car passengers' features such as age and gender, a special type of AI (CNN) is used to guess a car passenger's age and gender.
Through this, the self-driving car can identify the contents need to be downloaded from the MEC server and cached.
Using AI in cars to improve entertainment minimizes content downloading delay.
To solve the formulated problem, a special method is applied.
The simulation results show that our prediction accuracy is achieved at 98.04% and our approach can speed up the process.
This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE), a simple simulation of a centralised financial market, based on a Limit Order Book (LOB) such as is common in major stock exchanges.
Construction of BSE was motivated by the fact that most of the world’s major financial markets have automated, now being performed by automated trading systems, which were previously controlled by humans.
Research aimed at understanding the dynamics of this new style of financial market is hampered by the fact that no real-world market can be tested while it's open for business, forcing researchers to work from time-series of past trading data.
education of engineers to create automated trading systems requires that they have hands-on learning experience in a sufficiently realistic teaching environment.
BSE as described here addresses both those needs: it has been used for teaching and research in a leading UK university and the BSE program code is available for free on GitHub.
This paper provides a holistic study of how stock prices react to financial news.
Thereby, we specifically shed light into the extensive amount of filings for which no categorization of their content exists.
For this purpose, we utilize an approach from data mining - namely, latent Dirichlet allocation - as a means of topic modeling.
This technique facilitates our task of automatically categorizing, the content of over 70,000 8-K filings from U.S. companies.
We then evaluate the subsequent stock market reaction.
Our empirical evidence suggests a difference in various news stories in terms of their relevance and impact on financial markets.
For instance, we find a significant reaction to earnings and credit rating, but also for disclosures regarding business strategy, the health sector, as well as mergers and acquisitions.
Our results yield findings that benefit managers, investors and policy-makers by indicating how regulatory filings should be structured and the topics that often cause stock prices to change.
This paper addresses the financial markets problem space with particular emphasis on trading systems seen in banking today.
With the advent of modern computing, cross-regional trading transactions can now be executed within milliseconds, a reality that is impossible without the advancements of software systems technology.
We then move on and discuss a trading system and how it fits in with the banks ecosystem of vital inter-working components.
As for the humanoid robots, the noise generated by the robot's movement severely degrades the performance of the speech recognition performance.
A new speech recognition system robust to ego-noise for humanoid robots is proposed, in which the motor's on/off state is used to help the system work better.
For this, we consider the bottleneck features, which have been successfully applied to deep neural network (DNN) based speech recognition system.
When learning the key features to identify, we first exploit the motor state data as supplementary information in addition to the acoustic features as the input of the first neural network for acoustic modeling.
The first neural network
When the proposed method is evaluated in terms of phoneme error rate (PER) on TIMIT database, the experimental results show that an obvious improvement is achieved by our algorithm over the conventional systems, 10% better.
Many new techniques have been proposed in the literature for applying domestic service tasks on humanoid robots, such as teleoperation, learning from demonstration and imitation.
However sensor based robot control overcomes many of the difficulties of uncertain models and unknown environments which limit the domain of application of the previous methods.
Furthermore, for service and manipulation tasks, it is more suitable to study the interaction between the robot and its environment at the contact point using sensors to control, rather than specifying the exact movements required to achieve them.
Online social media provide users with big opportunities to engage with diverse opinions.
Simultaneously, they allow the spread of misinformation by empowering individuals to choose the information they want to see, through both actively seeking out what they agree with and algorithms that show them what they like.
A clear understanding of the trade-offs is still missing.
We introduce a stylized social learning model where most participants in a network update their beliefs unbiasedly based on the arrival of new information, while some participants resist news that contradict their existing views.
We show that this simple confirmation bias mechanism can generate permanent opinion polarisation.
Furthermore, the model results in states where unbiased agents behave become biased, due to their biased neighbours effectively functioning as gatekeepers, restricting their access to free and diverse information.
We derive analytic results for the distribution of individual agents’ beliefs, explicitly demonstrating the aforementioned trade-off between confirmation bias and social connectivity, which we further validate against US county-level data on the impact of Internet access on the formation of beliefs about global warming.
Our findings indicate that confirmation bias in small doses may actually result in improved accuracy across individuals by preserving information diversity in a social network.
as bias grows, accuracy declines as information is restricted.
We discuss the policy implications of our model, highlighting the downside of some strategies to fight false information and suggesting alternative strategies to correct false information.
Introduction of the web changed what we get from the web.
Recent studies showed that users tend to select information that is consistent with their system of beliefs, forming groups of people with similar views and ignoring opposing opinions.
In this environment, users work together to agree on a shared story making any attempt at debunking inefficient.
Such a configuration occurs even in the consumption of news online, and considering that 63% of users access news directly form social media, one hypothesis is that more polarization allows for further spreading of misinformation.
Along this path, we focus on the polarization of users around news outlets on Facebook in different European countries (Italy, France, Spain and Germany).
First, we compare the page posting behavior and behavior in different countries and observe different posting activities.
We explore users interact with pages and the emergence of polarized communities generated around specific pages.
Italy is the most polarized country, followed by France, Germany and lastly Spain.
Finally, we present a variation of a model to simulate the formation of these communities by considering the users' engagement and trust on the news.
Our findings suggest that trust in information broadcaster plays a pivotal role against polarization of users online.
It is very important to have a mechanism in place that allows the nodes to control resource usage and prevent flooding and denial-of-service attacks with spam in decentralized peer-to-peer networks.
In this paper, we discuss and compare the different approaches to central control that are used by projects in the cryptocurrency space.
Methods are applied to design a cryptocurrency exchange for Namecoin and other crypto for example.
With the introduction of special cryptocurrencies, such as Monero, the implementation of mining code in browser-based JavaScript has become a worthwhile alternative to specialized mining equipment.
Based on this technology, a new form of cryptojacking or drive-by mining has gained momentum in the web. A cryptojacking site secretly uses visitors' computers to mine for cryptocurrencies.
In this paper, we systematically explore this phenomenon. For this, we propose a thorough analysis process, which enables us to identify mining scripts and conduct a large-scale study on the prevalence of cryptojacking in the Alexa 1 million websites.
We find that cryptojacking is common, with 1 in 500 websites are hosting malware.
Moreover, we perform several secondary analyses to gain insight into the cryptojacking landscape, including a measurement of code characteristics, an estimate of the potential mining earnings, and an evaluation of current blacklist-based countermeasures.
The rise of modern blockchains has caused the development of smart contracts: autonomous programs that live and run on the blockchain.
Smart contracts have seen a rapid climb to prominence, with applications predicted in law, business, commerce, and governance. contracts [39],"are commonly written in a high-level language such as Ethereum's Solidity, and translated to compact low-level bytecode for deployment on the blockchain.
Once deployed, the code is automatically executed, usually by a virtual machine.
As with all programs, smart contracts can be highly vulnerable to malicious attacks due to deficient programming and tools, with problematic compilers.
At the same time, smart contracts :[39],"are also high-value targets, often commanding large amounts of cryptocurrency.
Hence, developers and auditors need security frameworks capable of analysing low-level bytecode to detect potential security vulnerabilities.
In this paper, we present Vandal: an analysis tool for Ethereum smart contracts.
Vandal consists of an analysis pipeline that converts low-level Ethereum Virtual Machine (EVM) bytecode to semantic logic relations.
Users can express security analyses using a specific language called \souffle.
Vandal is both fast and robust, successfully analysing over 95% of all 14,100 contracts with an average runtime of 4.15 seconds; outperforming the current state of the art tools---Oyente, EthIR, Mythril, and Rattle---under equivalent conditions.
Bitcoin's popularity has grown over the past decade, it has become a more attractive target for adversaries of all kinds.
Image tampering, being made easier and more common because of digital technology, is increasingly causing problems regarding the authenticity of images.
JPEG images can be easily tampered with; as a result, researchers are studying ways to detect such alterations in multimedia files.
Nevertheless, the interesting issue of detecting image tampering and its related operations by using the same quantization matrix has not been fully investigated.
Aiming to detect forgery under the same quantization matrix, we propose a detection method by using reshuffle pattern based on compression.
The learning classifiers are applied for classification.
Our experimental results indicate that the method is indeed highly effective in detecting image tampering and various manipulations with the same quantization matrix.
The malicious alteration of machine time is a big challenge in computer forensics.
Detecting such changes and reconstructing the actual timeline of events is of paramount importance.
However, this can be difficult since the attacker has many ways to hide such changes.
In particular, cloud computing, host and guest computer time can be manipulated in various ways by an attacker.
Guest virtual machines are especially vulnerable to attacks from their host.
As such, it is important to guarantee the timeline integrity of both hosts and guests in a cloud, or at least to ensure that timeline changes are not missed.
In this paper we survey the issues related to host and guest machine time integrity in the cloud.
Further, we describe a new solution for solving issues in at risk systems.
The proposed framework has been implemented on a custom-built simulator
Performance figures show the feasibility of our proposal.
Detection of different types of image editing operations carried out on an image is an important problem in image forensics.
It gives the information about the processing details about the image, and also can detect fake images.
There have been a few methods proposed to detect various image editing operations in one system.
However, all the operations have to be known before the model is trained.
But, real-forensics scenarios it's hard to detect changes made to an image.
To solve this problem, we propose a new machine learning approach which can differentiate between different types of image editing operations.
The proposed method classifies image patches in a pair-wise fashion as either similarly or differently processed using a deep neural network.
Once the network can recognize different image editing operations, it can differentiate between different image editing operations not present in the training stage.
The experimental results show the efficacy of the proposed method in detecting different types of image editing operations.
Digital assistants are emerging to become more prevalent in our daily lives. In interacting with these assistants, users may engage in multiple tasks within a short period of time.
DIANE is a digital assistant system that aims to improve doctor access to hospital information, such as medical records and staff data. The access could be achieved by implementing face recognition and live streaming as part of the digital assistant system.
Individuals suffer from diverse biases in decision-making. extensive research has shown
In our paper we analyze the effects of managers' biases in team decision-making on organizational performance.
In the simulations, managerial decisions which are based on different levels of organizational complexity and different incentive systems suffer from biases known from descriptive decision theory.
The results illustrate how biases when combined with each other and in different organizational contexts affect organizational performance.
"Some combinations of biases significantly improve organizational performance while these biases negatively affect organizational performance when they occur separately, unexpectedly."
This might evoke considerations whether decision-making should be as rational as possible.
Perception of the local environment is a precondition for robots to safely navigate in changing environments.
Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions.
For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information.
Considering dynamic obstacles introduces another level of complexity, since they can lead to necessary replanning or collisions later on.
In this paper, we present a system that identifies flat areas on maps and detects dynamic obstacles.
Our system then uses this information to create maps for predictions, in which paths can be planned efficiently and quickly.
We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.
An autonomous service robot often first has to search for a user to carry out a desired task.
This is a challenging problem, especially when this person moves around since the robot's view is limited and the environment structure typically poses further visibility constraints that influence the perception of the user.
In this paper, we propose a novel method that calculates the user's visibility at each location in the environment based on Monte Carlo simulations.
As the robot needs time to reach the possible search locations, we consider time and visibility when searching.
In this way, the robot can choose the next search location that has the maximum visibility to the user.
Our experiments in different computer simulations demonstrate that our approach leads to a significantly shorter search time compared to a greedy approach with background information.
users walk on typical paths to places where a robot is needed
Depending on the environment and the paths, following a human step-by-step might not be the best option, as there are more efficient paths for the robot.
We propose to predict the human's future movements and use this information to guide the robot's navigation for the robot.
Since frequent blockages of the person occur due to obstacles and the robot's limited view, the estimate of the person's location and the prediction of the next destination are affected by uncertainty.
Our approach deals with such situations by explicitly considering obstacles in the way so the robot can see the human.
We show in simulated and real-world experiments that our technique leads to significantly shorter paths compared to an approach in which the robot follows the user and handles obstacles.
In this paper, we introduce an approach to robot navigation in messy rooms.
We propose to estimate local obstacle densities based on already detected objects and use them to predict costs to avoid obstacles that the robot can't see yet.
By taking into account the calculated costs for navigation, the robot is then able to navigate and reduces the risk of getting stuck in cluttered regions.
As the experimental results demonstrate, our method enables the robot to efficiently navigate through environments with obstacles and achieves significantly shorter completion times compared to a standard approach not using any prediction.
In this paper, we present an integrated navigation system that allows humanoid robots to autonomously navigate in unknown, cluttered environments.
From the data of an onboard consumer-grade depth camera, our system estimates the robot's pose to compensate for drift of odometry and maintains a heightmap representation of the environment.
Based on the model, our system iteratively computes safe actions, leading the robot to target locations.
To efficiently check for collisions during planning, we developed a new approach that takes into account the shape of the robot and the obstacles.
As we demonstrate in experiments with a robot, our system leads to good navigation in cluttered environments and the robot is able to traverse highly challenging passages.
In this paper, we present a novel approach to accurately calibrate the kinematic model of a humanoid based on observations of its monocular camera.
Our technique estimates the parameters of the complete model, consisting of the body angles, as well as the camera extrinsic and intrinsic parameters.
Furthermore, we developed an approach to automatically select a subset of configurations for the calibration process that yields a good trade-off between the number of observations and accuracy.
Further, our approach to configuration selection yields much better optimization results compared to randomly chosen possible configurations.
our system needs a few configurations
Our optimization is effective and the implementation, which is available online, can be applied to various robots.
A lab automation concept is introduced.
A robotic limb is attached to a rotorcraft.
The limb's gripper allows the unmanned aerial vehicle to dexterously manipulate objects such as micro-arrays and test tubes often used in high throughput systems (HTS).
The resulting drone could augment existing standard operations
The 6 degree-of-freedom (DOF) arm and gripper design are presented.
Results are also given. test approach
Robot friendship has become more popular in past years.
however, humanoid walking might be somewhat unstable for these applications
Even with robots, falls occur frequently.
Thus, wheel attachments have been added onto a miniature humanoid, so it can move faster and with more stability than walking.
In addition, with such attachments a robot can switch from walking to rolling when necessary.
DARwIn-OP is a humanoid robot that has been used as an experimentation and performance evaluation platform.
This paper discusses preliminary work regarding robot friendship by using a miniature humanoid capable of fetching different toys based on voice command.
Advances in technology have expanded the use of drones for various purposes, including surveillance, video recording, and delivery.
These applications service need recording.
Large drones are used singly in missions while small ones are used in formations or swarms.
The small flying machines are proving to be helpful in civilian applications.
Consideration of small drones for the applications such as group flight, entertainment, and signal emission lead to deployment of networked drones.
To develop group display applications, a real-time drone control for group display is proposed.
Simulation shows that drone formation can display messages effectively.
The rapid development of the Internet and mobile technology has changed our daily lives.
To ride on the digital trend, more business activities have been engaged in the digital world.
Marketing and advertising is one of the most common business areas that is transformed digitally.
The rise of influential people, social media platforms, and multi-channel retailing have attracted countless business entities to consider the adoption of digital marketing tools for promoting and advertising their brands and products.
Variety of digital marketing tools must be carefully selected based on a multiple number of criterion.
In this paper, a fuzzy-AHP method is proposed and developed for assisting industry practitioners in systematically and effectively evaluate and select proper digital marketing tool(s) for adoption.
The developed method not only streamlines the internal operations of digital marketing tool selection, but it also increases the practitioner's effectiveness of achieving the pre-defined strategic marketing objectives.
This study focuses on the digital marketing for tourism businesses.
The study asks the question of how using technology tools benefit the organisational capabilities of a company.
By adopting marketing as a skills-based approach, the study provides new insights into the existing literature on e-marketing in tourism.
Initial findings indicate that the marketing capabilities of companies are transformed through technology adoption.
Four major capabilities were identified, each of which evolves as a result of using the tools.
The main result of the study is that the use
Big data, the enhanced ability to collect, store and analyze a large amount of data in tremendous speed and with negligible costs, delivers immense benefits in marketing efficiency, healthcare, environmental protection, national security and more.
The central tenets of the current privacy framework, the principles of data minimization and purpose limitation, are severely strained by the big data technological and business reality.
As we increasingly interact with these artificial agents in unmonitored settings, without human oversight, their seeming autonomy and increasingly complex and advanced behavior, raises legal and philosophical questions.
The focus on the machine is a distraction from the debate surrounding data-driven ethical issues, such as privacy, fairness and discrimination.
The machine may make ethical challenges worse, help them, or highlight them, but it is humans who must be held accountable.
Policymakers should seek to devise agreed-upon guidelines for ethical data analysis and profiling.
Such guidelines would address the use of legal and technical mechanisms to obfuscate data; criteria for calling out unethical, if not illegal, behavior; categories of privacy and non-privacy harms; and strategies for empowering individuals through access to data in intelligible form.
As smart speakers with voice interaction capability permeate continuously in the world, more and more people will gradually get used to the new interaction medium–voice.
Although speech recognition and language processing have been greatly improved over the past few years, users still may encounter errors from time to time like “cannot understand”, “no requested audio resource (such as music)”, which can frustrate users.
Therefore, when an error occurs, it is vital that the smart speaker gives an effective and proper response.
However, currently the strategies of popular speaker brands in China differed mainly on two approaches: apologizing or not using humor.
We looked at how users prefer to handle errors and under two error scenarios——“don't understand” and “missing audio resource”.
Two dependent variables (outcomes) were measured.
The results showed that participants were more satisfied and perceived higher sincerity when smart speaker apologized in both error scenarios.
In the "no requested audio resource" scenario, humor had little impact on how satisfied people felt and seemed.
But in the “cannot understand” scenario, funny tone decreased perceived sincerity.
the smart speakers cannot distinguish human voice from machine voice.
Determine whether human or machine is speaking to a smart speaker is desired.
to prevent unwanted voice commands when no one is present, we propose a system consisting of a speaker and a microphone array to detect the existence of a human nearby, supposing it can be incorporated in a smart speaker in the future.
Amazon's Echo, and Apple's Siri have drawn attention from different user groups; however, these assistants provide limited language for English speakers.
we conducted a study of the Google Home Smart Speaker with 20 participants
The findings show that compared with others, the native English speakers had better and more positive user experiences in interacting with the device.
It also shows that English language skills play an important role in interacting with VUIs.
The findings from this study can create insights for Voice interface designers and developers can improve it for people who speak different languages and for better voice recognition.
A pharmacophore analysis was used to compare different classes of compounds in the drug discovery process (drug molecules, compounds in high throughput screening libraries, combinatorial chemistry building blocks and nondrug molecules).
Significant differences were observed between the characteristics of the drug molecules and the compounds from the screening process, which appear to be closely related to the nondrug pharmacophore distribution.
It is suggested that the analysis of pharmacophore profiles could be used as an additional tool for the property-based optimization of compound selection and library design processes, thus improving the odds of success in lead discovery projects.
Annotation of bioassay protocols using a special web language is a way to make experiment descriptions machine-readable.
Protocols are communicated using concise scientific English, which blocks most software analysis.
Given the availability of a sufficiently expressive ontology, some or all of the pertinent information can be captured by asserting a series of facts, expressed as semantic web triples (subject, predicate, object).
With appropriate annotation, assays can be searched and evaluated in ways similar to drug discovery research.
The BioAssay Ontology was designed for this purpose
Next generation sequencing produces large amounts of data from many samples.
Subsequent bioinformatic analysis is typically done with the help of open source tools, where each application performs a single step towards the final result.
This situation leaves the bioinformaticians with the tasks to combine the tools, manage the data files and meta-information, document the analysis, and ensure reproducibility.
SPSS Clementinel2.0 statistical software was used to mine the association rules between traditional Chinese medicine (TCM) and causes, symptoms, and syndromes.
The classic Apriori algorithm is useful to mine cases of influenza treated by contemporary famous old Chinese medicine.
Identifying antibiotic-resistant bacteria in samples is crucial for public health and food safety.
Next-generation sequencing technology has provided a powerful tool in studying the genetic differences and how they affect the physical traits in humans and other species.
A statistical approach for estimating genetic information in mixed bacterial samples has reduced the error rate and mean absolute error (MAE) in the identification of genetic variations in DNA.
CRISPR is a tool that is widely used for gene editing.
However, unwanted side effects may occur as a result of long-term DNA cutting.
Anti-CRISPR proteins, which are powerful molecules that inhibit the gene editing tool, may have the potential to promote better utilization of the gene editing in gene therapy.
Additionally, more in-depth research on these proteins would help researchers to better understand the co-evolution of bacteria and phages.
Therefore, it is necessary to collect and integrate data on types of anti-CRISPRs.
The CRISPR/Cas9 system was recently developed as a powerful and flexible technology for targeted genome editing, including editing DNA.
These applications require the design of guide RNAs.
However, it is challenging, it needs consideration
CRISPR has become a hot research area ever since its advent for its ability to edit DNA sequences precisely.
Based on its function of gene perturbation, a variety of gene editing methods have been developed to achieve different aims.
The target locations of a DNA strain can be broken and fixed, during which the genes can be turned off, fixed, or activated.
The high efficiency of CRISPR/Cas9 reagents preparation and the easiness of experiment conduction make it now a powerful tool of high-content screen.
The hidden connection between these reports is that gene editing could be used to solve issues related to health care allocation.
Improving the health of future generations might coincide with public health goals; it might help people's health, and, if successful, might be seen as a public good.
Enhancing future generations will require Family planning.
Remarkably, the role of women in an enhancing scenario has not been discussed by its proponents.
The present discourse on moral obligations of future generations, although not referring to women, seems to imply that women might be required, morally, if not legally, to reproduce with IVF.
Enhancing future generations will be gendered, if an artificial womb is developed.
These are challenging issues that require a view that includes both genders.
Despite the lack of a clear conclusion on women's role in the discussions about the merits and risks of human genome modification, there is an urgent need to clarify the role of women in this scenario.
The CRISPR-Cpf1 system has been successfully applied in genome editing.
However, efficiency of the CRISPR-Cpf1 system varies
Using machine learning technology, a SVM model was created to predict target efficiency for any given gRNAs.
a web service called CRISPR-DT helps design the best gRNAs for the CRISPR-Cpf1 system.
A key problem for self-driving cars is the understanding, at a detailed level, of the current driving situation.
Addressing this issue requires the extraction of meaningful information from on-board stereo imagery by classifying the basic features of urban scenes into categories that can more easily be interpreted and be reflected upon (streets, buildings, pedestrians, vehicles, signs, etc.).
A random method is proposed to combine 3D map data with images and stereo imagery classification.
A novel fusion architecture based on the Stixel framework is presented for combining image segmentation with a type of AI (CNN) with depth information obtained from stereo imagery while integrating prior depth and labels.
The proposed approach was tested on a manually labeled data set in urban environments.
The accuracy of the basic elements was significantly enhanced by this method compared to what is obtained from the semantic pixel-wise segmentation of a CNN alone.
In recent years self-driving cars are becoming more common on public roads, improving safety and efficiency.
Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on highfidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle.
It is therefore of critical importance to ensure that self-driving software tested in many difficult driving simulations.
The state of the art in driving scenario generation, by some leading companies still relies on human input [1].
In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles.
We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using vision-based imitation learning we obtain safer self-driving behavior.
With the developing of the technology on self-driving, more and more L3 driverless vehicles are launched in market, people get opportunities to experience the self-driving cars in their daily life.
Because of this, there is an increased demand for the autopilot experience.
Natural and efficient human-computer interaction can not only improve the driving experience, but also accelerate the process of self-driving cars.
This paper discusses eye movements, voice commands and hand gestures in a self-driving car, and analyzes the technology, advantages and disadvantages of the existing interaction modes, and prospect the future development trend of self-driving human-computer interaction.
Self-driving vehicles are expected to change transportation in the future.
One of the main challenges for self-driving cars on public roads is the safe cooperation and collaboration among multiple vehicles using vehicle sensors and communication.
When self-driving cars try to share the same space, they might collide with one another, might become deadlocked, or might slam on the brakes making it uncomfortable or unsafe for passengers in a self-driving vehicle.
In this paper, we study how a self-driving vehicle can safely navigate merge points, where two lanes intersect.
We present a safe protocol for merge points named Autonomous Vehicle Protocol for Merge Points, where self-driving vehicles use both sensors and communication with other vehicles for cooperating with other self-driving and/or human-driven vehicles.
Our results show that our traffic protocol has higher traffic throughput, compared to simple traffic protocols, while ensuring safety.
Emerging self-driving vehicles are vulnerable to different attacks due to the principle and the type of communication systems that are used in these vehicles.
These vehicles are increasingly relying on vehicle-to-vehicle communication networks.
Vehicles communicating with each other add new threats to self-driving vehicles that contribute to big problems in autonomous systems.
These communication systems render self-driving vehicles vulnerable to other attacks.
In this paper, we propose an intelligent security system designed to secure external communications for self-driving and semi self-driving cars.
The hybrid detection system relies on the Back Propagation neural networks (BP), to detect a common type of attack in VANETs: Denial-of-Service (DoS).
The experimental results show that the proposed BP-IDS is capable of identifying malicious vehicles in self-driving and semi self-driving vehicles.
This paper proposes a simulation model for self-driving cars based on Robot Operating System (ROS).
One approach to the development of self-driving systems is the utilization of ROS which is an open-source middleware framework used in the development of robot applications.
On the other hand, the popular approach is the utilization of MATLAB/Simulink for modeling and analysis.
MATLAB/Simulink provides an interface between ROS and MATLAB/Simulink that enables to create functionalities of ROS-based robots in MATLAB/Simulink.
However, it is not been fully utilized in the development of self-driving systems yet because there's a lack of data for self-driving, making it hard for developers to adopt this approach.
Therefore, we provide a benchmark suite for a self-driving car system called Autoware.
Autoware is popular open-source software that provides a complete set of self-driving modules.
The benchmark contains MATLAB/Simulink samples available in Autonomous driving system.
They help to design self-driving systems using MATLAB/Simulink.
Ensuring the safety of self-driving cars is important, but industry and authorities have not agreed on a standard way to test them.
Deploying self-driving cars for testing in regular traffic is a common, but costly and risky method, which has already led to fatalities.
As a safer alternative, virtual tests, in which self-driving car software is tested in virtual tests, have been proposed.
One cannot hope to sufficiently cover the huge number of possible driving situations self-driving cars need to be tested by manually creating such tests.
Therefore, we developed AsFault, a tool for automatically generating virtual tests for systematically testing self-driving car software.
We demonstrate AsFault by testing the lane keeping feature of a self-driving car technology, for which AsFault generates scenarios that cause it to drive off the road.
A video illustrating AsFault in action is available at: https://youtu.be/lJ1sa42VLDw
At the start of self-driving cars, little is known about how users feel about them.
This is especially true for self-driving cars in public transport.
In this study, the relative preferences for a trip with a self-driving bus is assessed compared to a trip with a regular bus, based on a stated preference experiment.
Based on the responses of 282 respondents from the Netherlands and Germany, a discrete choice model is estimated as a Mixed Logit model including attitudes towards trust in self-driving vehicles and interest in technology.
The results show that currently public transport passengers prefer the self-driving bus over the regular bus only for short trips.
This is due to the finding that the travel time is about twice as high for the self-driving bus as for the regular bus for a short trip.
Findings from this study further suggest that the popularity of self-driving busses decreases with the presence of a human steward on-board, or if they are operated as a demand-responsive service with fixed routes.
People who are interested in technology or trust self-driving cars perceive the self-driving busses better.
Preferences towards automated public transport services are expected to evolve with the transition from pilot tests to regular use.
The management of self-driving systems is becoming more complex as the development of self-driving cars progresses.
One approach to the development of self-driving systems is the use of ROS; however, in the automotive industry, a typical system is designed with a specific software.
These models don't work with ROS systems.
To allow the two to be used in tandem, it is necessary to rewrite the C++ code and incorporate them into the ROS-based system, which makes development inefficient.
Therefore, the proposed framework allows models created in MATLAB to be used in a self-driving system, thereby improving development efficiency.
Furthermore, our evaluations of the proposed framework demonstrated its practical potential.
Social Media have get more popular ways to share information among users.
The spread of news regarding unexpected events is common in online social networks and so is the spread of misinformation related to the event.
We define as misinformation any false information that is spread either intentionally or unintentionally.
We identify and study misinformation on social networks, with a focus on Twitter.
Based on user and tweets characteristics, create a model that detects misinformation by looking for unusual behavior.
Our experimental results on thousands of tweets and users illustrate that our approach effectively identifies misinformation during emergencies.
Furthermore, our model manages to timely identify misinformation, a feature that can be used to limit the spread of the misinformation.
Superintelligence is a potential type of future artificial intelligence (AI) that is significantly more intelligent than humans in all major respects.
If it's built, super intelligence could be a big change, with good or bad consequences.
The prospect of highly advanced artificial intelligence is a topic of ongoing debate, which includes a significant amount of misinformation.
Superintelligence misinformation is potentially dangerous, ultimately leading bad decisions by the would-be developers of superintelligence and those who influence them.
This paper surveys strategies to counter advanced misinformation.
Two types of strategies are examined: strategies to prevent misinformation and correct it after it has spread.
In general, misinformation can be difficult to correct, implying the need for effective prevention methods.
The strategies proposed can be applied to lay public attention to superintelligence, education programs, and agreement among experts.
The widespread online misinformation could cause public panic and serious economic damages.
The misinformation problem aims at limiting the spread of misinformation in online social networks by launching competing campaigns.
Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem for the case when multiple cascades happen.
A model for cascading diffusion and explain cascade priority.
Second, we show that the misinformation containment problem cannot be approximated within a factor of $\\Omega(2^{\\log^{1-\\epsilon}n^4})$ in efficient computation unless NP \\subseteq DTIME(n^{polylog{n}}).
Third, we introduce several types of cascade priority that are frequently seen in real social networks.
We design ways to stop false information.
The effectiveness of the proposed algorithm is supported by encouraging experimental results.
Information that is incorrect in library science is often considered a problem that needs correction.
Misinformation and disinformation, however, may cause significant problems for users in online environments, where they are constantly exposed to an abundance of inaccurate and/or misleading information.
This paper aims to set the stage for future research by examining the relationships between true and false information and information that is intentionally false.
Our analysis extends to a discussion of signs of deception, as means for finding false information.
We argue that misinformation and disinformation are related concepts that have distinct meanings.
Misinformation is more than just being inaccurate or incomplete, disinformation does not always entail misinformation.
Social media has grown, but at the same time it becomes a hotbed of misinformation.
The wide spread of misinformation over social media is injurious to public interest.
We design a framework, which integrates collective intelligence and machine intelligence, to help identify misinformation.
Track users' expertise based on their blog posts and match the experts with given suspected misinformation.
By sending the suspected misinformation to appropriate experts, we can collect the assessments of experts to judge the credibility of information, and help refute misinformation.
In this paper, we focus on expert finding for misinformation identification.
We propose a tag-based method to track the skills of microblog users with social tags.
Experiments on a real world dataset demonstrate the effectiveness of our method for identifying experts who can correct misinformation.
The importance of research on misinformation has received wide recognition.
Two major challenges faced by this research community are a lack of theoretical models and a lack of reliable information.
This paper aims to address the aforementioned challenges by conceptualizing misinformation and enabling the sharing of false information.
In particular, a concept and a model of false information are proposed through surveying, synthesizing, and explicating existing work in the field.
The ontology-supported misinformation model can not only guide future misinformation research but also lay the foundation for building a digital library by advancing our understanding of misinformation and improving its management.
In addition, we present a formal methodology for managing misinformation in a digital library, and suggest future research directions related to the misinformation model.
Conspiracy theories have gained much academic and media attention recently, due to their large impact on public events.
Little is known about how conspiracy theories are spread on social media.
We present a research study of conspiracy theorizing on the internet during a health emergency--Zika.
Using a combination of content and discourse analysis, we identified types of conspiracy theories that appeared on Reddit in response to the Zika crisis, How Zika conspiracy theories arise, and the particular discursive strategies through which Zika conspiracy theories developed in online forums.
Our analysis shows that conspiracy talk emerged as people attempted to make sense of a public health crisis, reflecting their emergent information needs and their pervasive distrust in formal sources of Zika information.
Practical implications for computer researchers, health practitioners, and policymakers are discussed.
Conspiracy theories are omnipresent in online discussions---whether to explain a late-breaking event that still lacks official report or to give voice to political dissent.
Conspiracy theories evolve, multiply, and interconnect, to make them hard to control.
It is therefore crucial to develop efficient methods to examine the nature of suspicious conversations in online communities.
What do users talk about when they discuss conspiracy theories online? What are the recurring elements in their discussions? What do these elements reveal about users? This work answers these questions by analyzing a decade of discussions in a community that focuses on conspiracy theories.
We focus on the key elements of a conspiracy theory: the conspirators, what they do, and their targets.
a pattern such as "government controls information" represents the various ways in which multiple conspiratorial statements denote how governmental agencies control information.
Thus, narrative-motifs expose commonalities between multiple conspiracy theories even when they refer to different events or circumstances.
In the process, these representations help us understand how users talk about conspiracy theories and offer us a means to interpret what they talk about.
Our approach enables a study of conspiracy theories in various news sources with implications for understanding their adoption and combating their spread.
Recent studies in philosophy suggest that believing in conspiracy theories is understandable and might be true in some cases if we look at the evidence and conspiracy theories occur.
Drawing on this work, this shows that the problems with evidence for conspiracy theories are not exclusive to these theories.
As such, if there is a problem with the conspiracy theorist’s use of evidence, it is one of principle: is the principle which guides their use of evidence somehow in error? I argue that most people's views on conspiracy theories generally, there is a reason to question conspiracy theories based on how they use evidence.
Cryptocurrency is a new type of financial technology which has attracted a large number of people around the world.
The rapid changes, price swings, and mixed government attitudes towards cryptocurrency have triggered panic and chain reactions towards the application and adoption of cryptocurrency and have caused security concerns.
In this paper, we study the risks of the market based on the public available price history.
Furthermore, as seen by the public, our quantitative analysis reveals that the cryptocurrency market is relatively fragile and unstable.
Blockchain technology is the basis for Bitcoin, the most common cryptocurrency.
Blockchain technologies have become more popular with the potential to be a change.
Individuals and organizations may benefit from blockchain with its ability to securely share data and to make transactions easier.
We examine the factors that affect people's willingness to use blockchain-based cryptocurrencies.
We develop a model of cryptocurrency adoption based on a well-known psychological theory to: identify the determinants for the acceptance of cryptocurrency and look at how important each factor is.
We offer real-world evidence for a better understanding of cryptocurrency use in government systems.
Cryptocurrency was built initially as a possible implementation of digital currency, then various derivatives were created in a variety of fields such as financial transactions, capital management, and even nonmonetary applications.
This paper aims to offer analytical insights to help understand cryptocurrency by treating it as a financial asset.
We position cryptocurrency by comparing its dynamic characteristics with two traditional and massively adopted financial assets: foreign exchange and stock. Comparison: Cryptocurrency vs. Traditional Currencies
It suggests that the dynamics of cryptocurrency are more similar to stock.
Our analysis shows cryptocurrency market is more fragile than stock market, thus it is currently a high-risk financial market.
The smart device owning rate, including phones and watches is higher than ever before and mobile payment has become a major payment method in many areas.
At the same time, blockchain-based cryptocurrency is becoming a significant type of currency. The total value of all cryptocurrencies has reached $200 billion.
Therefore, it is a natural demand to support cryptocurrency payment on mobile devices.
Considering the poor infrastructure and low penetration of financial service in developing countries, this combination is especially attractive.
The high storage cost and delay in processing payments are the two main obstacles for mobile payment using cryptocurrency.
We propose two different schemes for cryptocurrency mobile payment, one uses a bank, the other does not.
We also provide a solution for the bank to meet money laundering regulations when it handles payments for crypto.
Motivated by recent financial crises significant research efforts have been put into studying contagion effects and herding behaviour in financial markets.
Much less has been said about influence of financial news on financial markets.
We propose a new way to measure financial news on the web, and show that it can be used to predict potential financial problems.
We evaluate the financial data from large news websites on a daily basis from October 2011 to July 2013 and analyse the interplay between financial markets and financially related news.
We hypothesized that strong relationship in financial news reflects movements in the financial markets.
Cohesiveness is more general and robust measure of systemic risk expressed in news, than measures based on simple occurrences of specific terms.
Financial news is closely linked to market volatility.
In this paper, I propose a methodology to study the movement between different financial markets.
The entropy is derived using singular value decomposition of the components of stock market indices in financial markets from selected developed economies, i.e., France, Germany, the United Kingdom, and the United States.
I study how a shock in the entropy in the United States affects the entropy in the other financial markets.
I also use a model to represent and understand changes in the markets. derive a common factor behind the entropy movements in these four markets.
Mobile devices are common in their life.
Nowadays such devices come with many features of a computer.
Hence people can use these devices for diverse applications. DC: For Everyone
As the acceptability and usability of such devices are very high, there are chances that these devices can be used for illegal activities.
Many mobile phones are used for cyber crime.
So it becomes necessary to analyze these devices using cyber forensics tools.
This paper discusses different types of digital evidence present in Microsoft’s Windows Mobile smart phones and an agent based approach for logically acquiring such devices.
Also it describes a tool developed for forensically acquiring and analyzing Windows Mobile devices and WinCE PDAs.
The increasing prevalence of Internet of Things (IoT) devices has made it inevitable that their relevance to digital forensic investigations will increase in the future.
These devices produced by various vendors often posses limited standard interfaces like USB and wireless connections.
With a growing focus on user data security and privacy, built-in encryption is becoming commonplace in consumer-level computing devices, and IoT devices are no exception.
Under these circumstances, a significant challenge is presented to digital forensic investigations of IoT devices.
This work explores the EM side-channel analysis literature for the purpose of assisting digital forensic investigations on IoT devices.
EM side-channel analysis is a technique where some signals can be used to spy on computer operations and data.
The non-intrusive nature of EM side-channel approaches makes it a viable option to assist digital forensic investigations as these attacks require, and must result in, no modification to the target device.
The literature on various EM side-channel analysis attack techniques are discussed – selected on the basis of their applicability in IoT device investigation scenarios.
The insight gained from the background study is used to identify promising future applications for digital forensic analysis on IoT devices – potentially expanding the scope of digital investigations.
The use of phone forensics to investigate scams is nothing new.
But mobile phones have evolved into smartphones, and fraudsters have evolved with them.
Smartphones are packed with functionality that can easily be used for unauthorized access or contact with other parties - none of which passes through the company's systems, and is to all intents and purposes outside of company control.
Employers need to be aware of these risks when devices are issued, along with ensuring that processes are in place when suspicions are raised, explains Philip Ridley of CCL-Forensics.
Detecting 'tech-savvy' corporate fraudsters is a constant game of catch-up.
It's not only about playing catch-up with the intellect, but also understanding of the online scammer. but also the technologies that can be misused.
These methods help scammers hide their activities - all while staying away from corporate networks where they can readily be monitored and detected.
This means a company's intellectual property and sensitive data is at risk of sabotage or just good old-fashioned theft.
Phishers alter the code of fake websites to look like real ones and avoid being detected.
Manipulations can be like code changes or removing significant content.
To appropriately respond to these changes to phishing campaigns, a team of algorithms designed to detect phishing websites based on their content, using a special database of over 17,000 phishing attacks targeting 159 different brands.
The results of the experiments using a variety of different content-based approaches demonstrate that they can achieve a detection rate of over 90% with few false alarms.
The focus of the early post-exercise period (i.e., 1–8 h) is to enhance physiological processes that help the body recover from exercise-induced disturbances and for promoting adaptations to training.
Recommended nutritional strategies to maximize recovery in skeletal muscle include protein to help repair muscle tissue for replenishing glycogen stores [2],[3].
Muscle contraction and the intake of leucine-rich protein sources activate independent but complimentary signaling responses that converge at the Key protein regulator (mTOR) to stimulate protein translation enhancing rates of muscle protein synthesis [4]–[6].
The ingestion of 20-25 grams of protein soon after exercise has been shown to maximise the anabolic response in skeletal muscle.
The cultural environment surrounding some sports often involves the intake of large amounts of alcohol after games and matches, with athletes in some team sports being particularly at risk of heavy drinking after games and matches.
The outcomes of binge drinking after exercise are likely to include the impact of alcohol on the body as well as the indirect effect on the athlete's recovery due to not eating or resting adequately as a result of intoxication.
Although consuming carbohydrates after drinking can partly counteract the negative effects of alcohol on muscle energy stores, the effect of alcohol consumption on muscle protein synthesis is unknown.
The aim of the current study was to determine the effect of alcohol intake on cell signaling and protein synthesis rates in humans during recovery from a bout of strenuous exercise approximating stresses an athlete may experience in training and performance for various team sports such as various football and rugby codes, and court sports.
We hypothesized that compared to after-exercise protein consumption, co-ingestion of alcohol would slow down protein production process and decrease rates of MPS.
Eight healthy physically active male subjects (age 21.4±4.8 yr, body mass (BM) 79.3±11.9 kg, peak oxygen uptake (VO2peak) 48.1±4.8 mL·kg−1·min−1, leg extension one repetition maximum (1RM) 104±20 kg; values are mean ± SD) who had been exercising regularly for more than 6 months for this study.
The study employed a randomized counter-balanced, cross-over design in which each subject completed bouts of consecutive resistance, continuous and intermittent high-intensity exercise with post-exercise drinks containing alcohol and carbs, alcohol and protein, or just protein on three separate occasions.
Resistance exercise consisted of eight sets of five repetitions at 80% strength.
After completion of the final set, subjects rested for 5 min before commencing 30 min of continuous cycling at ∼63% PPO (∼70% VO2peak).
Upon completion, subjects rested on the bike for 2 min before undertaking 10×30 s high intensity intervals at about 110% of their personal peak output, with 30 s active recovery (half their personal peak output) between each work bout.
Immediately following exercise and after 4 h recovery, subjects ingested a 500 mL drink containing either protein or a sugar-based energy source.
Furthermore, a high-carbohydrate meal, 1.5 grams per kilogram of body mass was consumed ∼2 h after exercise, immediately after the muscle biopsy, according to recommendations for post-exercise recovery.
The 8 h time frame represents an important phase of post-exercise recovery [1] as well as the period during which blood alcohol concentrations are likely to be elevated by a post-event drinking binge [14].
The alcohol ingestion protocol (15 calories per kilogram of body mass; 12 standard drinks) began 1 hour after exercise and was consumed in six equal volumes of 1 part vodka (∼60 mL) to four parts orange juice during a 3 h period.
For the condition, orange juice was consumed with the same amount of water without alcohol.
Subjects ingested the beverages within 5 min every 30 min.
Blood, cell signaling and mRNA data were analyzed by statistical analysis was done using a special method called ANOVA. Myofibrillar protein synthesis was analyzed by one-way ANOVA with repeated measures.
The first novel finding of this study was that mTOR signaling and rates of myofibrillar protein synthesis (MPS) following concurrent resistance, continuous and intermittent high-intensity exercise, designed to mimic the metabolic profile of many team sports, were impaired during the early (8 h) recovery phase by the ingestion of large amounts (1.5 g•kg−1 BM) of alcohol.
These outcomes were most evident (37% reduction in rates of MPS) when alcohol was consumed in the absence of post-exercise protein intake, as is likely to occur when intoxication reduces the athlete's compliance to sound recovery practices.
when protein was consumed in the optimal amount to stimulate muscle protein synthesis after exercise, the intake of alcohol reduced this effect by ∼24%, representing only a partial ‘rescue’ of the anabolic effect compared with protein alone.
The mechanistic target of rapamycin complex 1 (mTORC1) is a central node for integrating nutrient (i.e. amino acid) and exercise/contraction signal transduction [31], [32].
In conclusion, the current data provide the novel observation that alcohol impairs the response of MPS in exercise recovery in human muscle despite optimal nutrient provision.
The amount of alcohol consumed was based on amounts reported by athletes drink heavily.
Reports show that some people may consume more than others, which raises health and safety concerns.
Regrettably, there has been difficulty in finding an educational message with alcohol consumption related to sports performance that has meaningful to athletes.
Given the need to promote the process of muscle repair and growth the results of the current study provide clear evidence of impaired recovery when alcohol is consumed after various types of intense exercise, including resistance and high-intensity training, even in the presence of optimal nutritional conditions.
Our data is of interest to athletes and coaches.
Our findings provide evidence that moderate alcohol intake helps with recovery after exercise with the potential to alter current sports culture and athlete practices.
In this paper we revisit a topic originally discussed in the 1950s, namely the lack of direct evidence that muscle hypertrophy from exercise plays a key role in strength.
To this day, long-term adaptations in strength are caused by changes in muscle size.
Given this assumption, a lot of attention is given to programs that help build muscle size and strength.
However, the conclusion that muscle size affects strength is surprisingly based on little evidence.
We suggest that these changes may be completely separate phenomena based on: (1) the weak link between muscle size and strength gained from training; (2) the loss of muscle mass with detraining, yet a maintenance of muscle strength; and (3) the similar muscle growth between low-load and high-load resistance training, yet divergent results in strength.
Low-intensity occlusion (50-100 mm hg) training provides a unique beneficial training mode for promoting muscle hypertrophy.
Training at intensities as low as 20% intensity with moderate blood flow restriction results in muscle hypertrophy in as little as 3 weeks.
A typical exercise prescription calls for 3 to 5 sets to volitional fatigue with short rest periods.
The metabolic buildup causes positive physiologic reactions, specifically, a rise in growth hormone that's higher than with more intense exercise.
Occlusion training is applicable for those who are unable to sustain high loads due to joint pain, postoperative patients, cardiac rehabilitation, athletes who are unloading, and astronauts.
Exercise has little effect on muscle size.
We and others have demonstrated that Regular exercise affects how the body uses protein and leads to muscle growth.
These findings promote an antithesis to the status quo by providing novel perspective on skeletal muscle mass regulation and insight into exercise-countermeasures for populations prone to muscle loss.
Stretch training is widely used in a variety of fitness-related capacities such as increasing joint range of motion, preventing contractures and alleviating injuries.
Moreover, some researches indicate that stretch training may cause muscle growth; however, studies on the topic have been primarily relegated to animal and in vitro models.
The purpose of this brief review was to evaluate whether stretching helps build muscle.
Of the 10 studies identified, 3 observed some significantly positive effects of stretch training on muscle structure.
The stretching was done with equipment that helped the process, or with an external overload.
Of the 5 available studies that integrated stretching into a resistance training programme, 2 applied the stretching in the interset rest period and were the ones that showed enhanced muscle growth.
In conclusion, passive, low-intensity stretch does not appear to confer beneficial changes in muscle size and architecture; alternatively, albeit limited evidence suggests that when stretching is done with a certain degree of tensile strain (particularly when loaded or done between contractions) may elicit muscle hypertrophy.
Cycle training is widely performed as part of most exercise programs to improve cardiovascular health.
However, the effect of cycle training on muscle size and strength gain still requires further insight, it is known that professional cyclists have more muscle mass than non-athletes.
Therefore, the purpose of this review is to discuss the effects of cycle training on muscle size and the ways in which cycling can increase muscle size.
It is plausible that cycle training requires a longer period to significantly increase muscle size compared to typical resistance training due to a much slower hypertrophy rate.
Cycle training induces muscle hypertrophy similarly between young and older age groups, while strength gain seems to favor older adults. It appears that older adults have a better chance of improving muscle quality compared to young adults.
For young adults, higher-intensity intermittent cycling may be required to achieve strength gains.
It also appears that muscle protein balance induced by physical activity results from the changes in muscle protein.
Strength training is the most effective method to increase muscle mass.
It has been shown to promote good health.
Although it is deemed safe and of clinical relevance for treating and preventing a vast number of diseases, a time-efficient and minimal dose of exercise has been the focus of a great number of research studies.
Similarly, a U-shaped relationship between training dose/volume and physiological response has been hypothesized to exist.
However, the majority of the evidence supports a clear dose-response relationship between resistance training volume and physiological responses, such as muscle growth and overall health.
Additionally, there is a paucity of data to support the U-shaped response.
The overarching principle argued herein is that volume is the most easily modifiable variable that has the most based on evidence with important repercussions, be these muscle hypertrophy or health-related outcomes.
Although the effects of short versus long inter-set rest intervals in resistance training on measures of muscle hypertrophy have been investigated in several studies, the findings are equivocal and the practical implications remain unclear.
Training for muscle hypertrophy may be improved with short and long breaks between sets.
Novel findings involving trained participants using measures sensitive to detect changes in muscle hypertrophy suggest a possible advantage for the use of long rest intervals to elicit hypertrophic effects.
There is a lack of studies with similar designs, further research is needed to clear up the differences between these two approaches.
Memory is a process in which information is stored, and retrieved.
It is believed that it only occurs in the brain.
This review describes a cellular memory in the muscle in which muscle growth is remembered such that a fibre that has previously grown, but then lost its size, can regain mass faster than muscle fibres that have not grown before.
A new cell model based on the most reliable research, can explain this phenomenon.
According to this model, fibres recruit nuclei from satellite cells before hypertrophic growth.
Even if subsequently subjected to grave atrophy, the higher number of myonuclei is retained, and the myonuclei appear to be protected from cell death in muscle tissue that is wasting away.
Fibres with more nuclei grow faster when subjected to overload exercise, thus the nuclei represent a functionally important 'memory' of previous strength.
This memory might be very long lasting in humans, as myonuclei are stable for at least 15 years and might even be permanent.
Muscle cells in older people are harder to activate. If this long-lasting muscle memory also exists in humans, one should consider early strength training as a public health advice.
It has been hypothesized that eating small, frequent meals enhances fat loss and helps to achieve better weight maintenance.
Many studies have shown that eating less is linked to being thinner.
The purpose of this narrative review is to present and discuss a meta-analysis with regression that evaluated experimental research on meal frequency with respect to changes in fat mass and lean mass.
Eating more often helps you lose fat and build muscle.
However, sensitivity analysis of the data showed that the positive findings were the product of a single study, casting doubt as to whether more frequent meals confer beneficial effects on body composition.
In conclusion, although the initial results of this meta-analysis suggest a potential benefit of increased feeding frequencies for enhancing body composition, these findings need to be carefully considered.
Inactive adults experience a 5% loss of muscle mass per decade, accompanied by reduced metabolic rate and fat gain.
Ten weeks of resistance training may increase lean weight by 1.4 kg, increase resting metabolic rate by 7%, and reduce fat weight by 1.8 kg.
Benefits of resistance training include improved physical and mental abilities, including movement and thinking.
Resistance training may assist prevention and management of type 2 diabetes by losing belly fat, reducing HbA1c, increasing the density of glucose transporter type 4, and improving insulin sensitivity.
Resistance training may enhance cardiovascular health, by reducing resting blood pressure, lowering bad cholesterol and triglycerides, and increasing high-density lipoprotein cholesterol.
Resistance training may promote bone development, with studies showing 1% to 3% increase in bone mineral density.
Resistance training may be effective for reducing low back pain and easing discomfort associated with arthritis and fibromyalgia and has been shown to reverse muscle aging in skeletal muscle.
Physical activity has proved to be an effective means of preventing many diseases and improving general health.
Common sense advices call for late inception of intense, strength training-related activities, like weight lifting and plyometrics, which are usually postponed at the end of the growth age, even among sport practitioners.
However, such advices seem to have a mostly based on personal experience.
Current literature does not have any particular aversion against the practice of strength training by children and adolescents, provided that some safety guidelines are followed, such as a doctor's approval and proper instruction.
At the same time, multiple studies provide the findings supporting the benefits of regular exercise in young subjects.
Improved motor skills and body composition, in terms of increased fat free mass, reduced fat mass and enhanced bone health, have been extensively documented, especially if sport practice began early, when the subjects were pubescent.
It can be concluded that strength training is a safe and healthy practice for kids.
Human aging results in a variety of changes to skeletal muscle.
Sarcopenia is the age-associated loss of muscle mass and is one of the main contributors to musculoskeletal impairments in the elderly.
Previous research has demonstrated that resistance training can attenuate skeletal muscle function deficits in older adults, however few articles have focused on the effects of resistance training on functional mobility.
The purpose of this systematic review was to 1) present the current state of literature regarding the effects of resistance training on functional mobility outcomes for older adults with skeletal muscle function deficits and 2) provide clinicians with practical guidelines that can be used with seniors during resistance training, or to encourage exercise.
We set forth evidence that resistance training can ease age-related mobility decline, including improvements in gait speed, static and dynamic balance, and fall risk reduction.
Older adults should be encouraged to participate in regular exercise, such as weightlifting, and should be admonished to move along a continuum of exercise from immobility, toward the recommended daily amounts of activity.
Maximizing the hypertrophic response to resistance training (RT) is thought to be best achieved by proper manipulation of exercise program variables including exercise selection, exercise order, length of rest intervals, intensity of maximal load, and training volume.
An often overlooked a factor that affects muscle growth is repetition duration.
Duration amounts to the sum total of the concentric, eccentric, and isometric components of a repetition, and is predicated on the tempo at which the repetition is performed.
We conducted a review of existing studies and data analysis to determine whether alterations in repetition duration can amplify the hypertrophic response to RT.
Results indicate that muscle growth outcomes are similar when training with varying repetition durations.
From a practical standpoint it would seem that a fairly wide range of repetition durations can be employed if the primary goal is to maximize muscle growth.
Findings suggest that training at very slow durations (more than 10 seconds per repetition) is inferior from a hypertrophy standpoint, although a lack of studies on the topic makes it hard to draw firm conclusions.
Recovery from exercise refers to the time period between the end of a bout of exercise and the subsequent return to a resting or recovered state.
It also refers to changes in the body after exercise that are different from both exercise and rest.
In this context, recovery of the cardiovascular system after exercise occurs across a period of minutes to hours, during which many characteristics of the system change over time.
Some of these changes may be necessary for long-term changes from exercise, yet some can lead to cardiovascular instability during recovery.
Furthermore, some of these changes may provide insight into when the heart has recovered from its last workout and is physiologically prepared for more exercise.
This review focuses on the most consistently observed hemodynamic adjustments and the underlying causes that drive cardiovascular recovery and will highlight how they differ following resistance and aerobic exercise.
Primary emphasis will be placed on the hypotensive effect of aerobic and resistance exercise and mechanisms that can lead to symptoms like dizziness and fainting.
Finally, we focus on the practical application to maximize the benefits of cardiovascular recovery and minimize its risks.
We will explore ways to measure an athlete's progress and see how these can help them improve their training.
Exercise and physical activity are increasingly becoming key tools in the treatment and cure of many health problems including arthritis and diabetes; this notion has been termed "Exercise as a treatment".
Exercise has favorable effects on reducing cardiovascular risk, inflammation, cachexia, and hypertension, in addition to increasing physical functioning, strength, and lung function.
Chronic kidney disease, a condition that affects around 10% of the population, is often overlooked as a target for exercise-based therapy.
Despite the wide variety of kidney disease stages (e.g., before, during, and after treatment), exercise has a potential role in all patients suffering from the condition.
In this review, we summarise the important role exercise may have in the clinical management of kidney disease and how this form of 'medicine' should be best administered and 'prescribed'.
Blood flow restriction helps to increase strength in healthy people.
However, its effects on pain and function in individuals with knee pain are unknown.
Objective: To determine the effectiveness of adding BFR to resistance exercise for pain relief and improvement of function in patients with knee pain.
Methods: Systematic review with meta-analysis of randomized clinical trials.
Studies that compared exercise with or without blood flow restriction to treat knee pain and function in individuals older than 18 years of age with knee pain were included.
The pooled effect size estimate showed that resistance exercises with BFR was not more effective than resistance exercises for reducing pain (effect size: -0.37, 95% confidence interval: -0.93 to 0.19 points) and improving knee function (effect size: -0.23 points, 95% confidence interval: -0.71, 0.26) in patients with knee pain.
In Japan, there were an estimated 43 million patients with hypertension in 2010.
This condition is a top priority to manage, Lifestyle changes have been recognized as a key part of treating hypertension in Japan.
In particular, emphasis has been placed on increasing the levels of activities of daily living and physical exercise (sports).
In this literature review, we examined appropriate exercise prescriptions (e.g., type, intensity, and duration) for the prevention and treatment of hypertension in different languages and cultures.
This review recommends safe and effective whole-body aerobic exercise at moderate intensity (i.e., 50-65% of maximum physical ability, 30-60 minutes per session, 3 times a week) that primarily focuses on the major muscle groups for the prevention and treatment of hypertension.
Resistance exercise should be performed at low intensity without breath-holding and should be used as supplementary exercise, but resistance exercise is contraindicated in patients who have chest pain.
recently, there has been a public interest in iFast
Given the importance of nutrition in optimizing athletic performance, there is a concern about the effects of IFast on athletics.
Looking at intensive exercise, studies have been varied but are uniform in showing that there is no benefit to athletic performance while fasting.
Nearly every physically active person encounters periods in which the time available for exercise is limited (e.g., personal, family, or business conflicts).
During certain periods, the goal of training is to maintain performance.
Similarly, certain special populations may desire to maintain performance for prolonged periods, namely athletes during their active periods and military personnel (during deployment).
In general populations, endurance performance can be maintained for up to 15 weeks when training frequency is reduced to as little as 2 sessions per week or when exercise volume is reduced by 33–66% (as low as 13–26 minutes per session), as long as exercise intensity (exercising heart rate) is maintained.
Strength and muscle size (at least in younger populations) can be maintained for up to 32 weeks with as little as 1 session of strength training per week and 1 set per exercise, as long as exercise intensity (relative load) is maintained; whereas, in older populations, maintaining muscle size may require more frequent exercise, such as 2 sessions per week and more sets per exercise.
Our primary conclusion is that exercise intensity seems to be the key variable for maintaining physical performance over time, despite significant decreases in exercise frequency.
Nutrient timing is a popular nutritional strategy that involves the consumption of combinations of nutrients--primarily protein and carbohydrate--in and around an exercise session.
Some have claimed that this approach can produce dramatic improvements in body composition.
It has even been suggested that Eating timing may be more important than the amount of nutrients.
The post-exercise period is widely considered the most critical part of nutrient timing.
Theoretically, consuming the proper ratio of nutrients during this time not only initiates the rebuilding of damaged muscle tissue and restoration of energy reserves, but it does so in a supercompensated fashion that enhances both body composition and exercise performance.
Several researchers have made reference to an optimal training period whereby a limited time exists after training to optimize muscle growth.
However, the importance - and even the existence - of a post-exercise ‘window’ can vary due to several factors.
Not only is research on when to consume nutrients is unclear, but recent evidence has directly challenged the traditional idea of how exercise affects the way our bodies use nutrients.
Lack of time is among the most common reasons for not exercising.
The aim of this review was to determine how strength training can be most effectively carried out in a time-efficient manner by evaluating research on short-term training, specialized training methods, and the need for warming up and stretching.
When programming strength training for optimum time-efficiency we recommend prioritizing exercises that include full dynamic movements. To do this, perform a minimum of one leg exercise (e.g. squats), one upper-body pulling exercise (e.g. pull-up) and one upper-body pushing exercise (e.g. bench press).
Exercises can be performed with machines and/or free weights based on training goals, availability, and personal preferences.
Weekly training volume is more important than training frequency and we recommend performing a minimum of 4 weekly sets per muscle group using a weight range of 6-15.
Advanced training techniques, such as combining sets and short rests roughly halves training time compared to traditional training, while maintaining training volume.
However, these methods are probably better at inducing hypertrophy than muscular strength, and more research is needed on long-term training effects.
Finally, we advise restricting the warm-up to exercise-specific warm-ups, and only prioritize stretching if you're trying to improve flexibility.
Training frequency is considered an important variable in the hypertrophic response to weight training.
The purpose of this paper was to conduct a systematic review and meta-analysis of experimental studies designed to investigate the effects of weekly training frequency on hypertrophic adaptations.
Results showed no significant difference between higher and lower frequency on a volume basis.
Meta-regression analysis of unequal volume studies showed a significant effect favoring higher frequencies, although the overall difference in magnitude of effect between frequencies of 1 and 3+ days per week was modest.
In conclusion, strong evidence shows that frequency of resistance training does not affect muscle growth when the volume of training is the same.
Thus, for a given training volume, individuals can choose a weekly frequency per muscle based on personal preference.
A variety of various training methods have been advocated as a means to heighten muscle growth.
Specific types of weightlifting routines, such as forced reps and supersets, can help build muscle.
This article will explore the potential role of these techniques in promoting muscle hypertrophy and provide an insight into possible applications to resistance training programs.
The quest to increase lean body mass is widely pursued by those who lift weights.
Research is lacking, however, what is the best way to maximize muscle growth through exercise.
Bodybuilders generally train with moderate loads and fairly short rest intervals that induce high amounts of metabolic stress.
Powerlifters, on the other hand, routinely train with high loads and regular breaks between sets.
Although both groups show impressive muscle development, it's unclear which method is best for muscle growth.
It has been shown that many factors mediate the hypertrophic process and that tension, damage, and stress caused by exercise contribute to muscle growth.
Therefore, the purpose of this paper is twofold: (a) to extensively review the literature as to muscle growth and (b) to draw conclusions from the research as to the optimal protocol for maximizing muscle growth.
New technology in mobile devices can help with wildfires, making it easier to share information and coordinate efforts. enabling end-users to easily conduct several everyday tasks, such as access to data and information, sharing of intelligence and coordination of personnel and vehicles.
This work describes an innovative mobile application for wildfire information management that operates on Windows Phone devices and acts as a complementary tool to the web-based version of the AEGIS platform for wildfire prevention and management.
Several tasks can be accomplished from the AEGIS App, such as routing, spatial search for closest facilities and firefighting support infrastructures, access to weather data and visualizing fire management data, including water sources and emergency stations.
An innovative feature of AEGIS App is the support of these tasks by a digital assistant for artificial intelligence named Cortana (developed by Microsoft for Windows Phone devices), that allows voice commands.
The application is to be used by firefighting personnel in Greece and is potentially expected to contribute to more efficient information sharing between wildfire confrontation operation centers and firefighting units in the field.
In recent years, mobile technologies have developed and applied in education fields, and some mobile devices include smartphones, PDAs, and e-books.
Some of the mobile carriers combines context-aware technologies or involve into wireless network environments to make effective use through the combination of learning scenarios and technologies, and then provide students new learning experiences differed from the past learning.
In view of the application of mobile technology in education, some previous studies have addressed that mobile learning is a meaningful way to learn that can improve the interaction between students and the situations and reach the purposes of learning.
In the main stream of mobile learning, using mobile carriers with suitable learning methods or strategies in mobile learning activities for different students to enhance learning have gradually become a important and concern issue.
The purpose of this study is to investigate the learning achievement and learning attitude of elementary school students on a school garden project when they use mobile carriers and competitive learning strategies.
The experimental results show that the competitive learning group of students have better learning performance.
After completing the learning activity, the two groups of students presented high positive attitudes towards learning.
This paper proposes an electrophysiological wireless patient monitoring system which integrates a Wireless ECG signal transmitter, GPS device and a mobile phone to acquire physiological signals and transmit them to a local server via Bluetooth wireless technology.
This paper proposes an electrophysiological wireless patient monitoring system which integrates a small device that captures heart signals, GPS information and sends it to a nearby computer using a wireless connection.
Four kinds of monitor units were specially designed for a wireless communication, including a control center, a local monitor unit, mobile devices (PDA) for both patients and doctors, and a website for both patients and doctors.
Four kinds of monitor units were specially designed for a wireless communication, including a control center , a local monitor unit, mobile devices (personal digital assistant; PDA), and a Web page (for both patient and doctor).
The use of various monitor units is created to meet the needs of different medical staff.
The use of various monitor units is created to meet the needs of medical staff.
This application was developed to promote the mobility and flexibility for the patients and also for the medical personnel, which further will improve health care and patient's lifestyle.
This application was developed to improve mobility for the patients, which further will improve both the quality of health care and lifestyle of the patient.
As various kinds of output devices emerged, such as highresolution printers or a display of PDA(Personal Digital Assistant), the importance of high-quality resolution conversion has been increasing.
As various output devices emerged, such as high-resolution printers and PDAs, the importance of high-quality resolution conversion has been increasing.
This paper proposes a new way for making images bigger.
This paper proposes a new method for enlarging image with high quality.
One of the main problem in images is the exaggeration of the jaggy edges.
One of the largest problems on image enlargement is the distortion of jaggy edges.
To remedy this problem, we propose a new interpolation method, which uses a machine learning algorithm to find the best values for the missing pixels.
To remedy this problem, we propose a new interpolation method, which uses a computer algorithm to find the best pixels to fill in.
The test results are shown and evaluated.
The experimental results are shown and evaluated.
Our methods are compared to standard methods.
Our methods are compared to the conventional methods.
A significative percentage of the human population suffer from impairments in their capacity to distinguish or even see colours.
A significative percentage of the human population have trouble seeing or distinguishing colors.
For them, everyday tasks like navigating a train map becomes demanding.
For them, everyday tasks like navigating through a train or metro network map becomes demanding.
We present a new way to extract colors from everyday objects and presenting it to visually impaired users as pleasant, non-invasive sound.
We present a novel technique for getting color from everyday objects and presenting it to visually impaired users as pleasant, non-invasive sound.
This technique was implemented inside a Digital Assistant device.
In this implementation, colour information is extracted from the input image and categorised according to how people see colour.
In this implementation, colour information is extracted from the input image and categorised based on how people perceive colours.
This information is converted into sound and sent to the user via speakers or headphones.
In the original implementation, it is possible for the user to send its feedback to reconfigure the system, however several features such as these were not implemented because the current technology is limited. We are confident that the full implementation will be possible soon as technology improves.
In the original implementation, it is possible for the user to send its feedback to reconfigure the system, however several features such as these were not implemented because the current technology is limited. We are confident that the full implementation will be possible soon as PDA technology improves.
Medicine abuse causes hospital admissions for seniors.
Abuse of medicines increases the risk of hospital admissions for the elderly.
Not only does this lead to unnecessary suffering for the patients but also incurs a great financial cost to the society.
This lead to suffering for patients but also incurs a great financial cost to the society.
A medicine decision support system in a Digital assistant, with a barcode reader, can provide an overview of the patients' complete medicine use, and detect unsuitable drugs and drug combinations.
Focusing on the elderly, our aim was to evaluate if a mobile health decision support system is useful and user-friendly for nurses in home care.
Focusing on the elderly, our aim was to evaluate if a medicine support system that uses a barcode reader is useful and user-friendly for nurses in home care.
The participants received a comprehensive overview from the patients' medicine and noted potential drug interactions and warnings for elderly patients.
The participants received a comprehensive overview from the patients' medication and noted drug interactions, therapeutic duplications and warnings for drugs unsuitable for elderly people.
The nurses regarded that the decision support system increased prevention and safety, was useful and user-friendly.
The nurses regarded that the computer system made safety better, was useful and user-friendly.
Our findings suggest that most of the content and functions were regarded as important.
Our findings suggest that most of the content were regarded as important.
This decision support system might be useful for nurses.
 :[0],"access to patient appointment schedules can help clinicians manage time and problems better.
 :[0],"access to patient appointment schedules can help clinicians manage time and problems better.
Many large health care organizations manage clinical appointment scheduling via computer systems that are hard for doctors to use.
Many large health care organizations manage clinical appointment scheduling via enterprise resource scheduling systems which are poorly accessible by clinicians.
Also, staff other than the doctor's assistant may manage scheduling, It's hard for clinicians to keep up with changes.
staff other than their own staff making it difficult for clinicians to stay informed of changes.
Many a clinician today uses a digital assistant.
Many clinicians use an assistant
Our "PalmOversite" project demonstrates the feasibility of making schedule information more accessible to clinicians.
Our "Palm Calendar Project" demonstrates the feasibility of integrating enterprise appointment schedule information into a PDA calendar, making schedule information much more readily available to the clinician.
Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of drug-resistant tuberculosis patients in Peru, in conjunction with the National TB Program.
Partners In Health (PIH) and its sister organization in Lima, Peru, Socios En Salud (SES), treat a majority of drug-resistant tuberculosis (TB) patients in Peru, in conjunction with the Peruvian TB program.
Monthly bacteriology tests, which must be collected from health establishments located across this major city, are an integral part of this treatment.
Monthly bacteriology tests, which must be collected from health facilities across the city, are an integral part of this treatment.
A health official visits each health establishment to collect and enter the information into a computer system this paper, we describe the development and implementation of a personal digital assistant (PDA)-based electronic system to collect, verify and upload monthly bacteriology data into the PIH-EMR.
Currently, a health worker visits each clinic to collect and enter medical data into a digital system, we describe the development and implementation of a personal digital assistant (PDA)-based electronic system to collect, verify and upload monthly bacteriology data into the PIH-EMR.
After an initial implementation period, we performed a pilot study to test the use of this system.
After an initial implementation period, we performed a pilot study to test the use of this system.
We completed a baseline assessment in two health districts and then switched to an electronic system in one of the districts while the control site continued to use the paper-based system during the same period.
We completed a baseline assessment in two health districts and then implemented the electronic system in one of the districts while the control site continued to use the paper-based system during the same period.
The PDA-based system had a processing time of 6.2 days, significantly lower than measurements for both the baseline [54.8] and control sites [64.4] (less than 0.0001).
The PDA-based system had a processing time of 6.2 days, the baseline and control sites had much higher times.
It was also able to reduce the discrepancy by 8.3% and receive positive feedback from the users.
It was also able to reduce the frequency of errors from 10.1% to 2.8% and receive positive feedback from the users.
Finally, the system’s cost would be recuperated in three months from time savings due to increased work efficiency.
This system will be studied to understand its effects on delays and costs.
In order to provide methods and tools for doing so, facilitate knowledge transfer between different types of experts, and to promote interdisciplinary communication.
In order to transfer knowledge between experts and non-experts, and to promote sharing between different groups, there is a need to provide methods and tools for doing so.
A team of researchers developed and tested a tool on a digital assistant for when patients have chest pain.
This interdisciplinary research team developed and evaluated a decision support tool (DST) on a personal digital assistant (PDA) for cardiac tele-triage/tele-consultation when the presenting problem was chest pain.
Human factors methods, including cognitive analysis, were used in the design process to develop the DST.
A pilot clinical trial was conducted at a specialized cardiac care hospital over three months.
During this time, nine nurses who work 24/7 to provide emergency consultations.
This clinical trial validated the design and demonstrated its usefulness to advanced cardiac care nurses, its potential for use by less experienced nurses, and for its potential use in an interdisciplinary team environment.
This clinical trial validated the design and demonstrated its usefulness to advanced cardiac care nurses, its potential for use by nurses less experienced in cardiac care, and for its potential use in a team of healthcare professionals.
This paper presents M-CALL, a computer-assisted language learning tool.
Since conventional computer-assisted language learning is often boring, it uses a game to increase the learner’s interest.
M-CALL runs on a personal digital assistant with public internet connection for learning on-the-go.
M-CALL runs on a personal computer with Wi-Fi for mobile learning.
It grows a cyber pet by solving problems of Korean language learning.
Korean language proficiency test, a certified
It consists of cyber pet game, learning software for mobile devices, learning system for mobile devices, and mobile tutoring.
It provides various functions for Korean language learning.
Currently, the prototype M-CALL was designed and partly implemented between mobile PDA and personal computer.
This study compared text entry performance of two types of keyboards for handheld devices: the QWERTY and the T9.
People transcribed text on a computer screen into a personal digital assistant (PDA) using a stylus and one of these two keyboards.
Participants transcribed text presented on a computer screen into a computer assistant using a stylus and one of these two keyboards.
We introduced a new psychophysical technique for measuring transcription rate that provides a measure of both speed and accuracy.
We introduced a new psychophysical technique for measuring transcription rate that provides a composite measure of speed and accuracy.
Using this technique, we calculated the maximum transcription rate for each keyboard.
The results show that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9 keyboard's better design.
The results show that transcription rates were higher for the QWERTY keyboard than for the T9, despite the T9 keyboard's design advantages.
An ancillary experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in visual scanning time due to visual arrangement of the letters on the keys.
An ancillary experiment demonstrated that the poorer performance of the T9 layout may have resulted from an increase in scanning time due to the layout of the keys.
Together these findings imply that the QWERTY keyboard layout remains the most effective of the currently available designs for stylus tapping on soft keyboards.
These results show the outcome that the keyboard remains the most effective of the currently available designs for stylus tapping on soft keyboards.
The growth of mobile phones and similar devices opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system).
The proliferation of mobile devices such as smart phones and Personal Digital Assistant (PDA) opens new ways for developing mobile E-commerce systems (so called Mobile-commerce or M-commerce system).
In E-commerce systems, we still see many common components that we have in standard E-commerce applications, such as web servers and database servers.
In E-commerce systems, we still see many standard components used in E-commerce, such as web servers and database servers.
These new applications raise some unique challenges.
For example, the limitations of mobile devices (e.g., small screen size and reduced CPU performance) implies that software development is partly different from desktop applications.
Questions which are posed when designing M-commerce system include: “What kind of information do users want to access on their mobile devices?”, “How can we provide useful applications with limited user input facility?”, “How can we test a M-commerce system?” In this paper, we discuss about some software development issues for mobile commerce systems from our experience developing a tourist M-commerce system.
Our prototype, easyHotel, is an useful software that allows booking hotel rooms on mobile phones.
It is widely acknowledged that information such as web content should be adapted for mobile platforms to account for restrictions in mobile environments.
Various mobile platforms such as digital assistants tend to vary largely in their capabilities, we suggest that adaptation should be platform-specific.
Common approaches for content adaptation are automated conversion and explicit specification of adapted content, with a balance between quality and cost.
We propose a simple object-oriented framework for content adaptation. avoiding the trade-off
As alternative avoiding the trade-off, we propose a simple object-based framework for content adaptation.
To facilitate the use of this framework in the Web, we base our approach on the Web Composition model and its XML-based implementation WCML.
We apply an example application using an object-oriented approach reduces development and maintenance effort to demonstrate how object-oriented specification of platform-adapted content reduces development/maintenance effort.
We apply our object-oriented approach to an example application to show how object-oriented design makes content easier to maintain reduces development/maintenance effort.
In monitoring a patientu0027s real-time vital signs through Body Area Networks (BAN), rich data sources are communicated to medical practitioners.
It is essential that data is delivered on time
In this paper a system is designed for patients with cardiac disorders, with a focus on the sensing device and communication.
In this paper a system is designed for patients with cardiac disorders, with an emphasis on the device and the system
Several existing wearable physiological devices (Patient Sensing Device — PSD) used in the Healthcare systems are bulky in design and are not flexible and comfortable for the elderly patients.
Several existing wearable physiological devices used in the healthcare system are bulky in design and are flexible or comfortable for the elderly patients.
Presented is a unique flexible, as well as detachable PSD for the comfort of patients.
Also discussed is a system for storing and managing patient data, which ensures periodic logging of patient data without saturating communication networks.
Also discussed is a system for handling patient data, which ensures periodic logging of patient data without saturating communication networks.
A proof of concept prototype has been developed and implemented to enable transmission of heart signal and body temperature of a patient, which can be expanded to include other vital signs.
A working prototype has been developed and implemented to enable transmission of heart signals and body temperature of a patient, which can be expanded to include other health metrics.
Communication between a mobile smart-phone and the ECG device is implemented Bluetooth.
Communication between a mobile smart-phone and the ECG and temperature device is implemented Bluetooth.
The presented Data Management System — Periodic Model (DMS — PM) is designed to manage wireless interface of sensor units with the patient database at a Medical Service Provider (MSP) through a Personal Digital Assistant (PDA) or a Smart phone making use of the existing GSM network.
Advancement of wireless and mobile technology has enabled additional platforms to support learning in a single learning space.
This has made possible new platforms to support learning in one learning space.
Current trend integrates usage of mobile devices in a learning system.
Current trend integrates usage of mobile terminals such as smart PDA (personal digital assistant) in a learning system.
Such devices can communicate with wireless mobile terminal and exchange information with its surroundings
A LOCH (Language Learning Outside the Classroom) system named One Day Trip is developed to assist overseas students to learn Japanese in real life situations with the help of a PDA.
This paper proposes using knowledge management tools in the system to help the teacher and students.
In recent years, we have developed applications for teaching both wired and wireless networks.
These applications have been written for the Cybiko personal digital assistant, an inexpensive alternative to other hardware.
Unfortunately, the Cybiko PDA was recently discontinued.
As a result, these applications had to be ported to other platforms to remain useful.
Instead of porting each application to individual platforms, which would be very time-consuming due to other network complexities, we created the Vassar College Messaging Layer.
This layer abstracts the Cybiko networking structure and interface, allowing Cybiko applications to be ported to other devices with minimal changes.
Unlike many other classes of hardware, smartcards do not have the ability to communicate securely with the user.
Lacking a way to inform the owner, the positive properties of smartcards are difficult to utilize.
We explore the area at the border between smartcards and more powerful machines.
On the other side of this border we find the Personal Digital Assistant, our view, to be useful as an extension of the usersu0027 private sphere, a machine must have the necessary functionality to create trustworthy digital signatures for the user.
On the other side of this border we find the Personal Digital Assistant  :[66],"our view, to be useful as an extension of the usersu0027 private sphere, a machine must at least have enough functionality and resources to create trustworthy digital signatures (to speak for the user, as it were).
A less resourceful machine can merely act as a memory prothesis, helping the owner remembering addresses and phone  are :[121],"designed to be tamper resistant, and as such they seem ideal as a minimal machine.
Trustworthy digital signatures can't be created by smartcards alone; they need external support. a smartcard must be supported by external infrastructure outside the card proper.
Smartcards alone cannot create trustworthy digital signatures, because the user doesn't know what information is given to the card. A smartcard must be supported by some infrastructure outside the card proper.
We explore what must be included in such an infrastructure, and demonstrate that trustworthy digital signatures can in fact be made using a standard :[211],"argue that based on this fact, systems can be built using cards; a smartcard system is advanced.
Asserting that a smartcard can act as a trusted machine gives new opportunities for designers of user-centric devices. that smartcards are :[257], finding ways to use them constructively is a good idea.
In this paper we present the main features of a system that we have developed and that provides a new kind of remote assistance service to elderly people.apart from the functionalities offered by the current remote assistance services, also provides a high quality, anywhere and at any time assistance.
In this paper we present the main features of a system that we have developed and that provides a new kind of tele-assistance service to elderly people. Instead of the current tele-assistance services, it also provides assistance.
We rate the assistance as high quality because allows monitoring of vital signs and alerts for unusual situations using a personal device.
We rate the assistance as high quality because allows the monitoring of vital signs and a quick detection of unusual situations by the device that the person carries in real time.
explain the three main functionalities offered by AINGERU: universal assistance anywhere and at any time, monitoring of vital signs regardless of where you are or when and remote monitoring by allowing authorized external persons to consult data about monitored persons using the Internet.
Therefore, it sends alarms autonomously when  this paper we :[84],"explain the three main functionalities offered by AINGERU: universal assistance anywhere and at any time, monitoring of vital signs irrespective of location or time and remote monitoring by allowing authorized external persons to consult data about monitored persons using the Internet.
Moreover we show how those functionalities are achieved by making use of Personal digital assistants, wireless communication, Semantic Web technologies and Internet services.
To evaluate the effectiveness of a computer-based medical advisor on anti-inflammatory drug prescribing safety in the outpatient :The design was a study conducted in a university clinic.
To evaluate the effectiveness of a personal digital assistant (PDA)-based clinical decision support system (CDSS) on nonsteroidal anti-inflammatory drug (NSAID) prescribing safety in the outpatient, The study was a controlled trial conducted in a university clinic.
Internal medicine residents received a PDA-based CDSS suite.
Internal medicine residents received a mobile-based CDSS.
For intervention residents, the Decision Support System included a prediction for NSAID-related gastrointestinal risk assessment and treatment recommendations.
For intervention residents, the CDSS included a prediction rule for NSAID-related gastrointestinal risk assessment and treatment recommendations.
unannounced actors playing patient roles presented to study physicians to portray muscle and skeletal problems.
Safety outcomes were assessed from prescriptions for them.
Safety outcomes were assessed from the medication to the study participants.
Each prescription was reviewed by a panel of doctors without knowing which group the participants belonged to :[108],"Prescriptions were judged as safe or unsafe.
Each prescription was reviewed by a committee of clinicians blinded to participant details, treatment group, and initial data. Prescriptions were judged as safe or unsafe.
The main outcome measure was the differential change in unsafe prescribing of NSAIDs for the intervention versus the control At baseline, the rate of unsafe prescriptions was similar for both groups (27% vs. 29%).
The main outcome measure was the change in unsafe prescribing of NSAIDs for the intervention versus the control. The proportion of unsafe prescriptions was similar in both groups.
Controlling for baseline performance, intervention participants prescribed more safely than controls after receiving the CDSS (A 0.23 vs 0.45 difference, p-value is less than 0.05).
Controlling for baseline performance, intervention participants prescribed more safely than controls after receiving the CDSS. There was a 0.23 vs. 0.45 difference, indicating a significant result (p < 0.05).
With the CDSS, participants documented a more thorough assessment of patient risk from their gastrointestinal health. Participants provided with a PDA-based CDSS for NSAID prescribing made fewer unsafe treatment decisions than participants without the CDSS.
Recently pedestrian navigation has been studied, is similar to car navigation
On the other hand, a 3D map, used in various fields, including city planning, has been utilized as a simulation tool in other engineering fields.
3D maps provide a clearer picture compared to conventional 2-dimensional (2D) ones.
In this paper we first propose navigation for pedestrians using 3D maps, and describe required technologies and its use cases.
Secondly we compare effectiveness of 2D and 3D maps for navigation by object search experiments under conditions: 3D maps with and without texture; display sizes corresponding to mobile phones and PDAs.
The experimental results show that 3D maps on phone and 3D maps on smaller devices are superior to 2D maps in search time and error rate.
From these results, we can say the effectiveness of 3D maps for walking directions.
Mobile agents are a competitive concept of client-server computing and are especially suitable in mobile situations, with limited and unreliable internet connections.
They can be used for information retrieval and information filtering, in which case they evaluate and return relevant data.
Mobile agents as active objects are created on a mobile device such as a Personal Digital Assistant (PDA), will be launched into the information network and are fulfilling the user 's task on the services available on stationary systems.
One transmission channel for these traveling workers is email.
This paper introduces Active M 3 as an example of an active mail framework, which can be regarded as a first approach in writing mobile agents in an interactive way.
Active M 3 integrates two known concepts: active mail and multimedia mail.
Digital Video Broadcasting — Handheld (DVB-H) is a technology developed as an extension of Digital Video Broadcasting — Terrestrial (DVB-T) with additional features that make it suitable for delivery to mobile devices such as phones and Personal Digital Assistant (PDAs).
This paper deals with the conditions of receiving digital TV broadcasting in mobile handheld devices.
DVB-H is introduced and the key technology elements on physical and data layers are discussed.
Finally the terminal and network design is described.
Summary form only given, as follows.
We present a design for a low cost, powerful and high speed device powered by IDTu0027s RV4640 as its processing engine.
The device can achieve high speed, thanks to the PCI bus compatible IDT ATM NIC.
The device could be used as a set-top box, the internet, a personal digital assistant or a video phone.
The RV4640 is a very affordable 64 bit RISC processor that executes 133 MHz processor speed.
The RV4640 can be connected to a System Interface Chip which will provide I/O and memory control.
The IDT77903 is a 25 Mbps network card with a PCI bus interface and it costs less than $100 (US).
Integrating this card into our device as a network interface will make videoconferencing and multimedia applications easily implementable.
Dr. Who is a Microsoft research project aiming at creating a voice-controlled system, which serves as the foundation for a voice-controlled interface.
The paper discusses MiPadu0027s design, implementation work in progress, and preliminary user study in comparison to the existing pen-based PDA interface.
MiPad is the application prototype that demonstrates compelling user advantages for wireless personal digital assistant (PDA) devices, MiPad combines speech recognition and natural language understanding to enable users to accomplish many common tasks using a multimodal interface and wireless technologies.
It tries to solve the problem of pecking with tiny styluses or typing on minuscule keyboards in todayu0027s PDAs.
Unlike a cellular phone, MiPad avoids speech-only interaction.
It incorporates a built-in microphone that activates whenever a field is selected.
As a user taps the screen or uses a built in roller to navigate, the tapping action limits the options for spoken word understanding.
MiPad currently runs on a Windows device with a computer.
The Dr Who CSR engine uses a unified CFG and n-gram language model.
The Dr Who SLU engine is based on a parser and a dialog manager.
Little is known about new mobile applications emerge in commercial environments.
Research in the sociology of technology suggests that the evolution of new applications is a process of social interaction that defines mobile technology issues and solutions in hindsight.
This theory is illustrated by the early evolution of the personal digital assistant (PDA).
Technology leaders try to define the problems and solutions for new mobile technology, thereby forcing newer players to provide a "total system" that completely redefines a new application area.
In the common environment, mobile terminals like personal digital assistant or cellular phone are used to access the Web.
We implemented the procedures in a ubiquitous/universal passive viewer (u-PaV) system that transforms Web content into passive viewing content that is especially useful for mobile terminals.
extracting images and text from Web content generates a Macromedia Flash file, which is a popular multimedia format.
The appearance of Web content depends on the device type. The Web interface of mobile terminals is designed almost the same as that of personal computers.
Comparing mobile and desktop terminals, some difference in device characteristics, such as screen size or sound quality, affect the presentation on the terminal.
Moreover, when changing the access style between interactive and passive, the presentation should be adjusted for the terminal type because the lacking information is usually not perceived after transformation.
To adjust the play style of Web content to the terminal type, We created a way to display content on the screen.
First, using natural language processing techniques, show the emotional effect of a web page by changing the color.
Second, we emphasize the subject of the content by the logotype of the keyword.
We segment the picture into pieces. Break the picture into smaller parts
These procedures can be applied to any type of terminal.
We have developed a location-aware system, named as “The Beijing Explorer”, which exchanged positioning information and users’ situation to one another using a PDA (Personal Digital Assistant) with built-in wireless LAN and a GPS (Global Positioning System) receiver in real time.
Users can see their position and their chats on the screen of a PDA using the system real-timely.
The system was used for the guidance of the Palace Museum in Beijing.
We carried on experiments two times using the system.
The results of experiments show that the service using positioning data and sharing contents were valuable and interesting.
The correct positioning information is important for the guidance system.
A truly unique machine, called a private machine and implemented as a Personal Digital Assistant (PDA), is fundamentally different from traditional machines.
It is personal and private in a way that's never been seen before, and its operation is prone to frequent failures.
Designing systems that treat PDAs as important devices. assets (electronic money, keys for authentication and opening doors) will be stored in PDAs.
Ownership and control of these assets and the media that hold them should remain with the user.
This must be reflected in the design of systems for private  :[105],"introduce the "open-ended argument" to describe the design strategy we used for designing a system that is designed to reveal information to the user (as opposed to hide it).
We argue and show that when systems are designed for user control, the user (a human) is better able to control the system and his personal data, as he can make better decisions than the system itself based on an assessment of the information.
The system we have designed and implemented under this design guidelines is presented and discussed.
unrecognized in pediatric settings
The purpose of this paper is to describe the development and initial evaluation of a computer-based tool to help nurses screen for depression in children and teens by pediatric advanced practice nurse (APN) students.
Three aspects are described: selection of depression screening instrument; integration of the instrument into the PDA; and quantitative (usage) and qualitative (focus group) evaluation.
Only one third of eligible patients were screened.
Twenty percent of those screened were identified as prone to a mood disorder.
The barriers found in focus groups included a lack of time, knowledge, intervention protocol, referral resources, PDA usability issues, preceptor comfort and motivation, as well as cultural barriers people see as real.
Suggestions for educational, research, and interventions to integrate clinical based PDA-based screening are discussed.
This study explored the potential of the application of wireless and mobile computing technologies to be used in improving the efficiency of patient care and education and future developments in supporting healthcare professionals and students in medical research and education.
The design used for this study was a systematic review of published materials obtained from main medical databases, and the Cochrane Library database, including personal observations.
Over 50% of healthcare professionals and medical students are using Personal Digital Assistants, with a growth of over 75% by 2007.
In addition, wireless and mobile computing technologies allows Personal Digital Assistant to connect directly to networks or the Internet.
Studies relating to patient care and should evaluate mobile computing technologies as a potential timesaving tool.
Wireless and mobile computing technologies are starting to improve patient care and education.
They have shown a positive impact on patient safety, healthcare efficiency, and ultimately patient satisfaction.
Nursing students can learn many things through practical training by experiencing actual medical practice and by coming in contact with patients.
Therefore practical training is an effective learning opportunity for developing the skills of nursing students.
Moreover, at hospitals, which serve as training sites, with regard to medical safety, the use of learning tools that produce electrical waves is not possible.
So, we created a learning support environment that facilitates the imagination of nursing skills, and enables preparation and review at anytime and anywhere using a portable digital assistant (PDA) device for practical training.
As described in this paper, we report on the outline of the educational materials named "digital nursing dictionary" that we developed and its evaluation.
Limitation in display size and resolution on mobile devices is one of the main obstacles for wide-spread use of web applications in a wireless environment.
Web pages are often too large for a handheld computer screen to present.
The same problem exists for devices with low resolution such as WebTV.
Manual reconstruction of web pages for these devices would ease the problem; however, this will greatly increase the burden of web page designers since they have to customize a web page for each possible display device.
we propose a document segmentation system
The system automatically divides a web document into a number of logical segments based on the screen size and the structure and content of the document.
Additional information such as overviews and summaries is also extracted to facilitate navigation.
The system presents the segments to make the most of the screen's space for finding information.
Take 8-bit microcontroller (C8051F005) as the nucleus and study a kind of voltage harmonic monitor device that satisfies the long-range monitor.
The harmonic analysis algorithm uses a powerful technique.
This device has two work modes: ”native” and ”remote”.
It also can communicate with monitor center through telephone line, serial port, IC card, handheld devices.
With network and small screen device improvements, users can access information online from anywhere.
We are interested in studying the effect of users switching from a large computer screen, such as a desktop, to use the same web page on a small device, in this case a PDA (Personal Digital Assistant).
We discuss three common transformation approaches for display of web pages on the small screen: Direct Migration, Linear and Overview.
We introduce a new Overview method, called the Gateway, for use on the small screen that uses a user's knowledge of a web page.
The users in an initial study prefer using the Gateway and Direct Migration approach for web pages, despite the common Linear approach used by many websites.
The limitations and constraints of mobile systems should be addressed in software development.
We have been developing a taxonomy of risks based on SEI's risk assessment tool and applied it during the development of a negotiation support system for a Personal Digital Assistant (PDA).
In our planned research, we will explore how we can better integrate existing risk management strategies and Agile methods.
Expansions of mobile services and private data have required increased level of protection.
Speaker recognition, one of the biometric technologies, arises lots of research interests for its simple, cheap and convenient characteristics.
In this paper, a robust speaker recognition system which facilitates reliable authentication with multi-channel voices is presented.
A large collection of data from various devices, including phones and microphones to test the system.
This paper presents a method to generate unique and highly random pseudonyms in a distributed environment.
More precisely, each user can now generate his pseudonym locally in his security settings.
in his card or his personal assistant.
There is no need for any information interchange between issuing parties or global data (especially keys), a unique ID for each user and device.
The holder can prove, that he generated a specific pseudonym without revealing his identity and he can reveal his identity by disclosing the pseudonym.
The verifier of a disclosed pseudonym can be sure, that the presenter of the pseudonym is the actual owner of the pseudonym
Since no passage has been provided, there is nothing to revert.
The user's device and user ID will be used to create a unique pseudonym, which is encrypted to protect anonymity. The user's device and user's ID will be used to create a unique pseudonym, which is encrypted to protect anonymity.
In todayu0027s mobile information society, location services play an increasingly important role.
These services are to be accessed by users with a smartphone for the use of city maps, route planning, navigation, or traffic information.
Mobile end devices, however, do not have similar to a computer or laptop.
These deficits can be bypassed by employing special methods in development of the specific apps.
This paper outlines the experience gained in the development of a prototype for route computation in public transport networks to be used on a personal digital assistant.
Breaking down the process plays a significant role.
